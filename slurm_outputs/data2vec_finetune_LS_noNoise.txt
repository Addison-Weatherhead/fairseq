DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
[2024-04-23 21:28:36,558][HYDRA] Launching 1 jobs locally
[2024-04-23 21:28:36,558][HYDRA] 	#0 : distributed_training.distributed_world_size=4 +trainer.tensorboard_logdir=/h/addisonw/fairseq/logs/tb/ task.data=/h/addisonw/fairseq/manifests/finetuning_data10h model.w2v_path=/h/addisonw/fairseq/pretrained_models/base_libri.pt common.user_dir=examples/data2vec
[2024-04-23 21:28:36,561][HYDRA] Launching 1 jobs locally
[2024-04-23 21:28:36,561][HYDRA] 	#0 : distributed_training.distributed_world_size=4 +trainer.tensorboard_logdir=/h/addisonw/fairseq/logs/tb/ task.data=/h/addisonw/fairseq/manifests/finetuning_data10h model.w2v_path=/h/addisonw/fairseq/pretrained_models/base_libri.pt common.user_dir=examples/data2vec
[2024-04-23 21:28:36,564][HYDRA] Launching 1 jobs locally
[2024-04-23 21:28:36,564][HYDRA] 	#0 : distributed_training.distributed_world_size=4 +trainer.tensorboard_logdir=/h/addisonw/fairseq/logs/tb/ task.data=/h/addisonw/fairseq/manifests/finetuning_data10h model.w2v_path=/h/addisonw/fairseq/pretrained_models/base_libri.pt common.user_dir=examples/data2vec
[2024-04-23 21:28:36,644][HYDRA] Launching 1 jobs locally
[2024-04-23 21:28:36,645][HYDRA] 	#0 : distributed_training.distributed_world_size=4 +trainer.tensorboard_logdir=/h/addisonw/fairseq/logs/tb/ task.data=/h/addisonw/fairseq/manifests/finetuning_data10h model.w2v_path=/h/addisonw/fairseq/pretrained_models/base_libri.pt common.user_dir=examples/data2vec
HYDRA CONFIG:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': json, 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': legacy_ddp, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': '${dataset.grouped_shuffling}', 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'apply_mask': True, 'mask_prob': 0.75, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'layerdrop': 0.1, 'activation_dropout': 0.1, 'feature_grad_mult': 0.0, 'freeze_finetune_updates': 10000}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'normalize': True, 'labels': 'ltr', 'eval_wer': True}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2, 'wer_word_score': -1}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08}, 'lr_scheduler': {'_name': 'tri_stage', 'phase_ratio': [0.1, 0.4, 0.5], 'final_lr_scale': 0.05}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}}
[2024-04-23 21:28:39,371][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
HYDRA CONFIG:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': json, 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': legacy_ddp, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': '${dataset.grouped_shuffling}', 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'apply_mask': True, 'mask_prob': 0.75, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'layerdrop': 0.1, 'activation_dropout': 0.1, 'feature_grad_mult': 0.0, 'freeze_finetune_updates': 10000}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'normalize': True, 'labels': 'ltr', 'eval_wer': True}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2, 'wer_word_score': -1}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08}, 'lr_scheduler': {'_name': 'tri_stage', 'phase_ratio': [0.1, 0.4, 0.5], 'final_lr_scale': 0.05}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}}
[2024-04-23 21:28:39,377][fairseq.distributed.utils][INFO] - Rank 1, device_id: 1
[2024-04-23 21:28:39,378][fairseq.distributed.utils][INFO] - setting CUDA device=1 on rank 1
HYDRA CONFIG:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': json, 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': legacy_ddp, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': '${dataset.grouped_shuffling}', 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'apply_mask': True, 'mask_prob': 0.75, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'layerdrop': 0.1, 'activation_dropout': 0.1, 'feature_grad_mult': 0.0, 'freeze_finetune_updates': 10000}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'normalize': True, 'labels': 'ltr', 'eval_wer': True}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2, 'wer_word_score': -1}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08}, 'lr_scheduler': {'_name': 'tri_stage', 'phase_ratio': [0.1, 0.4, 0.5], 'final_lr_scale': 0.05}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}}
[2024-04-23 21:28:39,379][fairseq.distributed.utils][INFO] - Rank 2, device_id: 2
[2024-04-23 21:28:39,380][fairseq.distributed.utils][INFO] - setting CUDA device=2 on rank 2
HYDRA CONFIG:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': json, 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': legacy_ddp, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': '${dataset.grouped_shuffling}', 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'apply_mask': True, 'mask_prob': 0.75, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'layerdrop': 0.1, 'activation_dropout': 0.1, 'feature_grad_mult': 0.0, 'freeze_finetune_updates': 10000}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'normalize': True, 'labels': 'ltr', 'eval_wer': True}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2, 'wer_word_score': -1}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08}, 'lr_scheduler': {'_name': 'tri_stage', 'phase_ratio': [0.1, 0.4, 0.5], 'final_lr_scale': 0.05}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}}
[2024-04-23 21:28:39,428][fairseq.distributed.utils][INFO] - Rank 3, device_id: 3
[2024-04-23 21:28:39,429][fairseq.distributed.utils][INFO] - setting CUDA device=3 on rank 3
[2024-04-23 21:28:39,879][fairseq.distributed.utils][INFO] - distributed init (rank 1): tcp://localhost:26401
[2024-04-23 21:28:39,880][fairseq.distributed.utils][INFO] - distributed init (rank 3): tcp://localhost:26401
[2024-04-23 21:28:39,881][fairseq.distributed.utils][INFO] - distributed init (rank 2): tcp://localhost:26401
[2024-04-23 21:28:41,195][fairseq.distributed.utils][INFO] - distributed init (rank 0): tcp://localhost:26401
[2024-04-23 21:28:41,914][fairseq.distributed.utils][INFO] - initialized host gpu077.cluster.local as rank 1
[2024-04-23 21:28:41,914][fairseq.distributed.utils][INFO] - initialized host gpu077.cluster.local as rank 3
[2024-04-23 21:28:41,914][fairseq.distributed.utils][INFO] - initialized host gpu077.cluster.local as rank 0
[2024-04-23 21:28:41,914][fairseq.distributed.utils][INFO] - initialized host gpu077.cluster.local as rank 2
ENTERED MAIN
Python path: ['/fs01/home/addisonw/fairseq/fairseq_cli', '/h/addisonw/fairseq', '/fs01/home/addisonw/fairseq', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python38.zip', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/lib-dynload', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages']
[2024-04-23 21:28:47,444][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': 'json', 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:26401', 'distributed_port': 26401, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1280000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'labels': 'ltr', 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1, 'eval_wer': True, 'add_gaussian_train_noise': False, 'add_uniform_train_noise': False, 'eval_wer_config': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_wer_tokenizer': None, 'eval_wer_post_process': 'letter', 'eval_bleu': False, 'eval_bleu_detok': None, 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': '{}', 'eval_bleu_print_samples': False, 'autoregressive': False, 'target_dictionary': None}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 0, 'hold_steps': 0, 'decay_steps': 0, 'phase_ratio': [0.1, 0.4, 0.5], 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 20000.0, 'lr': [0.0001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
AA False
BB False
build model called with this config: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
[2024-04-23 21:28:47,497][fairseq.tasks.audio_finetuning][INFO] - Using dict_path : /h/addisonw/fairseq/manifests/finetuning_data10h/dict.ltr.txt
ENTERED MAIN
Python path: ['/fs01/home/addisonw/fairseq/fairseq_cli', '/h/addisonw/fairseq', '/fs01/home/addisonw/fairseq', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python38.zip', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/lib-dynload', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages']
AA False
BB False
build model called with this config: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
LOADING CHECKPOINT HERE!!!
path:  /h/addisonw/fairseq/pretrained_models/base_libri.pt
cfg: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
w2v_args:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['ema_decay', 'target_var', 'pred_var', 'model_norm', 'ema_norm', 'masked_pct'], 'rescale': 1.0, 'can_sum': True, 'log_ppl': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 8000, 'warmup_init_lr': -1.0, 'lr': [0.00075], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 400000}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
w2v_args NOW: 
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas'ENTERED MAIN
Python path: ['/fs01/home/addisonw/fairseq/fairseq_cli', '/h/addisonw/fairseq', '/fs01/home/addisonw/fairseq', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python38.zip', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/lib-dynload', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages']
AA False
BB False
build model called with this config: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
LOADING CHECKPOINT HERE!!!
path:  /h/addisonw/fairseq/pretrained_models/base_libri.pt
cfg: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
w2v_args:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['ema_decay', 'target_var', 'pred_var', 'model_norm', 'ema_norm', 'masked_pct'], 'rescale': 1.0, 'can_sum': True, 'log_ppl': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 8000, 'warmup_init_lr': -1.0, 'lr': [0.00075], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 400000}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'forENTERED MAIN
Python path: ['/fs01/home/addisonw/fairseq/fairseq_cli', '/h/addisonw/fairseq', '/fs01/home/addisonw/fairseq', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python38.zip', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/lib-dynload', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages']
AA False
BB False
build model called with this config: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
LOADING CHECKPOINT HERE!!!
path:  /h/addisonw/fairseq/pretrained_models/base_libri.pt
cfg: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
w2v_args:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['ema_decay', 'target_var', 'pred_var', 'model_norm', 'ema_norm', 'masked_pct'], 'rescale': 1.0, 'can_sum': True, 'log_ppl': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 8000, 'warmup_init_lr': -1.0, 'lr': [0.00075], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 400000}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
w2v_args NOW: 
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas'LOADING CHECKPOINT HERE!!!
path:  /h/addisonw/fairseq/pretrained_models/base_libri.pt
cfg: 
{'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': None, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}
w2v_args:
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['ema_decay', 'target_var', 'pred_var', 'model_norm', 'ema_norm', 'masked_pct'], 'rescale': 1.0, 'can_sum': True, 'log_ppl': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 8000, 'warmup_init_lr': -1.0, 'lr': [0.00075], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 400000}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
w2v_args NOW: 
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas'matter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-04-23 21:28:49,936][fairseq.models.wav2vec.wav2vec2_asr][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
w2v_args NOW: 
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
self.is_d2v_multi:  True
build model called with this config: 
{'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
[2024-04-23 21:28:53,328][data2vec.models.data2vec2][INFO] - making target model
: [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
self.is_d2v_multi:  True
build model called with this config: 
{'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
: [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
self.is_d2v_multi:  True
build model called with this config: 
{'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
: [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
self.is_d2v_multi:  True
build model called with this config: 
{'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
ADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
Data2VecMultiModel(
  (modality_encoders): ModuleDict(
    (AUDIO): AudioEncoder(
      (local_encoder): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
        )
      )
      (project_features): Sequential(
        (0): TransposeLast()
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=512, out_features=768, bias=True)
      )
      (relative_positional_encoder): Sequential(
        (0): TransposeLast()
        (1): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (4): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (5): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (6): TransposeLast()
      )
      (context_encoder): BlockEncoder(
        (blocks): ModuleList(
          (0-3): 4 x AltBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): AltAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.1, inplace=False)
            )
            (post_mlp_dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=True)
      )
      (decoder): None
    )
  )
  (dropout_input): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-7): 8 x AltBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): AltAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.1, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.1, inplace=False)
      )
      (post_mlp_dropout): Dropout(p=0.0, inplace=False)
    )
  )
)
load state dict config
None
again load state dict config
None
TASK NAME!!
AudioFinetuningTask
config passed in!
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': 'json', 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 2, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:26401', 'distributed_port': 26401, 'device_id': 2, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1280000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'labels': 'ltr', 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1, 'eval_wer': True, 'add_gaussian_train_noise': False, 'add_uniform_train_noise': False, 'eval_wer_config': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_wer_tokenizer': None, 'eval_wer_post_process': 'letter', 'eval_bleu': False, 'eval_bleu_detok': None, 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': '{}', 'eval_bleu_print_samples': False, 'autoregressive': False, 'target_dictionary': None}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 0, 'hold_steps': 0, 'decay_steps': 0, 'phase_ratio': [0.1, 0.4, 0.5], 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 20000.0, 'lr': [0.0001]}, 'scoring': NoData2VecMultiModel(
  (modality_encoders): ModuleDict(
    (AUDIO): AudioEncoder(
      (local_encoder): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
        )
      )
      (project_features): Sequential(
        (0): TransposeLast()
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=512, out_features=768, bias=True)
      )
      (relative_positional_encoder): Sequential(
        (0): TransposeLast()
        (1): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (4): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (5): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (6): TransposeLast()
      )
      (context_encoder): BlockEncoder(
        (blocks): ModuleList(
          (0-3): 4 x AltBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): AltAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.1, inplace=False)
            )
            (post_mlp_dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=True)
      )
      (decoder): None
    )
  )
  (dropout_input): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-7): 8 x AltBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): AltAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.1, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.1, inplace=False)
      )
      (post_mlp_dropout): Dropout(p=0.0, inplace=False)
    )
  )
)
load state dict config
None
again load state dict config
None
TASK NAME!!
AudioFinetuningTask
config passed in!
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': 'json', 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 3, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:26401', 'distributed_port': 26401, 'device_id': 3, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1280000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'labels': 'ltr', 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1, 'eval_wer': True, 'add_gaussian_train_noise': False, 'add_uniform_train_noise': False, 'eval_wer_config': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_wer_tokenizer': None, 'eval_wer_post_process': 'letter', 'eval_bleu': False, 'eval_bleu_detok': None, 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': '{}', 'eval_bleu_print_samples': False, 'autoregressive': False, 'target_dictionary': None}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 0, 'hold_steps': 0, 'decay_steps': 0, 'phase_ratio': [0.1, 0.4, 0.5], 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 20000.0, 'lr': [0.0001]}, 'scoring': NoData2VecMultiModel(
  (modality_encoders): ModuleDict(
    (AUDIO): AudioEncoder(
      (local_encoder): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
        )
      )
      (project_features): Sequential(
        (0): TransposeLast()
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=512, out_features=768, bias=True)
      )
      (relative_positional_encoder): Sequential(
        (0): TransposeLast()
        (1): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (4): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (5): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (6): TransposeLast()
      )
      (context_encoder): BlockEncoder(
        (blocks): ModuleList(
          (0-3): 4 x AltBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): AltAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.1, inplace=False)
            )
            (post_mlp_dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=True)
      )
      (decoder): None
    )
  )
  (dropout_input): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-7): 8 x AltBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): AltAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.1, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.1, inplace=False)
      )
      (post_mlp_dropout): Dropout(p=0.0, inplace=False)
    )
  )
)
load state dict config
None
again load state dict config
None
TASK NAME!!
AudioFinetuningTask
config passed in!
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': 'json', 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 1, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:26401', 'distributed_port': 26401, 'device_id': 1, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1280000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'labels': 'ltr', 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1, 'eval_wer': True, 'add_gaussian_train_noise': False, 'add_uniform_train_noise': False, 'eval_wer_config': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_wer_tokenizer': None, 'eval_wer_post_process': 'letter', 'eval_bleu': False, 'eval_bleu_detok': None, 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': '{}', 'eval_bleu_print_samples': False, 'autoregressive': False, 'target_dictionary': None}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 0, 'hold_steps': 0, 'decay_steps': 0, 'phase_ratio': [0.1, 0.4, 0.5], 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 20000.0, 'lr': [0.0001]}, 'scoring': NoADD GAUSSIAN NOISE TO TRAINING?:  True
ADD UNIFORM NOISE TO TRAINING?:  False
Data2VecMultiModel(
  (modality_encoders): ModuleDict(
    (AUDIO): AudioEncoder(
      (local_encoder): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
        )
      )
      (project_features): Sequential(
        (0): TransposeLast()
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=512, out_features=768, bias=True)
      )
      (relative_positional_encoder): Sequential(
        (0): TransposeLast()
        (1): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (4): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (5): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (6): TransposeLast()
      )
      (context_encoder): BlockEncoder(
        (blocks): ModuleList(
          (0-3): 4 x AltBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): AltAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.1, inplace=False)
            )
            (post_mlp_dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=True)
      )
      (decoder): None
    )
  )
  (dropout_input): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-7): 8 x AltBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): AltAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.1, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.1, inplace=False)
      )
      (post_mlp_dropout): Dropout(p=0.0, inplace=False)
    )
  )
)
load state dict config
None
again load state dict config
None
[2024-04-23 21:29:19,068][fairseq_cli.train][INFO] - Wav2VecCtc(
  (w2v_encoder): Wav2VecEncoder(
    (w2v_model): Data2VecMultiModel(
      (modality_encoders): ModuleDict(
        (AUDIO): AudioEncoder(
          (local_encoder): ConvFeatureExtractionModel(
            (conv_layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
                (1): Dropout(p=0.0, inplace=False)
                (2): Sequential(
                  (0): TransposeLast()
                  (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (2): TransposeLast()
                )
                (3): GELU(approximate='none')
              )
              (1-4): 4 x Sequential(
                (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
                (1): Dropout(p=0.0, inplace=False)
                (2): Sequential(
                  (0): TransposeLast()
                  (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (2): TransposeLast()
                )
                (3): GELU(approximate='none')
              )
              (5-6): 2 x Sequential(
                (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
                (1): Dropout(p=0.0, inplace=False)
                (2): Sequential(
                  (0): TransposeLast()
                  (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (2): TransposeLast()
                )
                (3): GELU(approximate='none')
              )
            )
          )
          (project_features): Sequential(
            (0): TransposeLast()
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): Linear(in_features=512, out_features=768, bias=True)
          )
          (relative_positional_encoder): Sequential(
            (0): TransposeLast()
            (1): Sequential(
              (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
              (1): SamePad()
              (2): TransposeLast()
              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
              (4): TransposeLast()
              (5): GELU(approximate='none')
            )
            (2): Sequential(
              (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
              (1): SamePad()
              (2): TransposeLast()
              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
              (4): TransposeLast()
              (5): GELU(approximate='none')
            )
            (3): Sequential(
              (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
              (1): SamePad()
              (2): TransposeLast()
              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
              (4): TransposeLast()
              (5): GELU(approximate='none')
            )
            (4): Sequential(
              (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
              (1): SamePad()
              (2): TransposeLast()
              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
              (4): TransposeLast()
              (5): GELU(approximate='none')
            )
            (5): Sequential(
              (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
              (1): SamePad()
              (2): TransposeLast()
              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
              (4): TransposeLast()
              (5): GELU(approximate='none')
            )
            (6): TransposeLast()
          )
          (context_encoder): BlockEncoder(
            (blocks): ModuleList(
              (0-3): 4 x AltBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): AltAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.1, inplace=False)
                  (norm): Identity()
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop2): Dropout(p=0.1, inplace=False)
                )
                (post_mlp_dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.0, inplace=True)
          )
          (decoder): None
        )
      )
      (dropout_input): Dropout(p=0.0, inplace=False)
      (blocks): ModuleList(
        (0-7): 8 x AltBlock(
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): AltAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.1, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.1, inplace=False)
          )
          (post_mlp_dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (final_dropout): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-04-23 21:29:19,274][fairseq_cli.train][INFO] - task: AudioFinetuningTask
[2024-04-23 21:29:19,275][fairseq_cli.train][INFO] - model: Wav2VecCtc
[2024-04-23 21:29:19,275][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-04-23 21:29:19,278][fairseq_cli.train][INFO] - num. shared model params: 93,188,140 (num. trained: 93,188,140)
[2024-04-23 21:29:19,289][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-04-23 21:29:19,311][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 32, skipped 0 samples
TASK NAME!!
AudioFinetuningTask
config passed in!
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': 'json', 'log_file': '/h/addisonw/fairseq/logs/noNoise/log.json', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:26401', 'distributed_port': 26401, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1280000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1280000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [5], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints/noNoise', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_ctc', 'w2v_path': '/h/addisonw/fairseq/pretrained_models/base_libri.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 64, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'drop_path': 0.0, 'mask_channel_min_space': 1, 'mask_channel_before': False, 'normalize': True, 'update_alibi': True, 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'w2v_args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/home/abaevski/fairseq-py/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://a100-st-p4d24xlarge-466:38089', 'distributed_port': 38089, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'fsdp_mp': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'cosine_loss_temp': 0.0, 'loss_beta': 0.0, 'loss_scale': None, 'mean_loss': False, 'reconstruct_all': False, 'depth': 8, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.0, 'post_mlp_drop': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'dropout_input': 0.0, 'layerdrop': 0.1, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': 400000, 'modalities': {'audio': {'type': 'AUDIO', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'final_layer_norm': False, 'tanh_scale': 0.0, 'project_first_residual': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0, 'residual_scale': 1.0, 'remove_residual_noise': False, 'post_residual_ln': False}, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False, 'mlp_encoder': False, 'mlp_n_in': 320, 'mlp_dim': None, 'mlp_layers': 9}, 'image': {'type': 'IMAGE', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'fix_masks': False, 'exact_mask_pct': False, 'unmask_focal': False, 'focal_length': 1, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'conv_pos_cfg': None, 'transformer_decoder': False, 'enc_dec_transformer': False, 'conv_mae': False, 'conv_mae_multiscale': True, 'conv_mae_masking': True}, 'text': {'type': 'TEXT', 'prenet_depth': 4, 'prenet_layerdrop': 0.1, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.75, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 10, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': False, 'mask_channel_prob': 0.25, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 0.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': 12, 'model_depth': 8, 'decoder': None, 'max_alibi_scale': 0.0, 'max_alibi_grad': 0.0, 'max_alibi_val': 0.0, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.0, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': 'AUDIO', 'mae_init': False, 'bert_init': True, 'seed': 1, 'skip_ema': False, 'cls_loss': 0.0, 'alt_cls_targets': False, 'recon_loss': 0.0, 'recon_dim': 0, 'd2v_loss': 1.0, 'qk_scale': None, 'cosine_attention': False, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/fsx-wav2vec/abaevski/data/librispeech', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 320000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': 'none', 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.75, 'mask_prob_adjust': 0.05, 'mask_length': 10, 'inverse_mask': False, 'clone_batch': 8}, 'post_save_script': None}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075], 'min_decay_val': 0.0}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'offload_activations': False, 'min_params_to_wrap': 100000000, 'checkpoint_activations': False, 'ddp_backend': 'legacy_ddp', 'zero_mask': False, 'load_ema': False, 'layer_decay': 1.0, 'layer_type': transformer, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all', 'freeze_regex': None, 'blank_weight': 0.0, 'blank_mode': 'add'}, 'task': {'_name': 'audio_finetuning', 'data': '/h/addisonw/fairseq/manifests/finetuning_data10h', 'labels': 'ltr', 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1, 'eval_wer': True, 'add_gaussian_train_noise': False, 'add_uniform_train_noise': False, 'eval_wer_config': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_wer_tokenizer': None, 'eval_wer_post_process': 'letter', 'eval_bleu': False, 'eval_bleu_detok': None, 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': '{}', 'eval_bleu_print_samples': False, 'autoregressive': False, 'target_dictionary': None}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': '/h/addisonw/fairseq/pretrained_models/kenlm/4-gram.bin', 'wer_lexicon': '/h/addisonw/fairseq/pretrained_models/kenlm/lexicon.txt', 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 0, 'hold_steps': 0, 'decay_steps': 0, 'phase_ratio': [0.1, 0.4, 0.5], 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 20000.0, 'lr': [0.0001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-04-23 21:29:21,453][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.0.bias
[2024-04-23 21:29:21,453][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.0.bias
[2024-04-23 21:29:21,453][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.0.bias
[2024-04-23 21:29:21,454][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.0.bias
[2024-04-23 21:29:21,454][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.0.bias
[2024-04-23 21:29:21,454][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.0.bias
[2024-04-23 21:29:21,454][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.3.weight
[2024-04-23 21:29:21,454][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.3.bias
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.3.weight
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.3.bias
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.3.weight
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.3.bias
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.3.weight
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.3.bias
[2024-04-23 21:29:21,455][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.3.weight
[2024-04-23 21:29:21,456][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- w2v_encoder.w2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.3.bias
[2024-04-23 21:29:21,861][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-04-23 21:29:21,861][fairseq.utils][INFO] - rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                
[2024-04-23 21:29:21,861][fairseq.utils][INFO] - rank   1: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                
[2024-04-23 21:29:21,861][fairseq.utils][INFO] - rank   2: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                
[2024-04-23 21:29:21,862][fairseq.utils][INFO] - rank   3: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                
[2024-04-23 21:29:21,862][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-04-23 21:29:21,862][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-04-23 21:29:21,863][fairseq_cli.train][INFO] - max tokens per device = 1280000 and max sentences per device = None
[2024-04-23 21:29:21,865][fairseq.trainer][INFO] - Preparing to load checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_last.pt
[2024-04-23 21:29:21,865][fairseq.trainer][INFO] - No existing checkpoint found /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_last.pt
[2024-04-23 21:29:21,865][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-04-23 21:29:21,876][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 2731, skipped 0 samples
[2024-04-23 21:29:21,982][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:29:21,983][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-04-23 21:29:21,983][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2024-04-23 21:29:21,984][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2024-04-23 21:29:21,984][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-04-23 21:29:22,804][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2024-04-23 21:29:22,811][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:29:22,812][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-04-23 21:29:22,813][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2024-04-23 21:29:22,813][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2024-04-23 21:29:22,813][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/h/addisonw/fairseq/fairseq/trainer.py:150: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845899/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
ne, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/h/addisonw/fairseq/fairseq/trainer.py:150: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845899/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
ne, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/h/addisonw/fairseq/fairseq/trainer.py:150: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845899/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
ne, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'trainer': {'tensorboard_logdir': '/h/addisonw/fairseq/logs/tb/'}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/h/addisonw/fairseq/fairseq/trainer.py:150: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845899/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
[2024-04-23 21:29:24,668][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:29:24,681][fairseq.trainer][INFO] - begin training epoch 1
[2024-04-23 21:29:24,682][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:29:35,637][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-04-23 21:29:38,006][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-04-23 21:29:40,233][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-04-23 21:29:42,141][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-04-23 21:29:44,351][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-04-23 21:30:18,216][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:30:18,218][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:30:18,304][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:30:20,791][valid][INFO] - {"epoch": 1, "valid_loss": "2531.08", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.261", "valid_uer": "118.602", "valid_wer": "101.981", "valid_raw_wer": "100", "valid_wps": "1445.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "20"}
[2024-04-23 21:30:20,791][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.981]
[2024-04-23 21:30:20,792][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:30:20,794][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:30:21,207][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:30:23,372][valid][INFO] - {"epoch": 1, "valid_loss": "2427.84", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.761", "valid_uer": "105.103", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1623.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "20"}
[2024-04-23 21:30:23,373][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.603]
[2024-04-23 21:30:23,373][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:30:23,375][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:30:23,940][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 4
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:30:26,059][valid][INFO] - {"epoch": 1, "valid_loss": "2486.96", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.047", "valid_uer": "112.708", "valid_wer": "101.464", "valid_raw_wer": "100", "valid_wps": "1715.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "20"}
[2024-04-23 21:30:26,060][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.464]
[2024-04-23 21:30:26,061][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-04-23 21:30:26,062][train][INFO] - {"epoch": 1, "train_loss": "2369.4", "train_ntokens": "20155", "train_nsentences": "107.7", "train_nll_loss": "12.661", "train_wps": "9590.2", "train_ups": "0.48", "train_wpb": "20155.1", "train_bsz": "107.7", "train_num_updates": "20", "train_lr": "1.99e-06", "train_gnorm": "1177.92", "train_loss_scale": "4", "train_train_wall": "52", "train_gb_free": "11.1", "train_wall": "64"}
[2024-04-23 21:30:26,065][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:30:26,696][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
[2024-04-23 21:30:26,819][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:30:26,833][fairseq.trainer][INFO] - begin training epoch 2
[2024-04-23 21:30:26,834][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:31:09,446][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:31:09,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:31:09,859][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 5
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:31:12,082][valid][INFO] - {"epoch": 2, "valid_loss": "2527.59", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.244", "valid_uer": "118.263", "valid_wer": "101.895", "valid_raw_wer": "100", "valid_wps": "1679.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "45"}
[2024-04-23 21:31:12,083][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.895]
[2024-04-23 21:31:12,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:31:12,085][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:31:12,551][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 6
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:31:14,669][valid][INFO] - {"epoch": 2, "valid_loss": "2418.55", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.716", "valid_uer": "104.44", "valid_wer": "100.947", "valid_raw_wer": "100", "valid_wps": "1693.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "45"}
[2024-04-23 21:31:14,670][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.947]
[2024-04-23 21:31:14,671][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:31:14,672][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:31:15,143][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 7
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:31:17,325][valid][INFO] - {"epoch": 2, "valid_loss": "2483.68", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.031", "valid_uer": "112.611", "valid_wer": "101.034", "valid_raw_wer": "100", "valid_wps": "1545.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "45"}
[2024-04-23 21:31:17,326][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.034]
[2024-04-23 21:31:17,326][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-04-23 21:31:17,327][train][INFO] - {"epoch": 2, "train_loss": "2354.13", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "12.629", "train_wps": "9912", "train_ups": "0.49", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "45", "train_lr": "3.2275e-06", "train_gnorm": "1185.53", "train_loss_scale": "4", "train_train_wall": "41", "train_gb_free": "10.6", "train_wall": "115"}
[2024-04-23 21:31:17,330][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:31:17,940][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
[2024-04-23 21:31:18,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:31:18,105][fairseq.trainer][INFO] - begin training epoch 3
[2024-04-23 21:31:18,106][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:31:27,697][train_inner][INFO] - {"epoch": 3, "update": 2.2, "loss": "2366.27", "ntokens": "20347.7", "nsentences": "108.68", "nll_loss": "12.639", "wps": "9818.8", "ups": "0.48", "wpb": "20347.7", "bsz": "108.7", "num_updates": "50", "lr": "3.475e-06", "gnorm": "1186.59", "loss_scale": "4", "train_wall": "102", "gb_free": "10.6", "wall": "126"}
[2024-04-23 21:31:59,131][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:31:59,133][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:31:59,519][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 8
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:01,835][valid][INFO] - {"epoch": 3, "valid_loss": "2523.52", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.224", "valid_uer": "118.246", "valid_wer": "101.723", "valid_raw_wer": "100", "valid_wps": "1462.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "70"}
[2024-04-23 21:32:01,837][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.723]
[2024-04-23 21:32:01,838][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:32:01,840][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:02,290][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 9
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:04,472][valid][INFO] - {"epoch": 3, "valid_loss": "2418.92", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.718", "valid_uer": "103.52", "valid_wer": "100.947", "valid_raw_wer": "100", "valid_wps": "1555.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "70"}
[2024-04-23 21:32:04,474][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.947]
[2024-04-23 21:32:04,474][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:32:04,476][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:04,943][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 10
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:07,090][valid][INFO] - {"epoch": 3, "valid_loss": "2479.43", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.011", "valid_uer": "112.902", "valid_wer": "101.809", "valid_raw_wer": "100", "valid_wps": "1677.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "70"}
[2024-04-23 21:32:07,090][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.809]
[2024-04-23 21:32:07,091][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-04-23 21:32:07,092][train][INFO] - {"epoch": 3, "train_loss": "2348.21", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "12.598", "train_wps": "10210.8", "train_ups": "0.5", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "70", "train_lr": "4.465e-06", "train_gnorm": "1221.52", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "10.6", "train_wall": "165"}
[2024-04-23 21:32:07,095][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:07,739][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 4
[2024-04-23 21:32:07,886][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:32:07,916][fairseq.trainer][INFO] - begin training epoch 4
[2024-04-23 21:32:07,926][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:32:49,964][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:32:49,966][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:50,438][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 11
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:52,545][valid][INFO] - {"epoch": 4, "valid_loss": "2517.68", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.196", "valid_uer": "118.117", "valid_wer": "101.895", "valid_raw_wer": "100", "valid_wps": "1839.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "95"}
[2024-04-23 21:32:52,546][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.895]
[2024-04-23 21:32:52,548][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:32:52,550][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:53,034][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 12
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:55,074][valid][INFO] - {"epoch": 4, "valid_loss": "2409.02", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.67", "valid_uer": "103.94", "valid_wer": "100.345", "valid_raw_wer": "100", "valid_wps": "1794.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "95"}
[2024-04-23 21:32:55,075][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.345]
[2024-04-23 21:32:55,075][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:32:55,078][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:55,587][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 13
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:32:57,855][valid][INFO] - {"epoch": 4, "valid_loss": "2471.18", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.971", "valid_uer": "112.11", "valid_wer": "101.55", "valid_raw_wer": "100", "valid_wps": "1518", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "95"}
[2024-04-23 21:32:57,856][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.55]
[2024-04-23 21:32:57,857][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-04-23 21:32:57,858][train][INFO] - {"epoch": 4, "train_loss": "2341.73", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "12.563", "train_wps": "10009.5", "train_ups": "0.49", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "95", "train_lr": "5.7025e-06", "train_gnorm": "1202.64", "train_loss_scale": "4", "train_train_wall": "41", "train_gb_free": "10.6", "train_wall": "216"}
[2024-04-23 21:32:57,861][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:32:58,468][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 5
[2024-04-23 21:32:58,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:32:58,607][fairseq.trainer][INFO] - begin training epoch 5
[2024-04-23 21:32:58,607][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:33:08,041][train_inner][INFO] - {"epoch": 5, "update": 4.2, "loss": "2331.77", "ntokens": "20303.6", "nsentences": "109.58", "nll_loss": "12.585", "wps": "10117.2", "ups": "0.5", "wpb": "20303.6", "bsz": "109.6", "num_updates": "100", "lr": "5.95e-06", "gnorm": "1198.74", "loss_scale": "4", "train_wall": "80", "gb_free": "10.5", "wall": "226"}
[2024-04-23 21:33:39,612][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:33:39,615][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:33:40,123][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 14
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:33:42,352][valid][INFO] - {"epoch": 5, "valid_loss": "2510.23", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.16", "valid_uer": "117.956", "valid_wer": "101.55", "valid_raw_wer": "100", "valid_wps": "1596.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "120"}
[2024-04-23 21:33:42,353][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.55]
[2024-04-23 21:33:42,353][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:33:42,355][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:33:42,731][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 15
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:33:44,918][valid][INFO] - {"epoch": 5, "valid_loss": "2392.05", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.588", "valid_uer": "103.31", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1685.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "120"}
[2024-04-23 21:33:44,920][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.603]
[2024-04-23 21:33:44,920][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:33:44,922][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:33:45,359][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 16
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:33:47,514][valid][INFO] - {"epoch": 5, "valid_loss": "2463.08", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.932", "valid_uer": "111.481", "valid_wer": "101.292", "valid_raw_wer": "100", "valid_wps": "1639.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "120"}
[2024-04-23 21:33:47,515][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.292]
[2024-04-23 21:33:47,518][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 120 updates
[2024-04-23 21:33:47,521][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:33:51,776][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:33:56,039][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt (epoch 5 @ 120 updates, score 101.55) (writing took 8.520466835005209 seconds)
[2024-04-23 21:33:56,040][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-04-23 21:33:56,041][train][INFO] - {"epoch": 5, "train_loss": "2333.75", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "12.52", "train_wps": "8733.5", "train_ups": "0.43", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "120", "train_lr": "6.94e-06", "train_gnorm": "1245.17", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "9.8", "train_wall": "274"}
[2024-04-23 21:33:56,045][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:33:56,434][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 6
[2024-04-23 21:33:56,509][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:33:56,521][fairseq.trainer][INFO] - begin training epoch 6
[2024-04-23 21:33:56,521][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:34:36,452][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:34:36,455][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:34:36,995][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 17
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:34:39,135][valid][INFO] - {"epoch": 6, "valid_loss": "2501.14", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.116", "valid_uer": "117.73", "valid_wer": "101.723", "valid_raw_wer": "100", "valid_wps": "1753.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "145", "valid_best_wer": "101.55"}
[2024-04-23 21:34:39,137][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.723]
[2024-04-23 21:34:39,138][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:34:39,139][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:34:39,579][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 18
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:34:41,629][valid][INFO] - {"epoch": 6, "valid_loss": "2370.47", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.483", "valid_uer": "102.89", "valid_wer": "100.689", "valid_raw_wer": "100", "valid_wps": "1714.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "145", "valid_best_wer": "100.689"}
[2024-04-23 21:34:41,630][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.689]
[2024-04-23 21:34:41,631][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:34:41,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:34:41,687][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 19
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:34:44,197][valid][INFO] - {"epoch": 6, "valid_loss": "2452.5", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.88", "valid_uer": "111.109", "valid_wer": "101.12", "valid_raw_wer": "100", "valid_wps": "1443.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "145", "valid_best_wer": "101.12"}
[2024-04-23 21:34:44,199][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.12]
[2024-04-23 21:34:44,199][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-04-23 21:34:44,200][train][INFO] - {"epoch": 6, "train_loss": "2323.63", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "12.466", "train_wps": "10551.3", "train_ups": "0.52", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "145", "train_lr": "8.1775e-06", "train_gnorm": "1246.9", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "322"}
[2024-04-23 21:34:44,204][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:34:44,903][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 7
[2024-04-23 21:34:44,996][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:34:45,011][fairseq.trainer][INFO] - begin training epoch 7
[2024-04-23 21:34:45,012][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:34:54,535][train_inner][INFO] - {"epoch": 7, "update": 6.2, "loss": "2321.32", "ntokens": "20336.8", "nsentences": "109.22", "nll_loss": "12.467", "wps": "9548.5", "ups": "0.47", "wpb": "20336.8", "bsz": "109.2", "num_updates": "150", "lr": "8.425e-06", "gnorm": "1259.14", "loss_scale": "4", "train_wall": "79", "gb_free": "9.7", "wall": "333"}
[2024-04-23 21:35:26,164][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:35:26,166][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:35:26,687][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 20
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:35:28,884][valid][INFO] - {"epoch": 7, "valid_loss": "2491.2", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.068", "valid_uer": "117.294", "valid_wer": "102.498", "valid_raw_wer": "100", "valid_wps": "1678.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "170", "valid_best_wer": "101.55"}
[2024-04-23 21:35:28,886][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [102.498]
[2024-04-23 21:35:28,886][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:35:28,888][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:35:29,336][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 21
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:35:31,476][valid][INFO] - {"epoch": 7, "valid_loss": "2361.21", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.438", "valid_uer": "103.342", "valid_wer": "100.689", "valid_raw_wer": "100", "valid_wps": "1691.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "170", "valid_best_wer": "100.689"}
[2024-04-23 21:35:31,477][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.689]
[2024-04-23 21:35:31,478][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:35:31,480][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:35:31,939][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 22
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:35:34,085][valid][INFO] - {"epoch": 7, "valid_loss": "2441.77", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.828", "valid_uer": "110.27", "valid_wer": "101.895", "valid_raw_wer": "100", "valid_wps": "1671.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "170", "valid_best_wer": "101.55"}
[2024-04-23 21:35:34,086][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.895]
[2024-04-23 21:35:34,087][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-04-23 21:35:34,088][train][INFO] - {"epoch": 7, "train_loss": "2310.07", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "12.393", "train_wps": "10185.8", "train_ups": "0.5", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "170", "train_lr": "9.415e-06", "train_gnorm": "1250.69", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "9.7", "train_wall": "372"}
[2024-04-23 21:35:34,091][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:35:34,751][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 8
[2024-04-23 21:35:34,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:35:34,891][fairseq.trainer][INFO] - begin training epoch 8
[2024-04-23 21:35:34,892][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:36:15,290][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:36:15,296][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:36:15,372][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 23
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:36:17,975][valid][INFO] - {"epoch": 8, "valid_loss": "2479.1", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "12.009", "valid_uer": "116.761", "valid_wer": "101.378", "valid_raw_wer": "100", "valid_wps": "1363.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "195", "valid_best_wer": "101.378"}
[2024-04-23 21:36:17,977][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.378]
[2024-04-23 21:36:17,977][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:36:17,979][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:36:18,415][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 24
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:36:20,566][valid][INFO] - {"epoch": 8, "valid_loss": "2336.62", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.319", "valid_uer": "101.857", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1687.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "195", "valid_best_wer": "100.431"}
[2024-04-23 21:36:20,568][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.431]
[2024-04-23 21:36:20,569][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:36:20,570][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:36:20,987][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 25
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:36:23,280][valid][INFO] - {"epoch": 8, "valid_loss": "2430.51", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.774", "valid_uer": "110.237", "valid_wer": "101.55", "valid_raw_wer": "100", "valid_wps": "1531.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "195", "valid_best_wer": "101.55"}
[2024-04-23 21:36:23,281][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.55]
[2024-04-23 21:36:23,281][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-04-23 21:36:23,282][train][INFO] - {"epoch": 8, "train_loss": "2298.41", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "12.33", "train_wps": "10329.4", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "195", "train_lr": "1.06525e-05", "train_gnorm": "1280.21", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "421"}
[2024-04-23 21:36:23,286][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:36:23,923][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 9
[2024-04-23 21:36:24,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:36:24,092][fairseq.trainer][INFO] - begin training epoch 9
[2024-04-23 21:36:24,092][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:36:32,924][train_inner][INFO] - {"epoch": 9, "update": 8.2, "loss": "2312.2", "ntokens": "20278.7", "nsentences": "108.38", "nll_loss": "12.358", "wps": "10305.5", "ups": "0.51", "wpb": "20278.7", "bsz": "108.4", "num_updates": "200", "lr": "1.09e-05", "gnorm": "1261.95", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "431"}
[2024-04-23 21:37:04,559][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:04,561][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:04,983][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 26
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:37:07,332][valid][INFO] - {"epoch": 9, "valid_loss": "2465.79", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.945", "valid_uer": "116.535", "valid_wer": "101.55", "valid_raw_wer": "100", "valid_wps": "1513.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "220", "valid_best_wer": "101.55"}
[2024-04-23 21:37:07,334][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.55]
[2024-04-23 21:37:07,335][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:07,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:07,739][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 27
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:37:09,930][valid][INFO] - {"epoch": 9, "valid_loss": "2310.6", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.193", "valid_uer": "100.404", "valid_wer": "100.345", "valid_raw_wer": "99.914", "valid_wps": "1636", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "220", "valid_best_wer": "100.345"}
[2024-04-23 21:37:09,931][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.345]
[2024-04-23 21:37:09,932][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:09,934][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:10,383][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 28
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:37:12,558][valid][INFO] - {"epoch": 9, "valid_loss": "2415.8", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.703", "valid_uer": "109.414", "valid_wer": "101.206", "valid_raw_wer": "100", "valid_wps": "1727.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "220", "valid_best_wer": "101.206"}
[2024-04-23 21:37:12,560][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.206]
[2024-04-23 21:37:12,560][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-04-23 21:37:12,561][train][INFO] - {"epoch": 9, "train_loss": "2281.38", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "12.239", "train_wps": "10311.6", "train_ups": "0.51", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "220", "train_lr": "1.189e-05", "train_gnorm": "1273.01", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "471"}
[2024-04-23 21:37:12,565][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:13,220][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 10
[2024-04-23 21:37:13,362][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:37:13,397][fairseq.trainer][INFO] - begin training epoch 10
[2024-04-23 21:37:13,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:37:53,820][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:53,822][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:54,280][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 29
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:37:56,514][valid][INFO] - {"epoch": 10, "valid_loss": "2450.49", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.871", "valid_uer": "116.083", "valid_wer": "101.206", "valid_raw_wer": "100", "valid_wps": "1644", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "245", "valid_best_wer": "101.206"}
[2024-04-23 21:37:56,515][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.206]
[2024-04-23 21:37:56,516][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:56,518][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:56,688][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 30
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:37:59,035][valid][INFO] - {"epoch": 10, "valid_loss": "2278.53", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.038", "valid_uer": "100.016", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1475.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "245", "valid_best_wer": "100.431"}
[2024-04-23 21:37:59,037][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.431]
[2024-04-23 21:37:59,038][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:37:59,040][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:37:59,112][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 31
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:38:01,668][valid][INFO] - {"epoch": 10, "valid_loss": "2399.41", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.623", "valid_uer": "108.962", "valid_wer": "100.775", "valid_raw_wer": "100", "valid_wps": "1347.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "245", "valid_best_wer": "100.775"}
[2024-04-23 21:38:01,669][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.775]
[2024-04-23 21:38:01,672][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 245 updates
[2024-04-23 21:38:01,675][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:38:05,945][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:38:10,168][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt (epoch 10 @ 245 updates, score 101.206) (writing took 8.495563531061634 seconds)
[2024-04-23 21:38:10,168][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-04-23 21:38:10,169][train][INFO] - {"epoch": 10, "train_loss": "2256.94", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "12.108", "train_wps": "8820.7", "train_ups": "0.43", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "245", "train_lr": "1.31275e-05", "train_gnorm": "1354.57", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "528"}
[2024-04-23 21:38:10,174][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:38:10,224][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 11
[2024-04-23 21:38:10,284][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:38:10,296][fairseq.trainer][INFO] - begin training epoch 11
[2024-04-23 21:38:10,297][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:38:18,619][train_inner][INFO] - {"epoch": 11, "update": 10.2, "loss": "2269.68", "ntokens": "20360.4", "nsentences": "108.92", "nll_loss": "12.142", "wps": "9631.9", "ups": "0.47", "wpb": "20360.4", "bsz": "108.9", "num_updates": "250", "lr": "1.3375e-05", "gnorm": "1331.6", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "537"}
[2024-04-23 21:38:49,340][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:38:49,342][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:38:49,787][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 32
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:38:52,057][valid][INFO] - {"epoch": 11, "valid_loss": "2434.35", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.792", "valid_uer": "115.324", "valid_wer": "101.895", "valid_raw_wer": "100", "valid_wps": "1595.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "270", "valid_best_wer": "101.206"}
[2024-04-23 21:38:52,059][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.895]
[2024-04-23 21:38:52,059][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:38:52,061][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:38:52,523][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 33
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:38:54,760][valid][INFO] - {"epoch": 11, "valid_loss": "2247.68", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.888", "valid_uer": "97.933", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1592.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "270", "valid_best_wer": "100.603"}
[2024-04-23 21:38:54,761][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.603]
[2024-04-23 21:38:54,761][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:38:54,764][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:38:55,195][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 34
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:38:57,443][valid][INFO] - {"epoch": 11, "valid_loss": "2380.43", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.531", "valid_uer": "108.38", "valid_wer": "101.034", "valid_raw_wer": "100", "valid_wps": "1558.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "270", "valid_best_wer": "101.034"}
[2024-04-23 21:38:57,444][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [101.034]
[2024-04-23 21:38:57,444][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-04-23 21:38:57,445][train][INFO] - {"epoch": 11, "train_loss": "2240.75", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "12.021", "train_wps": "10748.8", "train_ups": "0.53", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "270", "train_lr": "1.4365e-05", "train_gnorm": "1351.36", "train_loss_scale": "4", "train_train_wall": "38", "train_gb_free": "9.8", "train_wall": "576"}
[2024-04-23 21:38:57,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:38:58,024][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 12
[2024-04-23 21:38:58,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:38:58,152][fairseq.trainer][INFO] - begin training epoch 12
[2024-04-23 21:38:58,159][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:39:38,403][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:39:38,406][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:39:38,535][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 35
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:39:41,084][valid][INFO] - {"epoch": 12, "valid_loss": "2416.61", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.706", "valid_uer": "114.387", "valid_wer": "101.464", "valid_raw_wer": "100", "valid_wps": "1392.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "295", "valid_best_wer": "101.206"}
[2024-04-23 21:39:41,085][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.464]
[2024-04-23 21:39:41,086][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:39:41,088][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:39:41,463][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 36
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:39:43,636][valid][INFO] - {"epoch": 12, "valid_loss": "2220.36", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.756", "valid_uer": "97.675", "valid_wer": "100.517", "valid_raw_wer": "100", "valid_wps": "1665", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "295", "valid_best_wer": "100.517"}
[2024-04-23 21:39:43,638][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.517]
[2024-04-23 21:39:43,638][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:39:43,641][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:39:44,141][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 37
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:39:46,288][valid][INFO] - {"epoch": 12, "valid_loss": "2359.31", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.429", "valid_uer": "107.412", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1653.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "295", "valid_best_wer": "100.603"}
[2024-04-23 21:39:46,289][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.603]
[2024-04-23 21:39:46,290][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-04-23 21:39:46,291][train][INFO] - {"epoch": 12, "train_loss": "2220.33", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "11.911", "train_wps": "10403.2", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "295", "train_lr": "1.56025e-05", "train_gnorm": "1344.08", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "624"}
[2024-04-23 21:39:46,295][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:39:46,911][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 13
[2024-04-23 21:39:47,017][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:39:47,046][fairseq.trainer][INFO] - begin training epoch 13
[2024-04-23 21:39:47,060][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:39:56,235][train_inner][INFO] - {"epoch": 13, "update": 12.2, "loss": "2225.61", "ntokens": "20332.7", "nsentences": "109.06", "nll_loss": "11.938", "wps": "10416.7", "ups": "0.51", "wpb": "20332.7", "bsz": "109.1", "num_updates": "300", "lr": "1.585e-05", "gnorm": "1354.75", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "634"}
[2024-04-23 21:40:26,807][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:40:26,810][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:40:27,307][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 38
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:40:29,489][valid][INFO] - {"epoch": 13, "valid_loss": "2397.22", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.613", "valid_uer": "113.435", "valid_wer": "101.723", "valid_raw_wer": "100", "valid_wps": "1745.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "320", "valid_best_wer": "101.206"}
[2024-04-23 21:40:29,490][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.723]
[2024-04-23 21:40:29,491][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:40:29,493][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:40:29,998][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 39
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:40:32,115][valid][INFO] - {"epoch": 13, "valid_loss": "2184.3", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.581", "valid_uer": "95.979", "valid_wer": "100.345", "valid_raw_wer": "100", "valid_wps": "1746.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "320", "valid_best_wer": "100.345"}
[2024-04-23 21:40:32,117][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.345]
[2024-04-23 21:40:32,117][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:40:32,119][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:40:32,294][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 40
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:40:34,534][valid][INFO] - {"epoch": 13, "valid_loss": "2339.4", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.332", "valid_uer": "105.991", "valid_wer": "100.861", "valid_raw_wer": "100", "valid_wps": "1678.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "320", "valid_best_wer": "100.861"}
[2024-04-23 21:40:34,536][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.861]
[2024-04-23 21:40:34,536][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-04-23 21:40:34,537][train][INFO] - {"epoch": 13, "train_loss": "2192.1", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "11.76", "train_wps": "10532.5", "train_ups": "0.52", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "320", "train_lr": "1.684e-05", "train_gnorm": "1391.05", "train_loss_scale": "4", "train_train_wall": "38", "train_gb_free": "9.7", "train_wall": "673"}
[2024-04-23 21:40:34,541][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:40:34,614][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 14
[2024-04-23 21:40:34,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:40:34,748][fairseq.trainer][INFO] - begin training epoch 14
[2024-04-23 21:40:34,763][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:41:15,665][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:41:15,668][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:41:16,145][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 41
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:41:18,469][valid][INFO] - {"epoch": 14, "valid_loss": "2375.99", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.51", "valid_uer": "112.175", "valid_wer": "101.55", "valid_raw_wer": "100", "valid_wps": "1530", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "345", "valid_best_wer": "101.206"}
[2024-04-23 21:41:18,470][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.55]
[2024-04-23 21:41:18,471][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:41:18,473][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:41:18,951][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 42
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:41:21,153][valid][INFO] - {"epoch": 14, "valid_loss": "2144.9", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.39", "valid_uer": "95.188", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1628.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "345", "valid_best_wer": "100.431"}
[2024-04-23 21:41:21,155][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.431]
[2024-04-23 21:41:21,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:41:21,157][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:41:21,617][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 43
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:41:23,852][valid][INFO] - {"epoch": 14, "valid_loss": "2315.92", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.219", "valid_uer": "104.78", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1574.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "345", "valid_best_wer": "100.603"}
[2024-04-23 21:41:23,854][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.603]
[2024-04-23 21:41:23,854][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-04-23 21:41:23,855][train][INFO] - {"epoch": 14, "train_loss": "2165.63", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "11.618", "train_wps": "10303.5", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "345", "train_lr": "1.80775e-05", "train_gnorm": "1395.7", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "9.8", "train_wall": "722"}
[2024-04-23 21:41:23,859][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:41:24,634][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 15
[2024-04-23 21:41:24,772][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:41:24,796][fairseq.trainer][INFO] - begin training epoch 15
[2024-04-23 21:41:24,814][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:41:33,974][train_inner][INFO] - {"epoch": 15, "update": 14.2, "loss": "2169.29", "ntokens": "20358.9", "nsentences": "109.36", "nll_loss": "11.653", "wps": "10415.1", "ups": "0.51", "wpb": "20358.9", "bsz": "109.4", "num_updates": "350", "lr": "1.8325e-05", "gnorm": "1387.92", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "732"}
[2024-04-23 21:42:04,764][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:42:04,766][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:05,255][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 44
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:42:07,560][valid][INFO] - {"epoch": 15, "valid_loss": "2354.02", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.403", "valid_uer": "111.319", "valid_wer": "101.809", "valid_raw_wer": "100", "valid_wps": "1595", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "370", "valid_best_wer": "101.206"}
[2024-04-23 21:42:07,562][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.809]
[2024-04-23 21:42:07,563][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:42:07,565][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:07,999][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 45
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:42:10,135][valid][INFO] - {"epoch": 15, "valid_loss": "2106.6", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.205", "valid_uer": "92.427", "valid_wer": "100.258", "valid_raw_wer": "99.828", "valid_wps": "1763.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "370", "valid_best_wer": "100.258"}
[2024-04-23 21:42:10,137][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.258]
[2024-04-23 21:42:10,137][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:42:10,139][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:10,583][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 46
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:42:12,794][valid][INFO] - {"epoch": 15, "valid_loss": "2293.02", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.108", "valid_uer": "103.52", "valid_wer": "100.689", "valid_raw_wer": "100", "valid_wps": "1635.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "370", "valid_best_wer": "100.689"}
[2024-04-23 21:42:12,795][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.689]
[2024-04-23 21:42:12,798][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 370 updates
[2024-04-23 21:42:12,800][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_last.pt
[2024-04-23 21:42:16,534][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_last.pt
[2024-04-23 21:42:16,596][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_last.pt (epoch 15 @ 370 updates, score 101.809) (writing took 3.7979641060810536 seconds)
[2024-04-23 21:42:16,596][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-04-23 21:42:16,597][train][INFO] - {"epoch": 15, "train_loss": "2136.52", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "11.462", "train_wps": "9634.5", "train_ups": "0.47", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "370", "train_lr": "1.9315e-05", "train_gnorm": "1363.73", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "775"}
[2024-04-23 21:42:16,602][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:17,043][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 16
[2024-04-23 21:42:17,123][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:42:17,135][fairseq.trainer][INFO] - begin training epoch 16
[2024-04-23 21:42:17,135][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:42:56,783][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:42:56,785][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:56,914][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 47
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:42:59,455][valid][INFO] - {"epoch": 16, "valid_loss": "2330.48", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.289", "valid_uer": "109.801", "valid_wer": "101.034", "valid_raw_wer": "100", "valid_wps": "1393.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "395", "valid_best_wer": "101.034"}
[2024-04-23 21:42:59,456][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [101.034]
[2024-04-23 21:42:59,457][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:42:59,459][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:42:59,891][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 48
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:43:02,026][valid][INFO] - {"epoch": 16, "valid_loss": "2065.2", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.004", "valid_uer": "90.78", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1751.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "395", "valid_best_wer": "100.431"}
[2024-04-23 21:43:02,027][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.431]
[2024-04-23 21:43:02,028][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:43:02,030][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:02,104][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 49
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:43:04,706][valid][INFO] - {"epoch": 16, "valid_loss": "2264.19", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.968", "valid_uer": "101.97", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1346.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "395", "valid_best_wer": "100.431"}
[2024-04-23 21:43:04,707][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.431]
[2024-04-23 21:43:04,708][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-04-23 21:43:04,709][train][INFO] - {"epoch": 16, "train_loss": "2105.38", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "11.295", "train_wps": "10562.1", "train_ups": "0.52", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "395", "train_lr": "2.05525e-05", "train_gnorm": "1368.58", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "823"}
[2024-04-23 21:43:04,713][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:04,789][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 17
[2024-04-23 21:43:04,914][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:43:04,924][fairseq.trainer][INFO] - begin training epoch 17
[2024-04-23 21:43:04,939][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:43:15,018][train_inner][INFO] - {"epoch": 17, "update": 16.2, "loss": "2124.56", "ntokens": "20283", "nsentences": "108.38", "nll_loss": "11.352", "wps": "10039.7", "ups": "0.49", "wpb": "20283", "bsz": "108.4", "num_updates": "400", "lr": "2.08e-05", "gnorm": "1377.75", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "833"}
[2024-04-23 21:43:45,660][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:43:45,663][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:46,151][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 50
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:43:48,461][valid][INFO] - {"epoch": 17, "valid_loss": "2304.19", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.162", "valid_uer": "107.848", "valid_wer": "100.947", "valid_raw_wer": "100", "valid_wps": "1600.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "420", "valid_best_wer": "100.947"}
[2024-04-23 21:43:48,463][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.947]
[2024-04-23 21:43:48,463][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:43:48,465][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:48,851][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 51
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:43:51,158][valid][INFO] - {"epoch": 17, "valid_loss": "2019.27", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.782", "valid_uer": "89.601", "valid_wer": "100.258", "valid_raw_wer": "99.914", "valid_wps": "1502.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "420", "valid_best_wer": "100.258"}
[2024-04-23 21:43:51,161][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.258]
[2024-04-23 21:43:51,161][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:43:51,163][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:51,673][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 52
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:43:53,872][valid][INFO] - {"epoch": 17, "valid_loss": "2236.25", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.833", "valid_uer": "100.92", "valid_wer": "100.258", "valid_raw_wer": "100", "valid_wps": "1637.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "420", "valid_best_wer": "100.258"}
[2024-04-23 21:43:53,874][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.258]
[2024-04-23 21:43:53,874][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-04-23 21:43:53,875][train][INFO] - {"epoch": 17, "train_loss": "2067.24", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "11.09", "train_wps": "10335.3", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "420", "train_lr": "2.179e-05", "train_gnorm": "1428.75", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "9.9", "train_wall": "872"}
[2024-04-23 21:43:53,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:43:54,459][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 18
[2024-04-23 21:43:54,578][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:43:54,602][fairseq.trainer][INFO] - begin training epoch 18
[2024-04-23 21:43:54,603][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:44:35,095][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:44:35,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:44:35,578][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 53
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:44:37,944][valid][INFO] - {"epoch": 18, "valid_loss": "2277.03", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "11.03", "valid_uer": "106.507", "valid_wer": "100.861", "valid_raw_wer": "100", "valid_wps": "1535.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "445", "valid_best_wer": "100.861"}
[2024-04-23 21:44:37,946][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.861]
[2024-04-23 21:44:37,946][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:44:37,948][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:44:38,403][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 54
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:44:40,694][valid][INFO] - {"epoch": 18, "valid_loss": "1980.82", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.595", "valid_uer": "88.035", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1534.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "445", "valid_best_wer": "100"}
[2024-04-23 21:44:40,695][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:44:40,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:44:40,698][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:44:41,183][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 55
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:44:43,307][valid][INFO] - {"epoch": 18, "valid_loss": "2207.76", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.695", "valid_uer": "99.047", "valid_wer": "100.345", "valid_raw_wer": "100", "valid_wps": "1756.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "445", "valid_best_wer": "100.345"}
[2024-04-23 21:44:43,310][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.345]
[2024-04-23 21:44:43,311][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-04-23 21:44:43,312][train][INFO] - {"epoch": 18, "train_loss": "2044.73", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "10.969", "train_wps": "10278.7", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "445", "train_lr": "2.30275e-05", "train_gnorm": "1372.48", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "921"}
[2024-04-23 21:44:43,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:44:43,946][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 19
[2024-04-23 21:44:44,100][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:44:44,114][fairseq.trainer][INFO] - begin training epoch 19
[2024-04-23 21:44:44,127][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:44:53,491][train_inner][INFO] - {"epoch": 19, "update": 18.2, "loss": "2049.85", "ntokens": "20317.2", "nsentences": "109.22", "nll_loss": "11.019", "wps": "10319.3", "ups": "0.51", "wpb": "20317.2", "bsz": "109.2", "num_updates": "450", "lr": "2.3275e-05", "gnorm": "1380.6", "loss_scale": "4", "train_wall": "78", "gb_free": "9.8", "wall": "932"}
[2024-04-23 21:45:24,639][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:45:24,641][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:45:24,701][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 56
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:45:27,407][valid][INFO] - {"epoch": 19, "valid_loss": "2249.45", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.897", "valid_uer": "104.521", "valid_wer": "100.431", "valid_raw_wer": "100", "valid_wps": "1317.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "470", "valid_best_wer": "100.431"}
[2024-04-23 21:45:27,409][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.431]
[2024-04-23 21:45:27,410][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:45:27,412][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:45:27,895][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 57
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:45:30,111][valid][INFO] - {"epoch": 19, "valid_loss": "1938.29", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.389", "valid_uer": "86.501", "valid_wer": "100.086", "valid_raw_wer": "99.914", "valid_wps": "1636.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "470", "valid_best_wer": "100.086"}
[2024-04-23 21:45:30,112][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.086]
[2024-04-23 21:45:30,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:45:30,115][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:45:30,606][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 58
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:45:32,890][valid][INFO] - {"epoch": 19, "valid_loss": "2176.68", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.544", "valid_uer": "97.465", "valid_wer": "100.086", "valid_raw_wer": "100", "valid_wps": "1522.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "470", "valid_best_wer": "100.086"}
[2024-04-23 21:45:32,892][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.086]
[2024-04-23 21:45:32,893][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-04-23 21:45:32,894][train][INFO] - {"epoch": 19, "train_loss": "2017.97", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "10.826", "train_wps": "10248.7", "train_ups": "0.5", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "470", "train_lr": "2.4265e-05", "train_gnorm": "1285.55", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "971"}
[2024-04-23 21:45:32,898][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:45:33,519][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 20
[2024-04-23 21:45:33,632][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:45:33,647][fairseq.trainer][INFO] - begin training epoch 20
[2024-04-23 21:45:33,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:46:14,203][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:46:14,205][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:46:14,263][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 59
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:46:17,041][valid][INFO] - {"epoch": 20, "valid_loss": "2220.15", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.755", "valid_uer": "102.374", "valid_wer": "100.775", "valid_raw_wer": "100", "valid_wps": "1273.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "495", "valid_best_wer": "100.775"}
[2024-04-23 21:46:17,044][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.775]
[2024-04-23 21:46:17,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:46:17,046][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:46:17,435][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 60
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:46:19,700][valid][INFO] - {"epoch": 20, "valid_loss": "1883.26", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.123", "valid_uer": "84.918", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1596", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "495", "valid_best_wer": "100"}
[2024-04-23 21:46:19,702][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:46:19,702][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:46:19,704][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:46:19,813][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 61
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:46:22,393][valid][INFO] - {"epoch": 20, "valid_loss": "2143.59", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.384", "valid_uer": "95.317", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1348.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "495", "valid_best_wer": "100"}
[2024-04-23 21:46:22,396][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:46:22,398][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 495 updates
[2024-04-23 21:46:22,401][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:46:26,360][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:46:30,463][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt (epoch 20 @ 495 updates, score 100.775) (writing took 8.064572121948004 seconds)
[2024-04-23 21:46:30,464][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-04-23 21:46:30,465][train][INFO] - {"epoch": 20, "train_loss": "1962.53", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "10.528", "train_wps": "8826.5", "train_ups": "0.43", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "495", "train_lr": "2.55025e-05", "train_gnorm": "1341.56", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "1029"}
[2024-04-23 21:46:30,470][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:46:30,523][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 21
[2024-04-23 21:46:30,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:46:30,597][fairseq.trainer][INFO] - begin training epoch 21
[2024-04-23 21:46:30,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:46:38,987][train_inner][INFO] - {"epoch": 21, "update": 20.2, "loss": "1964.18", "ntokens": "20333", "nsentences": "110.1", "nll_loss": "10.636", "wps": "9637.1", "ups": "0.47", "wpb": "20333", "bsz": "110.1", "num_updates": "500", "lr": "2.575e-05", "gnorm": "1293.27", "loss_scale": "4", "train_wall": "78", "gb_free": "9.8", "wall": "1037"}
[2024-04-23 21:47:09,756][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:47:09,759][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:47:10,159][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 62
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:47:12,597][valid][INFO] - {"epoch": 21, "valid_loss": "2190.15", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.609", "valid_uer": "99.677", "valid_wer": "100.258", "valid_raw_wer": "100", "valid_wps": "1470.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "520", "valid_best_wer": "100.258"}
[2024-04-23 21:47:12,599][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.258]
[2024-04-23 21:47:12,600][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:47:12,602][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:47:13,065][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 63
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:47:15,232][valid][INFO] - {"epoch": 21, "valid_loss": "1845.69", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.941", "valid_uer": "83.837", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1663.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "520", "valid_best_wer": "100"}
[2024-04-23 21:47:15,234][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:47:15,234][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:47:15,236][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
[2024-04-23 21:47:15,659][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 64
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:47:17,807][valid][INFO] - {"epoch": 21, "valid_loss": "2109.62", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.219", "valid_uer": "94.026", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1755.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "520", "valid_best_wer": "100"}
[2024-04-23 21:47:17,809][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:47:17,810][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-04-23 21:47:17,810][train][INFO] - {"epoch": 21, "train_loss": "1943", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "10.424", "train_wps": "10733", "train_ups": "0.53", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "520", "train_lr": "2.674e-05", "train_gnorm": "1281.55", "train_loss_scale": "4", "train_train_wall": "38", "train_gb_free": "9.7", "train_wall": "1076"}
[2024-04-23 21:47:17,815][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:47:18,511][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 22
[2024-04-23 21:47:18,649][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:47:18,691][fairseq.trainer][INFO] - begin training epoch 22
[2024-04-23 21:47:18,699][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:47:58,997][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:47:58,999][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:47:59,463][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 65
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:01,835][valid][INFO] - {"epoch": 22, "valid_loss": "2157.48", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.451", "valid_uer": "97.174", "valid_wer": "100.603", "valid_raw_wer": "100", "valid_wps": "1569", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "545", "valid_best_wer": "100.603"}
[2024-04-23 21:48:01,838][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.603]
[2024-04-23 21:48:01,838][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:48:01,840][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:02,252][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 66
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:04,514][valid][INFO] - {"epoch": 22, "valid_loss": "1799.14", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.715", "valid_uer": "83.094", "valid_wer": "100", "valid_raw_wer": "99.828", "valid_wps": "1525.2", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "545", "valid_best_wer": "100"}
[2024-04-23 21:48:04,516][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:48:04,517][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:48:04,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:04,989][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 67
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:07,283][valid][INFO] - {"epoch": 22, "valid_loss": "2073.61", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.045", "valid_uer": "91.426", "valid_wer": "100.086", "valid_raw_wer": "100", "valid_wps": "1583", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "545", "valid_best_wer": "100.086"}
[2024-04-23 21:48:07,285][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.086]
[2024-04-23 21:48:07,286][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-04-23 21:48:07,286][train][INFO] - {"epoch": 22, "train_loss": "1909.45", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "10.244", "train_wps": "10270.8", "train_ups": "0.51", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "545", "train_lr": "2.79775e-05", "train_gnorm": "1268.85", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "1125"}
[2024-04-23 21:48:07,291][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:08,002][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 23
[2024-04-23 21:48:08,082][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:48:08,096][fairseq.trainer][INFO] - begin training epoch 23
[2024-04-23 21:48:08,097][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:48:17,246][train_inner][INFO] - {"epoch": 23, "update": 22.2, "loss": "1924.52", "ntokens": "20319.7", "nsentences": "108.34", "nll_loss": "10.261", "wps": "10341.5", "ups": "0.51", "wpb": "20319.7", "bsz": "108.3", "num_updates": "550", "lr": "2.8225e-05", "gnorm": "1294.62", "loss_scale": "4", "train_wall": "78", "gb_free": "9.8", "wall": "1135"}
[2024-04-23 21:48:48,095][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:48:48,098][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:48,579][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 68
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:50,923][valid][INFO] - {"epoch": 23, "valid_loss": "2123.35", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.286", "valid_uer": "94.671", "valid_wer": "100.345", "valid_raw_wer": "100", "valid_wps": "1693.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "570", "valid_best_wer": "100.345"}
[2024-04-23 21:48:50,925][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.345]
[2024-04-23 21:48:50,926][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:48:50,928][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:51,309][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 69
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:53,652][valid][INFO] - {"epoch": 23, "valid_loss": "1761.72", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.534", "valid_uer": "82.303", "valid_wer": "100", "valid_raw_wer": "99.742", "valid_wps": "1493.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "570", "valid_best_wer": "100"}
[2024-04-23 21:48:53,655][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:48:53,656][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:48:53,658][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:54,163][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 70
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:48:56,414][valid][INFO] - {"epoch": 23, "valid_loss": "2041.8", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.891", "valid_uer": "89.262", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1659.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "570", "valid_best_wer": "100"}
[2024-04-23 21:48:56,415][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:48:56,416][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-04-23 21:48:56,417][train][INFO] - {"epoch": 23, "train_loss": "1876.85", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "10.069", "train_wps": "10342.9", "train_ups": "0.51", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "570", "train_lr": "2.9215e-05", "train_gnorm": "1231.16", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "1175"}
[2024-04-23 21:48:56,422][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:48:57,011][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 24
[2024-04-23 21:48:57,115][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:48:57,143][fairseq.trainer][INFO] - begin training epoch 24
[2024-04-23 21:48:57,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:49:36,812][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:49:36,814][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:49:36,933][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 71
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:49:39,575][valid][INFO] - {"epoch": 24, "valid_loss": "2088.92", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "10.119", "valid_uer": "92.314", "valid_wer": "100.258", "valid_raw_wer": "100", "valid_wps": "1313.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "595", "valid_best_wer": "100.258"}
[2024-04-23 21:49:39,577][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.258]
[2024-04-23 21:49:39,578][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:49:39,580][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:49:40,027][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 72
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:49:42,318][valid][INFO] - {"epoch": 24, "valid_loss": "1720.14", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.333", "valid_uer": "82.157", "valid_wer": "100", "valid_raw_wer": "99.828", "valid_wps": "1563.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "595", "valid_best_wer": "100"}
[2024-04-23 21:49:42,320][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:49:42,320][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:49:42,322][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:49:42,810][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 73
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:49:45,052][valid][INFO] - {"epoch": 24, "valid_loss": "2004.33", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.709", "valid_uer": "86.953", "valid_wer": "99.914", "valid_raw_wer": "100", "valid_wps": "1583", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "595", "valid_best_wer": "99.914"}
[2024-04-23 21:49:45,054][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [99.914]
[2024-04-23 21:49:45,055][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-04-23 21:49:45,056][train][INFO] - {"epoch": 24, "train_loss": "1817.23", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "9.749", "train_wps": "10447.5", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "595", "train_lr": "3.04525e-05", "train_gnorm": "1228.44", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.9", "train_wall": "1223"}
[2024-04-23 21:49:45,061][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:49:45,635][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 25
[2024-04-23 21:49:45,767][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:49:45,780][fairseq.trainer][INFO] - begin training epoch 25
[2024-04-23 21:49:45,781][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:49:54,949][train_inner][INFO] - {"epoch": 25, "update": 24.2, "loss": "1844.04", "ntokens": "20350.1", "nsentences": "109.04", "nll_loss": "9.881", "wps": "10416", "ups": "0.51", "wpb": "20350.1", "bsz": "109", "num_updates": "600", "lr": "3.07e-05", "gnorm": "1217.35", "loss_scale": "4", "train_wall": "77", "gb_free": "9.7", "wall": "1233"}
[2024-04-23 21:50:25,533][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:50:25,536][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:50:25,999][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 74
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:50:28,378][valid][INFO] - {"epoch": 25, "valid_loss": "2054.62", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.953", "valid_uer": "89.924", "valid_wer": "99.914", "valid_raw_wer": "99.914", "valid_wps": "1559.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "620", "valid_best_wer": "99.914"}
[2024-04-23 21:50:28,381][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [99.914]
[2024-04-23 21:50:28,381][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:50:28,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:50:28,851][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 75
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:50:31,076][valid][INFO] - {"epoch": 25, "valid_loss": "1672.15", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.1", "valid_uer": "81.447", "valid_wer": "100", "valid_raw_wer": "99.828", "valid_wps": "1684.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "620", "valid_best_wer": "100"}
[2024-04-23 21:50:31,078][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:50:31,079][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:50:31,081][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:50:31,543][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 76
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:50:33,900][valid][INFO] - {"epoch": 25, "valid_loss": "1970.05", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.543", "valid_uer": "85.467", "valid_wer": "99.914", "valid_raw_wer": "100", "valid_wps": "1565.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "620", "valid_best_wer": "99.914"}
[2024-04-23 21:50:33,903][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [99.914]
[2024-04-23 21:50:33,905][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 620 updates
[2024-04-23 21:50:33,908][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:50:37,737][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:50:41,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt (epoch 25 @ 620 updates, score 99.914) (writing took 7.800033228006214 seconds)
[2024-04-23 21:50:41,706][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-04-23 21:50:41,707][train][INFO] - {"epoch": 25, "train_loss": "1789.53", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "9.6", "train_wps": "8969.9", "train_ups": "0.44", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "620", "train_lr": "3.169e-05", "train_gnorm": "1146.73", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.9", "train_wall": "1280"}
[2024-04-23 21:50:41,712][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:50:42,259][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 26
[2024-04-23 21:50:42,325][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:50:42,336][fairseq.trainer][INFO] - begin training epoch 26
[2024-04-23 21:50:42,337][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:51:20,927][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:51:20,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:51:21,331][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 77
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:51:23,860][valid][INFO] - {"epoch": 26, "valid_loss": "2019.87", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.785", "valid_uer": "87.421", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1525.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "645", "valid_best_wer": "99.914"}
[2024-04-23 21:51:23,862][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.0]
[2024-04-23 21:51:23,862][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:51:23,864][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:51:24,363][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 78
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:51:26,730][valid][INFO] - {"epoch": 26, "valid_loss": "1637.44", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.932", "valid_uer": "81.544", "valid_wer": "100", "valid_raw_wer": "99.828", "valid_wps": "1447.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "645", "valid_best_wer": "99.914"}
[2024-04-23 21:51:26,732][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:51:26,733][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:51:26,735][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:51:27,169][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 79
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:51:29,488][valid][INFO] - {"epoch": 26, "valid_loss": "1934.44", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.371", "valid_uer": "83.933", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1560.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "645", "valid_best_wer": "99.914"}
[2024-04-23 21:51:29,491][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:51:29,492][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-04-23 21:51:29,492][train][INFO] - {"epoch": 26, "train_loss": "1764.5", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "9.466", "train_wps": "10634.2", "train_ups": "0.52", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "645", "train_lr": "3.29275e-05", "train_gnorm": "1121.15", "train_loss_scale": "4", "train_train_wall": "38", "train_gb_free": "9.8", "train_wall": "1328"}
[2024-04-23 21:51:29,497][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:51:30,179][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 27
[2024-04-23 21:51:30,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:51:30,296][fairseq.trainer][INFO] - begin training epoch 27
[2024-04-23 21:51:30,296][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:51:39,384][train_inner][INFO] - {"epoch": 27, "update": 26.2, "loss": "1761.98", "ntokens": "20293.8", "nsentences": "109.28", "nll_loss": "9.488", "wps": "9716.2", "ups": "0.48", "wpb": "20293.8", "bsz": "109.3", "num_updates": "650", "lr": "3.3175e-05", "gnorm": "1125.04", "loss_scale": "4", "train_wall": "76", "gb_free": "9.7", "wall": "1338"}
[2024-04-23 21:52:10,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:52:10,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:52:10,153][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 80
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:52:12,808][valid][INFO] - {"epoch": 27, "valid_loss": "1985.13", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.616", "valid_uer": "85.694", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1355.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "670", "valid_best_wer": "99.914"}
[2024-04-23 21:52:12,811][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.0]
[2024-04-23 21:52:12,811][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:52:12,813][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:52:12,916][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 81
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:52:15,402][valid][INFO] - {"epoch": 27, "valid_loss": "1602.64", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.763", "valid_uer": "81.964", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1408.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "670", "valid_best_wer": "99.914"}
[2024-04-23 21:52:15,405][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:52:15,405][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:52:15,407][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:52:15,879][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 82
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:52:18,243][valid][INFO] - {"epoch": 27, "valid_loss": "1898.6", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.197", "valid_uer": "82.771", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1504.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "670", "valid_best_wer": "99.914"}
[2024-04-23 21:52:18,245][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:52:18,246][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-04-23 21:52:18,246][train][INFO] - {"epoch": 27, "train_loss": "1710.68", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "9.177", "train_wps": "10422.8", "train_ups": "0.51", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "670", "train_lr": "3.4165e-05", "train_gnorm": "1075.95", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.9", "train_wall": "1376"}
[2024-04-23 21:52:18,251][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:52:18,907][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 28
[2024-04-23 21:52:18,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:52:19,009][fairseq.trainer][INFO] - begin training epoch 28
[2024-04-23 21:52:19,010][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:52:59,636][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:52:59,639][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:00,158][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 83
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:02,563][valid][INFO] - {"epoch": 28, "valid_loss": "1949.56", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.444", "valid_uer": "83.982", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1498", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "695", "valid_best_wer": "99.914"}
[2024-04-23 21:53:02,567][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.0]
[2024-04-23 21:53:02,567][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:53:02,569][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:02,990][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 84
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:05,203][valid][INFO] - {"epoch": 28, "valid_loss": "1578.67", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.647", "valid_uer": "81.996", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1704.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "695", "valid_best_wer": "99.914"}
[2024-04-23 21:53:05,205][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:53:05,206][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:53:05,208][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:05,667][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 85
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:08,068][valid][INFO] - {"epoch": 28, "valid_loss": "1866.73", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.043", "valid_uer": "81.754", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1537.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "695", "valid_best_wer": "99.914"}
[2024-04-23 21:53:08,070][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:53:08,071][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-04-23 21:53:08,071][train][INFO] - {"epoch": 28, "train_loss": "1684.1", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "9.035", "train_wps": "10198.8", "train_ups": "0.5", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "695", "train_lr": "3.54025e-05", "train_gnorm": "1020.18", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "1426"}
[2024-04-23 21:53:08,076][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:08,679][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 29
[2024-04-23 21:53:08,845][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:53:08,869][fairseq.trainer][INFO] - begin training epoch 29
[2024-04-23 21:53:08,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:53:18,125][train_inner][INFO] - {"epoch": 29, "update": 28.2, "loss": "1700.19", "ntokens": "20337.2", "nsentences": "108.7", "nll_loss": "9.087", "wps": "10301", "ups": "0.51", "wpb": "20337.2", "bsz": "108.7", "num_updates": "700", "lr": "3.565e-05", "gnorm": "1039.91", "loss_scale": "4", "train_wall": "78", "gb_free": "9.8", "wall": "1436"}
[2024-04-23 21:53:48,775][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:53:48,777][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:49,271][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 86
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:51,693][valid][INFO] - {"epoch": 29, "valid_loss": "1915.04", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.277", "valid_uer": "82.755", "valid_wer": "99.914", "valid_raw_wer": "99.914", "valid_wps": "1474.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "720", "valid_best_wer": "99.914"}
[2024-04-23 21:53:51,696][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [99.914]
[2024-04-23 21:53:51,697][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:53:51,699][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:52,127][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 87
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:54,513][valid][INFO] - {"epoch": 29, "valid_loss": "1547.32", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.495", "valid_uer": "82.077", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1514.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "720", "valid_best_wer": "99.914"}
[2024-04-23 21:53:54,516][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:53:54,516][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:53:54,518][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:54,989][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 88
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:53:57,313][valid][INFO] - {"epoch": 29, "valid_loss": "1831.71", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.873", "valid_uer": "80.704", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1598.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "720", "valid_best_wer": "99.914"}
[2024-04-23 21:53:57,316][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:53:57,316][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-04-23 21:53:57,317][train][INFO] - {"epoch": 29, "train_loss": "1657.59", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "8.893", "train_wps": "10318.7", "train_ups": "0.51", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "720", "train_lr": "3.664e-05", "train_gnorm": "965.566", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "1475"}
[2024-04-23 21:53:57,321][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:53:57,980][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 30
[2024-04-23 21:53:58,087][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:53:58,100][fairseq.trainer][INFO] - begin training epoch 30
[2024-04-23 21:53:58,100][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:54:38,197][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:54:38,201][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:54:38,597][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 89
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:54:41,012][valid][INFO] - {"epoch": 30, "valid_loss": "1881.96", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "9.117", "valid_uer": "81.415", "valid_wer": "99.914", "valid_raw_wer": "99.914", "valid_wps": "1477.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "745", "valid_best_wer": "99.914"}
[2024-04-23 21:54:41,015][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [99.914]
[2024-04-23 21:54:41,016][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:54:41,018][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:54:41,499][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 90
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:54:43,757][valid][INFO] - {"epoch": 30, "valid_loss": "1517.61", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.352", "valid_uer": "82.432", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1548.5", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "745", "valid_best_wer": "99.914"}
[2024-04-23 21:54:43,759][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:54:43,759][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:54:43,761][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:54:44,227][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 91
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:54:46,553][valid][INFO] - {"epoch": 30, "valid_loss": "1797.6", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.708", "valid_uer": "80.09", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1603.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "745", "valid_best_wer": "99.914"}
[2024-04-23 21:54:46,555][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:54:46,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 745 updates
[2024-04-23 21:54:46,561][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:54:50,507][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt
[2024-04-23 21:54:54,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/noNoise/checkpoint_best.pt (epoch 30 @ 745 updates, score 99.914) (writing took 7.912530084140599 seconds)
[2024-04-23 21:54:54,472][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-04-23 21:54:54,473][train][INFO] - {"epoch": 30, "train_loss": "1618.26", "train_ntokens": "20325.2", "train_nsentences": "109.04", "train_nll_loss": "8.682", "train_wps": "8890.5", "train_ups": "0.44", "train_wpb": "20325.2", "train_bsz": "109", "train_num_updates": "745", "train_lr": "3.78775e-05", "train_gnorm": "922.523", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "1533"}
[2024-04-23 21:54:54,478][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:54:54,927][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 31
[2024-04-23 21:54:54,992][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:54:55,004][fairseq.trainer][INFO] - begin training epoch 31
[2024-04-23 21:54:55,005][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:55:03,569][train_inner][INFO] - {"epoch": 31, "update": 30.2, "loss": "1627.3", "ntokens": "20339.9", "nsentences": "109.16", "nll_loss": "8.733", "wps": "9648", "ups": "0.47", "wpb": "20339.9", "bsz": "109.2", "num_updates": "750", "lr": "3.8125e-05", "gnorm": "935.298", "loss_scale": "4", "train_wall": "77", "gb_free": "9.7", "wall": "1542"}
[2024-04-23 21:55:34,450][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:55:34,452][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:55:34,578][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 92
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:55:37,249][valid][INFO] - {"epoch": 31, "valid_loss": "1848.55", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.955", "valid_uer": "80.575", "valid_wer": "99.828", "valid_raw_wer": "99.914", "valid_wps": "1319.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "770", "valid_best_wer": "99.828"}
[2024-04-23 21:55:37,252][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [99.828]
[2024-04-23 21:55:37,253][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:55:37,254][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:55:37,309][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 93
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:55:40,058][valid][INFO] - {"epoch": 31, "valid_loss": "1494.23", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.238", "valid_uer": "82.981", "valid_wer": "100", "valid_raw_wer": "99.828", "valid_wps": "1171.3", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "770", "valid_best_wer": "99.914"}
[2024-04-23 21:55:40,060][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:55:40,061][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:55:40,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:55:40,555][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 94
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:55:42,979][valid][INFO] - {"epoch": 31, "valid_loss": "1763.65", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.543", "valid_uer": "79.735", "valid_wer": "99.914", "valid_raw_wer": "100", "valid_wps": "1557.8", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "770", "valid_best_wer": "99.914"}
[2024-04-23 21:55:42,982][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [99.914]
[2024-04-23 21:55:42,982][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-04-23 21:55:42,983][train][INFO] - {"epoch": 31, "train_loss": "1583.49", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "8.495", "train_wps": "10475.3", "train_ups": "0.52", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "770", "train_lr": "3.9115e-05", "train_gnorm": "882.825", "train_loss_scale": "4", "train_train_wall": "38", "train_gb_free": "10", "train_wall": "1581"}
[2024-04-23 21:55:42,988][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:55:43,056][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 32
[2024-04-23 21:55:43,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:55:43,172][fairseq.trainer][INFO] - begin training epoch 32
[2024-04-23 21:55:43,184][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:56:23,519][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:56:23,522][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:56:23,983][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 95
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:56:26,421][valid][INFO] - {"epoch": 32, "valid_loss": "1815.94", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.797", "valid_uer": "79.945", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1429.7", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "795", "valid_best_wer": "99.914"}
[2024-04-23 21:56:26,423][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.0]
[2024-04-23 21:56:26,424][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:56:26,426][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:56:26,859][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 96
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:56:29,184][valid][INFO] - {"epoch": 32, "valid_loss": "1478.06", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.16", "valid_uer": "83.659", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1522.9", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "795", "valid_best_wer": "99.914"}
[2024-04-23 21:56:29,186][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:56:29,186][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:56:29,188][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:56:29,591][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 97
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:56:32,018][valid][INFO] - {"epoch": 32, "valid_loss": "1731.67", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.389", "valid_uer": "79.396", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1455.6", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "795", "valid_best_wer": "99.914"}
[2024-04-23 21:56:32,021][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [100.0]
[2024-04-23 21:56:32,021][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-04-23 21:56:32,022][train][INFO] - {"epoch": 32, "train_loss": "1565.13", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "8.396", "train_wps": "10362.4", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "795", "train_lr": "4.03525e-05", "train_gnorm": "844.434", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "9.8", "train_wall": "1630"}
[2024-04-23 21:56:32,026][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:56:32,683][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 33
[2024-04-23 21:56:32,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:56:32,801][fairseq.trainer][INFO] - begin training epoch 33
[2024-04-23 21:56:32,802][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:56:41,969][train_inner][INFO] - {"epoch": 33, "update": 32.2, "loss": "1570.01", "ntokens": "20357.3", "nsentences": "109.1", "nll_loss": "8.414", "wps": "10344.5", "ups": "0.51", "wpb": "20357.3", "bsz": "109.1", "num_updates": "800", "lr": "4.06e-05", "gnorm": "852.62", "loss_scale": "4", "train_wall": "78", "gb_free": "9.7", "wall": "1640"}
[2024-04-23 21:57:12,875][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:57:12,877][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:57:13,350][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 98
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITHOUT NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:57:15,717][valid][INFO] - {"epoch": 33, "valid_loss": "1783.61", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.64", "valid_uer": "79.509", "valid_wer": "100", "valid_raw_wer": "100", "valid_wps": "1550.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "820", "valid_best_wer": "99.914"}
[2024-04-23 21:57:15,720][fairseq_cli.train][INFO] - Validation losses for noise type 'None': [100.0]
[2024-04-23 21:57:15,721][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:57:15,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:57:16,199][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 99
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH GAUSSIAN NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:57:18,532][valid][INFO] - {"epoch": 33, "valid_loss": "1459.42", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "7.07", "valid_uer": "84.321", "valid_wer": "100", "valid_raw_wer": "99.914", "valid_wps": "1443.1", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "820", "valid_best_wer": "99.914"}
[2024-04-23 21:57:18,534][fairseq_cli.train][INFO] - Validation losses for noise type 'gaussian': [100.0]
[2024-04-23 21:57:18,535][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-04-23 21:57:18,536][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:57:18,987][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 100
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
VALID STEP WITH UNIFORM NOISE
EVAL STEP. CRITERION 
CtcCriterion()
[2024-04-23 21:57:21,478][valid][INFO] - {"epoch": 33, "valid_loss": "1701.8", "valid_ntokens": "3096.5", "valid_nsentences": "15", "valid_nll_loss": "8.244", "valid_uer": "79.218", "valid_wer": "99.914", "valid_raw_wer": "100", "valid_wps": "1452.4", "valid_wpb": "3096.5", "valid_bsz": "15", "valid_num_updates": "820", "valid_best_wer": "99.914"}
[2024-04-23 21:57:21,481][fairseq_cli.train][INFO] - Validation losses for noise type 'uniform': [99.914]
[2024-04-23 21:57:21,482][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-04-23 21:57:21,482][train][INFO] - {"epoch": 33, "train_loss": "1531.03", "train_ntokens": "20325.4", "train_nsentences": "109.04", "train_nll_loss": "8.214", "train_wps": "10274", "train_ups": "0.51", "train_wpb": "20325.4", "train_bsz": "109", "train_num_updates": "820", "train_lr": "4.159e-05", "train_gnorm": "788.024", "train_loss_scale": "8", "train_train_wall": "39", "train_gb_free": "9.7", "train_wall": "1680"}
[2024-04-23 21:57:21,487][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-04-23 21:57:22,107][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 34
[2024-04-23 21:57:22,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 25
[2024-04-23 21:57:22,233][fairseq.trainer][INFO] - begin training epoch 34
[2024-04-23 21:57:22,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-04-23 21:57:31,386][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
