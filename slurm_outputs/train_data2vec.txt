INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
ENTERED MAIN
Python path: ['/fs01/home/addisonw/anaconda3/envs/noisyD2V/bin', '/h/addisonw/fairseq', '/fs01/home/addisonw/fairseq', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python38.zip', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/lib-dynload', '/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages']
[2024-03-26 16:29:35,810][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 1e-06, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/h/addisonw/fairseq/examples/data2vec', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00075], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': True}, 'checkpoint': {'_name': None, 'save_dir': '/h/addisonw/fairseq/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'data2vec_multi', 'loss_beta': 0.0, 'loss_scale': None, 'depth': 12, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_heads': 12, 'norm_eps': 1e-05, 'norm_affine': True, 'encoder_dropout': 0.1, 'post_mlp_drop': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'dropout_input': 0.0, 'layerdrop': 0.05, 'embed_dim': 768, 'mlp_ratio': 4.0, 'layer_norm_first': False, 'average_top_k_layers': 8, 'end_of_block_targets': False, 'clone_batch': 8, 'layer_norm_target_layer': False, 'batch_norm_target_layer': False, 'instance_norm_target_layer': True, 'instance_norm_targets': False, 'layer_norm_targets': False, 'ema_decay': 0.999, 'ema_same_dtype': True, 'log_norms': True, 'ema_end_decay': 0.99999, 'ema_anneal_end_step': 75000, 'ema_encoder_only': False, 'max_update': '${optimization.max_update}', 'modalities': {'_name': None, 'audio': {'type': <Modality.AUDIO: 1>, 'prenet_depth': 0, 'prenet_layerdrop': 0.05, 'prenet_dropout': 0.1, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.5, 'inverse_mask': False, 'mask_prob_adjust': 0.05, 'keep_masked_pct': 0.0, 'mask_length': 5, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': True, 'mask_channel_prob': 0.0, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 1.0, 'use_alibi_encoder': True, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': True, 'learned_alibi_scale_per_head': True, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': '${model.num_heads}', 'model_depth': '${model.depth}', 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 7, 'decoder_layers': 4, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0}, 'extractor_mode': 'layer_norm', 'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_pos_width': 95, 'conv_pos_groups': 16, 'conv_pos_depth': 5, 'conv_pos_pre_ln': False}, 'image': {'type': <Modality.IMAGE: 2>, 'prenet_depth': 4, 'prenet_layerdrop': 0.0, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.7, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 5, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': True, 'mask_channel_prob': 0.0, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 1.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': False, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': '${model.num_heads}', 'model_depth': '${model.depth}', 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 5, 'decoder_layers': 5, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0}, 'input_size': 224, 'in_chans': 3, 'patch_size': 16, 'embed_dim': 768, 'alibi_dims': 2, 'alibi_distance': 'manhattan', 'fixed_positions': True, 'transformer_decoder': False, 'enc_dec_transformer': False}, 'text': {'type': <Modality.TEXT: 3>, 'prenet_depth': 4, 'prenet_layerdrop': 0.0, 'prenet_dropout': 0.0, 'start_drop_path_rate': 0.0, 'end_drop_path_rate': 0.0, 'num_extra_tokens': 0, 'init_extra_token_zero': True, 'mask_noise_std': 0.01, 'mask_prob_min': None, 'mask_prob': 0.7, 'inverse_mask': False, 'mask_prob_adjust': 0.0, 'keep_masked_pct': 0.0, 'mask_length': 5, 'add_masks': False, 'remove_masks': False, 'mask_dropout': 0.0, 'encoder_zero_mask': True, 'mask_channel_prob': 0.0, 'mask_channel_length': 64, 'ema_local_encoder': False, 'local_grad_mult': 1.0, 'use_alibi_encoder': False, 'alibi_scale': 1.0, 'learned_alibi': False, 'alibi_max_pos': None, 'learned_alibi_scale': False, 'learned_alibi_scale_per_head': False, 'learned_alibi_scale_per_layer': False, 'num_alibi_heads': '${model.num_heads}', 'model_depth': '${model.depth}', 'decoder': {'decoder_dim': 384, 'decoder_groups': 16, 'decoder_kernel': 5, 'decoder_layers': 5, 'input_dropout': 0.1, 'add_positions_masked': False, 'add_positions_all': False, 'decoder_residual': True, 'projection_layers': 1, 'projection_ratio': 2.0}, 'max_source_positions': 512, 'learned_pos': True, 'dropout': 0.1, 'no_scale_embedding': True, 'layernorm_embedding': True, 'no_token_positional_embeddings': False}}, 'shared_decoder': None, 'min_target_var': 0.1, 'min_pred_var': 0.01, 'supported_modality': <Modality.AUDIO: 1>, 'mae_init': False, 'seed': '${common.seed}', 'skip_ema': False, 'cls_loss': 0.0, 'recon_loss': 0.0, 'd2v_loss': 1.0, 'decoder_group': False}, 'task': {'_name': 'audio_pretraining', 'data': '/h/addisonw/fairseq/manifests', 'labels': None, 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 8000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 38720, 'min_sample_size': 37760, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': {'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'mask_prob': 0.5, 'mask_prob_adjust': 0.05, 'mask_length': 5, 'inverse_mask': False, 'mask_dropout': 0.0, 'clone_batch': 8, 'expand_adjacent': False, 'non_overlapping': False}, 'post_save_script': None, 'subsample': 1.0, 'seed': 1}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['ema_decay', 'target_var', 'pred_var', 'model_norm', 'ema_norm', 'masked_pct'], 'can_sum': True}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.00075]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 8000, 'warmup_init_lr': -1.0, 'lr': [0.00075], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 400000}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-03-26 16:29:37,775][data2vec.models.data2vec2][INFO] - making target model
[2024-03-26 16:29:39,715][fairseq_cli.train][INFO] - Data2VecMultiModel(
  (modality_encoders): ModuleDict(
    (AUDIO): AudioEncoder(
      (local_encoder): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Sequential(
              (0): TransposeLast()
              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (2): TransposeLast()
            )
            (3): GELU(approximate='none')
          )
        )
      )
      (project_features): Sequential(
        (0): TransposeLast()
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=512, out_features=768, bias=True)
      )
      (relative_positional_encoder): Sequential(
        (0): TransposeLast()
        (1): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (4): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (5): Sequential(
          (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)
          (1): SamePad()
          (2): TransposeLast()
          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)
          (4): TransposeLast()
          (5): GELU(approximate='none')
        )
        (6): TransposeLast()
      )
      (context_encoder): BlockEncoder(
        (blocks): ModuleList()
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=True)
      )
      (decoder): Decoder1d(
        (blocks): Sequential(
          (0): Sequential(
            (0): Conv1d(768, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=16)
            (1): SamePad()
            (2): TransposeLast()
            (3): LayerNorm((384,), eps=1e-05, elementwise_affine=False)
            (4): TransposeLast()
            (5): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=16)
            (1): SamePad()
            (2): TransposeLast()
            (3): LayerNorm((384,), eps=1e-05, elementwise_affine=False)
            (4): TransposeLast()
            (5): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=16)
            (1): SamePad()
            (2): TransposeLast()
            (3): LayerNorm((384,), eps=1e-05, elementwise_affine=False)
            (4): TransposeLast()
            (5): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=16)
            (1): SamePad()
            (2): TransposeLast()
            (3): LayerNorm((384,), eps=1e-05, elementwise_affine=False)
            (4): TransposeLast()
            (5): GELU(approximate='none')
          )
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
    )
  )
  (dropout_input): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-11): 12 x AltBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): AltAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.1, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (post_mlp_dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
[2024-03-26 16:29:39,719][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-03-26 16:29:39,720][fairseq_cli.train][INFO] - model: Data2VecMultiModel
[2024-03-26 16:29:39,720][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-03-26 16:29:39,722][fairseq_cli.train][INFO] - num. shared model params: 93,783,308 (num. trained: 93,783,308)
[2024-03-26 16:29:39,723][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-03-26 16:29:39,728][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 25, skipped 0 samples
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.1.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.2.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.3.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.4.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.5.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.local_encoder.conv_layers.6.0.bias
[2024-03-26 16:29:42,169][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.1.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.1.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.2.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.2.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.3.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.3.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.4.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.4.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.5.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.relative_positional_encoder.5.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.0.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.0.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.1.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.1.3.bias
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.2.3.weight
[2024-03-26 16:29:42,170][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.2.3.bias
[2024-03-26 16:29:42,171][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.3.3.weight
[2024-03-26 16:29:42,171][fairseq.trainer][INFO] - detected shared parameter: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.bias <- modality_encoders.AUDIO.decoder.blocks.3.3.bias
[2024-03-26 16:29:42,171][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2024-03-26 16:29:42,171][fairseq.utils][INFO] - rank   0: capabilities =  7.5  ; total memory = 14.578 GB ; name = Tesla T4                                
[2024-03-26 16:29:42,171][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2024-03-26 16:29:42,172][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2024-03-26 16:29:42,172][fairseq_cli.train][INFO] - max tokens per device = 1000000 and max sentences per device = None
[2024-03-26 16:29:42,173][fairseq.trainer][INFO] - Preparing to load checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:29:42,173][fairseq.trainer][INFO] - No existing checkpoint found /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:29:42,173][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-03-26 16:29:42,176][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 183, skipped 0 samples
[2024-03-26 16:29:42,178][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:29:42,179][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-03-26 16:29:42,179][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2024-03-26 16:29:42,179][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2024-03-26 16:29:42,179][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-03-26 16:29:42,422][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2024-03-26 16:29:42,423][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:29:42,423][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-03-26 16:29:42,423][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2024-03-26 16:29:42,423][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2024-03-26 16:29:42,423][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/h/addisonw/anaconda3/envs/noisyD2V/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[2024-03-26 16:29:44,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:29:44,210][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:29:44,214][fairseq.trainer][INFO] - begin training epoch 1
[2024-03-26 16:29:44,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:29:50,180][data2vec.models.data2vec2][INFO] - adjusting ema dtype to torch.float16 and device to cuda:0
[2024-03-26 16:29:51,828][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-03-26 16:29:52,811][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-03-26 16:29:53,717][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-03-26 16:29:54,696][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-03-26 16:29:55,623][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-03-26 16:29:56,605][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-03-26 16:29:57,393][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-03-26 16:29:57,396][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1 updates
[2024-03-26 16:29:57,398][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:29:59,875][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:29:59,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 1 @ 1 updates, score None) (writing took 2.5196826737374067 seconds)
[2024-03-26 16:29:59,917][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-03-26 16:29:59,918][train][INFO] - {"epoch": 1, "train_loss": "28.407", "train_ntokens": "928", "train_nsentences": "2", "train_sample_size": "928", "train_ema_decay": "999", "train_target_var": "0.353", "train_pred_var": "0.551", "train_masked_pct": "0.496", "train_wps": "0", "train_ups": "0", "train_wpb": "928", "train_bsz": "2", "train_num_updates": "1", "train_lr": "9.375e-08", "train_gnorm": "76.094", "train_loss_scale": "1", "train_train_wall": "12", "train_gb_free": "5.8", "train_wall": "18"}
[2024-03-26 16:29:59,920][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:29:59,999][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
[2024-03-26 16:30:00,002][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:00,006][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:00,010][fairseq.trainer][INFO] - begin training epoch 2
[2024-03-26 16:30:00,011][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:06,560][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9 updates
[2024-03-26 16:30:06,561][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:08,848][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:08,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 2 @ 9 updates, score None) (writing took 2.3425131789408624 seconds)
[2024-03-26 16:30:08,903][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-03-26 16:30:08,903][train][INFO] - {"epoch": 2, "train_loss": "28.31", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999", "train_target_var": "0.352", "train_pred_var": "0.55", "train_masked_pct": "0.501", "train_wps": "9588.9", "train_ups": "0.89", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "9", "train_lr": "8.4375e-07", "train_gnorm": "77.281", "train_loss_scale": "1", "train_train_wall": "6", "train_gb_free": "5.4", "train_wall": "27"}
[2024-03-26 16:30:08,905][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:08,969][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
[2024-03-26 16:30:08,971][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:08,974][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:08,978][fairseq.trainer][INFO] - begin training epoch 3
[2024-03-26 16:30:08,979][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:15,565][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 17 updates
[2024-03-26 16:30:15,567][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:18,054][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:18,109][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 3 @ 17 updates, score None) (writing took 2.5435215160250664 seconds)
[2024-03-26 16:30:18,110][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-03-26 16:30:18,111][train][INFO] - {"epoch": 3, "train_loss": "27.491", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999", "train_target_var": "0.352", "train_pred_var": "0.552", "train_masked_pct": "0.5", "train_wps": "9357.9", "train_ups": "0.87", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "17", "train_lr": "1.59375e-06", "train_gnorm": "69.933", "train_loss_scale": "1", "train_train_wall": "6", "train_gb_free": "5.8", "train_wall": "36"}
[2024-03-26 16:30:18,113][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:18,178][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 4
[2024-03-26 16:30:18,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:18,183][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:18,188][fairseq.trainer][INFO] - begin training epoch 4
[2024-03-26 16:30:18,188][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:25,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 25 updates
[2024-03-26 16:30:25,039][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:27,533][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:27,588][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 4 @ 25 updates, score None) (writing took 2.5495814168825746 seconds)
[2024-03-26 16:30:27,588][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-03-26 16:30:27,589][train][INFO] - {"epoch": 4, "train_loss": "25.205", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999", "train_target_var": "0.351", "train_pred_var": "0.544", "train_masked_pct": "0.5", "train_wps": "9090.8", "train_ups": "0.84", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "25", "train_lr": "2.34375e-06", "train_gnorm": "56.929", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "45"}
[2024-03-26 16:30:27,591][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:27,653][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 5
[2024-03-26 16:30:27,654][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:27,657][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:27,662][fairseq.trainer][INFO] - begin training epoch 5
[2024-03-26 16:30:27,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:34,537][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:30:34,538][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:34,619][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
[2024-03-26 16:30:34,622][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:35,022][valid][INFO] - {"epoch": 5, "valid_loss": "21.302", "valid_ntokens": "11703", "valid_nsentences": "25", "valid_sample_size": "11703", "valid_ema_decay": "999", "valid_target_var": "0.352", "valid_pred_var": "0.484", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11703", "valid_bsz": "25", "valid_num_updates": "33"}
[2024-03-26 16:30:35,024][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 33 updates
[2024-03-26 16:30:35,025][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:30:37,503][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:30:41,534][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 5 @ 33 updates, score 21.302) (writing took 6.509840223006904 seconds)
[2024-03-26 16:30:41,535][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-03-26 16:30:41,535][train][INFO] - {"epoch": 5, "train_loss": "23.283", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999", "train_target_var": "0.352", "train_pred_var": "0.527", "train_masked_pct": "0.501", "train_wps": "6177.9", "train_ups": "0.57", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "33", "train_lr": "3.09375e-06", "train_gnorm": "48.355", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "59"}
[2024-03-26 16:30:41,537][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:41,609][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 6
[2024-03-26 16:30:41,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:41,614][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:41,619][fairseq.trainer][INFO] - begin training epoch 6
[2024-03-26 16:30:41,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:48,526][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 41 updates
[2024-03-26 16:30:48,527][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:51,042][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:30:51,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 6 @ 41 updates, score None) (writing took 2.5714617460034788 seconds)
[2024-03-26 16:30:51,098][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-03-26 16:30:51,098][train][INFO] - {"epoch": 6, "train_loss": "21.722", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999", "train_target_var": "0.351", "train_pred_var": "0.506", "train_masked_pct": "0.499", "train_wps": "9009.4", "train_ups": "0.84", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "41", "train_lr": "3.84375e-06", "train_gnorm": "44.149", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "69"}
[2024-03-26 16:30:51,101][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:30:51,164][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 7
[2024-03-26 16:30:51,166][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:30:51,169][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:30:51,174][fairseq.trainer][INFO] - begin training epoch 7
[2024-03-26 16:30:51,174][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:30:58,051][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 49 updates
[2024-03-26 16:30:58,052][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:00,540][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:00,594][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 7 @ 49 updates, score None) (writing took 2.5434550386853516 seconds)
[2024-03-26 16:31:00,595][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-03-26 16:31:00,596][train][INFO] - {"epoch": 7, "train_loss": "19.901", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.001", "train_target_var": "0.351", "train_pred_var": "0.482", "train_masked_pct": "0.5", "train_wps": "9072.1", "train_ups": "0.84", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "49", "train_lr": "4.59375e-06", "train_gnorm": "40.034", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "78"}
[2024-03-26 16:31:00,598][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:00,665][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 8
[2024-03-26 16:31:00,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:00,670][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:00,675][fairseq.trainer][INFO] - begin training epoch 8
[2024-03-26 16:31:00,676][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:07,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 57 updates
[2024-03-26 16:31:07,434][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:09,945][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:09,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 8 @ 57 updates, score None) (writing took 2.5667511597275734 seconds)
[2024-03-26 16:31:10,001][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-03-26 16:31:10,001][train][INFO] - {"epoch": 8, "train_loss": "19.241", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.001", "train_target_var": "0.352", "train_pred_var": "0.47", "train_masked_pct": "0.5", "train_wps": "9160.9", "train_ups": "0.85", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "57", "train_lr": "5.34375e-06", "train_gnorm": "40.933", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.9", "train_wall": "88"}
[2024-03-26 16:31:10,003][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:10,068][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 9
[2024-03-26 16:31:10,070][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:10,073][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:10,078][fairseq.trainer][INFO] - begin training epoch 9
[2024-03-26 16:31:10,078][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:16,929][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 65 updates
[2024-03-26 16:31:16,931][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:19,415][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:19,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 9 @ 65 updates, score None) (writing took 2.530364315956831 seconds)
[2024-03-26 16:31:19,460][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-03-26 16:31:19,461][train][INFO] - {"epoch": 9, "train_loss": "17.738", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.001", "train_target_var": "0.351", "train_pred_var": "0.45", "train_masked_pct": "0.5", "train_wps": "9108.2", "train_ups": "0.85", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "65", "train_lr": "6.09375e-06", "train_gnorm": "35.72", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "97"}
[2024-03-26 16:31:19,463][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:19,532][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 10
[2024-03-26 16:31:19,534][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:19,537][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:19,542][fairseq.trainer][INFO] - begin training epoch 10
[2024-03-26 16:31:19,542][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:26,405][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:31:26,406][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:26,480][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
[2024-03-26 16:31:26,483][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:26,879][valid][INFO] - {"epoch": 10, "valid_loss": "15.257", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.001", "valid_target_var": "0.352", "valid_pred_var": "0.393", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "73", "valid_best_loss": "15.257"}
[2024-03-26 16:31:26,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 73 updates
[2024-03-26 16:31:26,882][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:31:29,683][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:31:33,746][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 10 @ 73 updates, score 15.257) (writing took 6.865370239131153 seconds)
[2024-03-26 16:31:33,747][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-03-26 16:31:33,748][train][INFO] - {"epoch": 10, "train_loss": "16.726", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.001", "train_target_var": "0.352", "train_pred_var": "0.435", "train_masked_pct": "0.501", "train_wps": "6030.3", "train_ups": "0.56", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "73", "train_lr": "6.84375e-06", "train_gnorm": "33.706", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "112"}
[2024-03-26 16:31:33,750][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:33,820][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 11
[2024-03-26 16:31:33,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:33,825][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:33,830][fairseq.trainer][INFO] - begin training epoch 11
[2024-03-26 16:31:33,830][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:40,823][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 81 updates
[2024-03-26 16:31:40,825][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:43,280][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:43,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 11 @ 81 updates, score None) (writing took 2.509523296263069 seconds)
[2024-03-26 16:31:43,333][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-03-26 16:31:43,334][train][INFO] - {"epoch": 11, "train_loss": "15.765", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.001", "train_target_var": "0.351", "train_pred_var": "0.425", "train_masked_pct": "0.501", "train_wps": "8989.1", "train_ups": "0.83", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "81", "train_lr": "7.59375e-06", "train_gnorm": "32.357", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "121"}
[2024-03-26 16:31:43,336][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:43,397][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 12
[2024-03-26 16:31:43,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:43,402][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:43,407][fairseq.trainer][INFO] - begin training epoch 12
[2024-03-26 16:31:43,407][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:50,310][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 89 updates
[2024-03-26 16:31:50,312][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:52,883][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:31:52,927][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 12 @ 89 updates, score None) (writing took 2.6161819850094616 seconds)
[2024-03-26 16:31:52,927][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-03-26 16:31:52,928][train][INFO] - {"epoch": 12, "train_loss": "15.02", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.001", "train_target_var": "0.352", "train_pred_var": "0.416", "train_masked_pct": "0.498", "train_wps": "8981.5", "train_ups": "0.83", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "89", "train_lr": "8.34375e-06", "train_gnorm": "30.854", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "131"}
[2024-03-26 16:31:52,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:31:53,004][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 13
[2024-03-26 16:31:53,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:31:53,009][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:31:53,014][fairseq.trainer][INFO] - begin training epoch 13
[2024-03-26 16:31:53,014][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:31:59,969][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 97 updates
[2024-03-26 16:31:59,970][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:02,457][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:02,509][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 13 @ 97 updates, score None) (writing took 2.539983900729567 seconds)
[2024-03-26 16:32:02,509][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-03-26 16:32:02,510][train][INFO] - {"epoch": 13, "train_loss": "13.998", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.001", "train_target_var": "0.352", "train_pred_var": "0.405", "train_masked_pct": "0.501", "train_wps": "8992.6", "train_ups": "0.83", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "97", "train_lr": "9.09375e-06", "train_gnorm": "28.988", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "140"}
[2024-03-26 16:32:02,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:02,580][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 14
[2024-03-26 16:32:02,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:02,585][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:02,590][fairseq.trainer][INFO] - begin training epoch 14
[2024-03-26 16:32:02,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:32:09,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 105 updates
[2024-03-26 16:32:09,360][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:11,922][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:11,975][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 14 @ 105 updates, score None) (writing took 2.6162587869912386 seconds)
[2024-03-26 16:32:11,976][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-03-26 16:32:11,976][train][INFO] - {"epoch": 14, "train_loss": "13.529", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.001", "train_target_var": "0.351", "train_pred_var": "0.401", "train_masked_pct": "0.499", "train_wps": "9101.4", "train_ups": "0.85", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "105", "train_lr": "9.84375e-06", "train_gnorm": "28.43", "train_loss_scale": "1", "train_train_wall": "6", "train_gb_free": "6", "train_wall": "150"}
[2024-03-26 16:32:11,978][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:12,062][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 15
[2024-03-26 16:32:12,064][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:12,067][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:12,072][fairseq.trainer][INFO] - begin training epoch 15
[2024-03-26 16:32:12,072][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:32:19,024][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:32:19,025][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:19,101][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 4
[2024-03-26 16:32:19,104][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:19,504][valid][INFO] - {"epoch": 15, "valid_loss": "11.109", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.001", "valid_target_var": "0.353", "valid_pred_var": "0.338", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "113", "valid_best_loss": "11.109"}
[2024-03-26 16:32:19,505][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 113 updates
[2024-03-26 16:32:19,507][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:32:22,109][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:32:26,162][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 15 @ 113 updates, score 11.109) (writing took 6.6567380940541625 seconds)
[2024-03-26 16:32:26,163][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-03-26 16:32:26,164][train][INFO] - {"epoch": 15, "train_loss": "12.443", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.001", "train_target_var": "0.351", "train_pred_var": "0.386", "train_masked_pct": "0.5", "train_wps": "6072.8", "train_ups": "0.56", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "113", "train_lr": "1.05938e-05", "train_gnorm": "25.678", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "164"}
[2024-03-26 16:32:26,166][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:26,232][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 16
[2024-03-26 16:32:26,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:26,237][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:26,241][fairseq.trainer][INFO] - begin training epoch 16
[2024-03-26 16:32:26,242][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:32:33,311][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 121 updates
[2024-03-26 16:32:33,313][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:35,815][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:35,868][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 16 @ 121 updates, score None) (writing took 2.5562478131614625 seconds)
[2024-03-26 16:32:35,868][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-03-26 16:32:35,869][train][INFO] - {"epoch": 16, "train_loss": "11.649", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.377", "train_masked_pct": "0.5", "train_wps": "8878.4", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "121", "train_lr": "1.13437e-05", "train_gnorm": "24.525", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "12", "train_wall": "174"}
[2024-03-26 16:32:35,871][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:35,933][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 17
[2024-03-26 16:32:35,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:35,938][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:35,942][fairseq.trainer][INFO] - begin training epoch 17
[2024-03-26 16:32:35,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:32:42,895][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 129 updates
[2024-03-26 16:32:42,897][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:45,390][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:45,444][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 17 @ 129 updates, score None) (writing took 2.5488214888609946 seconds)
[2024-03-26 16:32:45,445][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-03-26 16:32:45,445][train][INFO] - {"epoch": 17, "train_loss": "10.963", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.366", "train_masked_pct": "0.501", "train_wps": "8996.3", "train_ups": "0.84", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "129", "train_lr": "1.20938e-05", "train_gnorm": "22.843", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "183"}
[2024-03-26 16:32:45,447][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:45,510][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 18
[2024-03-26 16:32:45,512][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:45,515][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:45,519][fairseq.trainer][INFO] - begin training epoch 18
[2024-03-26 16:32:45,520][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:32:52,402][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 137 updates
[2024-03-26 16:32:52,404][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:54,826][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:32:54,878][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 18 @ 137 updates, score None) (writing took 2.4756762869656086 seconds)
[2024-03-26 16:32:54,879][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-03-26 16:32:54,879][train][INFO] - {"epoch": 18, "train_loss": "10.386", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.361", "train_masked_pct": "0.501", "train_wps": "9132.9", "train_ups": "0.85", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "137", "train_lr": "1.28438e-05", "train_gnorm": "21.697", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "193"}
[2024-03-26 16:32:54,881][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:32:54,945][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 19
[2024-03-26 16:32:54,947][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:32:54,950][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:32:54,955][fairseq.trainer][INFO] - begin training epoch 19
[2024-03-26 16:32:54,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:02,003][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 145 updates
[2024-03-26 16:33:02,004][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:04,477][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:04,523][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 19 @ 145 updates, score None) (writing took 2.5200763810425997 seconds)
[2024-03-26 16:33:04,523][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-03-26 16:33:04,524][train][INFO] - {"epoch": 19, "train_loss": "9.613", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.348", "train_masked_pct": "0.501", "train_wps": "8934", "train_ups": "0.83", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "145", "train_lr": "1.35938e-05", "train_gnorm": "19.863", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "202"}
[2024-03-26 16:33:04,526][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:04,601][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 20
[2024-03-26 16:33:04,602][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:04,605][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:04,610][fairseq.trainer][INFO] - begin training epoch 20
[2024-03-26 16:33:04,611][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:11,642][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:33:11,643][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:11,709][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 5
[2024-03-26 16:33:11,712][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:12,108][valid][INFO] - {"epoch": 20, "valid_loss": "7.98", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.002", "valid_target_var": "0.352", "valid_pred_var": "0.29", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "153", "valid_best_loss": "7.98"}
[2024-03-26 16:33:12,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 153 updates
[2024-03-26 16:33:12,111][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:33:14,702][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:33:18,731][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 20 @ 153 updates, score 7.98) (writing took 6.6214006268419325 seconds)
[2024-03-26 16:33:18,732][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-03-26 16:33:18,732][train][INFO] - {"epoch": 20, "train_loss": "9.003", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.339", "train_masked_pct": "0.5", "train_wps": "6063.5", "train_ups": "0.56", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "153", "train_lr": "1.43437e-05", "train_gnorm": "18.431", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "217"}
[2024-03-26 16:33:18,734][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:18,797][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 21
[2024-03-26 16:33:18,799][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:18,802][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:18,807][fairseq.trainer][INFO] - begin training epoch 21
[2024-03-26 16:33:18,807][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:25,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 161 updates
[2024-03-26 16:33:25,934][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:28,427][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:28,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 21 @ 161 updates, score None) (writing took 2.53823198704049 seconds)
[2024-03-26 16:33:28,472][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-03-26 16:33:28,472][train][INFO] - {"epoch": 21, "train_loss": "8.462", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.331", "train_masked_pct": "0.5", "train_wps": "8845.7", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "161", "train_lr": "1.50938e-05", "train_gnorm": "17.121", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "226"}
[2024-03-26 16:33:28,474][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:28,545][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 22
[2024-03-26 16:33:28,546][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:28,549][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:28,554][fairseq.trainer][INFO] - begin training epoch 22
[2024-03-26 16:33:28,555][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:35,468][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 169 updates
[2024-03-26 16:33:35,470][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:38,015][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:38,068][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 22 @ 169 updates, score None) (writing took 2.600147327873856 seconds)
[2024-03-26 16:33:38,070][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-03-26 16:33:38,070][train][INFO] - {"epoch": 22, "train_loss": "8.007", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.324", "train_masked_pct": "0.5", "train_wps": "8977.1", "train_ups": "0.83", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "169", "train_lr": "1.58437e-05", "train_gnorm": "16.305", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.5", "train_wall": "236"}
[2024-03-26 16:33:38,072][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:38,134][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 23
[2024-03-26 16:33:38,136][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:38,139][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:38,143][fairseq.trainer][INFO] - begin training epoch 23
[2024-03-26 16:33:38,144][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:45,266][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 177 updates
[2024-03-26 16:33:45,268][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:47,786][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:47,827][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 23 @ 177 updates, score None) (writing took 2.5605994509533048 seconds)
[2024-03-26 16:33:47,828][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-03-26 16:33:47,828][train][INFO] - {"epoch": 23, "train_loss": "7.508", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.313", "train_masked_pct": "0.501", "train_wps": "8829.9", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "177", "train_lr": "1.65938e-05", "train_gnorm": "14.51", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "246"}
[2024-03-26 16:33:47,831][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:47,907][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 24
[2024-03-26 16:33:47,909][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:47,912][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:47,917][fairseq.trainer][INFO] - begin training epoch 24
[2024-03-26 16:33:47,918][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:33:54,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 185 updates
[2024-03-26 16:33:54,970][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:57,455][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:33:57,504][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 24 @ 185 updates, score None) (writing took 2.53515540715307 seconds)
[2024-03-26 16:33:57,504][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-03-26 16:33:57,505][train][INFO] - {"epoch": 24, "train_loss": "7.103", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.303", "train_masked_pct": "0.499", "train_wps": "8904.3", "train_ups": "0.83", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "185", "train_lr": "1.73438e-05", "train_gnorm": "12.994", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "255"}
[2024-03-26 16:33:57,507][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:33:57,572][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 25
[2024-03-26 16:33:57,574][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:33:57,577][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:33:57,582][fairseq.trainer][INFO] - begin training epoch 25
[2024-03-26 16:33:57,582][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:04,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:34:04,697][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:04,763][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 6
[2024-03-26 16:34:04,767][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:05,156][valid][INFO] - {"epoch": 25, "valid_loss": "5.837", "valid_ntokens": "11698", "valid_nsentences": "25", "valid_sample_size": "11698", "valid_ema_decay": "999.003", "valid_target_var": "0.351", "valid_pred_var": "0.242", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11698", "valid_bsz": "25", "valid_num_updates": "193", "valid_best_loss": "5.837"}
[2024-03-26 16:34:05,158][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 193 updates
[2024-03-26 16:34:05,159][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:34:07,731][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:34:11,781][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 25 @ 193 updates, score 5.837) (writing took 6.623315955046564 seconds)
[2024-03-26 16:34:11,782][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-03-26 16:34:11,782][train][INFO] - {"epoch": 25, "train_loss": "6.721", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.002", "train_target_var": "0.351", "train_pred_var": "0.295", "train_masked_pct": "0.5", "train_wps": "6034.6", "train_ups": "0.56", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "193", "train_lr": "1.80937e-05", "train_gnorm": "11.88", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "270"}
[2024-03-26 16:34:11,784][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:11,847][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 26
[2024-03-26 16:34:11,849][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:34:11,852][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:11,857][fairseq.trainer][INFO] - begin training epoch 26
[2024-03-26 16:34:11,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:18,003][train_inner][INFO] - {"epoch": 26, "update": 25.875, "loss": "14.7", "ntokens": "10712.6", "nsentences": "22.755", "sample_size": "10712.6", "ema_decay": "999.001", "target_var": "0.351", "pred_var": "0.409", "masked_pct": "0.5", "wps": "8169.1", "ups": "0.76", "wpb": "10712.6", "bsz": "22.8", "num_updates": "200", "lr": "1.875e-05", "gnorm": "31.701", "loss_scale": "1", "train_wall": "178", "gb_free": "5.7", "wall": "276"}
[2024-03-26 16:34:18,985][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 201 updates
[2024-03-26 16:34:18,986][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:21,451][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:21,505][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 26 @ 201 updates, score None) (writing took 2.5201294738799334 seconds)
[2024-03-26 16:34:21,505][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-03-26 16:34:21,506][train][INFO] - {"epoch": 26, "train_loss": "6.353", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.003", "train_target_var": "0.351", "train_pred_var": "0.284", "train_masked_pct": "0.5", "train_wps": "8860.4", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "201", "train_lr": "1.88438e-05", "train_gnorm": "10.753", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "279"}
[2024-03-26 16:34:21,508][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:21,570][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 27
[2024-03-26 16:34:21,572][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:34:21,575][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:21,580][fairseq.trainer][INFO] - begin training epoch 27
[2024-03-26 16:34:21,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:28,666][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 209 updates
[2024-03-26 16:34:28,667][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:31,176][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:31,213][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 27 @ 209 updates, score None) (writing took 2.546536731068045 seconds)
[2024-03-26 16:34:31,213][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-03-26 16:34:31,214][train][INFO] - {"epoch": 27, "train_loss": "6.092", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.003", "train_target_var": "0.351", "train_pred_var": "0.276", "train_masked_pct": "0.501", "train_wps": "8875.8", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "209", "train_lr": "1.95938e-05", "train_gnorm": "9.669", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "289"}
[2024-03-26 16:34:31,216][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:31,301][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 28
[2024-03-26 16:34:31,302][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:34:31,305][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:31,310][fairseq.trainer][INFO] - begin training epoch 28
[2024-03-26 16:34:31,311][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:38,509][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 217 updates
[2024-03-26 16:34:38,511][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:40,945][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:40,998][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 28 @ 217 updates, score None) (writing took 2.4887552550062537 seconds)
[2024-03-26 16:34:40,998][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-03-26 16:34:40,999][train][INFO] - {"epoch": 28, "train_loss": "5.793", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.003", "train_target_var": "0.35", "train_pred_var": "0.268", "train_masked_pct": "0.5", "train_wps": "8805.2", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "217", "train_lr": "2.03437e-05", "train_gnorm": "8.622", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "299"}
[2024-03-26 16:34:41,002][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:41,065][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 29
[2024-03-26 16:34:41,067][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:34:41,070][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:41,075][fairseq.trainer][INFO] - begin training epoch 29
[2024-03-26 16:34:41,075][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:48,181][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 225 updates
[2024-03-26 16:34:48,183][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:50,687][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:34:50,742][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 29 @ 225 updates, score None) (writing took 2.5607271981425583 seconds)
[2024-03-26 16:34:50,743][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-03-26 16:34:50,743][train][INFO] - {"epoch": 29, "train_loss": "5.609", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.003", "train_target_var": "0.351", "train_pred_var": "0.26", "train_masked_pct": "0.5", "train_wps": "8842.7", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "225", "train_lr": "2.10938e-05", "train_gnorm": "7.661", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "309"}
[2024-03-26 16:34:50,745][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:50,808][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 30
[2024-03-26 16:34:50,809][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:34:50,812][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:50,817][fairseq.trainer][INFO] - begin training epoch 30
[2024-03-26 16:34:50,818][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:34:58,028][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:34:58,030][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:34:58,093][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 7
[2024-03-26 16:34:58,097][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:34:58,505][valid][INFO] - {"epoch": 30, "valid_loss": "4.776", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.003", "valid_target_var": "0.352", "valid_pred_var": "0.201", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "233", "valid_best_loss": "4.776"}
[2024-03-26 16:34:58,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 233 updates
[2024-03-26 16:34:58,508][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:35:01,113][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:35:05,169][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 30 @ 233 updates, score 4.776) (writing took 6.6624773079529405 seconds)
[2024-03-26 16:35:05,169][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-03-26 16:35:05,170][train][INFO] - {"epoch": 30, "train_loss": "5.401", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.003", "train_target_var": "0.351", "train_pred_var": "0.25", "train_masked_pct": "0.5", "train_wps": "5972", "train_ups": "0.55", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "233", "train_lr": "2.18437e-05", "train_gnorm": "6.987", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "323"}
[2024-03-26 16:35:05,172][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:05,239][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 31
[2024-03-26 16:35:05,241][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:05,244][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:05,249][fairseq.trainer][INFO] - begin training epoch 31
[2024-03-26 16:35:05,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:35:12,344][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 241 updates
[2024-03-26 16:35:12,346][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:14,831][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:14,884][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 31 @ 241 updates, score None) (writing took 2.540238986723125 seconds)
[2024-03-26 16:35:14,885][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-03-26 16:35:14,886][train][INFO] - {"epoch": 31, "train_loss": "5.235", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.003", "train_target_var": "0.35", "train_pred_var": "0.244", "train_masked_pct": "0.499", "train_wps": "8867.8", "train_ups": "0.82", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "241", "train_lr": "2.25938e-05", "train_gnorm": "6.367", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "333"}
[2024-03-26 16:35:14,888][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:14,949][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 32
[2024-03-26 16:35:14,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:14,954][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:14,959][fairseq.trainer][INFO] - begin training epoch 32
[2024-03-26 16:35:14,959][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:35:22,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 249 updates
[2024-03-26 16:35:22,243][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:24,724][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:24,778][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 32 @ 249 updates, score None) (writing took 2.5361491017974913 seconds)
[2024-03-26 16:35:24,778][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-03-26 16:35:24,779][train][INFO] - {"epoch": 32, "train_loss": "5.05", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.003", "train_target_var": "0.351", "train_pred_var": "0.234", "train_masked_pct": "0.499", "train_wps": "8709.2", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "249", "train_lr": "2.33438e-05", "train_gnorm": "5.56", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "343"}
[2024-03-26 16:35:24,782][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:24,844][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 33
[2024-03-26 16:35:24,846][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:24,849][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:24,854][fairseq.trainer][INFO] - begin training epoch 33
[2024-03-26 16:35:24,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:35:31,818][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 257 updates
[2024-03-26 16:35:31,820][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:34,304][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:34,346][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 33 @ 257 updates, score None) (writing took 2.5282311481423676 seconds)
[2024-03-26 16:35:34,347][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-03-26 16:35:34,348][train][INFO] - {"epoch": 33, "train_loss": "4.964", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.003", "train_target_var": "0.35", "train_pred_var": "0.229", "train_masked_pct": "0.499", "train_wps": "9004", "train_ups": "0.84", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "257", "train_lr": "2.40937e-05", "train_gnorm": "5.637", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "352"}
[2024-03-26 16:35:34,350][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:34,426][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 34
[2024-03-26 16:35:34,428][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:34,431][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:34,436][fairseq.trainer][INFO] - begin training epoch 34
[2024-03-26 16:35:34,436][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:35:41,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 265 updates
[2024-03-26 16:35:41,565][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:44,048][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:35:44,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 34 @ 265 updates, score None) (writing took 2.5356323989108205 seconds)
[2024-03-26 16:35:44,100][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-03-26 16:35:44,101][train][INFO] - {"epoch": 34, "train_loss": "4.806", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.003", "train_target_var": "0.35", "train_pred_var": "0.22", "train_masked_pct": "0.5", "train_wps": "8835.1", "train_ups": "0.82", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "265", "train_lr": "2.48438e-05", "train_gnorm": "4.957", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "362"}
[2024-03-26 16:35:44,103][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:44,167][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 35
[2024-03-26 16:35:44,168][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:44,171][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:44,176][fairseq.trainer][INFO] - begin training epoch 35
[2024-03-26 16:35:44,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:35:51,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:35:51,401][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:51,464][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 8
[2024-03-26 16:35:51,467][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:51,877][valid][INFO] - {"epoch": 35, "valid_loss": "4.222", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.004", "valid_target_var": "0.351", "valid_pred_var": "0.165", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "273", "valid_best_loss": "4.222"}
[2024-03-26 16:35:51,879][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 273 updates
[2024-03-26 16:35:51,880][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:35:54,477][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:35:58,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 35 @ 273 updates, score 4.222) (writing took 6.6890279720537364 seconds)
[2024-03-26 16:35:58,569][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-03-26 16:35:58,570][train][INFO] - {"epoch": 35, "train_loss": "4.702", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.004", "train_target_var": "0.35", "train_pred_var": "0.214", "train_masked_pct": "0.501", "train_wps": "5954.3", "train_ups": "0.55", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "273", "train_lr": "2.55938e-05", "train_gnorm": "5.674", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "376"}
[2024-03-26 16:35:58,573][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:35:58,635][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 36
[2024-03-26 16:35:58,636][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:35:58,639][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:35:58,644][fairseq.trainer][INFO] - begin training epoch 36
[2024-03-26 16:35:58,645][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:05,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 281 updates
[2024-03-26 16:36:05,721][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:08,189][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:08,241][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 36 @ 281 updates, score None) (writing took 2.5219360957853496 seconds)
[2024-03-26 16:36:08,242][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-03-26 16:36:08,242][train][INFO] - {"epoch": 36, "train_loss": "4.624", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.004", "train_target_var": "0.35", "train_pred_var": "0.207", "train_masked_pct": "0.501", "train_wps": "8908.1", "train_ups": "0.83", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "281", "train_lr": "2.63437e-05", "train_gnorm": "4.615", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "386"}
[2024-03-26 16:36:08,245][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:08,306][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 37
[2024-03-26 16:36:08,308][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:36:08,311][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:08,316][fairseq.trainer][INFO] - begin training epoch 37
[2024-03-26 16:36:08,316][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:15,399][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 289 updates
[2024-03-26 16:36:15,400][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:17,897][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:17,950][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 37 @ 289 updates, score None) (writing took 2.551418391056359 seconds)
[2024-03-26 16:36:17,951][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-03-26 16:36:17,952][train][INFO] - {"epoch": 37, "train_loss": "4.521", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.199", "train_masked_pct": "0.5", "train_wps": "8874", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "289", "train_lr": "2.70938e-05", "train_gnorm": "4.567", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "396"}
[2024-03-26 16:36:17,954][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:18,027][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 38
[2024-03-26 16:36:18,028][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:36:18,032][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:18,037][fairseq.trainer][INFO] - begin training epoch 38
[2024-03-26 16:36:18,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:25,138][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 297 updates
[2024-03-26 16:36:25,140][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:27,580][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:27,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 38 @ 297 updates, score None) (writing took 2.4961761138401926 seconds)
[2024-03-26 16:36:27,635][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-03-26 16:36:27,635][train][INFO] - {"epoch": 38, "train_loss": "4.465", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.195", "train_masked_pct": "0.5", "train_wps": "8898.4", "train_ups": "0.83", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "297", "train_lr": "2.78437e-05", "train_gnorm": "4.012", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "405"}
[2024-03-26 16:36:27,637][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:27,700][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 39
[2024-03-26 16:36:27,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:36:27,705][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:27,710][fairseq.trainer][INFO] - begin training epoch 39
[2024-03-26 16:36:27,711][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:34,864][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 305 updates
[2024-03-26 16:36:34,865][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:37,335][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:36:37,367][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 39 @ 305 updates, score None) (writing took 2.503443173132837 seconds)
[2024-03-26 16:36:37,368][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-03-26 16:36:37,368][train][INFO] - {"epoch": 39, "train_loss": "4.359", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.004", "train_target_var": "0.35", "train_pred_var": "0.187", "train_masked_pct": "0.501", "train_wps": "8853", "train_ups": "0.82", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "305", "train_lr": "2.85938e-05", "train_gnorm": "3.16", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "415"}
[2024-03-26 16:36:37,370][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:37,456][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 40
[2024-03-26 16:36:37,458][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:36:37,461][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:37,467][fairseq.trainer][INFO] - begin training epoch 40
[2024-03-26 16:36:37,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:44,724][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:36:44,725][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:44,798][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 9
[2024-03-26 16:36:44,802][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:45,190][valid][INFO] - {"epoch": 40, "valid_loss": "3.92", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.004", "valid_target_var": "0.35", "valid_pred_var": "0.138", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "313", "valid_best_loss": "3.92"}
[2024-03-26 16:36:45,192][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 313 updates
[2024-03-26 16:36:45,193][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:36:47,833][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:36:51,888][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 40 @ 313 updates, score 3.92) (writing took 6.696056132204831 seconds)
[2024-03-26 16:36:51,889][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-03-26 16:36:51,889][train][INFO] - {"epoch": 40, "train_loss": "4.29", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.181", "train_masked_pct": "0.499", "train_wps": "5933.1", "train_ups": "0.55", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "313", "train_lr": "2.93438e-05", "train_gnorm": "3.439", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "430"}
[2024-03-26 16:36:51,891][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:36:51,966][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 41
[2024-03-26 16:36:51,968][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:36:51,971][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:36:51,975][fairseq.trainer][INFO] - begin training epoch 41
[2024-03-26 16:36:51,976][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:36:59,186][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 321 updates
[2024-03-26 16:36:59,187][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:01,686][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:01,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 41 @ 321 updates, score None) (writing took 2.5538538359105587 seconds)
[2024-03-26 16:37:01,740][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-03-26 16:37:01,741][train][INFO] - {"epoch": 41, "train_loss": "4.211", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.176", "train_masked_pct": "0.499", "train_wps": "8745.5", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "321", "train_lr": "3.00937e-05", "train_gnorm": "2.755", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "440"}
[2024-03-26 16:37:01,743][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:01,807][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 42
[2024-03-26 16:37:01,809][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:01,812][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:01,817][fairseq.trainer][INFO] - begin training epoch 42
[2024-03-26 16:37:01,817][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:37:08,966][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 329 updates
[2024-03-26 16:37:08,968][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:11,519][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:11,554][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 42 @ 329 updates, score None) (writing took 2.587952708825469 seconds)
[2024-03-26 16:37:11,555][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-03-26 16:37:11,556][train][INFO] - {"epoch": 42, "train_loss": "4.172", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.172", "train_masked_pct": "0.501", "train_wps": "8778.6", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "329", "train_lr": "3.08438e-05", "train_gnorm": "3.528", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "449"}
[2024-03-26 16:37:11,558][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:11,639][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 43
[2024-03-26 16:37:11,641][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:11,644][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:11,649][fairseq.trainer][INFO] - begin training epoch 43
[2024-03-26 16:37:11,649][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:37:18,959][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 337 updates
[2024-03-26 16:37:18,963][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:21,451][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:21,506][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 43 @ 337 updates, score None) (writing took 2.547499106731266 seconds)
[2024-03-26 16:37:21,508][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-03-26 16:37:21,508][train][INFO] - {"epoch": 43, "train_loss": "4.101", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.166", "train_masked_pct": "0.499", "train_wps": "8657.3", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "337", "train_lr": "3.15937e-05", "train_gnorm": "2.888", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "459"}
[2024-03-26 16:37:21,511][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:21,575][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 44
[2024-03-26 16:37:21,576][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:21,580][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:21,585][fairseq.trainer][INFO] - begin training epoch 44
[2024-03-26 16:37:21,585][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:37:28,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 345 updates
[2024-03-26 16:37:28,791][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:31,275][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:31,320][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 44 @ 345 updates, score None) (writing took 2.5303903250023723 seconds)
[2024-03-26 16:37:31,320][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-03-26 16:37:31,321][train][INFO] - {"epoch": 44, "train_loss": "4.115", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.004", "train_target_var": "0.349", "train_pred_var": "0.165", "train_masked_pct": "0.499", "train_wps": "8779.7", "train_ups": "0.82", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "345", "train_lr": "3.23438e-05", "train_gnorm": "4.305", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "469"}
[2024-03-26 16:37:31,323][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:31,400][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 45
[2024-03-26 16:37:31,402][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:31,405][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:31,410][fairseq.trainer][INFO] - begin training epoch 45
[2024-03-26 16:37:31,410][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:37:38,626][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:37:38,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:38,707][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 10
[2024-03-26 16:37:38,710][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:39,119][valid][INFO] - {"epoch": 45, "valid_loss": "3.715", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.005", "valid_target_var": "0.35", "valid_pred_var": "0.119", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "353", "valid_best_loss": "3.715"}
[2024-03-26 16:37:39,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 353 updates
[2024-03-26 16:37:39,122][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:37:41,720][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:37:45,776][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 45 @ 353 updates, score 3.715) (writing took 6.655076626222581 seconds)
[2024-03-26 16:37:45,779][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-03-26 16:37:45,780][train][INFO] - {"epoch": 45, "train_loss": "4.011", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.005", "train_target_var": "0.349", "train_pred_var": "0.158", "train_masked_pct": "0.499", "train_wps": "5959", "train_ups": "0.55", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "353", "train_lr": "3.30938e-05", "train_gnorm": "2.743", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "484"}
[2024-03-26 16:37:45,782][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:45,851][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 46
[2024-03-26 16:37:45,852][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:45,855][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:45,861][fairseq.trainer][INFO] - begin training epoch 46
[2024-03-26 16:37:45,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:37:52,809][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 361 updates
[2024-03-26 16:37:52,810][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:55,311][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:37:55,364][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 46 @ 361 updates, score None) (writing took 2.554891411215067 seconds)
[2024-03-26 16:37:55,365][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-03-26 16:37:55,365][train][INFO] - {"epoch": 46, "train_loss": "4.011", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.005", "train_target_var": "0.35", "train_pred_var": "0.157", "train_masked_pct": "0.499", "train_wps": "8989.1", "train_ups": "0.83", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "361", "train_lr": "3.38437e-05", "train_gnorm": "4.876", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "493"}
[2024-03-26 16:37:55,367][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:37:55,437][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 47
[2024-03-26 16:37:55,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:37:55,442][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:37:55,446][fairseq.trainer][INFO] - begin training epoch 47
[2024-03-26 16:37:55,447][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:02,586][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 369 updates
[2024-03-26 16:38:02,587][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:05,098][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:05,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 47 @ 369 updates, score None) (writing took 2.555317458231002 seconds)
[2024-03-26 16:38:05,142][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-03-26 16:38:05,142][train][INFO] - {"epoch": 47, "train_loss": "3.904", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.005", "train_target_var": "0.346", "train_pred_var": "0.152", "train_masked_pct": "0.5", "train_wps": "8812", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "369", "train_lr": "3.45938e-05", "train_gnorm": "3.509", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "503"}
[2024-03-26 16:38:05,145][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:05,220][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 48
[2024-03-26 16:38:05,221][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:05,225][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:05,229][fairseq.trainer][INFO] - begin training epoch 48
[2024-03-26 16:38:05,230][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:12,401][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 377 updates
[2024-03-26 16:38:12,405][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:14,895][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:14,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 48 @ 377 updates, score None) (writing took 2.546841845382005 seconds)
[2024-03-26 16:38:14,948][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-03-26 16:38:14,949][train][INFO] - {"epoch": 48, "train_loss": "3.889", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.005", "train_target_var": "0.347", "train_pred_var": "0.152", "train_masked_pct": "0.498", "train_wps": "8785.7", "train_ups": "0.82", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "377", "train_lr": "3.53438e-05", "train_gnorm": "3.422", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "513"}
[2024-03-26 16:38:14,951][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:15,012][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 49
[2024-03-26 16:38:15,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:15,017][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:15,021][fairseq.trainer][INFO] - begin training epoch 49
[2024-03-26 16:38:15,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:22,175][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 385 updates
[2024-03-26 16:38:22,177][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:24,663][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:24,717][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 49 @ 385 updates, score None) (writing took 2.541969317011535 seconds)
[2024-03-26 16:38:24,718][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-03-26 16:38:24,718][train][INFO] - {"epoch": 49, "train_loss": "3.874", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.005", "train_target_var": "0.349", "train_pred_var": "0.147", "train_masked_pct": "0.5", "train_wps": "8819.8", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "385", "train_lr": "3.60937e-05", "train_gnorm": "4.805", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "523"}
[2024-03-26 16:38:24,720][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:24,781][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 50
[2024-03-26 16:38:24,783][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:24,789][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:24,793][fairseq.trainer][INFO] - begin training epoch 50
[2024-03-26 16:38:24,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:32,049][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:38:32,050][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:32,128][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 11
[2024-03-26 16:38:32,131][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:32,531][valid][INFO] - {"epoch": 50, "valid_loss": "3.548", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.005", "valid_target_var": "0.35", "valid_pred_var": "0.115", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "393", "valid_best_loss": "3.548"}
[2024-03-26 16:38:32,533][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 393 updates
[2024-03-26 16:38:32,535][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:38:35,111][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:38:39,121][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 50 @ 393 updates, score 3.548) (writing took 6.587864823173732 seconds)
[2024-03-26 16:38:39,121][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-03-26 16:38:39,122][train][INFO] - {"epoch": 50, "train_loss": "3.773", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.005", "train_target_var": "0.349", "train_pred_var": "0.147", "train_masked_pct": "0.5", "train_wps": "5981.5", "train_ups": "0.56", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "393", "train_lr": "3.68437e-05", "train_gnorm": "2.912", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "537"}
[2024-03-26 16:38:39,123][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:39,185][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 51
[2024-03-26 16:38:39,187][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:39,190][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:39,195][fairseq.trainer][INFO] - begin training epoch 51
[2024-03-26 16:38:39,195][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:45,424][train_inner][INFO] - {"epoch": 51, "update": 50.875, "loss": "4.561", "ntokens": "10769.3", "nsentences": "22.875", "sample_size": "10769.3", "ema_decay": "999.004", "target_var": "0.349", "pred_var": "0.197", "masked_pct": "0.5", "wps": "8054.2", "ups": "0.75", "wpb": "10769.3", "bsz": "22.9", "num_updates": "400", "lr": "3.75e-05", "gnorm": "4.796", "loss_scale": "1", "train_wall": "172", "gb_free": "5.1", "wall": "543"}
[2024-03-26 16:38:46,368][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 401 updates
[2024-03-26 16:38:46,370][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:48,851][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:48,909][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 51 @ 401 updates, score None) (writing took 2.5402336856350303 seconds)
[2024-03-26 16:38:48,910][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-03-26 16:38:48,910][train][INFO] - {"epoch": 51, "train_loss": "3.701", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.005", "train_target_var": "0.348", "train_pred_var": "0.143", "train_masked_pct": "0.499", "train_wps": "8801.4", "train_ups": "0.82", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "401", "train_lr": "3.75938e-05", "train_gnorm": "2.249", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "547"}
[2024-03-26 16:38:48,912][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:48,988][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 52
[2024-03-26 16:38:48,990][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:48,993][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:48,998][fairseq.trainer][INFO] - begin training epoch 52
[2024-03-26 16:38:48,998][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:38:56,219][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 409 updates
[2024-03-26 16:38:56,222][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:58,713][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:38:58,768][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 52 @ 409 updates, score None) (writing took 2.5488299657590687 seconds)
[2024-03-26 16:38:58,769][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-03-26 16:38:58,769][train][INFO] - {"epoch": 52, "train_loss": "3.645", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.005", "train_target_var": "0.348", "train_pred_var": "0.147", "train_masked_pct": "0.5", "train_wps": "8739.1", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "409", "train_lr": "3.83438e-05", "train_gnorm": "1.968", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "557"}
[2024-03-26 16:38:58,771][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:38:58,835][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 53
[2024-03-26 16:38:58,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:38:58,840][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:38:58,845][fairseq.trainer][INFO] - begin training epoch 53
[2024-03-26 16:38:58,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:06,135][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 417 updates
[2024-03-26 16:39:06,136][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:08,589][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:08,638][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 53 @ 417 updates, score None) (writing took 2.5032105958089232 seconds)
[2024-03-26 16:39:08,639][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-03-26 16:39:08,640][train][INFO] - {"epoch": 53, "train_loss": "3.631", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.005", "train_target_var": "0.347", "train_pred_var": "0.144", "train_masked_pct": "0.5", "train_wps": "8729.2", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "417", "train_lr": "3.90937e-05", "train_gnorm": "3.075", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "566"}
[2024-03-26 16:39:08,642][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:08,712][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 54
[2024-03-26 16:39:08,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:39:08,718][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:08,723][fairseq.trainer][INFO] - begin training epoch 54
[2024-03-26 16:39:08,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:15,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 425 updates
[2024-03-26 16:39:15,935][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:18,431][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:18,489][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 54 @ 425 updates, score None) (writing took 2.5556958517991006 seconds)
[2024-03-26 16:39:18,489][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-03-26 16:39:18,490][train][INFO] - {"epoch": 54, "train_loss": "3.545", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.006", "train_target_var": "0.347", "train_pred_var": "0.147", "train_masked_pct": "0.499", "train_wps": "8746.5", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "425", "train_lr": "3.98438e-05", "train_gnorm": "2.743", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "576"}
[2024-03-26 16:39:18,492][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:18,555][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 55
[2024-03-26 16:39:18,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:39:18,560][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:18,564][fairseq.trainer][INFO] - begin training epoch 55
[2024-03-26 16:39:18,565][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:25,853][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:39:25,854][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:25,930][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 12
[2024-03-26 16:39:25,934][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:26,334][valid][INFO] - {"epoch": 55, "valid_loss": "3.22", "valid_ntokens": "11704", "valid_nsentences": "25", "valid_sample_size": "11704", "valid_ema_decay": "999.006", "valid_target_var": "0.346", "valid_pred_var": "0.137", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11704", "valid_bsz": "25", "valid_num_updates": "433", "valid_best_loss": "3.22"}
[2024-03-26 16:39:26,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 433 updates
[2024-03-26 16:39:26,337][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:39:28,933][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:39:33,005][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 55 @ 433 updates, score 3.22) (writing took 6.670073565095663 seconds)
[2024-03-26 16:39:33,006][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-03-26 16:39:33,006][train][INFO] - {"epoch": 55, "train_loss": "3.485", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.006", "train_target_var": "0.347", "train_pred_var": "0.142", "train_masked_pct": "0.5", "train_wps": "5934.9", "train_ups": "0.55", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "433", "train_lr": "4.05938e-05", "train_gnorm": "2.25", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "591"}
[2024-03-26 16:39:33,009][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:33,078][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 56
[2024-03-26 16:39:33,079][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:39:33,082][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:33,087][fairseq.trainer][INFO] - begin training epoch 56
[2024-03-26 16:39:33,088][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:40,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 441 updates
[2024-03-26 16:39:40,087][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:42,558][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:42,612][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 56 @ 441 updates, score None) (writing took 2.5260058608837426 seconds)
[2024-03-26 16:39:42,613][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-03-26 16:39:42,613][train][INFO] - {"epoch": 56, "train_loss": "3.475", "train_ntokens": "10770.5", "train_nsentences": "22.875", "train_sample_size": "10770.5", "train_ema_decay": "999.006", "train_target_var": "0.349", "train_pred_var": "0.156", "train_masked_pct": "0.501", "train_wps": "8970", "train_ups": "0.83", "train_wpb": "10770.5", "train_bsz": "22.9", "train_num_updates": "441", "train_lr": "4.13437e-05", "train_gnorm": "3.23", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "600"}
[2024-03-26 16:39:42,615][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:42,678][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 57
[2024-03-26 16:39:42,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:39:42,683][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:42,688][fairseq.trainer][INFO] - begin training epoch 57
[2024-03-26 16:39:42,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:49,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 449 updates
[2024-03-26 16:39:49,847][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:52,322][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:39:52,357][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 57 @ 449 updates, score None) (writing took 2.511547404807061 seconds)
[2024-03-26 16:39:52,358][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-03-26 16:39:52,358][train][INFO] - {"epoch": 57, "train_loss": "3.378", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.006", "train_target_var": "0.349", "train_pred_var": "0.153", "train_masked_pct": "0.499", "train_wps": "8840.6", "train_ups": "0.82", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "449", "train_lr": "4.20938e-05", "train_gnorm": "2.574", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "610"}
[2024-03-26 16:39:52,360][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:39:52,441][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 58
[2024-03-26 16:39:52,443][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:39:52,446][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:39:52,451][fairseq.trainer][INFO] - begin training epoch 58
[2024-03-26 16:39:52,451][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:39:59,732][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 457 updates
[2024-03-26 16:39:59,733][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:02,202][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:02,258][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 58 @ 457 updates, score None) (writing took 2.5261908271349967 seconds)
[2024-03-26 16:40:02,259][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-03-26 16:40:02,260][train][INFO] - {"epoch": 58, "train_loss": "3.294", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.006", "train_target_var": "0.35", "train_pred_var": "0.161", "train_masked_pct": "0.499", "train_wps": "8702.1", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "457", "train_lr": "4.28438e-05", "train_gnorm": "2.246", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "620"}
[2024-03-26 16:40:02,262][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:02,326][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 59
[2024-03-26 16:40:02,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:02,331][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:02,336][fairseq.trainer][INFO] - begin training epoch 59
[2024-03-26 16:40:02,337][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:40:09,522][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 465 updates
[2024-03-26 16:40:09,524][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:11,991][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:12,032][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 59 @ 465 updates, score None) (writing took 2.5091395410709083 seconds)
[2024-03-26 16:40:12,032][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-03-26 16:40:12,033][train][INFO] - {"epoch": 59, "train_loss": "3.209", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.006", "train_target_var": "0.349", "train_pred_var": "0.167", "train_masked_pct": "0.499", "train_wps": "8816.9", "train_ups": "0.82", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "465", "train_lr": "4.35937e-05", "train_gnorm": "2.475", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "630"}
[2024-03-26 16:40:12,035][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:12,109][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 60
[2024-03-26 16:40:12,111][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:12,114][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:12,119][fairseq.trainer][INFO] - begin training epoch 60
[2024-03-26 16:40:12,119][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:40:19,118][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:40:19,120][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:19,193][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 13
[2024-03-26 16:40:19,196][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:19,595][valid][INFO] - {"epoch": 60, "valid_loss": "2.827", "valid_ntokens": "11723", "valid_nsentences": "25", "valid_sample_size": "11723", "valid_ema_decay": "999.006", "valid_target_var": "0.346", "valid_pred_var": "0.174", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11723", "valid_bsz": "25", "valid_num_updates": "473", "valid_best_loss": "2.827"}
[2024-03-26 16:40:19,596][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 473 updates
[2024-03-26 16:40:19,598][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:40:22,203][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:40:26,307][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 60 @ 473 updates, score 2.827) (writing took 6.710595118813217 seconds)
[2024-03-26 16:40:26,308][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-03-26 16:40:26,309][train][INFO] - {"epoch": 60, "train_loss": "3.085", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.006", "train_target_var": "0.346", "train_pred_var": "0.169", "train_masked_pct": "0.501", "train_wps": "6035", "train_ups": "0.56", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "473", "train_lr": "4.43438e-05", "train_gnorm": "2.301", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "644"}
[2024-03-26 16:40:26,311][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:26,382][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 61
[2024-03-26 16:40:26,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:26,387][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:26,392][fairseq.trainer][INFO] - begin training epoch 61
[2024-03-26 16:40:26,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:40:33,601][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 481 updates
[2024-03-26 16:40:33,602][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:36,088][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:36,143][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 61 @ 481 updates, score None) (writing took 2.541728602722287 seconds)
[2024-03-26 16:40:36,143][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-03-26 16:40:36,144][train][INFO] - {"epoch": 61, "train_loss": "2.998", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.006", "train_target_var": "0.35", "train_pred_var": "0.179", "train_masked_pct": "0.5", "train_wps": "8760.6", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "481", "train_lr": "4.50938e-05", "train_gnorm": "1.943", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "654"}
[2024-03-26 16:40:36,146][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:36,213][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 62
[2024-03-26 16:40:36,215][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:36,219][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:36,224][fairseq.trainer][INFO] - begin training epoch 62
[2024-03-26 16:40:36,224][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:40:43,347][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 489 updates
[2024-03-26 16:40:43,349][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:45,912][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:45,967][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 62 @ 489 updates, score None) (writing took 2.619440269190818 seconds)
[2024-03-26 16:40:45,967][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-03-26 16:40:45,968][train][INFO] - {"epoch": 62, "train_loss": "2.9", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.006", "train_target_var": "0.348", "train_pred_var": "0.186", "train_masked_pct": "0.499", "train_wps": "8769.7", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "489", "train_lr": "4.58437e-05", "train_gnorm": "3.44", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "664"}
[2024-03-26 16:40:45,971][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:46,037][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 63
[2024-03-26 16:40:46,038][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:46,041][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:46,046][fairseq.trainer][INFO] - begin training epoch 63
[2024-03-26 16:40:46,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:40:53,364][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 497 updates
[2024-03-26 16:40:53,366][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:55,854][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:40:55,908][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 63 @ 497 updates, score None) (writing took 2.5444110543467104 seconds)
[2024-03-26 16:40:55,909][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-03-26 16:40:55,910][train][INFO] - {"epoch": 63, "train_loss": "2.816", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.007", "train_target_var": "0.348", "train_pred_var": "0.19", "train_masked_pct": "0.501", "train_wps": "8668.1", "train_ups": "0.8", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "497", "train_lr": "4.65938e-05", "train_gnorm": "2.924", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "674"}
[2024-03-26 16:40:55,912][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:40:55,975][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 64
[2024-03-26 16:40:55,977][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:40:55,980][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:40:55,985][fairseq.trainer][INFO] - begin training epoch 64
[2024-03-26 16:40:55,985][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:03,222][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 505 updates
[2024-03-26 16:41:03,224][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:05,714][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:05,771][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 64 @ 505 updates, score None) (writing took 2.5485018347389996 seconds)
[2024-03-26 16:41:05,771][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-03-26 16:41:05,772][train][INFO] - {"epoch": 64, "train_loss": "2.749", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.007", "train_target_var": "0.351", "train_pred_var": "0.195", "train_masked_pct": "0.5", "train_wps": "8736.5", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "505", "train_lr": "4.73438e-05", "train_gnorm": "4.05", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "684"}
[2024-03-26 16:41:05,774][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:05,837][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 65
[2024-03-26 16:41:05,839][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:41:05,842][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:05,847][fairseq.trainer][INFO] - begin training epoch 65
[2024-03-26 16:41:05,847][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:13,058][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:41:13,059][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:13,135][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 14
[2024-03-26 16:41:13,139][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:13,549][valid][INFO] - {"epoch": 65, "valid_loss": "2.41", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.007", "valid_target_var": "0.351", "valid_pred_var": "0.218", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "513", "valid_best_loss": "2.41"}
[2024-03-26 16:41:13,551][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 513 updates
[2024-03-26 16:41:13,552][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:41:16,166][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:41:20,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 65 @ 513 updates, score 2.41) (writing took 6.743881817907095 seconds)
[2024-03-26 16:41:20,295][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-03-26 16:41:20,296][train][INFO] - {"epoch": 65, "train_loss": "2.662", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.007", "train_target_var": "0.351", "train_pred_var": "0.208", "train_masked_pct": "0.498", "train_wps": "5932.2", "train_ups": "0.55", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "513", "train_lr": "4.80938e-05", "train_gnorm": "3.819", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "698"}
[2024-03-26 16:41:20,298][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:20,366][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 66
[2024-03-26 16:41:20,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:41:20,370][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:20,375][fairseq.trainer][INFO] - begin training epoch 66
[2024-03-26 16:41:20,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:27,686][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 521 updates
[2024-03-26 16:41:27,688][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:30,169][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:30,204][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 66 @ 521 updates, score None) (writing took 2.5178748718462884 seconds)
[2024-03-26 16:41:30,205][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-03-26 16:41:30,205][train][INFO] - {"epoch": 66, "train_loss": "2.549", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.007", "train_target_var": "0.351", "train_pred_var": "0.211", "train_masked_pct": "0.5", "train_wps": "8694.7", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "521", "train_lr": "4.88437e-05", "train_gnorm": "2.771", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "708"}
[2024-03-26 16:41:30,207][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:30,289][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 67
[2024-03-26 16:41:30,291][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:41:30,294][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:30,299][fairseq.trainer][INFO] - begin training epoch 67
[2024-03-26 16:41:30,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:37,597][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 529 updates
[2024-03-26 16:41:37,599][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:40,154][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:40,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 67 @ 529 updates, score None) (writing took 2.612172899302095 seconds)
[2024-03-26 16:41:40,210][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-03-26 16:41:40,211][train][INFO] - {"epoch": 67, "train_loss": "2.455", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.007", "train_target_var": "0.352", "train_pred_var": "0.22", "train_masked_pct": "0.5", "train_wps": "8612.2", "train_ups": "0.8", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "529", "train_lr": "4.95938e-05", "train_gnorm": "2.33", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "718"}
[2024-03-26 16:41:40,213][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:40,275][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 68
[2024-03-26 16:41:40,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:41:40,280][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:40,284][fairseq.trainer][INFO] - begin training epoch 68
[2024-03-26 16:41:40,285][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:47,453][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 537 updates
[2024-03-26 16:41:47,455][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:49,939][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:49,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 68 @ 537 updates, score None) (writing took 2.5211380808614194 seconds)
[2024-03-26 16:41:49,975][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-03-26 16:41:49,976][train][INFO] - {"epoch": 68, "train_loss": "2.364", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.007", "train_target_var": "0.353", "train_pred_var": "0.227", "train_masked_pct": "0.501", "train_wps": "8822.6", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "537", "train_lr": "5.03438e-05", "train_gnorm": "2.087", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "728"}
[2024-03-26 16:41:49,978][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:50,068][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 69
[2024-03-26 16:41:50,070][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:41:50,073][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:41:50,079][fairseq.trainer][INFO] - begin training epoch 69
[2024-03-26 16:41:50,079][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:41:57,377][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 545 updates
[2024-03-26 16:41:57,379][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:59,875][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:41:59,927][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 69 @ 545 updates, score None) (writing took 2.5490968809463084 seconds)
[2024-03-26 16:41:59,927][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-03-26 16:41:59,928][train][INFO] - {"epoch": 69, "train_loss": "2.255", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.007", "train_target_var": "0.354", "train_pred_var": "0.232", "train_masked_pct": "0.5", "train_wps": "8657.1", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "545", "train_lr": "5.10937e-05", "train_gnorm": "1.989", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "738"}
[2024-03-26 16:41:59,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:41:59,998][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 70
[2024-03-26 16:42:00,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:00,003][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:00,008][fairseq.trainer][INFO] - begin training epoch 70
[2024-03-26 16:42:00,008][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:42:07,230][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:42:07,231][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:07,297][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 15
[2024-03-26 16:42:07,300][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:07,714][valid][INFO] - {"epoch": 70, "valid_loss": "2.005", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.007", "valid_target_var": "0.356", "valid_pred_var": "0.26", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "553", "valid_best_loss": "2.005"}
[2024-03-26 16:42:07,715][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 553 updates
[2024-03-26 16:42:07,717][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:42:10,327][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:42:14,404][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 70 @ 553 updates, score 2.005) (writing took 6.688631188124418 seconds)
[2024-03-26 16:42:14,405][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2024-03-26 16:42:14,406][train][INFO] - {"epoch": 70, "train_loss": "2.201", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.007", "train_target_var": "0.355", "train_pred_var": "0.237", "train_masked_pct": "0.501", "train_wps": "5951.4", "train_ups": "0.55", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "553", "train_lr": "5.18438e-05", "train_gnorm": "1.663", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "752"}
[2024-03-26 16:42:14,408][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:14,483][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 71
[2024-03-26 16:42:14,484][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:14,487][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:14,492][fairseq.trainer][INFO] - begin training epoch 71
[2024-03-26 16:42:14,493][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:42:21,641][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 561 updates
[2024-03-26 16:42:21,643][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:24,121][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:24,175][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 71 @ 561 updates, score None) (writing took 2.5337410159409046 seconds)
[2024-03-26 16:42:24,176][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2024-03-26 16:42:24,176][train][INFO] - {"epoch": 71, "train_loss": "2.094", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.007", "train_target_var": "0.352", "train_pred_var": "0.244", "train_masked_pct": "0.499", "train_wps": "8818.9", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "561", "train_lr": "5.25938e-05", "train_gnorm": "1.836", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "762"}
[2024-03-26 16:42:24,178][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:24,241][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 72
[2024-03-26 16:42:24,243][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:24,246][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:24,251][fairseq.trainer][INFO] - begin training epoch 72
[2024-03-26 16:42:24,251][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:42:31,323][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 569 updates
[2024-03-26 16:42:31,324][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:33,816][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:33,869][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 72 @ 569 updates, score None) (writing took 2.546742885839194 seconds)
[2024-03-26 16:42:33,870][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2024-03-26 16:42:33,871][train][INFO] - {"epoch": 72, "train_loss": "2.032", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.007", "train_target_var": "0.355", "train_pred_var": "0.249", "train_masked_pct": "0.501", "train_wps": "8887.5", "train_ups": "0.83", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "569", "train_lr": "5.33437e-05", "train_gnorm": "2.011", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.9", "train_wall": "772"}
[2024-03-26 16:42:33,873][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:33,943][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 73
[2024-03-26 16:42:33,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:33,948][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:33,953][fairseq.trainer][INFO] - begin training epoch 73
[2024-03-26 16:42:33,954][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:42:41,298][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 577 updates
[2024-03-26 16:42:41,299][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:43,736][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:43,790][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 73 @ 577 updates, score None) (writing took 2.492235481273383 seconds)
[2024-03-26 16:42:43,791][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2024-03-26 16:42:43,792][train][INFO] - {"epoch": 73, "train_loss": "1.924", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.008", "train_target_var": "0.357", "train_pred_var": "0.258", "train_masked_pct": "0.499", "train_wps": "8685", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "577", "train_lr": "5.40938e-05", "train_gnorm": "1.325", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "782"}
[2024-03-26 16:42:43,794][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:43,857][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 74
[2024-03-26 16:42:43,859][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:43,862][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:43,867][fairseq.trainer][INFO] - begin training epoch 74
[2024-03-26 16:42:43,867][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:42:51,103][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 585 updates
[2024-03-26 16:42:51,104][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:53,566][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:42:53,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 74 @ 585 updates, score None) (writing took 2.517978136893362 seconds)
[2024-03-26 16:42:53,621][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2024-03-26 16:42:53,622][train][INFO] - {"epoch": 74, "train_loss": "1.906", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.008", "train_target_var": "0.361", "train_pred_var": "0.266", "train_masked_pct": "0.501", "train_wps": "8764.3", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "585", "train_lr": "5.48438e-05", "train_gnorm": "2.481", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "791"}
[2024-03-26 16:42:53,624][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:42:53,687][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 75
[2024-03-26 16:42:53,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:42:53,692][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:42:53,697][fairseq.trainer][INFO] - begin training epoch 75
[2024-03-26 16:42:53,697][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:01,006][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:43:01,008][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:01,089][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 16
[2024-03-26 16:43:01,092][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:01,490][valid][INFO] - {"epoch": 75, "valid_loss": "1.621", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.008", "valid_target_var": "0.36", "valid_pred_var": "0.265", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "593", "valid_best_loss": "1.621"}
[2024-03-26 16:43:01,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 593 updates
[2024-03-26 16:43:01,492][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:43:04,093][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:43:08,146][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 75 @ 593 updates, score 1.621) (writing took 6.654389183968306 seconds)
[2024-03-26 16:43:08,146][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2024-03-26 16:43:08,147][train][INFO] - {"epoch": 75, "train_loss": "1.801", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.008", "train_target_var": "0.359", "train_pred_var": "0.266", "train_masked_pct": "0.499", "train_wps": "5931.6", "train_ups": "0.55", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "593", "train_lr": "5.55937e-05", "train_gnorm": "2.236", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "806"}
[2024-03-26 16:43:08,149][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:08,235][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 76
[2024-03-26 16:43:08,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:43:08,239][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:08,244][fairseq.trainer][INFO] - begin training epoch 76
[2024-03-26 16:43:08,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:15,318][train_inner][INFO] - {"epoch": 76, "update": 75.875, "loss": "2.734", "ntokens": "10826.1", "nsentences": "22.995", "sample_size": "10826.1", "ema_decay": "999.007", "target_var": "0.352", "pred_var": "0.201", "masked_pct": "0.5", "wps": "8022.5", "ups": "0.74", "wpb": "10826.1", "bsz": "23", "num_updates": "600", "lr": "5.625e-05", "gnorm": "2.479", "loss_scale": "1", "train_wall": "174", "gb_free": "5.4", "wall": "813"}
[2024-03-26 16:43:15,465][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 601 updates
[2024-03-26 16:43:15,466][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:17,913][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:17,955][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 76 @ 601 updates, score None) (writing took 2.4900813857093453 seconds)
[2024-03-26 16:43:17,955][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2024-03-26 16:43:17,956][train][INFO] - {"epoch": 76, "train_loss": "1.747", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.008", "train_target_var": "0.361", "train_pred_var": "0.275", "train_masked_pct": "0.499", "train_wps": "8784", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "601", "train_lr": "5.63438e-05", "train_gnorm": "2.442", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "816"}
[2024-03-26 16:43:17,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:18,031][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 77
[2024-03-26 16:43:18,033][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:43:18,036][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:18,041][fairseq.trainer][INFO] - begin training epoch 77
[2024-03-26 16:43:18,041][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:25,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 609 updates
[2024-03-26 16:43:25,120][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:27,605][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:27,659][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 77 @ 609 updates, score None) (writing took 2.5401085959747434 seconds)
[2024-03-26 16:43:27,660][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2024-03-26 16:43:27,660][train][INFO] - {"epoch": 77, "train_loss": "1.711", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.008", "train_target_var": "0.362", "train_pred_var": "0.278", "train_masked_pct": "0.499", "train_wps": "8878.3", "train_ups": "0.82", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "609", "train_lr": "5.70938e-05", "train_gnorm": "2.721", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "825"}
[2024-03-26 16:43:27,662][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:27,735][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 78
[2024-03-26 16:43:27,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:43:27,739][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:27,744][fairseq.trainer][INFO] - begin training epoch 78
[2024-03-26 16:43:27,745][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:35,042][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 617 updates
[2024-03-26 16:43:35,043][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:37,532][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:37,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 78 @ 617 updates, score None) (writing took 2.5264294878579676 seconds)
[2024-03-26 16:43:37,569][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2024-03-26 16:43:37,570][train][INFO] - {"epoch": 78, "train_loss": "1.639", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.008", "train_target_var": "0.365", "train_pred_var": "0.284", "train_masked_pct": "0.5", "train_wps": "8695", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "617", "train_lr": "5.78437e-05", "train_gnorm": "2.07", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "835"}
[2024-03-26 16:43:37,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:37,663][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 79
[2024-03-26 16:43:37,665][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:43:37,668][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:37,673][fairseq.trainer][INFO] - begin training epoch 79
[2024-03-26 16:43:37,674][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:44,835][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 625 updates
[2024-03-26 16:43:44,836][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:47,310][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:43:47,366][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 79 @ 625 updates, score None) (writing took 2.530845189001411 seconds)
[2024-03-26 16:43:47,366][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2024-03-26 16:43:47,367][train][INFO] - {"epoch": 79, "train_loss": "1.613", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.008", "train_target_var": "0.37", "train_pred_var": "0.292", "train_masked_pct": "0.5", "train_wps": "8793.8", "train_ups": "0.82", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "625", "train_lr": "5.85938e-05", "train_gnorm": "2.851", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "845"}
[2024-03-26 16:43:47,370][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:47,433][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 80
[2024-03-26 16:43:47,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:43:47,438][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:47,442][fairseq.trainer][INFO] - begin training epoch 80
[2024-03-26 16:43:47,443][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:43:54,675][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:43:54,676][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:43:54,751][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 17
[2024-03-26 16:43:54,754][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:43:55,168][valid][INFO] - {"epoch": 80, "valid_loss": "1.44", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.008", "valid_target_var": "0.375", "valid_pred_var": "0.318", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "633", "valid_best_loss": "1.44"}
[2024-03-26 16:43:55,170][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 633 updates
[2024-03-26 16:43:55,171][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:43:57,764][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:44:01,834][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 80 @ 633 updates, score 1.44) (writing took 6.6638547279872 seconds)
[2024-03-26 16:44:01,835][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2024-03-26 16:44:01,835][train][INFO] - {"epoch": 80, "train_loss": "1.563", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.008", "train_target_var": "0.369", "train_pred_var": "0.295", "train_masked_pct": "0.5", "train_wps": "5954.9", "train_ups": "0.55", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "633", "train_lr": "5.93438e-05", "train_gnorm": "2.234", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "860"}
[2024-03-26 16:44:01,838][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:01,909][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 81
[2024-03-26 16:44:01,911][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:01,914][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:01,919][fairseq.trainer][INFO] - begin training epoch 81
[2024-03-26 16:44:01,919][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:44:09,071][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 641 updates
[2024-03-26 16:44:09,072][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:11,560][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:11,616][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 81 @ 641 updates, score None) (writing took 2.545034671202302 seconds)
[2024-03-26 16:44:11,617][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2024-03-26 16:44:11,618][train][INFO] - {"epoch": 81, "train_loss": "1.489", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.008", "train_target_var": "0.367", "train_pred_var": "0.297", "train_masked_pct": "0.501", "train_wps": "8807.8", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "641", "train_lr": "6.00938e-05", "train_gnorm": "2.014", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "869"}
[2024-03-26 16:44:11,620][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:11,682][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 82
[2024-03-26 16:44:11,684][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:11,687][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:11,692][fairseq.trainer][INFO] - begin training epoch 82
[2024-03-26 16:44:11,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:44:18,875][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 649 updates
[2024-03-26 16:44:18,877][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:21,458][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:21,515][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 82 @ 649 updates, score None) (writing took 2.6403384967707098 seconds)
[2024-03-26 16:44:21,516][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2024-03-26 16:44:21,517][train][INFO] - {"epoch": 82, "train_loss": "1.427", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.009", "train_target_var": "0.369", "train_pred_var": "0.304", "train_masked_pct": "0.5", "train_wps": "8704", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "649", "train_lr": "6.08437e-05", "train_gnorm": "2.164", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "879"}
[2024-03-26 16:44:21,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:21,583][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 83
[2024-03-26 16:44:21,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:21,587][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:21,593][fairseq.trainer][INFO] - begin training epoch 83
[2024-03-26 16:44:21,593][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:44:28,706][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 657 updates
[2024-03-26 16:44:28,707][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:31,210][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:31,267][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 83 @ 657 updates, score None) (writing took 2.5608572042547166 seconds)
[2024-03-26 16:44:31,268][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2024-03-26 16:44:31,268][train][INFO] - {"epoch": 83, "train_loss": "1.44", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.009", "train_target_var": "0.375", "train_pred_var": "0.312", "train_masked_pct": "0.499", "train_wps": "8835.6", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "657", "train_lr": "6.15938e-05", "train_gnorm": "3.109", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "889"}
[2024-03-26 16:44:31,272][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:31,334][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 84
[2024-03-26 16:44:31,336][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:31,340][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:31,345][fairseq.trainer][INFO] - begin training epoch 84
[2024-03-26 16:44:31,345][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:44:38,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 665 updates
[2024-03-26 16:44:38,560][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:41,052][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:44:41,108][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 84 @ 665 updates, score None) (writing took 2.5490991789847612 seconds)
[2024-03-26 16:44:41,109][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2024-03-26 16:44:41,109][train][INFO] - {"epoch": 84, "train_loss": "1.394", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.009", "train_target_var": "0.376", "train_pred_var": "0.316", "train_masked_pct": "0.5", "train_wps": "8755.8", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "665", "train_lr": "6.23438e-05", "train_gnorm": "3.238", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "899"}
[2024-03-26 16:44:41,111][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:41,172][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 85
[2024-03-26 16:44:41,174][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:41,177][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:41,181][fairseq.trainer][INFO] - begin training epoch 85
[2024-03-26 16:44:41,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:44:48,418][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:44:48,420][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:48,493][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 18
[2024-03-26 16:44:48,497][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:48,899][valid][INFO] - {"epoch": 85, "valid_loss": "1.262", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.009", "valid_target_var": "0.383", "valid_pred_var": "0.324", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "673", "valid_best_loss": "1.262"}
[2024-03-26 16:44:48,900][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 673 updates
[2024-03-26 16:44:48,902][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:44:51,491][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:44:55,578][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 85 @ 673 updates, score 1.262) (writing took 6.677700483240187 seconds)
[2024-03-26 16:44:55,579][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2024-03-26 16:44:55,580][train][INFO] - {"epoch": 85, "train_loss": "1.274", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.009", "train_target_var": "0.378", "train_pred_var": "0.319", "train_masked_pct": "0.498", "train_wps": "5953.2", "train_ups": "0.55", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "673", "train_lr": "6.30937e-05", "train_gnorm": "2.458", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "913"}
[2024-03-26 16:44:55,582][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:44:55,645][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 86
[2024-03-26 16:44:55,646][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:44:55,649][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:44:55,654][fairseq.trainer][INFO] - begin training epoch 86
[2024-03-26 16:44:55,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:02,708][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 681 updates
[2024-03-26 16:45:02,709][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:05,198][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:05,229][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 86 @ 681 updates, score None) (writing took 2.521513756364584 seconds)
[2024-03-26 16:45:05,230][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2024-03-26 16:45:05,230][train][INFO] - {"epoch": 86, "train_loss": "1.33", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.009", "train_target_var": "0.381", "train_pred_var": "0.325", "train_masked_pct": "0.499", "train_wps": "8927.4", "train_ups": "0.83", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "681", "train_lr": "6.38438e-05", "train_gnorm": "2.629", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "923"}
[2024-03-26 16:45:05,232][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:05,319][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 87
[2024-03-26 16:45:05,321][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:05,324][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:05,329][fairseq.trainer][INFO] - begin training epoch 87
[2024-03-26 16:45:05,329][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:12,583][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 689 updates
[2024-03-26 16:45:12,585][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:15,093][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:15,132][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 87 @ 689 updates, score None) (writing took 2.5493888901546597 seconds)
[2024-03-26 16:45:15,133][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2024-03-26 16:45:15,133][train][INFO] - {"epoch": 87, "train_loss": "1.266", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.009", "train_target_var": "0.38", "train_pred_var": "0.324", "train_masked_pct": "0.5", "train_wps": "8700.4", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "689", "train_lr": "6.45938e-05", "train_gnorm": "2.651", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "933"}
[2024-03-26 16:45:15,135][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:15,218][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 88
[2024-03-26 16:45:15,220][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:15,223][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:15,228][fairseq.trainer][INFO] - begin training epoch 88
[2024-03-26 16:45:15,228][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:22,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 697 updates
[2024-03-26 16:45:22,445][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:24,884][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:24,919][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 88 @ 697 updates, score None) (writing took 2.4756838460452855 seconds)
[2024-03-26 16:45:24,920][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2024-03-26 16:45:24,920][train][INFO] - {"epoch": 88, "train_loss": "1.223", "train_ntokens": "10768", "train_nsentences": "22.875", "train_sample_size": "10768", "train_ema_decay": "999.009", "train_target_var": "0.387", "train_pred_var": "0.331", "train_masked_pct": "0.501", "train_wps": "8802.4", "train_ups": "0.82", "train_wpb": "10768", "train_bsz": "22.9", "train_num_updates": "697", "train_lr": "6.53437e-05", "train_gnorm": "2.603", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "943"}
[2024-03-26 16:45:24,922][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:25,004][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 89
[2024-03-26 16:45:25,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:25,009][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:25,013][fairseq.trainer][INFO] - begin training epoch 89
[2024-03-26 16:45:25,014][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:32,200][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 705 updates
[2024-03-26 16:45:32,202][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:34,665][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:34,720][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 89 @ 705 updates, score None) (writing took 2.5196482739411294 seconds)
[2024-03-26 16:45:34,721][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2024-03-26 16:45:34,722][train][INFO] - {"epoch": 89, "train_loss": "1.171", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.009", "train_target_var": "0.388", "train_pred_var": "0.343", "train_masked_pct": "0.501", "train_wps": "8790.5", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "705", "train_lr": "6.60938e-05", "train_gnorm": "2.141", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "953"}
[2024-03-26 16:45:34,724][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:34,787][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 90
[2024-03-26 16:45:34,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:34,791][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:34,796][fairseq.trainer][INFO] - begin training epoch 90
[2024-03-26 16:45:34,797][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:42,203][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:45:42,205][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:42,278][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 19
[2024-03-26 16:45:42,281][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:42,680][valid][INFO] - {"epoch": 90, "valid_loss": "1.17", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.009", "valid_target_var": "0.397", "valid_pred_var": "0.354", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "713", "valid_best_loss": "1.17"}
[2024-03-26 16:45:42,681][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 713 updates
[2024-03-26 16:45:42,683][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:45:45,290][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:45:49,358][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 90 @ 713 updates, score 1.17) (writing took 6.676382243167609 seconds)
[2024-03-26 16:45:49,358][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2024-03-26 16:45:49,359][train][INFO] - {"epoch": 90, "train_loss": "1.123", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.009", "train_target_var": "0.387", "train_pred_var": "0.339", "train_masked_pct": "0.5", "train_wps": "5886.5", "train_ups": "0.55", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "713", "train_lr": "6.68437e-05", "train_gnorm": "1.989", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "967"}
[2024-03-26 16:45:49,361][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:49,427][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 91
[2024-03-26 16:45:49,428][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:49,431][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:49,436][fairseq.trainer][INFO] - begin training epoch 91
[2024-03-26 16:45:49,437][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:45:56,774][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 721 updates
[2024-03-26 16:45:56,776][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:59,258][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:45:59,313][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 91 @ 721 updates, score None) (writing took 2.5383504880592227 seconds)
[2024-03-26 16:45:59,313][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2024-03-26 16:45:59,314][train][INFO] - {"epoch": 91, "train_loss": "1.071", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.009", "train_target_var": "0.391", "train_pred_var": "0.348", "train_masked_pct": "0.499", "train_wps": "8654.5", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "721", "train_lr": "6.75937e-05", "train_gnorm": "1.469", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "977"}
[2024-03-26 16:45:59,316][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:45:59,380][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 92
[2024-03-26 16:45:59,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:45:59,384][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:45:59,389][fairseq.trainer][INFO] - begin training epoch 92
[2024-03-26 16:45:59,390][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:46:06,570][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 729 updates
[2024-03-26 16:46:06,571][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:09,058][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:09,113][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 92 @ 729 updates, score None) (writing took 2.543636925984174 seconds)
[2024-03-26 16:46:09,114][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2024-03-26 16:46:09,114][train][INFO] - {"epoch": 92, "train_loss": "1.073", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.01", "train_target_var": "0.394", "train_pred_var": "0.348", "train_masked_pct": "0.501", "train_wps": "8791.4", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "729", "train_lr": "6.83438e-05", "train_gnorm": "2.395", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "987"}
[2024-03-26 16:46:09,116][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:09,181][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 93
[2024-03-26 16:46:09,183][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:46:09,186][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:09,191][fairseq.trainer][INFO] - begin training epoch 93
[2024-03-26 16:46:09,191][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:46:16,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 737 updates
[2024-03-26 16:46:16,517][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:18,998][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:19,045][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 93 @ 737 updates, score None) (writing took 2.5294403322041035 seconds)
[2024-03-26 16:46:19,046][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2024-03-26 16:46:19,047][train][INFO] - {"epoch": 93, "train_loss": "0.975", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.01", "train_target_var": "0.393", "train_pred_var": "0.353", "train_masked_pct": "0.498", "train_wps": "8673.7", "train_ups": "0.81", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "737", "train_lr": "6.90937e-05", "train_gnorm": "1.801", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "997"}
[2024-03-26 16:46:19,050][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:19,123][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 94
[2024-03-26 16:46:19,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:46:19,128][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:19,133][fairseq.trainer][INFO] - begin training epoch 94
[2024-03-26 16:46:19,133][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:46:26,396][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 745 updates
[2024-03-26 16:46:26,397][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:28,853][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:28,888][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 94 @ 745 updates, score None) (writing took 2.4926064321771264 seconds)
[2024-03-26 16:46:28,889][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2024-03-26 16:46:28,890][train][INFO] - {"epoch": 94, "train_loss": "0.993", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.01", "train_target_var": "0.401", "train_pred_var": "0.363", "train_masked_pct": "0.501", "train_wps": "8753.4", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "745", "train_lr": "6.98438e-05", "train_gnorm": "2.759", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "1007"}
[2024-03-26 16:46:28,892][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:28,976][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 95
[2024-03-26 16:46:28,977][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:46:28,981][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:28,985][fairseq.trainer][INFO] - begin training epoch 95
[2024-03-26 16:46:28,986][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:46:36,128][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:46:36,129][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:36,203][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 20
[2024-03-26 16:46:36,206][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:36,598][valid][INFO] - {"epoch": 95, "valid_loss": "1", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.01", "valid_target_var": "0.402", "valid_pred_var": "0.355", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "753", "valid_best_loss": "1"}
[2024-03-26 16:46:36,599][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 753 updates
[2024-03-26 16:46:36,601][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:46:39,212][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:46:43,365][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 95 @ 753 updates, score 1.0) (writing took 6.765516045037657 seconds)
[2024-03-26 16:46:43,366][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2024-03-26 16:46:43,366][train][INFO] - {"epoch": 95, "train_loss": "1.048", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.01", "train_target_var": "0.4", "train_pred_var": "0.362", "train_masked_pct": "0.499", "train_wps": "5951.9", "train_ups": "0.55", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "753", "train_lr": "7.05938e-05", "train_gnorm": "4.528", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1021"}
[2024-03-26 16:46:43,368][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:43,431][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 96
[2024-03-26 16:46:43,433][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:46:43,436][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:43,441][fairseq.trainer][INFO] - begin training epoch 96
[2024-03-26 16:46:43,441][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:46:50,478][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 761 updates
[2024-03-26 16:46:50,482][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:52,984][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:46:53,038][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 96 @ 761 updates, score None) (writing took 2.560549098998308 seconds)
[2024-03-26 16:46:53,039][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2024-03-26 16:46:53,039][train][INFO] - {"epoch": 96, "train_loss": "1.004", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.01", "train_target_var": "0.401", "train_pred_var": "0.362", "train_masked_pct": "0.501", "train_wps": "8907.4", "train_ups": "0.83", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "761", "train_lr": "7.13437e-05", "train_gnorm": "3.373", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1031"}
[2024-03-26 16:46:53,041][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:46:53,102][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 97
[2024-03-26 16:46:53,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:46:53,106][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:46:53,111][fairseq.trainer][INFO] - begin training epoch 97
[2024-03-26 16:46:53,112][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:00,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 97 @ 769 updates
[2024-03-26 16:47:00,389][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:02,904][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:02,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 97 @ 769 updates, score None) (writing took 2.5710291769355536 seconds)
[2024-03-26 16:47:02,960][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2024-03-26 16:47:02,960][train][INFO] - {"epoch": 97, "train_loss": "0.972", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.01", "train_target_var": "0.409", "train_pred_var": "0.369", "train_masked_pct": "0.501", "train_wps": "8683.9", "train_ups": "0.81", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "769", "train_lr": "7.20938e-05", "train_gnorm": "2.808", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1041"}
[2024-03-26 16:47:02,963][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:03,026][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 98
[2024-03-26 16:47:03,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:03,030][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:03,035][fairseq.trainer][INFO] - begin training epoch 98
[2024-03-26 16:47:03,036][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:10,296][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 98 @ 777 updates
[2024-03-26 16:47:10,297][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:12,757][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:12,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 98 @ 777 updates, score None) (writing took 2.5151438801549375 seconds)
[2024-03-26 16:47:12,811][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2024-03-26 16:47:12,812][train][INFO] - {"epoch": 98, "train_loss": "0.913", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.01", "train_target_var": "0.413", "train_pred_var": "0.379", "train_masked_pct": "0.5", "train_wps": "8746.6", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "777", "train_lr": "7.28438e-05", "train_gnorm": "1.831", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1051"}
[2024-03-26 16:47:12,815][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:12,877][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 99
[2024-03-26 16:47:12,879][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:12,881][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:12,886][fairseq.trainer][INFO] - begin training epoch 99
[2024-03-26 16:47:12,886][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:20,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 99 @ 785 updates
[2024-03-26 16:47:20,246][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:22,695][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:22,750][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 99 @ 785 updates, score None) (writing took 2.5052340333350003 seconds)
[2024-03-26 16:47:22,750][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2024-03-26 16:47:22,751][train][INFO] - {"epoch": 99, "train_loss": "0.898", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.01", "train_target_var": "0.416", "train_pred_var": "0.382", "train_masked_pct": "0.5", "train_wps": "8669.7", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "785", "train_lr": "7.35937e-05", "train_gnorm": "1.674", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "1061"}
[2024-03-26 16:47:22,753][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:22,816][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 100
[2024-03-26 16:47:22,817][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:22,820][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:22,825][fairseq.trainer][INFO] - begin training epoch 100
[2024-03-26 16:47:22,826][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:30,078][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:47:30,079][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:30,144][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 21
[2024-03-26 16:47:30,147][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:30,556][valid][INFO] - {"epoch": 100, "valid_loss": "0.848", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.01", "valid_target_var": "0.419", "valid_pred_var": "0.357", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "793", "valid_best_loss": "0.848"}
[2024-03-26 16:47:30,557][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 793 updates
[2024-03-26 16:47:30,559][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:47:33,148][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:47:37,242][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 100 @ 793 updates, score 0.848) (writing took 6.684694413095713 seconds)
[2024-03-26 16:47:37,243][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2024-03-26 16:47:37,244][train][INFO] - {"epoch": 100, "train_loss": "0.892", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.01", "train_target_var": "0.417", "train_pred_var": "0.388", "train_masked_pct": "0.499", "train_wps": "5944.7", "train_ups": "0.55", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "793", "train_lr": "7.43438e-05", "train_gnorm": "2.21", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1075"}
[2024-03-26 16:47:37,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:37,312][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 101
[2024-03-26 16:47:37,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:37,317][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:37,322][fairseq.trainer][INFO] - begin training epoch 101
[2024-03-26 16:47:37,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:43,513][train_inner][INFO] - {"epoch": 101, "update": 100.875, "loss": "1.218", "ntokens": "10714.7", "nsentences": "22.76", "sample_size": "10714.7", "ema_decay": "999.009", "target_var": "0.388", "pred_var": "0.335", "masked_pct": "0.5", "wps": "7990.2", "ups": "0.75", "wpb": "10714.7", "bsz": "22.8", "num_updates": "800", "lr": "7.5e-05", "gnorm": "2.521", "loss_scale": "1", "train_wall": "173", "gb_free": "5.8", "wall": "1081"}
[2024-03-26 16:47:44,436][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 101 @ 801 updates
[2024-03-26 16:47:44,437][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:46,908][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:46,963][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 101 @ 801 updates, score None) (writing took 2.527752298861742 seconds)
[2024-03-26 16:47:46,964][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2024-03-26 16:47:46,965][train][INFO] - {"epoch": 101, "train_loss": "0.903", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.011", "train_target_var": "0.415", "train_pred_var": "0.383", "train_masked_pct": "0.501", "train_wps": "8863.8", "train_ups": "0.82", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "801", "train_lr": "7.50938e-05", "train_gnorm": "3.319", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1085"}
[2024-03-26 16:47:46,967][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:47,029][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 102
[2024-03-26 16:47:47,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:47,034][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:47,039][fairseq.trainer][INFO] - begin training epoch 102
[2024-03-26 16:47:47,039][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:47:54,280][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 102 @ 809 updates
[2024-03-26 16:47:54,284][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:56,770][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:47:56,817][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 102 @ 809 updates, score None) (writing took 2.5365287009626627 seconds)
[2024-03-26 16:47:56,818][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2024-03-26 16:47:56,819][train][INFO] - {"epoch": 102, "train_loss": "0.877", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.011", "train_target_var": "0.425", "train_pred_var": "0.397", "train_masked_pct": "0.5", "train_wps": "8743", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "809", "train_lr": "7.58437e-05", "train_gnorm": "2.525", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1095"}
[2024-03-26 16:47:56,822][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:47:56,894][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 103
[2024-03-26 16:47:56,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:47:56,899][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:47:56,904][fairseq.trainer][INFO] - begin training epoch 103
[2024-03-26 16:47:56,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:04,148][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 103 @ 817 updates
[2024-03-26 16:48:04,149][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:06,619][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:06,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 103 @ 817 updates, score None) (writing took 2.515484663657844 seconds)
[2024-03-26 16:48:06,664][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2024-03-26 16:48:06,664][train][INFO] - {"epoch": 103, "train_loss": "0.85", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.011", "train_target_var": "0.425", "train_pred_var": "0.391", "train_masked_pct": "0.499", "train_wps": "8751.2", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "817", "train_lr": "7.65938e-05", "train_gnorm": "3.065", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1104"}
[2024-03-26 16:48:06,666][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:06,743][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 104
[2024-03-26 16:48:06,744][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:48:06,748][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:06,753][fairseq.trainer][INFO] - begin training epoch 104
[2024-03-26 16:48:06,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:13,868][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 104 @ 825 updates
[2024-03-26 16:48:13,869][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:16,356][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:16,401][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 104 @ 825 updates, score None) (writing took 2.5327983764000237 seconds)
[2024-03-26 16:48:16,401][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2024-03-26 16:48:16,402][train][INFO] - {"epoch": 104, "train_loss": "0.844", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.011", "train_target_var": "0.429", "train_pred_var": "0.401", "train_masked_pct": "0.499", "train_wps": "8847.9", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "825", "train_lr": "7.73438e-05", "train_gnorm": "3.201", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "1114"}
[2024-03-26 16:48:16,405][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:16,481][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 105
[2024-03-26 16:48:16,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:48:16,486][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:16,490][fairseq.trainer][INFO] - begin training epoch 105
[2024-03-26 16:48:16,490][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:23,614][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:48:23,616][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:23,685][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 22
[2024-03-26 16:48:23,688][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:24,108][valid][INFO] - {"epoch": 105, "valid_loss": "0.745", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.011", "valid_target_var": "0.433", "valid_pred_var": "0.411", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "833", "valid_best_loss": "0.745"}
[2024-03-26 16:48:24,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 833 updates
[2024-03-26 16:48:24,112][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:48:26,754][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:48:30,787][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 105 @ 833 updates, score 0.745) (writing took 6.676992393098772 seconds)
[2024-03-26 16:48:30,787][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2024-03-26 16:48:30,788][train][INFO] - {"epoch": 105, "train_loss": "0.778", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.011", "train_target_var": "0.429", "train_pred_var": "0.402", "train_masked_pct": "0.501", "train_wps": "5989.3", "train_ups": "0.56", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "833", "train_lr": "7.80937e-05", "train_gnorm": "2.141", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1129"}
[2024-03-26 16:48:30,790][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:30,872][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 106
[2024-03-26 16:48:30,874][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:48:30,877][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:30,882][fairseq.trainer][INFO] - begin training epoch 106
[2024-03-26 16:48:30,882][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:38,089][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 106 @ 841 updates
[2024-03-26 16:48:38,091][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:40,590][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:40,646][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 106 @ 841 updates, score None) (writing took 2.5567056289874017 seconds)
[2024-03-26 16:48:40,647][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2024-03-26 16:48:40,647][train][INFO] - {"epoch": 106, "train_loss": "0.762", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.011", "train_target_var": "0.43", "train_pred_var": "0.404", "train_masked_pct": "0.498", "train_wps": "8738.9", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "841", "train_lr": "7.88438e-05", "train_gnorm": "2.037", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "1138"}
[2024-03-26 16:48:40,650][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:40,712][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 107
[2024-03-26 16:48:40,713][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:48:40,716][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:40,721][fairseq.trainer][INFO] - begin training epoch 107
[2024-03-26 16:48:40,722][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:48,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 107 @ 849 updates
[2024-03-26 16:48:48,087][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:50,580][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:48:50,640][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 107 @ 849 updates, score None) (writing took 2.5537238619290292 seconds)
[2024-03-26 16:48:50,640][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2024-03-26 16:48:50,641][train][INFO] - {"epoch": 107, "train_loss": "0.73", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.011", "train_target_var": "0.436", "train_pred_var": "0.411", "train_masked_pct": "0.498", "train_wps": "8621.6", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "849", "train_lr": "7.95938e-05", "train_gnorm": "2.114", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1148"}
[2024-03-26 16:48:50,643][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:48:50,716][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 108
[2024-03-26 16:48:50,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:48:50,721][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:48:50,726][fairseq.trainer][INFO] - begin training epoch 108
[2024-03-26 16:48:50,727][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:48:57,700][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 108 @ 857 updates
[2024-03-26 16:48:57,701][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:00,151][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:00,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 108 @ 857 updates, score None) (writing took 2.5091063580475748 seconds)
[2024-03-26 16:49:00,209][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2024-03-26 16:49:00,210][train][INFO] - {"epoch": 108, "train_loss": "0.806", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.011", "train_target_var": "0.44", "train_pred_var": "0.416", "train_masked_pct": "0.5", "train_wps": "9004.1", "train_ups": "0.84", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "857", "train_lr": "8.03437e-05", "train_gnorm": "3.67", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1158"}
[2024-03-26 16:49:00,212][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:00,276][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 109
[2024-03-26 16:49:00,278][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:00,281][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:00,286][fairseq.trainer][INFO] - begin training epoch 109
[2024-03-26 16:49:00,286][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:49:07,593][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 109 @ 865 updates
[2024-03-26 16:49:07,594][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:10,073][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:10,133][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 109 @ 865 updates, score None) (writing took 2.540778674185276 seconds)
[2024-03-26 16:49:10,134][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2024-03-26 16:49:10,134][train][INFO] - {"epoch": 109, "train_loss": "0.754", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.011", "train_target_var": "0.445", "train_pred_var": "0.419", "train_masked_pct": "0.499", "train_wps": "8681.5", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "865", "train_lr": "8.10938e-05", "train_gnorm": "2.647", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "1168"}
[2024-03-26 16:49:10,136][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:10,200][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 110
[2024-03-26 16:49:10,202][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:10,205][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:10,209][fairseq.trainer][INFO] - begin training epoch 110
[2024-03-26 16:49:10,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:49:17,568][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:49:17,569][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:17,647][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 23
[2024-03-26 16:49:17,650][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:18,066][valid][INFO] - {"epoch": 110, "valid_loss": "0.702", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.012", "valid_target_var": "0.449", "valid_pred_var": "0.437", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "873", "valid_best_loss": "0.702"}
[2024-03-26 16:49:18,068][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 873 updates
[2024-03-26 16:49:18,069][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:49:20,706][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:49:24,830][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 110 @ 873 updates, score 0.702) (writing took 6.762599057983607 seconds)
[2024-03-26 16:49:24,831][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2024-03-26 16:49:24,831][train][INFO] - {"epoch": 110, "train_loss": "0.729", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.011", "train_target_var": "0.451", "train_pred_var": "0.426", "train_masked_pct": "0.499", "train_wps": "5862.3", "train_ups": "0.54", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "873", "train_lr": "8.18438e-05", "train_gnorm": "2.095", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1183"}
[2024-03-26 16:49:24,834][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:24,905][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 111
[2024-03-26 16:49:24,907][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:24,910][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:24,915][fairseq.trainer][INFO] - begin training epoch 111
[2024-03-26 16:49:24,915][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:49:32,070][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 111 @ 881 updates
[2024-03-26 16:49:32,071][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:34,574][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:34,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 111 @ 881 updates, score None) (writing took 2.547754938248545 seconds)
[2024-03-26 16:49:34,618][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2024-03-26 16:49:34,618][train][INFO] - {"epoch": 111, "train_loss": "0.725", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.012", "train_target_var": "0.455", "train_pred_var": "0.433", "train_masked_pct": "0.5", "train_wps": "8804.5", "train_ups": "0.82", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "881", "train_lr": "8.25937e-05", "train_gnorm": "2.149", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1192"}
[2024-03-26 16:49:34,620][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:34,697][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 112
[2024-03-26 16:49:34,699][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:34,702][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:34,707][fairseq.trainer][INFO] - begin training epoch 112
[2024-03-26 16:49:34,707][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:49:41,746][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 112 @ 889 updates
[2024-03-26 16:49:41,747][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:44,246][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:44,304][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 112 @ 889 updates, score None) (writing took 2.5583501108922064 seconds)
[2024-03-26 16:49:44,304][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2024-03-26 16:49:44,305][train][INFO] - {"epoch": 112, "train_loss": "0.731", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.012", "train_target_var": "0.456", "train_pred_var": "0.432", "train_masked_pct": "0.5", "train_wps": "8894.8", "train_ups": "0.83", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "889", "train_lr": "8.33438e-05", "train_gnorm": "2.882", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1202"}
[2024-03-26 16:49:44,307][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:44,370][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 113
[2024-03-26 16:49:44,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:44,375][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:44,379][fairseq.trainer][INFO] - begin training epoch 113
[2024-03-26 16:49:44,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:49:51,604][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 113 @ 897 updates
[2024-03-26 16:49:51,606][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:54,097][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:49:54,156][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 113 @ 897 updates, score None) (writing took 2.551681937184185 seconds)
[2024-03-26 16:49:54,157][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-03-26 16:49:54,157][train][INFO] - {"epoch": 113, "train_loss": "0.69", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.012", "train_target_var": "0.461", "train_pred_var": "0.438", "train_masked_pct": "0.499", "train_wps": "8745", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "897", "train_lr": "8.40938e-05", "train_gnorm": "2.59", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1212"}
[2024-03-26 16:49:54,159][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:49:54,222][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 114
[2024-03-26 16:49:54,223][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:49:54,226][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:49:54,231][fairseq.trainer][INFO] - begin training epoch 114
[2024-03-26 16:49:54,231][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:01,424][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 114 @ 905 updates
[2024-03-26 16:50:01,425][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:03,902][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:03,960][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 114 @ 905 updates, score None) (writing took 2.536077951081097 seconds)
[2024-03-26 16:50:03,960][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-03-26 16:50:03,961][train][INFO] - {"epoch": 114, "train_loss": "0.649", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.012", "train_target_var": "0.463", "train_pred_var": "0.443", "train_masked_pct": "0.498", "train_wps": "8788.2", "train_ups": "0.82", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "905", "train_lr": "8.48437e-05", "train_gnorm": "1.695", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1222"}
[2024-03-26 16:50:03,963][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:04,025][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 115
[2024-03-26 16:50:04,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:04,030][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:04,035][fairseq.trainer][INFO] - begin training epoch 115
[2024-03-26 16:50:04,035][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:11,355][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:50:11,356][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:11,426][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 24
[2024-03-26 16:50:11,429][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:11,854][valid][INFO] - {"epoch": 115, "valid_loss": "0.635", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.012", "valid_target_var": "0.47", "valid_pred_var": "0.451", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "913", "valid_best_loss": "0.635"}
[2024-03-26 16:50:11,855][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 913 updates
[2024-03-26 16:50:11,857][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:50:14,470][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:50:18,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 115 @ 913 updates, score 0.635) (writing took 6.715849359985441 seconds)
[2024-03-26 16:50:18,572][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-03-26 16:50:18,573][train][INFO] - {"epoch": 115, "train_loss": "0.642", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.012", "train_target_var": "0.463", "train_pred_var": "0.444", "train_masked_pct": "0.501", "train_wps": "5897", "train_ups": "0.55", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "913", "train_lr": "8.55938e-05", "train_gnorm": "1.861", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1236"}
[2024-03-26 16:50:18,575][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:18,645][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 116
[2024-03-26 16:50:18,647][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:18,650][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:18,655][fairseq.trainer][INFO] - begin training epoch 116
[2024-03-26 16:50:18,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:26,004][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 116 @ 921 updates
[2024-03-26 16:50:26,005][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:28,509][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:28,567][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 116 @ 921 updates, score None) (writing took 2.5628291689790785 seconds)
[2024-03-26 16:50:28,568][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-03-26 16:50:28,568][train][INFO] - {"epoch": 116, "train_loss": "0.626", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.012", "train_target_var": "0.47", "train_pred_var": "0.449", "train_masked_pct": "0.499", "train_wps": "8619.7", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "921", "train_lr": "8.63438e-05", "train_gnorm": "1.733", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1246"}
[2024-03-26 16:50:28,570][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:28,632][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 117
[2024-03-26 16:50:28,634][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:28,637][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:28,641][fairseq.trainer][INFO] - begin training epoch 117
[2024-03-26 16:50:28,642][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:35,767][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 117 @ 929 updates
[2024-03-26 16:50:35,769][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:38,276][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:38,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 117 @ 929 updates, score None) (writing took 2.5662997318431735 seconds)
[2024-03-26 16:50:38,334][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-03-26 16:50:38,335][train][INFO] - {"epoch": 117, "train_loss": "0.681", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.012", "train_target_var": "0.475", "train_pred_var": "0.456", "train_masked_pct": "0.501", "train_wps": "8821.6", "train_ups": "0.82", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "929", "train_lr": "8.70937e-05", "train_gnorm": "3.271", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1256"}
[2024-03-26 16:50:38,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:38,399][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 118
[2024-03-26 16:50:38,401][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:38,404][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:38,409][fairseq.trainer][INFO] - begin training epoch 118
[2024-03-26 16:50:38,409][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:45,521][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 118 @ 937 updates
[2024-03-26 16:50:45,523][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:48,014][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:48,073][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 118 @ 937 updates, score None) (writing took 2.5514284227974713 seconds)
[2024-03-26 16:50:48,073][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-03-26 16:50:48,074][train][INFO] - {"epoch": 118, "train_loss": "0.66", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.012", "train_target_var": "0.478", "train_pred_var": "0.461", "train_masked_pct": "0.499", "train_wps": "8847", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "937", "train_lr": "8.78438e-05", "train_gnorm": "3.318", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1266"}
[2024-03-26 16:50:48,077][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:48,139][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 119
[2024-03-26 16:50:48,140][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:48,144][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:48,148][fairseq.trainer][INFO] - begin training epoch 119
[2024-03-26 16:50:48,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:50:55,521][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 119 @ 945 updates
[2024-03-26 16:50:55,523][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:58,001][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:50:58,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 119 @ 945 updates, score None) (writing took 2.5369847351685166 seconds)
[2024-03-26 16:50:58,060][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-03-26 16:50:58,060][train][INFO] - {"epoch": 119, "train_loss": "0.637", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.012", "train_target_var": "0.48", "train_pred_var": "0.458", "train_masked_pct": "0.499", "train_wps": "8627.6", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "945", "train_lr": "8.85938e-05", "train_gnorm": "2.721", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1276"}
[2024-03-26 16:50:58,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:50:58,126][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 120
[2024-03-26 16:50:58,128][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:50:58,131][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:50:58,136][fairseq.trainer][INFO] - begin training epoch 120
[2024-03-26 16:50:58,136][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:05,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:51:05,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:05,529][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 25
[2024-03-26 16:51:05,533][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:05,932][valid][INFO] - {"epoch": 120, "valid_loss": "0.558", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.013", "valid_target_var": "0.484", "valid_pred_var": "0.474", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "953", "valid_best_loss": "0.558"}
[2024-03-26 16:51:05,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 953 updates
[2024-03-26 16:51:05,935][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:51:08,550][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:51:12,625][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 120 @ 953 updates, score 0.558) (writing took 6.691617849748582 seconds)
[2024-03-26 16:51:12,626][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-03-26 16:51:12,627][train][INFO] - {"epoch": 120, "train_loss": "0.593", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.013", "train_target_var": "0.482", "train_pred_var": "0.466", "train_masked_pct": "0.501", "train_wps": "5915", "train_ups": "0.55", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "953", "train_lr": "8.93437e-05", "train_gnorm": "2.076", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1290"}
[2024-03-26 16:51:12,629][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:12,701][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 121
[2024-03-26 16:51:12,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:51:12,706][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:12,711][fairseq.trainer][INFO] - begin training epoch 121
[2024-03-26 16:51:12,711][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:19,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 121 @ 961 updates
[2024-03-26 16:51:19,790][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:22,298][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:22,355][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 121 @ 961 updates, score None) (writing took 2.565823924727738 seconds)
[2024-03-26 16:51:22,355][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-03-26 16:51:22,356][train][INFO] - {"epoch": 121, "train_loss": "0.634", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.013", "train_target_var": "0.482", "train_pred_var": "0.465", "train_masked_pct": "0.499", "train_wps": "8855.8", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "961", "train_lr": "9.00938e-05", "train_gnorm": "2.627", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "12", "train_wall": "1300"}
[2024-03-26 16:51:22,358][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:22,420][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 122
[2024-03-26 16:51:22,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:51:22,425][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:22,430][fairseq.trainer][INFO] - begin training epoch 122
[2024-03-26 16:51:22,430][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:29,642][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 122 @ 969 updates
[2024-03-26 16:51:29,644][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:32,117][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:32,154][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 122 @ 969 updates, score None) (writing took 2.5119921201840043 seconds)
[2024-03-26 16:51:32,155][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-03-26 16:51:32,156][train][INFO] - {"epoch": 122, "train_loss": "0.591", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.013", "train_target_var": "0.488", "train_pred_var": "0.47", "train_masked_pct": "0.499", "train_wps": "8792.1", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "969", "train_lr": "9.08437e-05", "train_gnorm": "2.233", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1310"}
[2024-03-26 16:51:32,158][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:32,244][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 123
[2024-03-26 16:51:32,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:51:32,249][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:32,254][fairseq.trainer][INFO] - begin training epoch 123
[2024-03-26 16:51:32,254][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:39,625][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 123 @ 977 updates
[2024-03-26 16:51:39,626][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:42,102][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:42,160][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 123 @ 977 updates, score None) (writing took 2.5353622590191662 seconds)
[2024-03-26 16:51:42,161][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-03-26 16:51:42,161][train][INFO] - {"epoch": 123, "train_loss": "0.573", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.013", "train_target_var": "0.493", "train_pred_var": "0.475", "train_masked_pct": "0.5", "train_wps": "8611", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "977", "train_lr": "9.15938e-05", "train_gnorm": "1.654", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1320"}
[2024-03-26 16:51:42,164][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:42,224][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 124
[2024-03-26 16:51:42,226][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:51:42,229][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:42,234][fairseq.trainer][INFO] - begin training epoch 124
[2024-03-26 16:51:42,234][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:49,464][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 124 @ 985 updates
[2024-03-26 16:51:49,465][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:51,957][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:51:52,015][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 124 @ 985 updates, score None) (writing took 2.5514456261880696 seconds)
[2024-03-26 16:51:52,016][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-03-26 16:51:52,016][train][INFO] - {"epoch": 124, "train_loss": "0.594", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.013", "train_target_var": "0.494", "train_pred_var": "0.48", "train_masked_pct": "0.501", "train_wps": "8743.2", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "985", "train_lr": "9.23438e-05", "train_gnorm": "2.384", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1330"}
[2024-03-26 16:51:52,018][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:52,083][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 125
[2024-03-26 16:51:52,085][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:51:52,088][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:52,092][fairseq.trainer][INFO] - begin training epoch 125
[2024-03-26 16:51:52,093][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:51:59,270][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:51:59,272][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:51:59,350][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 26
[2024-03-26 16:51:59,353][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:51:59,767][valid][INFO] - {"epoch": 125, "valid_loss": "0.574", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.013", "valid_target_var": "0.502", "valid_pred_var": "0.498", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "993", "valid_best_loss": "0.558"}
[2024-03-26 16:51:59,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 125 @ 993 updates
[2024-03-26 16:51:59,770][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:02,407][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:02,461][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 125 @ 993 updates, score 0.574) (writing took 2.692719055339694 seconds)
[2024-03-26 16:52:02,462][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-03-26 16:52:02,463][train][INFO] - {"epoch": 125, "train_loss": "0.596", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.013", "train_target_var": "0.497", "train_pred_var": "0.478", "train_masked_pct": "0.499", "train_wps": "8247.3", "train_ups": "0.77", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "993", "train_lr": "9.30937e-05", "train_gnorm": "3.217", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1340"}
[2024-03-26 16:52:02,465][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:02,533][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 126
[2024-03-26 16:52:02,535][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:02,538][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:02,543][fairseq.trainer][INFO] - begin training epoch 126
[2024-03-26 16:52:02,543][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:52:08,757][train_inner][INFO] - {"epoch": 126, "update": 125.875, "loss": "0.696", "ntokens": "10766.8", "nsentences": "22.87", "sample_size": "10766.8", "ema_decay": "999.012", "target_var": "0.461", "pred_var": "0.439", "masked_pct": "0.499", "wps": "8118.4", "ups": "0.75", "wpb": "10766.8", "bsz": "22.9", "num_updates": "1000", "lr": "9.375e-05", "gnorm": "2.518", "loss_scale": "1", "train_wall": "174", "gb_free": "6.1", "wall": "1347"}
[2024-03-26 16:52:09,762][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 126 @ 1001 updates
[2024-03-26 16:52:09,764][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:12,356][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:12,415][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 126 @ 1001 updates, score None) (writing took 2.6520910691469908 seconds)
[2024-03-26 16:52:12,415][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-03-26 16:52:12,416][train][INFO] - {"epoch": 126, "train_loss": "0.595", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.013", "train_target_var": "0.499", "train_pred_var": "0.481", "train_masked_pct": "0.498", "train_wps": "8656.9", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1001", "train_lr": "9.38438e-05", "train_gnorm": "2.857", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1350"}
[2024-03-26 16:52:12,418][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:12,482][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 127
[2024-03-26 16:52:12,484][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:12,487][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:12,492][fairseq.trainer][INFO] - begin training epoch 127
[2024-03-26 16:52:12,492][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:52:19,646][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 127 @ 1009 updates
[2024-03-26 16:52:19,648][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:22,152][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:22,211][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 127 @ 1009 updates, score None) (writing took 2.5647472920827568 seconds)
[2024-03-26 16:52:22,212][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-03-26 16:52:22,213][train][INFO] - {"epoch": 127, "train_loss": "0.58", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.013", "train_target_var": "0.505", "train_pred_var": "0.49", "train_masked_pct": "0.5", "train_wps": "8795.2", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1009", "train_lr": "9.45938e-05", "train_gnorm": "3.02", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1360"}
[2024-03-26 16:52:22,215][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:22,280][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 128
[2024-03-26 16:52:22,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:22,285][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:22,290][fairseq.trainer][INFO] - begin training epoch 128
[2024-03-26 16:52:22,291][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:52:29,634][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 128 @ 1017 updates
[2024-03-26 16:52:29,636][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:32,122][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:32,180][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 128 @ 1017 updates, score None) (writing took 2.5454070796258748 seconds)
[2024-03-26 16:52:32,180][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-03-26 16:52:32,181][train][INFO] - {"epoch": 128, "train_loss": "0.555", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.013", "train_target_var": "0.505", "train_pred_var": "0.491", "train_masked_pct": "0.5", "train_wps": "8643.3", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1017", "train_lr": "9.53437e-05", "train_gnorm": "2.19", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1370"}
[2024-03-26 16:52:32,183][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:32,246][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 129
[2024-03-26 16:52:32,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:32,251][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:32,256][fairseq.trainer][INFO] - begin training epoch 129
[2024-03-26 16:52:32,256][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:52:39,606][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 129 @ 1025 updates
[2024-03-26 16:52:39,607][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:42,087][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:52:42,147][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 129 @ 1025 updates, score None) (writing took 2.541224818211049 seconds)
[2024-03-26 16:52:42,148][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-03-26 16:52:42,148][train][INFO] - {"epoch": 129, "train_loss": "0.563", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.013", "train_target_var": "0.512", "train_pred_var": "0.494", "train_masked_pct": "0.498", "train_wps": "8643.7", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1025", "train_lr": "9.60938e-05", "train_gnorm": "2.71", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1380"}
[2024-03-26 16:52:42,151][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:42,215][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 130
[2024-03-26 16:52:42,217][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:42,220][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:42,225][fairseq.trainer][INFO] - begin training epoch 130
[2024-03-26 16:52:42,226][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:52:49,318][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:52:49,319][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:49,386][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 27
[2024-03-26 16:52:49,389][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:49,792][valid][INFO] - {"epoch": 130, "valid_loss": "0.533", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.014", "valid_target_var": "0.515", "valid_pred_var": "0.488", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "1033", "valid_best_loss": "0.533"}
[2024-03-26 16:52:49,794][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 1033 updates
[2024-03-26 16:52:49,795][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:52:52,420][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:52:56,515][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 130 @ 1033 updates, score 0.533) (writing took 6.721338276751339 seconds)
[2024-03-26 16:52:56,516][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-03-26 16:52:56,517][train][INFO] - {"epoch": 130, "train_loss": "0.595", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.014", "train_target_var": "0.518", "train_pred_var": "0.504", "train_masked_pct": "0.5", "train_wps": "5996.1", "train_ups": "0.56", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1033", "train_lr": "9.68438e-05", "train_gnorm": "3.134", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1394"}
[2024-03-26 16:52:56,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:52:56,591][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 131
[2024-03-26 16:52:56,592][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:52:56,595][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:52:56,600][fairseq.trainer][INFO] - begin training epoch 131
[2024-03-26 16:52:56,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:03,709][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 131 @ 1041 updates
[2024-03-26 16:53:03,711][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:06,224][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:06,275][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 131 @ 1041 updates, score None) (writing took 2.565779109019786 seconds)
[2024-03-26 16:53:06,276][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-03-26 16:53:06,277][train][INFO] - {"epoch": 131, "train_loss": "0.537", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.014", "train_target_var": "0.524", "train_pred_var": "0.511", "train_masked_pct": "0.499", "train_wps": "8828.3", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1041", "train_lr": "9.75937e-05", "train_gnorm": "2.329", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1404"}
[2024-03-26 16:53:06,279][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:06,352][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 132
[2024-03-26 16:53:06,354][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:53:06,357][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:06,362][fairseq.trainer][INFO] - begin training epoch 132
[2024-03-26 16:53:06,363][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:13,685][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 132 @ 1049 updates
[2024-03-26 16:53:13,687][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:16,163][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:16,221][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 132 @ 1049 updates, score None) (writing took 2.53609512001276 seconds)
[2024-03-26 16:53:16,222][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-03-26 16:53:16,222][train][INFO] - {"epoch": 132, "train_loss": "0.517", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.014", "train_target_var": "0.521", "train_pred_var": "0.507", "train_masked_pct": "0.499", "train_wps": "8663.1", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1049", "train_lr": "9.83438e-05", "train_gnorm": "2.055", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1414"}
[2024-03-26 16:53:16,224][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:16,285][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 133
[2024-03-26 16:53:16,286][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:53:16,289][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:16,294][fairseq.trainer][INFO] - begin training epoch 133
[2024-03-26 16:53:16,295][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:23,449][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 133 @ 1057 updates
[2024-03-26 16:53:23,451][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:25,885][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:25,936][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 133 @ 1057 updates, score None) (writing took 2.48687001504004 seconds)
[2024-03-26 16:53:25,937][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-03-26 16:53:25,937][train][INFO] - {"epoch": 133, "train_loss": "0.526", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.014", "train_target_var": "0.522", "train_pred_var": "0.508", "train_masked_pct": "0.501", "train_wps": "8867.8", "train_ups": "0.82", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "1057", "train_lr": "9.90938e-05", "train_gnorm": "2.56", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1424"}
[2024-03-26 16:53:25,939][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:26,012][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 134
[2024-03-26 16:53:26,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:53:26,017][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:26,022][fairseq.trainer][INFO] - begin training epoch 134
[2024-03-26 16:53:26,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:33,176][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 134 @ 1065 updates
[2024-03-26 16:53:33,178][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:35,670][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:53:35,730][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 134 @ 1065 updates, score None) (writing took 2.55368391610682 seconds)
[2024-03-26 16:53:35,730][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-03-26 16:53:35,731][train][INFO] - {"epoch": 134, "train_loss": "0.569", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.014", "train_target_var": "0.529", "train_pred_var": "0.514", "train_masked_pct": "0.498", "train_wps": "8797.9", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1065", "train_lr": "9.98437e-05", "train_gnorm": "4.017", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1434"}
[2024-03-26 16:53:35,733][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:35,796][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 135
[2024-03-26 16:53:35,797][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:53:35,800][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:35,805][fairseq.trainer][INFO] - begin training epoch 135
[2024-03-26 16:53:35,806][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:43,114][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:53:43,115][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:43,194][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 28
[2024-03-26 16:53:43,197][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:43,614][valid][INFO] - {"epoch": 135, "valid_loss": "0.452", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.014", "valid_target_var": "0.532", "valid_pred_var": "0.522", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "1073", "valid_best_loss": "0.452"}
[2024-03-26 16:53:43,615][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 135 @ 1073 updates
[2024-03-26 16:53:43,617][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:53:46,237][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:53:50,363][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 135 @ 1073 updates, score 0.452) (writing took 6.747892783023417 seconds)
[2024-03-26 16:53:50,365][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-03-26 16:53:50,366][train][INFO] - {"epoch": 135, "train_loss": "0.507", "train_ntokens": "10770.6", "train_nsentences": "22.875", "train_sample_size": "10770.6", "train_ema_decay": "999.014", "train_target_var": "0.529", "train_pred_var": "0.515", "train_masked_pct": "0.501", "train_wps": "5888.1", "train_ups": "0.55", "train_wpb": "10770.6", "train_bsz": "22.9", "train_num_updates": "1073", "train_lr": "0.000100594", "train_gnorm": "2.554", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1448"}
[2024-03-26 16:53:50,369][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:53:50,439][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 136
[2024-03-26 16:53:50,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:53:50,443][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:53:50,448][fairseq.trainer][INFO] - begin training epoch 136
[2024-03-26 16:53:50,449][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:53:57,622][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 136 @ 1081 updates
[2024-03-26 16:53:57,623][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:00,129][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:00,181][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 136 @ 1081 updates, score None) (writing took 2.5590919512324035 seconds)
[2024-03-26 16:54:00,181][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-03-26 16:54:00,182][train][INFO] - {"epoch": 136, "train_loss": "0.486", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.014", "train_target_var": "0.533", "train_pred_var": "0.521", "train_masked_pct": "0.499", "train_wps": "8777.9", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1081", "train_lr": "0.000101344", "train_gnorm": "2.115", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1458"}
[2024-03-26 16:54:00,184][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:00,252][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 137
[2024-03-26 16:54:00,254][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:00,257][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:00,262][fairseq.trainer][INFO] - begin training epoch 137
[2024-03-26 16:54:00,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:07,620][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 137 @ 1089 updates
[2024-03-26 16:54:07,621][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:10,105][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:10,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 137 @ 1089 updates, score None) (writing took 2.5240181158296764 seconds)
[2024-03-26 16:54:10,144][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-03-26 16:54:10,145][train][INFO] - {"epoch": 137, "train_loss": "0.479", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.014", "train_target_var": "0.532", "train_pred_var": "0.518", "train_masked_pct": "0.499", "train_wps": "8647.4", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1089", "train_lr": "0.000102094", "train_gnorm": "1.945", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1468"}
[2024-03-26 16:54:10,147][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:10,231][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 138
[2024-03-26 16:54:10,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:10,236][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:10,241][fairseq.trainer][INFO] - begin training epoch 138
[2024-03-26 16:54:10,242][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:17,555][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 138 @ 1097 updates
[2024-03-26 16:54:17,556][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:20,023][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:20,082][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 138 @ 1097 updates, score None) (writing took 2.5271288524381816 seconds)
[2024-03-26 16:54:20,083][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-03-26 16:54:20,083][train][INFO] - {"epoch": 138, "train_loss": "0.539", "train_ntokens": "10767.9", "train_nsentences": "22.875", "train_sample_size": "10767.9", "train_ema_decay": "999.014", "train_target_var": "0.542", "train_pred_var": "0.527", "train_masked_pct": "0.499", "train_wps": "8668.3", "train_ups": "0.81", "train_wpb": "10767.9", "train_bsz": "22.9", "train_num_updates": "1097", "train_lr": "0.000102844", "train_gnorm": "3.738", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1478"}
[2024-03-26 16:54:20,085][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:20,149][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 139
[2024-03-26 16:54:20,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:20,154][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:20,158][fairseq.trainer][INFO] - begin training epoch 139
[2024-03-26 16:54:20,159][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:27,522][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 139 @ 1105 updates
[2024-03-26 16:54:27,524][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:29,993][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:30,052][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 139 @ 1105 updates, score None) (writing took 2.52927762363106 seconds)
[2024-03-26 16:54:30,052][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-03-26 16:54:30,053][train][INFO] - {"epoch": 139, "train_loss": "0.484", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.015", "train_target_var": "0.545", "train_pred_var": "0.531", "train_masked_pct": "0.5", "train_wps": "8641.5", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1105", "train_lr": "0.000103594", "train_gnorm": "2.44", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1488"}
[2024-03-26 16:54:30,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:30,118][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 140
[2024-03-26 16:54:30,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:30,123][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:30,127][fairseq.trainer][INFO] - begin training epoch 140
[2024-03-26 16:54:30,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:37,330][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:54:37,331][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:37,404][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 29
[2024-03-26 16:54:37,408][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:37,824][valid][INFO] - {"epoch": 140, "valid_loss": "0.471", "valid_ntokens": "11701", "valid_nsentences": "25", "valid_sample_size": "11701", "valid_ema_decay": "999.015", "valid_target_var": "0.551", "valid_pred_var": "0.545", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11701", "valid_bsz": "25", "valid_num_updates": "1113", "valid_best_loss": "0.452"}
[2024-03-26 16:54:37,826][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 1113 updates
[2024-03-26 16:54:37,827][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:40,327][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:40,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 140 @ 1113 updates, score 0.471) (writing took 2.5495229568332434 seconds)
[2024-03-26 16:54:40,376][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-03-26 16:54:40,377][train][INFO] - {"epoch": 140, "train_loss": "0.48", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.015", "train_target_var": "0.548", "train_pred_var": "0.537", "train_masked_pct": "0.5", "train_wps": "8345.6", "train_ups": "0.77", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1113", "train_lr": "0.000104344", "train_gnorm": "2.442", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1498"}
[2024-03-26 16:54:40,379][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:40,453][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 141
[2024-03-26 16:54:40,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:40,458][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:40,463][fairseq.trainer][INFO] - begin training epoch 141
[2024-03-26 16:54:40,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:47,818][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 141 @ 1121 updates
[2024-03-26 16:54:47,819][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:50,308][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:54:50,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 141 @ 1121 updates, score None) (writing took 2.5272760023362935 seconds)
[2024-03-26 16:54:50,346][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-03-26 16:54:50,346][train][INFO] - {"epoch": 141, "train_loss": "0.454", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.015", "train_target_var": "0.548", "train_pred_var": "0.535", "train_masked_pct": "0.499", "train_wps": "8642.4", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1121", "train_lr": "0.000105094", "train_gnorm": "1.63", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1508"}
[2024-03-26 16:54:50,348][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:54:50,437][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 142
[2024-03-26 16:54:50,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:54:50,442][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:54:50,447][fairseq.trainer][INFO] - begin training epoch 142
[2024-03-26 16:54:50,447][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:54:57,738][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 142 @ 1129 updates
[2024-03-26 16:54:57,740][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:00,235][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:00,292][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 142 @ 1129 updates, score None) (writing took 2.5532684070058167 seconds)
[2024-03-26 16:55:00,292][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-03-26 16:55:00,293][train][INFO] - {"epoch": 142, "train_loss": "0.44", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.015", "train_target_var": "0.553", "train_pred_var": "0.541", "train_masked_pct": "0.5", "train_wps": "8662.6", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "1129", "train_lr": "0.000105844", "train_gnorm": "1.848", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1518"}
[2024-03-26 16:55:00,295][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:00,361][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 143
[2024-03-26 16:55:00,362][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:00,365][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:00,370][fairseq.trainer][INFO] - begin training epoch 143
[2024-03-26 16:55:00,371][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:07,608][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 143 @ 1137 updates
[2024-03-26 16:55:07,610][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:10,091][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:10,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 143 @ 1137 updates, score None) (writing took 2.5330177303403616 seconds)
[2024-03-26 16:55:10,142][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-03-26 16:55:10,143][train][INFO] - {"epoch": 143, "train_loss": "0.621", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.015", "train_target_var": "0.548", "train_pred_var": "0.535", "train_masked_pct": "0.499", "train_wps": "8747.2", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1137", "train_lr": "0.000106594", "train_gnorm": "5.206", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1528"}
[2024-03-26 16:55:10,145][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:10,206][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 144
[2024-03-26 16:55:10,208][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:10,211][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:10,216][fairseq.trainer][INFO] - begin training epoch 144
[2024-03-26 16:55:10,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:17,351][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 144 @ 1145 updates
[2024-03-26 16:55:17,352][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:19,822][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:19,868][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 144 @ 1145 updates, score None) (writing took 2.5168474381789565 seconds)
[2024-03-26 16:55:19,869][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-03-26 16:55:19,869][train][INFO] - {"epoch": 144, "train_loss": "0.548", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.015", "train_target_var": "0.554", "train_pred_var": "0.537", "train_masked_pct": "0.501", "train_wps": "8858.1", "train_ups": "0.82", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1145", "train_lr": "0.000107344", "train_gnorm": "4.198", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "1538"}
[2024-03-26 16:55:19,871][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:19,941][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 145
[2024-03-26 16:55:19,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:19,946][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:19,950][fairseq.trainer][INFO] - begin training epoch 145
[2024-03-26 16:55:19,951][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:27,326][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:55:27,327][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:27,392][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 30
[2024-03-26 16:55:27,396][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:27,802][valid][INFO] - {"epoch": 145, "valid_loss": "0.67", "valid_ntokens": "11718", "valid_nsentences": "25", "valid_sample_size": "11718", "valid_ema_decay": "999.015", "valid_target_var": "0.562", "valid_pred_var": "0.557", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11718", "valid_bsz": "25", "valid_num_updates": "1153", "valid_best_loss": "0.452"}
[2024-03-26 16:55:27,804][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 145 @ 1153 updates
[2024-03-26 16:55:27,806][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:30,200][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:30,251][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 145 @ 1153 updates, score 0.67) (writing took 2.446899174246937 seconds)
[2024-03-26 16:55:30,252][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-03-26 16:55:30,253][train][INFO] - {"epoch": 145, "train_loss": "0.756", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.015", "train_target_var": "0.56", "train_pred_var": "0.548", "train_masked_pct": "0.5", "train_wps": "8298.1", "train_ups": "0.77", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1153", "train_lr": "0.000108094", "train_gnorm": "6.075", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1548"}
[2024-03-26 16:55:30,255][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:30,316][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 146
[2024-03-26 16:55:30,318][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:30,321][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:30,326][fairseq.trainer][INFO] - begin training epoch 146
[2024-03-26 16:55:30,326][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:37,534][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 146 @ 1161 updates
[2024-03-26 16:55:37,535][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:39,921][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:39,971][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 146 @ 1161 updates, score None) (writing took 2.4378790641203523 seconds)
[2024-03-26 16:55:39,972][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-03-26 16:55:39,973][train][INFO] - {"epoch": 146, "train_loss": "0.565", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.015", "train_target_var": "0.562", "train_pred_var": "0.55", "train_masked_pct": "0.5", "train_wps": "8864", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1161", "train_lr": "0.000108844", "train_gnorm": "3.544", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "1558"}
[2024-03-26 16:55:39,975][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:40,036][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 147
[2024-03-26 16:55:40,037][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:40,041][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:40,045][fairseq.trainer][INFO] - begin training epoch 147
[2024-03-26 16:55:40,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:47,198][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 147 @ 1169 updates
[2024-03-26 16:55:47,200][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:49,594][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:49,646][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 147 @ 1169 updates, score None) (writing took 2.4477577903307974 seconds)
[2024-03-26 16:55:49,646][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-03-26 16:55:49,647][train][INFO] - {"epoch": 147, "train_loss": "0.518", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.015", "train_target_var": "0.568", "train_pred_var": "0.554", "train_masked_pct": "0.5", "train_wps": "8905.9", "train_ups": "0.83", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1169", "train_lr": "0.000109594", "train_gnorm": "2.272", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1567"}
[2024-03-26 16:55:49,650][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:49,712][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 148
[2024-03-26 16:55:49,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:49,717][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:49,721][fairseq.trainer][INFO] - begin training epoch 148
[2024-03-26 16:55:49,722][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:55:56,889][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 148 @ 1177 updates
[2024-03-26 16:55:56,890][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:59,263][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:55:59,316][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 148 @ 1177 updates, score None) (writing took 2.426668809261173 seconds)
[2024-03-26 16:55:59,316][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-03-26 16:55:59,317][train][INFO] - {"epoch": 148, "train_loss": "0.491", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.015", "train_target_var": "0.569", "train_pred_var": "0.556", "train_masked_pct": "0.501", "train_wps": "8910", "train_ups": "0.83", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1177", "train_lr": "0.000110344", "train_gnorm": "2.152", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1577"}
[2024-03-26 16:55:59,319][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:55:59,381][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 149
[2024-03-26 16:55:59,382][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:55:59,385][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:55:59,390][fairseq.trainer][INFO] - begin training epoch 149
[2024-03-26 16:55:59,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:56:06,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 149 @ 1185 updates
[2024-03-26 16:56:06,633][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:09,149][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:09,184][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 149 @ 1185 updates, score None) (writing took 2.5530072189867496 seconds)
[2024-03-26 16:56:09,185][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-03-26 16:56:09,185][train][INFO] - {"epoch": 149, "train_loss": "0.48", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.016", "train_target_var": "0.577", "train_pred_var": "0.562", "train_masked_pct": "0.501", "train_wps": "8730.9", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1185", "train_lr": "0.000111094", "train_gnorm": "1.884", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1587"}
[2024-03-26 16:56:09,187][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:09,274][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 150
[2024-03-26 16:56:09,275][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:56:09,278][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:09,284][fairseq.trainer][INFO] - begin training epoch 150
[2024-03-26 16:56:09,284][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:56:16,714][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:56:16,716][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:16,791][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 31
[2024-03-26 16:56:16,795][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:17,208][valid][INFO] - {"epoch": 150, "valid_loss": "0.426", "valid_ntokens": "11704", "valid_nsentences": "25", "valid_sample_size": "11704", "valid_ema_decay": "999.016", "valid_target_var": "0.585", "valid_pred_var": "0.591", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11704", "valid_bsz": "25", "valid_num_updates": "1193", "valid_best_loss": "0.426"}
[2024-03-26 16:56:17,209][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 1193 updates
[2024-03-26 16:56:17,211][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:56:19,822][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:56:23,955][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 150 @ 1193 updates, score 0.426) (writing took 6.745577495079488 seconds)
[2024-03-26 16:56:23,956][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2024-03-26 16:56:23,957][train][INFO] - {"epoch": 150, "train_loss": "0.441", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.016", "train_target_var": "0.57", "train_pred_var": "0.556", "train_masked_pct": "0.5", "train_wps": "5832.8", "train_ups": "0.54", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1193", "train_lr": "0.000111844", "train_gnorm": "1.991", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1602"}
[2024-03-26 16:56:23,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:24,034][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 151
[2024-03-26 16:56:24,036][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:56:24,039][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:24,044][fairseq.trainer][INFO] - begin training epoch 151
[2024-03-26 16:56:24,044][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:56:30,401][train_inner][INFO] - {"epoch": 151, "update": 150.875, "loss": "0.528", "ntokens": "10769.1", "nsentences": "22.875", "sample_size": "10769.1", "ema_decay": "999.015", "target_var": "0.542", "pred_var": "0.528", "masked_pct": "0.5", "wps": "8231.9", "ups": "0.76", "wpb": "10769.1", "bsz": "22.9", "num_updates": "1200", "lr": "0.0001125", "gnorm": "2.829", "loss_scale": "1", "train_wall": "175", "gb_free": "5.4", "wall": "1608"}
[2024-03-26 16:56:31,403][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 151 @ 1201 updates
[2024-03-26 16:56:31,405][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:33,903][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:33,962][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 151 @ 1201 updates, score None) (writing took 2.5580971031449735 seconds)
[2024-03-26 16:56:33,962][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2024-03-26 16:56:33,963][train][INFO] - {"epoch": 151, "train_loss": "0.443", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.016", "train_target_var": "0.581", "train_pred_var": "0.569", "train_masked_pct": "0.5", "train_wps": "8610.6", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1201", "train_lr": "0.000112594", "train_gnorm": "2.619", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1612"}
[2024-03-26 16:56:33,965][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:34,027][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 152
[2024-03-26 16:56:34,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:56:34,032][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:34,036][fairseq.trainer][INFO] - begin training epoch 152
[2024-03-26 16:56:34,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:56:41,191][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 152 @ 1209 updates
[2024-03-26 16:56:41,192][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:43,664][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:43,701][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 152 @ 1209 updates, score None) (writing took 2.5101084280759096 seconds)
[2024-03-26 16:56:43,702][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2024-03-26 16:56:43,703][train][INFO] - {"epoch": 152, "train_loss": "0.456", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.016", "train_target_var": "0.583", "train_pred_var": "0.571", "train_masked_pct": "0.499", "train_wps": "8846.5", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1209", "train_lr": "0.000113344", "train_gnorm": "2.155", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1622"}
[2024-03-26 16:56:43,705][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:43,789][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 153
[2024-03-26 16:56:43,790][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:56:43,793][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:43,798][fairseq.trainer][INFO] - begin training epoch 153
[2024-03-26 16:56:43,799][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:56:51,031][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 153 @ 1217 updates
[2024-03-26 16:56:51,033][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:53,522][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:56:53,585][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 153 @ 1217 updates, score None) (writing took 2.5542317000217736 seconds)
[2024-03-26 16:56:53,586][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2024-03-26 16:56:53,587][train][INFO] - {"epoch": 153, "train_loss": "0.442", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.016", "train_target_var": "0.586", "train_pred_var": "0.575", "train_masked_pct": "0.5", "train_wps": "8717", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1217", "train_lr": "0.000114094", "train_gnorm": "2.046", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "1631"}
[2024-03-26 16:56:53,589][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:56:53,650][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 154
[2024-03-26 16:56:53,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:56:53,655][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:56:53,660][fairseq.trainer][INFO] - begin training epoch 154
[2024-03-26 16:56:53,661][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:00,873][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 154 @ 1225 updates
[2024-03-26 16:57:00,874][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:03,375][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:03,435][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 154 @ 1225 updates, score None) (writing took 2.562669967766851 seconds)
[2024-03-26 16:57:03,436][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2024-03-26 16:57:03,437][train][INFO] - {"epoch": 154, "train_loss": "0.434", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.016", "train_target_var": "0.586", "train_pred_var": "0.575", "train_masked_pct": "0.5", "train_wps": "8747.2", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1225", "train_lr": "0.000114844", "train_gnorm": "1.532", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1641"}
[2024-03-26 16:57:03,439][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:03,502][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 155
[2024-03-26 16:57:03,503][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:03,506][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:03,511][fairseq.trainer][INFO] - begin training epoch 155
[2024-03-26 16:57:03,511][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:10,885][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:57:10,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:10,955][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 32
[2024-03-26 16:57:10,959][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:11,376][valid][INFO] - {"epoch": 155, "valid_loss": "0.431", "valid_ntokens": "11720", "valid_nsentences": "25", "valid_sample_size": "11720", "valid_ema_decay": "999.016", "valid_target_var": "0.589", "valid_pred_var": "0.589", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11720", "valid_bsz": "25", "valid_num_updates": "1233", "valid_best_loss": "0.426"}
[2024-03-26 16:57:11,377][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 155 @ 1233 updates
[2024-03-26 16:57:11,379][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:13,847][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:13,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 155 @ 1233 updates, score 0.431) (writing took 2.5244753127917647 seconds)
[2024-03-26 16:57:13,902][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2024-03-26 16:57:13,903][train][INFO] - {"epoch": 155, "train_loss": "0.388", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.016", "train_target_var": "0.59", "train_pred_var": "0.579", "train_masked_pct": "0.501", "train_wps": "8231.9", "train_ups": "0.76", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1233", "train_lr": "0.000115594", "train_gnorm": "1.371", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1652"}
[2024-03-26 16:57:13,906][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:13,967][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 156
[2024-03-26 16:57:13,969][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:13,972][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:13,977][fairseq.trainer][INFO] - begin training epoch 156
[2024-03-26 16:57:13,977][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:21,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 156 @ 1241 updates
[2024-03-26 16:57:21,336][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:23,835][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:23,898][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 156 @ 1241 updates, score None) (writing took 2.5633546113967896 seconds)
[2024-03-26 16:57:23,899][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2024-03-26 16:57:23,899][train][INFO] - {"epoch": 156, "train_loss": "0.388", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.016", "train_target_var": "0.593", "train_pred_var": "0.581", "train_masked_pct": "0.5", "train_wps": "8619.8", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1241", "train_lr": "0.000116344", "train_gnorm": "2.417", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "1662"}
[2024-03-26 16:57:23,902][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:23,963][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 157
[2024-03-26 16:57:23,965][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:23,968][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:23,973][fairseq.trainer][INFO] - begin training epoch 157
[2024-03-26 16:57:23,973][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:31,306][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 157 @ 1249 updates
[2024-03-26 16:57:31,308][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:33,794][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:33,852][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 157 @ 1249 updates, score None) (writing took 2.545956749934703 seconds)
[2024-03-26 16:57:33,853][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2024-03-26 16:57:33,853][train][INFO] - {"epoch": 157, "train_loss": "0.412", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.016", "train_target_var": "0.596", "train_pred_var": "0.585", "train_masked_pct": "0.5", "train_wps": "8655.6", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1249", "train_lr": "0.000117094", "train_gnorm": "2.138", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1672"}
[2024-03-26 16:57:33,855][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:33,919][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 158
[2024-03-26 16:57:33,920][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:33,924][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:33,929][fairseq.trainer][INFO] - begin training epoch 158
[2024-03-26 16:57:33,929][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:41,152][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 158 @ 1257 updates
[2024-03-26 16:57:41,153][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:43,619][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:43,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 158 @ 1257 updates, score None) (writing took 2.5295852520503104 seconds)
[2024-03-26 16:57:43,682][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2024-03-26 16:57:43,682][train][INFO] - {"epoch": 158, "train_loss": "0.389", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.017", "train_target_var": "0.599", "train_pred_var": "0.59", "train_masked_pct": "0.498", "train_wps": "8765.6", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1257", "train_lr": "0.000117844", "train_gnorm": "1.889", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1682"}
[2024-03-26 16:57:43,685][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:43,749][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 159
[2024-03-26 16:57:43,750][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:43,754][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:43,758][fairseq.trainer][INFO] - begin training epoch 159
[2024-03-26 16:57:43,759][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:57:51,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 159 @ 1265 updates
[2024-03-26 16:57:51,040][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:53,574][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:57:53,636][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 159 @ 1265 updates, score None) (writing took 2.5978972990997136 seconds)
[2024-03-26 16:57:53,637][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2024-03-26 16:57:53,637][train][INFO] - {"epoch": 159, "train_loss": "0.391", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.017", "train_target_var": "0.602", "train_pred_var": "0.594", "train_masked_pct": "0.499", "train_wps": "8655.2", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1265", "train_lr": "0.000118594", "train_gnorm": "1.676", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "1691"}
[2024-03-26 16:57:53,639][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:57:53,704][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 160
[2024-03-26 16:57:53,706][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:57:53,709][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:57:53,714][fairseq.trainer][INFO] - begin training epoch 160
[2024-03-26 16:57:53,714][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:00,994][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:58:00,995][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:01,058][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 33
[2024-03-26 16:58:01,061][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:01,467][valid][INFO] - {"epoch": 160, "valid_loss": "0.458", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.017", "valid_target_var": "0.601", "valid_pred_var": "0.598", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "1273", "valid_best_loss": "0.426"}
[2024-03-26 16:58:01,468][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 1273 updates
[2024-03-26 16:58:01,470][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:03,978][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:04,041][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 160 @ 1273 updates, score 0.458) (writing took 2.572587618138641 seconds)
[2024-03-26 16:58:04,042][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2024-03-26 16:58:04,043][train][INFO] - {"epoch": 160, "train_loss": "0.416", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.017", "train_target_var": "0.603", "train_pred_var": "0.591", "train_masked_pct": "0.5", "train_wps": "8280.8", "train_ups": "0.77", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "1273", "train_lr": "0.000119344", "train_gnorm": "1.886", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1702"}
[2024-03-26 16:58:04,046][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:04,110][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 161
[2024-03-26 16:58:04,112][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:04,115][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:04,121][fairseq.trainer][INFO] - begin training epoch 161
[2024-03-26 16:58:04,121][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:11,316][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 161 @ 1281 updates
[2024-03-26 16:58:11,318][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:13,798][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:13,851][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 161 @ 1281 updates, score None) (writing took 2.534703071694821 seconds)
[2024-03-26 16:58:13,852][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2024-03-26 16:58:13,852][train][INFO] - {"epoch": 161, "train_loss": "0.425", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.017", "train_target_var": "0.607", "train_pred_var": "0.599", "train_masked_pct": "0.5", "train_wps": "8783.3", "train_ups": "0.82", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "1281", "train_lr": "0.000120094", "train_gnorm": "2.588", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1712"}
[2024-03-26 16:58:13,854][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:13,928][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 162
[2024-03-26 16:58:13,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:13,933][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:13,938][fairseq.trainer][INFO] - begin training epoch 162
[2024-03-26 16:58:13,938][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:21,319][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 162 @ 1289 updates
[2024-03-26 16:58:21,320][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:23,829][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:23,893][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 162 @ 1289 updates, score None) (writing took 2.5739998817443848 seconds)
[2024-03-26 16:58:23,893][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2024-03-26 16:58:23,894][train][INFO] - {"epoch": 162, "train_loss": "0.401", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.017", "train_target_var": "0.608", "train_pred_var": "0.595", "train_masked_pct": "0.501", "train_wps": "8580.3", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1289", "train_lr": "0.000120844", "train_gnorm": "2.301", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1722"}
[2024-03-26 16:58:23,896][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:23,957][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 163
[2024-03-26 16:58:23,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:23,962][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:23,967][fairseq.trainer][INFO] - begin training epoch 163
[2024-03-26 16:58:23,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:31,405][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 163 @ 1297 updates
[2024-03-26 16:58:31,406][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:33,883][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:33,944][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 163 @ 1297 updates, score None) (writing took 2.539062689989805 seconds)
[2024-03-26 16:58:33,944][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2024-03-26 16:58:33,945][train][INFO] - {"epoch": 163, "train_loss": "0.371", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.017", "train_target_var": "0.612", "train_pred_var": "0.602", "train_masked_pct": "0.5", "train_wps": "8571.8", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1297", "train_lr": "0.000121594", "train_gnorm": "1.764", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1732"}
[2024-03-26 16:58:33,947][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:34,008][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 164
[2024-03-26 16:58:34,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:34,013][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:34,018][fairseq.trainer][INFO] - begin training epoch 164
[2024-03-26 16:58:34,019][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:41,383][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 164 @ 1305 updates
[2024-03-26 16:58:41,384][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:43,901][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:58:43,965][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 164 @ 1305 updates, score None) (writing took 2.5819677747786045 seconds)
[2024-03-26 16:58:43,966][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2024-03-26 16:58:43,966][train][INFO] - {"epoch": 164, "train_loss": "0.36", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.017", "train_target_var": "0.612", "train_pred_var": "0.601", "train_masked_pct": "0.5", "train_wps": "8596.9", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1305", "train_lr": "0.000122344", "train_gnorm": "1.936", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "1742"}
[2024-03-26 16:58:43,968][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:44,034][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 165
[2024-03-26 16:58:44,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:44,038][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:44,043][fairseq.trainer][INFO] - begin training epoch 165
[2024-03-26 16:58:44,044][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:58:51,485][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:58:51,486][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:51,549][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 34
[2024-03-26 16:58:51,553][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:51,979][valid][INFO] - {"epoch": 165, "valid_loss": "0.37", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.017", "valid_target_var": "0.622", "valid_pred_var": "0.628", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "1313", "valid_best_loss": "0.37"}
[2024-03-26 16:58:51,980][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 165 @ 1313 updates
[2024-03-26 16:58:51,982][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:58:54,577][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 16:58:58,684][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 165 @ 1313 updates, score 0.37) (writing took 6.703914963174611 seconds)
[2024-03-26 16:58:58,685][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2024-03-26 16:58:58,686][train][INFO] - {"epoch": 165, "train_loss": "0.338", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.017", "train_target_var": "0.613", "train_pred_var": "0.605", "train_masked_pct": "0.498", "train_wps": "5853", "train_ups": "0.54", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1313", "train_lr": "0.000123094", "train_gnorm": "2.09", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1757"}
[2024-03-26 16:58:58,688][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:58:58,761][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 166
[2024-03-26 16:58:58,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:58:58,766][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:58:58,770][fairseq.trainer][INFO] - begin training epoch 166
[2024-03-26 16:58:58,771][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:06,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 166 @ 1321 updates
[2024-03-26 16:59:06,051][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:08,530][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:08,567][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 166 @ 1321 updates, score None) (writing took 2.5174418059177697 seconds)
[2024-03-26 16:59:08,567][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2024-03-26 16:59:08,568][train][INFO] - {"epoch": 166, "train_loss": "0.328", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.017", "train_target_var": "0.616", "train_pred_var": "0.61", "train_masked_pct": "0.499", "train_wps": "8718.6", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1321", "train_lr": "0.000123844", "train_gnorm": "1.425", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1766"}
[2024-03-26 16:59:08,570][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:08,656][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 167
[2024-03-26 16:59:08,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:08,661][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:08,666][fairseq.trainer][INFO] - begin training epoch 167
[2024-03-26 16:59:08,667][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:15,912][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 167 @ 1329 updates
[2024-03-26 16:59:15,914][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:18,385][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:18,436][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 167 @ 1329 updates, score None) (writing took 2.523764220997691 seconds)
[2024-03-26 16:59:18,436][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2024-03-26 16:59:18,437][train][INFO] - {"epoch": 167, "train_loss": "0.429", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.017", "train_target_var": "0.616", "train_pred_var": "0.612", "train_masked_pct": "0.499", "train_wps": "8730.5", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1329", "train_lr": "0.000124594", "train_gnorm": "3.438", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1776"}
[2024-03-26 16:59:18,439][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:18,512][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 168
[2024-03-26 16:59:18,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:18,517][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:18,521][fairseq.trainer][INFO] - begin training epoch 168
[2024-03-26 16:59:18,521][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:25,915][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 168 @ 1337 updates
[2024-03-26 16:59:25,916][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:28,335][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:28,371][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 168 @ 1337 updates, score None) (writing took 2.4568573511205614 seconds)
[2024-03-26 16:59:28,372][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2024-03-26 16:59:28,373][train][INFO] - {"epoch": 168, "train_loss": "0.399", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.018", "train_target_var": "0.62", "train_pred_var": "0.609", "train_masked_pct": "0.501", "train_wps": "8671.4", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1337", "train_lr": "0.000125344", "train_gnorm": "3.508", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1786"}
[2024-03-26 16:59:28,375][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:28,465][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 169
[2024-03-26 16:59:28,467][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:28,470][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:28,474][fairseq.trainer][INFO] - begin training epoch 169
[2024-03-26 16:59:28,475][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:35,744][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 169 @ 1345 updates
[2024-03-26 16:59:35,746][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:38,271][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:38,305][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 169 @ 1345 updates, score None) (writing took 2.5606633690185845 seconds)
[2024-03-26 16:59:38,306][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2024-03-26 16:59:38,307][train][INFO] - {"epoch": 169, "train_loss": "0.375", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.018", "train_target_var": "0.622", "train_pred_var": "0.61", "train_masked_pct": "0.501", "train_wps": "8673.7", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1345", "train_lr": "0.000126094", "train_gnorm": "2.206", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1796"}
[2024-03-26 16:59:38,309][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:38,402][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 170
[2024-03-26 16:59:38,403][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:38,406][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:38,411][fairseq.trainer][INFO] - begin training epoch 170
[2024-03-26 16:59:38,412][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:45,623][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 16:59:45,625][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:45,704][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 35
[2024-03-26 16:59:45,707][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:46,110][valid][INFO] - {"epoch": 170, "valid_loss": "0.486", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.018", "valid_target_var": "0.632", "valid_pred_var": "0.645", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "1353", "valid_best_loss": "0.37"}
[2024-03-26 16:59:46,111][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 1353 updates
[2024-03-26 16:59:46,113][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:48,601][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:48,661][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 170 @ 1353 updates, score 0.486) (writing took 2.549637631047517 seconds)
[2024-03-26 16:59:48,662][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2024-03-26 16:59:48,662][train][INFO] - {"epoch": 170, "train_loss": "0.399", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.018", "train_target_var": "0.621", "train_pred_var": "0.605", "train_masked_pct": "0.501", "train_wps": "8319.8", "train_ups": "0.77", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1353", "train_lr": "0.000126844", "train_gnorm": "2.329", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "1806"}
[2024-03-26 16:59:48,664][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:48,726][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 171
[2024-03-26 16:59:48,728][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:48,731][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:48,736][fairseq.trainer][INFO] - begin training epoch 171
[2024-03-26 16:59:48,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 16:59:56,037][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 171 @ 1361 updates
[2024-03-26 16:59:56,039][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:58,521][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 16:59:58,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 171 @ 1361 updates, score None) (writing took 2.5445253350771964 seconds)
[2024-03-26 16:59:58,582][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2024-03-26 16:59:58,583][train][INFO] - {"epoch": 171, "train_loss": "0.437", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.018", "train_target_var": "0.628", "train_pred_var": "0.62", "train_masked_pct": "0.499", "train_wps": "8685.2", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1361", "train_lr": "0.000127594", "train_gnorm": "4.057", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1816"}
[2024-03-26 16:59:58,585][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 16:59:58,648][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 172
[2024-03-26 16:59:58,649][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 16:59:58,652][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 16:59:58,657][fairseq.trainer][INFO] - begin training epoch 172
[2024-03-26 16:59:58,658][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:05,832][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 172 @ 1369 updates
[2024-03-26 17:00:05,833][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:08,294][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:08,354][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 172 @ 1369 updates, score None) (writing took 2.522528037894517 seconds)
[2024-03-26 17:00:08,355][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2024-03-26 17:00:08,355][train][INFO] - {"epoch": 172, "train_loss": "0.408", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.018", "train_target_var": "0.632", "train_pred_var": "0.626", "train_masked_pct": "0.501", "train_wps": "8816.9", "train_ups": "0.82", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "1369", "train_lr": "0.000128344", "train_gnorm": "2.938", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "1826"}
[2024-03-26 17:00:08,358][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:08,419][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 173
[2024-03-26 17:00:08,421][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:08,424][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:08,429][fairseq.trainer][INFO] - begin training epoch 173
[2024-03-26 17:00:08,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:15,840][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 173 @ 1377 updates
[2024-03-26 17:00:15,842][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:18,336][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:18,373][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 173 @ 1377 updates, score None) (writing took 2.5325005669146776 seconds)
[2024-03-26 17:00:18,373][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2024-03-26 17:00:18,374][train][INFO] - {"epoch": 173, "train_loss": "0.416", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.018", "train_target_var": "0.631", "train_pred_var": "0.627", "train_masked_pct": "0.501", "train_wps": "8600.4", "train_ups": "0.8", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "1377", "train_lr": "0.000129094", "train_gnorm": "2.711", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1836"}
[2024-03-26 17:00:18,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:18,463][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 174
[2024-03-26 17:00:18,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:18,468][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:18,472][fairseq.trainer][INFO] - begin training epoch 174
[2024-03-26 17:00:18,473][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:25,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 174 @ 1385 updates
[2024-03-26 17:00:25,790][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:28,295][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:28,353][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 174 @ 1385 updates, score None) (writing took 2.564369885250926 seconds)
[2024-03-26 17:00:28,354][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2024-03-26 17:00:28,354][train][INFO] - {"epoch": 174, "train_loss": "0.378", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.018", "train_target_var": "0.633", "train_pred_var": "0.619", "train_masked_pct": "0.498", "train_wps": "8633", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1385", "train_lr": "0.000129844", "train_gnorm": "3.8", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1846"}
[2024-03-26 17:00:28,356][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:28,420][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 175
[2024-03-26 17:00:28,421][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:28,424][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:28,430][fairseq.trainer][INFO] - begin training epoch 175
[2024-03-26 17:00:28,430][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:35,755][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:00:35,756][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:35,819][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 36
[2024-03-26 17:00:35,823][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:36,229][valid][INFO] - {"epoch": 175, "valid_loss": "0.374", "valid_ntokens": "11715", "valid_nsentences": "25", "valid_sample_size": "11715", "valid_ema_decay": "999.018", "valid_target_var": "0.639", "valid_pred_var": "0.634", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11715", "valid_bsz": "25", "valid_num_updates": "1393", "valid_best_loss": "0.37"}
[2024-03-26 17:00:36,230][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 175 @ 1393 updates
[2024-03-26 17:00:36,232][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:38,722][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:38,762][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 175 @ 1393 updates, score 0.374) (writing took 2.531130484305322 seconds)
[2024-03-26 17:00:38,762][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2024-03-26 17:00:38,763][train][INFO] - {"epoch": 175, "train_loss": "0.349", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.018", "train_target_var": "0.635", "train_pred_var": "0.626", "train_masked_pct": "0.498", "train_wps": "8278.1", "train_ups": "0.77", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "1393", "train_lr": "0.000130594", "train_gnorm": "2.454", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "1857"}
[2024-03-26 17:00:38,765][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:38,846][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 176
[2024-03-26 17:00:38,848][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:38,851][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:38,856][fairseq.trainer][INFO] - begin training epoch 176
[2024-03-26 17:00:38,856][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:45,237][train_inner][INFO] - {"epoch": 176, "update": 175.875, "loss": "0.396", "ntokens": "10769.2", "nsentences": "22.875", "sample_size": "10769.2", "ema_decay": "999.017", "target_var": "0.611", "pred_var": "0.601", "masked_pct": "0.5", "wps": "8451.9", "ups": "0.78", "wpb": "10769.2", "bsz": "22.9", "num_updates": "1400", "lr": "0.00013125", "gnorm": "2.359", "loss_scale": "1", "train_wall": "175", "gb_free": "5.1", "wall": "1863"}
[2024-03-26 17:00:46,247][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 176 @ 1401 updates
[2024-03-26 17:00:46,248][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:48,740][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:48,803][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 176 @ 1401 updates, score None) (writing took 2.556391845922917 seconds)
[2024-03-26 17:00:48,804][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2024-03-26 17:00:48,804][train][INFO] - {"epoch": 176, "train_loss": "0.344", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.018", "train_target_var": "0.634", "train_pred_var": "0.626", "train_masked_pct": "0.5", "train_wps": "8579.7", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1401", "train_lr": "0.000131344", "train_gnorm": "2.314", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1867"}
[2024-03-26 17:00:48,807][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:48,870][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 177
[2024-03-26 17:00:48,871][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:48,874][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:48,879][fairseq.trainer][INFO] - begin training epoch 177
[2024-03-26 17:00:48,880][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:00:56,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 177 @ 1409 updates
[2024-03-26 17:00:56,164][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:58,651][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:00:58,712][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 177 @ 1409 updates, score None) (writing took 2.5489240461029112 seconds)
[2024-03-26 17:00:58,713][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2024-03-26 17:00:58,714][train][INFO] - {"epoch": 177, "train_loss": "0.371", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.019", "train_target_var": "0.639", "train_pred_var": "0.629", "train_masked_pct": "0.501", "train_wps": "8695", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1409", "train_lr": "0.000132094", "train_gnorm": "2.931", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1877"}
[2024-03-26 17:00:58,716][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:00:58,778][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 178
[2024-03-26 17:00:58,780][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:00:58,783][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:00:58,787][fairseq.trainer][INFO] - begin training epoch 178
[2024-03-26 17:00:58,788][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:06,127][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 178 @ 1417 updates
[2024-03-26 17:01:06,128][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:08,590][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:08,652][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 178 @ 1417 updates, score None) (writing took 2.5247694458812475 seconds)
[2024-03-26 17:01:08,652][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2024-03-26 17:01:08,653][train][INFO] - {"epoch": 178, "train_loss": "0.385", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.019", "train_target_var": "0.638", "train_pred_var": "0.629", "train_masked_pct": "0.499", "train_wps": "8668.3", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1417", "train_lr": "0.000132844", "train_gnorm": "1.979", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1886"}
[2024-03-26 17:01:08,655][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:08,718][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 179
[2024-03-26 17:01:08,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:08,723][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:08,728][fairseq.trainer][INFO] - begin training epoch 179
[2024-03-26 17:01:08,728][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:16,166][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 179 @ 1425 updates
[2024-03-26 17:01:16,168][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:18,679][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:18,741][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 179 @ 1425 updates, score None) (writing took 2.574254374951124 seconds)
[2024-03-26 17:01:18,741][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2024-03-26 17:01:18,742][train][INFO] - {"epoch": 179, "train_loss": "0.359", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.019", "train_target_var": "0.644", "train_pred_var": "0.635", "train_masked_pct": "0.5", "train_wps": "8539.9", "train_ups": "0.79", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1425", "train_lr": "0.000133594", "train_gnorm": "1.797", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1897"}
[2024-03-26 17:01:18,744][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:18,808][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 180
[2024-03-26 17:01:18,810][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:18,813][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:18,818][fairseq.trainer][INFO] - begin training epoch 180
[2024-03-26 17:01:18,818][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:26,141][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:01:26,142][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:26,205][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 37
[2024-03-26 17:01:26,209][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:26,627][valid][INFO] - {"epoch": 180, "valid_loss": "0.431", "valid_ntokens": "11700", "valid_nsentences": "25", "valid_sample_size": "11700", "valid_ema_decay": "999.019", "valid_target_var": "0.645", "valid_pred_var": "0.649", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11700", "valid_bsz": "25", "valid_num_updates": "1433", "valid_best_loss": "0.37"}
[2024-03-26 17:01:26,629][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 1433 updates
[2024-03-26 17:01:26,630][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:29,106][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:29,167][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 180 @ 1433 updates, score 0.431) (writing took 2.538446682970971 seconds)
[2024-03-26 17:01:29,168][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2024-03-26 17:01:29,169][train][INFO] - {"epoch": 180, "train_loss": "0.334", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.019", "train_target_var": "0.645", "train_pred_var": "0.636", "train_masked_pct": "0.5", "train_wps": "8263", "train_ups": "0.77", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1433", "train_lr": "0.000134344", "train_gnorm": "1.77", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1907"}
[2024-03-26 17:01:29,171][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:29,235][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 181
[2024-03-26 17:01:29,237][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:29,240][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:29,245][fairseq.trainer][INFO] - begin training epoch 181
[2024-03-26 17:01:29,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:36,704][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 181 @ 1441 updates
[2024-03-26 17:01:36,705][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:39,177][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:39,236][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 181 @ 1441 updates, score None) (writing took 2.5324968961067498 seconds)
[2024-03-26 17:01:39,237][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2024-03-26 17:01:39,238][train][INFO] - {"epoch": 181, "train_loss": "0.498", "train_ntokens": "10768", "train_nsentences": "22.875", "train_sample_size": "10768", "train_ema_decay": "999.019", "train_target_var": "0.644", "train_pred_var": "0.636", "train_masked_pct": "0.498", "train_wps": "8555.8", "train_ups": "0.79", "train_wpb": "10768", "train_bsz": "22.9", "train_num_updates": "1441", "train_lr": "0.000135094", "train_gnorm": "2.222", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1917"}
[2024-03-26 17:01:39,240][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:39,302][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 182
[2024-03-26 17:01:39,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:39,306][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:39,311][fairseq.trainer][INFO] - begin training epoch 182
[2024-03-26 17:01:39,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:46,612][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 182 @ 1449 updates
[2024-03-26 17:01:46,613][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:49,097][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:49,130][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 182 @ 1449 updates, score None) (writing took 2.517842680681497 seconds)
[2024-03-26 17:01:49,130][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2024-03-26 17:01:49,131][train][INFO] - {"epoch": 182, "train_loss": "0.444", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.019", "train_target_var": "0.642", "train_pred_var": "0.624", "train_masked_pct": "0.5", "train_wps": "8709.5", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1449", "train_lr": "0.000135844", "train_gnorm": "3.89", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "1927"}
[2024-03-26 17:01:49,133][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:49,223][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 183
[2024-03-26 17:01:49,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:49,227][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:49,233][fairseq.trainer][INFO] - begin training epoch 183
[2024-03-26 17:01:49,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:01:56,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 183 @ 1457 updates
[2024-03-26 17:01:56,473][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:58,968][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:01:59,015][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 183 @ 1457 updates, score None) (writing took 2.5429118587635458 seconds)
[2024-03-26 17:01:59,015][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2024-03-26 17:01:59,016][train][INFO] - {"epoch": 183, "train_loss": "0.389", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.019", "train_target_var": "0.651", "train_pred_var": "0.642", "train_masked_pct": "0.499", "train_wps": "8715.8", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1457", "train_lr": "0.000136594", "train_gnorm": "2.549", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1937"}
[2024-03-26 17:01:59,018][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:01:59,078][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 184
[2024-03-26 17:01:59,080][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:01:59,083][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:01:59,088][fairseq.trainer][INFO] - begin training epoch 184
[2024-03-26 17:01:59,088][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:06,412][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 184 @ 1465 updates
[2024-03-26 17:02:06,413][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:08,777][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:08,825][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 184 @ 1465 updates, score None) (writing took 2.4131600609980524 seconds)
[2024-03-26 17:02:08,826][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2024-03-26 17:02:08,826][train][INFO] - {"epoch": 184, "train_loss": "0.367", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.019", "train_target_var": "0.652", "train_pred_var": "0.644", "train_masked_pct": "0.498", "train_wps": "8782.7", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1465", "train_lr": "0.000137344", "train_gnorm": "2.935", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.6", "train_wall": "1947"}
[2024-03-26 17:02:08,828][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:08,893][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 185
[2024-03-26 17:02:08,895][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:08,898][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:08,903][fairseq.trainer][INFO] - begin training epoch 185
[2024-03-26 17:02:08,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:16,260][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:02:16,261][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:16,323][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 38
[2024-03-26 17:02:16,326][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:16,728][valid][INFO] - {"epoch": 185, "valid_loss": "0.379", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.019", "valid_target_var": "0.658", "valid_pred_var": "0.658", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "1473", "valid_best_loss": "0.37"}
[2024-03-26 17:02:16,729][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 185 @ 1473 updates
[2024-03-26 17:02:16,731][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:19,126][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:19,178][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 185 @ 1473 updates, score 0.379) (writing took 2.4482295187190175 seconds)
[2024-03-26 17:02:19,178][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2024-03-26 17:02:19,179][train][INFO] - {"epoch": 185, "train_loss": "0.354", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.019", "train_target_var": "0.652", "train_pred_var": "0.642", "train_masked_pct": "0.5", "train_wps": "8322.9", "train_ups": "0.77", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "1473", "train_lr": "0.000138094", "train_gnorm": "2.841", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1957"}
[2024-03-26 17:02:19,182][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:19,245][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 186
[2024-03-26 17:02:19,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:19,250][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:19,255][fairseq.trainer][INFO] - begin training epoch 186
[2024-03-26 17:02:19,256][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:26,499][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 186 @ 1481 updates
[2024-03-26 17:02:26,500][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:28,854][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:28,889][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 186 @ 1481 updates, score None) (writing took 2.3899309197440743 seconds)
[2024-03-26 17:02:28,889][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2024-03-26 17:02:28,890][train][INFO] - {"epoch": 186, "train_loss": "0.358", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.019", "train_target_var": "0.658", "train_pred_var": "0.651", "train_masked_pct": "0.499", "train_wps": "8873.2", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1481", "train_lr": "0.000138844", "train_gnorm": "3.117", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1967"}
[2024-03-26 17:02:28,892][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:28,969][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 187
[2024-03-26 17:02:28,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:28,974][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:28,978][fairseq.trainer][INFO] - begin training epoch 187
[2024-03-26 17:02:28,979][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:36,386][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 187 @ 1489 updates
[2024-03-26 17:02:36,388][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:38,770][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:38,823][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 187 @ 1489 updates, score None) (writing took 2.436578187160194 seconds)
[2024-03-26 17:02:38,823][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2024-03-26 17:02:38,824][train][INFO] - {"epoch": 187, "train_loss": "0.275", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.02", "train_target_var": "0.653", "train_pred_var": "0.644", "train_masked_pct": "0.5", "train_wps": "8673", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1489", "train_lr": "0.000139594", "train_gnorm": "1.677", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "1977"}
[2024-03-26 17:02:38,826][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:38,888][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 188
[2024-03-26 17:02:38,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:38,893][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:38,898][fairseq.trainer][INFO] - begin training epoch 188
[2024-03-26 17:02:38,898][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:46,149][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 188 @ 1497 updates
[2024-03-26 17:02:46,150][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:48,514][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:48,554][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 188 @ 1497 updates, score None) (writing took 2.4049232322722673 seconds)
[2024-03-26 17:02:48,555][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2024-03-26 17:02:48,555][train][INFO] - {"epoch": 188, "train_loss": "0.319", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.02", "train_target_var": "0.661", "train_pred_var": "0.65", "train_masked_pct": "0.501", "train_wps": "8854.2", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1497", "train_lr": "0.000140344", "train_gnorm": "3.395", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "1986"}
[2024-03-26 17:02:48,557][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:48,633][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 189
[2024-03-26 17:02:48,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:48,638][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:48,643][fairseq.trainer][INFO] - begin training epoch 189
[2024-03-26 17:02:48,643][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:02:55,924][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 189 @ 1505 updates
[2024-03-26 17:02:55,925][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:58,381][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:02:58,433][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 189 @ 1505 updates, score None) (writing took 2.5091109820641577 seconds)
[2024-03-26 17:02:58,434][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2024-03-26 17:02:58,434][train][INFO] - {"epoch": 189, "train_loss": "0.345", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.02", "train_target_var": "0.663", "train_pred_var": "0.66", "train_masked_pct": "0.5", "train_wps": "8721.5", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1505", "train_lr": "0.000141094", "train_gnorm": "4.451", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "1996"}
[2024-03-26 17:02:58,436][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:02:58,499][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 190
[2024-03-26 17:02:58,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:02:58,504][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:02:58,509][fairseq.trainer][INFO] - begin training epoch 190
[2024-03-26 17:02:58,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:05,803][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:03:05,805][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:05,869][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 39
[2024-03-26 17:03:05,873][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:06,280][valid][INFO] - {"epoch": 190, "valid_loss": "0.316", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.02", "valid_target_var": "0.66", "valid_pred_var": "0.656", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "1513", "valid_best_loss": "0.316"}
[2024-03-26 17:03:06,282][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 1513 updates
[2024-03-26 17:03:06,283][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:03:08,777][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:03:12,891][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 190 @ 1513 updates, score 0.316) (writing took 6.608595207799226 seconds)
[2024-03-26 17:03:12,891][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2024-03-26 17:03:12,892][train][INFO] - {"epoch": 190, "train_loss": "0.312", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.02", "train_target_var": "0.661", "train_pred_var": "0.654", "train_masked_pct": "0.499", "train_wps": "5959.4", "train_ups": "0.55", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1513", "train_lr": "0.000141844", "train_gnorm": "2.706", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2011"}
[2024-03-26 17:03:12,894][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:12,965][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 191
[2024-03-26 17:03:12,967][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:03:12,970][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:12,975][fairseq.trainer][INFO] - begin training epoch 191
[2024-03-26 17:03:12,975][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:20,199][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 191 @ 1521 updates
[2024-03-26 17:03:20,200][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:22,700][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:22,739][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 191 @ 1521 updates, score None) (writing took 2.540580947417766 seconds)
[2024-03-26 17:03:22,740][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-03-26 17:03:22,741][train][INFO] - {"epoch": 191, "train_loss": "0.309", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.02", "train_target_var": "0.662", "train_pred_var": "0.652", "train_masked_pct": "0.501", "train_wps": "8748.6", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1521", "train_lr": "0.000142594", "train_gnorm": "3.275", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2021"}
[2024-03-26 17:03:22,743][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:22,835][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 192
[2024-03-26 17:03:22,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:03:22,840][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:22,845][fairseq.trainer][INFO] - begin training epoch 192
[2024-03-26 17:03:22,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:29,885][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 192 @ 1529 updates
[2024-03-26 17:03:29,887][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:32,371][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:32,431][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 192 @ 1529 updates, score None) (writing took 2.545179353095591 seconds)
[2024-03-26 17:03:32,431][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-03-26 17:03:32,432][train][INFO] - {"epoch": 192, "train_loss": "0.339", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.02", "train_target_var": "0.667", "train_pred_var": "0.658", "train_masked_pct": "0.5", "train_wps": "8890.9", "train_ups": "0.83", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1529", "train_lr": "0.000143344", "train_gnorm": "3.285", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "2030"}
[2024-03-26 17:03:32,434][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:32,496][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 193
[2024-03-26 17:03:32,498][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:03:32,501][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:32,506][fairseq.trainer][INFO] - begin training epoch 193
[2024-03-26 17:03:32,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:39,568][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 193 @ 1537 updates
[2024-03-26 17:03:39,569][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:42,040][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:42,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 193 @ 1537 updates, score None) (writing took 2.530316381249577 seconds)
[2024-03-26 17:03:42,099][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-03-26 17:03:42,099][train][INFO] - {"epoch": 193, "train_loss": "0.311", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.02", "train_target_var": "0.668", "train_pred_var": "0.658", "train_masked_pct": "0.499", "train_wps": "8912.1", "train_ups": "0.83", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1537", "train_lr": "0.000144094", "train_gnorm": "2.649", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2040"}
[2024-03-26 17:03:42,102][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:42,164][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 194
[2024-03-26 17:03:42,166][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:03:42,169][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:42,173][fairseq.trainer][INFO] - begin training epoch 194
[2024-03-26 17:03:42,174][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:49,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 194 @ 1545 updates
[2024-03-26 17:03:49,423][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:51,986][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:03:52,048][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 194 @ 1545 updates, score None) (writing took 2.6259745680727065 seconds)
[2024-03-26 17:03:52,048][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-03-26 17:03:52,049][train][INFO] - {"epoch": 194, "train_loss": "0.29", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.02", "train_target_var": "0.67", "train_pred_var": "0.666", "train_masked_pct": "0.5", "train_wps": "8659.7", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1545", "train_lr": "0.000144844", "train_gnorm": "2.194", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2050"}
[2024-03-26 17:03:52,051][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:52,114][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 195
[2024-03-26 17:03:52,116][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:03:52,119][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:52,123][fairseq.trainer][INFO] - begin training epoch 195
[2024-03-26 17:03:52,124][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:03:59,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:03:59,432][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:03:59,505][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 40
[2024-03-26 17:03:59,508][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:03:59,936][valid][INFO] - {"epoch": 195, "valid_loss": "0.239", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.02", "valid_target_var": "0.675", "valid_pred_var": "0.682", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "1553", "valid_best_loss": "0.239"}
[2024-03-26 17:03:59,938][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 195 @ 1553 updates
[2024-03-26 17:03:59,939][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:04:02,551][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:04:06,671][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 195 @ 1553 updates, score 0.239) (writing took 6.733441249933094 seconds)
[2024-03-26 17:04:06,672][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-03-26 17:04:06,673][train][INFO] - {"epoch": 195, "train_loss": "0.273", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.02", "train_target_var": "0.67", "train_pred_var": "0.664", "train_masked_pct": "0.5", "train_wps": "5891.3", "train_ups": "0.55", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1553", "train_lr": "0.000145594", "train_gnorm": "1.956", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2065"}
[2024-03-26 17:04:06,675][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:06,743][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 196
[2024-03-26 17:04:06,745][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:06,748][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:06,753][fairseq.trainer][INFO] - begin training epoch 196
[2024-03-26 17:04:06,754][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:04:13,908][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 196 @ 1561 updates
[2024-03-26 17:04:13,910][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:16,387][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:16,423][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 196 @ 1561 updates, score None) (writing took 2.514831633772701 seconds)
[2024-03-26 17:04:16,424][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-03-26 17:04:16,424][train][INFO] - {"epoch": 196, "train_loss": "0.29", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.021", "train_target_var": "0.669", "train_pred_var": "0.662", "train_masked_pct": "0.501", "train_wps": "8836.4", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1561", "train_lr": "0.000146344", "train_gnorm": "1.976", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2074"}
[2024-03-26 17:04:16,426][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:16,512][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 197
[2024-03-26 17:04:16,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:16,517][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:16,522][fairseq.trainer][INFO] - begin training epoch 197
[2024-03-26 17:04:16,522][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:04:23,767][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 197 @ 1569 updates
[2024-03-26 17:04:23,768][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:26,256][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:26,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 197 @ 1569 updates, score None) (writing took 2.5266678272746503 seconds)
[2024-03-26 17:04:26,294][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-03-26 17:04:26,295][train][INFO] - {"epoch": 197, "train_loss": "0.286", "train_ntokens": "10770.5", "train_nsentences": "22.875", "train_sample_size": "10770.5", "train_ema_decay": "999.021", "train_target_var": "0.677", "train_pred_var": "0.671", "train_masked_pct": "0.5", "train_wps": "8730", "train_ups": "0.81", "train_wpb": "10770.5", "train_bsz": "22.9", "train_num_updates": "1569", "train_lr": "0.000147094", "train_gnorm": "2.673", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2084"}
[2024-03-26 17:04:26,297][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:26,381][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 198
[2024-03-26 17:04:26,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:26,386][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:26,391][fairseq.trainer][INFO] - begin training epoch 198
[2024-03-26 17:04:26,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:04:33,696][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 198 @ 1577 updates
[2024-03-26 17:04:33,697][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:36,135][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:36,180][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 198 @ 1577 updates, score None) (writing took 2.4838777030818164 seconds)
[2024-03-26 17:04:36,181][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-03-26 17:04:36,181][train][INFO] - {"epoch": 198, "train_loss": "0.304", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.021", "train_target_var": "0.679", "train_pred_var": "0.672", "train_masked_pct": "0.5", "train_wps": "8714.9", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1577", "train_lr": "0.000147844", "train_gnorm": "2.89", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2094"}
[2024-03-26 17:04:36,183][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:36,258][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 199
[2024-03-26 17:04:36,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:36,262][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:36,267][fairseq.trainer][INFO] - begin training epoch 199
[2024-03-26 17:04:36,268][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:04:43,480][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 199 @ 1585 updates
[2024-03-26 17:04:43,481][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:45,974][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:46,033][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 199 @ 1585 updates, score None) (writing took 2.5528514282777905 seconds)
[2024-03-26 17:04:46,033][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-03-26 17:04:46,034][train][INFO] - {"epoch": 199, "train_loss": "0.294", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.021", "train_target_var": "0.677", "train_pred_var": "0.67", "train_masked_pct": "0.501", "train_wps": "8744.5", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1585", "train_lr": "0.000148594", "train_gnorm": "2.664", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2104"}
[2024-03-26 17:04:46,036][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:46,099][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 200
[2024-03-26 17:04:46,101][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:46,104][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:46,110][fairseq.trainer][INFO] - begin training epoch 200
[2024-03-26 17:04:46,110][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:04:53,372][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:04:53,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:53,441][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 41
[2024-03-26 17:04:53,445][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:53,854][valid][INFO] - {"epoch": 200, "valid_loss": "0.299", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.021", "valid_target_var": "0.672", "valid_pred_var": "0.669", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "1593", "valid_best_loss": "0.239"}
[2024-03-26 17:04:53,856][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 1593 updates
[2024-03-26 17:04:53,857][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:56,337][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:04:56,395][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 200 @ 1593 updates, score 0.299) (writing took 2.53892546473071 seconds)
[2024-03-26 17:04:56,396][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-03-26 17:04:56,396][train][INFO] - {"epoch": 200, "train_loss": "0.273", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.021", "train_target_var": "0.675", "train_pred_var": "0.668", "train_masked_pct": "0.5", "train_wps": "8314.6", "train_ups": "0.77", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1593", "train_lr": "0.000149344", "train_gnorm": "2.425", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "2114"}
[2024-03-26 17:04:56,398][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:04:56,459][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 201
[2024-03-26 17:04:56,461][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:04:56,464][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:04:56,469][fairseq.trainer][INFO] - begin training epoch 201
[2024-03-26 17:04:56,469][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:02,599][train_inner][INFO] - {"epoch": 201, "update": 200.875, "loss": "0.335", "ntokens": "10769.2", "nsentences": "22.875", "sample_size": "10769.2", "ema_decay": "999.02", "target_var": "0.66", "pred_var": "0.652", "masked_pct": "0.5", "wps": "8369", "ups": "0.78", "wpb": "10769.2", "bsz": "22.9", "num_updates": "1600", "lr": "0.00015", "gnorm": "2.681", "loss_scale": "1", "train_wall": "176", "gb_free": "5.1", "wall": "2120"}
[2024-03-26 17:05:03,557][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 201 @ 1601 updates
[2024-03-26 17:05:03,559][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:06,022][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:06,066][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 201 @ 1601 updates, score None) (writing took 2.5087040117941797 seconds)
[2024-03-26 17:05:06,067][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-03-26 17:05:06,067][train][INFO] - {"epoch": 201, "train_loss": "0.298", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.021", "train_target_var": "0.684", "train_pred_var": "0.679", "train_masked_pct": "0.501", "train_wps": "8909", "train_ups": "0.83", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1601", "train_lr": "0.000150094", "train_gnorm": "2.975", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2124"}
[2024-03-26 17:05:06,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:06,147][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 202
[2024-03-26 17:05:06,148][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:06,151][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:06,156][fairseq.trainer][INFO] - begin training epoch 202
[2024-03-26 17:05:06,157][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:13,408][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 202 @ 1609 updates
[2024-03-26 17:05:13,410][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:15,901][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:15,963][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 202 @ 1609 updates, score None) (writing took 2.5544504239223897 seconds)
[2024-03-26 17:05:15,963][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-03-26 17:05:15,964][train][INFO] - {"epoch": 202, "train_loss": "0.268", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.021", "train_target_var": "0.683", "train_pred_var": "0.675", "train_masked_pct": "0.501", "train_wps": "8706.6", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1609", "train_lr": "0.000150844", "train_gnorm": "2.232", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2134"}
[2024-03-26 17:05:15,966][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:16,029][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 203
[2024-03-26 17:05:16,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:16,034][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:16,039][fairseq.trainer][INFO] - begin training epoch 203
[2024-03-26 17:05:16,039][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:23,274][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 203 @ 1617 updates
[2024-03-26 17:05:23,275][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:25,746][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:25,806][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 203 @ 1617 updates, score None) (writing took 2.5321475439704955 seconds)
[2024-03-26 17:05:25,807][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-03-26 17:05:25,807][train][INFO] - {"epoch": 203, "train_loss": "0.276", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.021", "train_target_var": "0.683", "train_pred_var": "0.675", "train_masked_pct": "0.498", "train_wps": "8753.1", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1617", "train_lr": "0.000151594", "train_gnorm": "2.555", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2144"}
[2024-03-26 17:05:25,809][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:25,873][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 204
[2024-03-26 17:05:25,875][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:25,878][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:25,882][fairseq.trainer][INFO] - begin training epoch 204
[2024-03-26 17:05:25,883][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:33,077][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 204 @ 1625 updates
[2024-03-26 17:05:33,079][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:35,575][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:35,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 204 @ 1625 updates, score None) (writing took 2.556998140178621 seconds)
[2024-03-26 17:05:35,635][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-03-26 17:05:35,636][train][INFO] - {"epoch": 204, "train_loss": "0.314", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.021", "train_target_var": "0.684", "train_pred_var": "0.677", "train_masked_pct": "0.499", "train_wps": "8765", "train_ups": "0.81", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "1625", "train_lr": "0.000152344", "train_gnorm": "6.59", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2153"}
[2024-03-26 17:05:35,638][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:35,703][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 205
[2024-03-26 17:05:35,704][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:35,707][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:35,712][fairseq.trainer][INFO] - begin training epoch 205
[2024-03-26 17:05:35,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:43,124][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:05:43,126][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:43,191][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 42
[2024-03-26 17:05:43,195][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:43,612][valid][INFO] - {"epoch": 205, "valid_loss": "0.267", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.022", "valid_target_var": "0.688", "valid_pred_var": "0.678", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "1633", "valid_best_loss": "0.239"}
[2024-03-26 17:05:43,614][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 205 @ 1633 updates
[2024-03-26 17:05:43,615][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:46,122][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:46,180][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 205 @ 1633 updates, score 0.267) (writing took 2.5663019539788365 seconds)
[2024-03-26 17:05:46,181][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-03-26 17:05:46,181][train][INFO] - {"epoch": 205, "train_loss": "0.297", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.021", "train_target_var": "0.686", "train_pred_var": "0.681", "train_masked_pct": "0.5", "train_wps": "8169.7", "train_ups": "0.76", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1633", "train_lr": "0.000153094", "train_gnorm": "2.14", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2164"}
[2024-03-26 17:05:46,184][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:46,245][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 206
[2024-03-26 17:05:46,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:46,250][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:46,254][fairseq.trainer][INFO] - begin training epoch 206
[2024-03-26 17:05:46,255][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:05:53,501][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 206 @ 1641 updates
[2024-03-26 17:05:53,503][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:55,983][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:05:56,035][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 206 @ 1641 updates, score None) (writing took 2.5337431747466326 seconds)
[2024-03-26 17:05:56,036][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-03-26 17:05:56,037][train][INFO] - {"epoch": 206, "train_loss": "0.26", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.022", "train_target_var": "0.686", "train_pred_var": "0.68", "train_masked_pct": "0.5", "train_wps": "8742.3", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1641", "train_lr": "0.000153844", "train_gnorm": "1.685", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "2174"}
[2024-03-26 17:05:56,039][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:05:56,108][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 207
[2024-03-26 17:05:56,110][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:05:56,113][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:05:56,118][fairseq.trainer][INFO] - begin training epoch 207
[2024-03-26 17:05:56,118][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:03,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 207 @ 1649 updates
[2024-03-26 17:06:03,424][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:05,908][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:05,969][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 207 @ 1649 updates, score None) (writing took 2.546474108006805 seconds)
[2024-03-26 17:06:05,969][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-03-26 17:06:05,970][train][INFO] - {"epoch": 207, "train_loss": "0.306", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.022", "train_target_var": "0.689", "train_pred_var": "0.682", "train_masked_pct": "0.501", "train_wps": "8673.3", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1649", "train_lr": "0.000154594", "train_gnorm": "2.737", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.9", "train_wall": "2184"}
[2024-03-26 17:06:05,972][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:06,035][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 208
[2024-03-26 17:06:06,036][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:06,040][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:06,045][fairseq.trainer][INFO] - begin training epoch 208
[2024-03-26 17:06:06,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:13,296][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 208 @ 1657 updates
[2024-03-26 17:06:13,298][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:15,768][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:15,827][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 208 @ 1657 updates, score None) (writing took 2.53019413491711 seconds)
[2024-03-26 17:06:15,827][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-03-26 17:06:15,828][train][INFO] - {"epoch": 208, "train_loss": "0.315", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.022", "train_target_var": "0.688", "train_pred_var": "0.681", "train_masked_pct": "0.501", "train_wps": "8739.6", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1657", "train_lr": "0.000155344", "train_gnorm": "2.801", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "2194"}
[2024-03-26 17:06:15,830][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:15,893][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 209
[2024-03-26 17:06:15,895][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:15,898][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:15,903][fairseq.trainer][INFO] - begin training epoch 209
[2024-03-26 17:06:15,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:23,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 1665 updates
[2024-03-26 17:06:23,123][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:25,624][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:25,684][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 209 @ 1665 updates, score None) (writing took 2.5626213597133756 seconds)
[2024-03-26 17:06:25,685][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-03-26 17:06:25,685][train][INFO] - {"epoch": 209, "train_loss": "0.308", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.022", "train_target_var": "0.688", "train_pred_var": "0.679", "train_masked_pct": "0.5", "train_wps": "8741.4", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1665", "train_lr": "0.000156094", "train_gnorm": "3.133", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2204"}
[2024-03-26 17:06:25,687][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:25,755][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 210
[2024-03-26 17:06:25,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:25,760][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:25,765][fairseq.trainer][INFO] - begin training epoch 210
[2024-03-26 17:06:25,765][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:33,191][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:06:33,193][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:33,263][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 43
[2024-03-26 17:06:33,268][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:33,672][valid][INFO] - {"epoch": 210, "valid_loss": "0.331", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.022", "valid_target_var": "0.699", "valid_pred_var": "0.7", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "1673", "valid_best_loss": "0.239"}
[2024-03-26 17:06:33,674][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 1673 updates
[2024-03-26 17:06:33,675][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:36,188][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:36,243][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 210 @ 1673 updates, score 0.331) (writing took 2.568839255720377 seconds)
[2024-03-26 17:06:36,243][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-03-26 17:06:36,244][train][INFO] - {"epoch": 210, "train_loss": "0.26", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.022", "train_target_var": "0.696", "train_pred_var": "0.69", "train_masked_pct": "0.499", "train_wps": "8159.1", "train_ups": "0.76", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "1673", "train_lr": "0.000156844", "train_gnorm": "1.972", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "2214"}
[2024-03-26 17:06:36,247][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:36,312][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 211
[2024-03-26 17:06:36,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:36,317][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:36,322][fairseq.trainer][INFO] - begin training epoch 211
[2024-03-26 17:06:36,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:43,617][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 211 @ 1681 updates
[2024-03-26 17:06:43,618][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:46,103][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:46,158][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 211 @ 1681 updates, score None) (writing took 2.5415207440964878 seconds)
[2024-03-26 17:06:46,159][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-03-26 17:06:46,159][train][INFO] - {"epoch": 211, "train_loss": "0.275", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.022", "train_target_var": "0.689", "train_pred_var": "0.683", "train_masked_pct": "0.498", "train_wps": "8690.2", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1681", "train_lr": "0.000157594", "train_gnorm": "2.058", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "2224"}
[2024-03-26 17:06:46,161][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:46,227][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 212
[2024-03-26 17:06:46,229][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:46,232][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:46,236][fairseq.trainer][INFO] - begin training epoch 212
[2024-03-26 17:06:46,237][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:06:53,693][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 212 @ 1689 updates
[2024-03-26 17:06:53,694][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:56,158][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:06:56,217][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 212 @ 1689 updates, score None) (writing took 2.523482101969421 seconds)
[2024-03-26 17:06:56,217][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-03-26 17:06:56,218][train][INFO] - {"epoch": 212, "train_loss": "0.264", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.022", "train_target_var": "0.696", "train_pred_var": "0.688", "train_masked_pct": "0.501", "train_wps": "8565", "train_ups": "0.8", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "1689", "train_lr": "0.000158344", "train_gnorm": "2.963", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2234"}
[2024-03-26 17:06:56,220][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:06:56,282][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 213
[2024-03-26 17:06:56,285][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:06:56,288][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:06:56,293][fairseq.trainer][INFO] - begin training epoch 213
[2024-03-26 17:06:56,293][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:03,556][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 213 @ 1697 updates
[2024-03-26 17:07:03,558][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:06,038][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:06,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 213 @ 1697 updates, score None) (writing took 2.542017966043204 seconds)
[2024-03-26 17:07:06,099][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2024-03-26 17:07:06,099][train][INFO] - {"epoch": 213, "train_loss": "0.264", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.022", "train_target_var": "0.695", "train_pred_var": "0.69", "train_masked_pct": "0.499", "train_wps": "8718.9", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "1697", "train_lr": "0.000159094", "train_gnorm": "2.641", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2244"}
[2024-03-26 17:07:06,101][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:06,162][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 214
[2024-03-26 17:07:06,164][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:06,167][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:06,171][fairseq.trainer][INFO] - begin training epoch 214
[2024-03-26 17:07:06,172][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:13,341][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 214 @ 1705 updates
[2024-03-26 17:07:13,342][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:15,856][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:15,915][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 214 @ 1705 updates, score None) (writing took 2.5743160089477897 seconds)
[2024-03-26 17:07:15,916][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2024-03-26 17:07:15,916][train][INFO] - {"epoch": 214, "train_loss": "0.254", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.022", "train_target_var": "0.691", "train_pred_var": "0.685", "train_masked_pct": "0.501", "train_wps": "8776.5", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1705", "train_lr": "0.000159844", "train_gnorm": "2.088", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "2254"}
[2024-03-26 17:07:15,919][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:15,982][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 215
[2024-03-26 17:07:15,983][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:15,986][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:15,991][fairseq.trainer][INFO] - begin training epoch 215
[2024-03-26 17:07:15,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:23,310][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:07:23,311][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:23,382][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 44
[2024-03-26 17:07:23,386][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:23,802][valid][INFO] - {"epoch": 215, "valid_loss": "0.249", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.023", "valid_target_var": "0.706", "valid_pred_var": "0.715", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "1713", "valid_best_loss": "0.239"}
[2024-03-26 17:07:23,803][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 215 @ 1713 updates
[2024-03-26 17:07:23,805][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:26,311][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:26,372][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 215 @ 1713 updates, score 0.249) (writing took 2.568998063914478 seconds)
[2024-03-26 17:07:26,373][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2024-03-26 17:07:26,374][train][INFO] - {"epoch": 215, "train_loss": "0.244", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.023", "train_target_var": "0.698", "train_pred_var": "0.691", "train_masked_pct": "0.5", "train_wps": "8239.4", "train_ups": "0.77", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1713", "train_lr": "0.000160594", "train_gnorm": "2.034", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "2264"}
[2024-03-26 17:07:26,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:26,439][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 216
[2024-03-26 17:07:26,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:26,443][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:26,448][fairseq.trainer][INFO] - begin training epoch 216
[2024-03-26 17:07:26,449][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:33,906][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 216 @ 1721 updates
[2024-03-26 17:07:33,908][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:36,416][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:36,452][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 216 @ 1721 updates, score None) (writing took 2.5460028862580657 seconds)
[2024-03-26 17:07:36,453][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2024-03-26 17:07:36,453][train][INFO] - {"epoch": 216, "train_loss": "0.221", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.023", "train_target_var": "0.698", "train_pred_var": "0.693", "train_masked_pct": "0.5", "train_wps": "8547", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "1721", "train_lr": "0.000161344", "train_gnorm": "1.625", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2274"}
[2024-03-26 17:07:36,455][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:36,543][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 217
[2024-03-26 17:07:36,545][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:36,548][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:36,553][fairseq.trainer][INFO] - begin training epoch 217
[2024-03-26 17:07:36,553][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:43,720][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 217 @ 1729 updates
[2024-03-26 17:07:43,721][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:46,197][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:46,256][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 217 @ 1729 updates, score None) (writing took 2.536225046031177 seconds)
[2024-03-26 17:07:46,257][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2024-03-26 17:07:46,257][train][INFO] - {"epoch": 217, "train_loss": "0.245", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.023", "train_target_var": "0.696", "train_pred_var": "0.691", "train_masked_pct": "0.5", "train_wps": "8788.2", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1729", "train_lr": "0.000162094", "train_gnorm": "1.993", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2284"}
[2024-03-26 17:07:46,259][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:46,322][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 218
[2024-03-26 17:07:46,324][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:46,327][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:46,332][fairseq.trainer][INFO] - begin training epoch 218
[2024-03-26 17:07:46,332][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:07:53,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 218 @ 1737 updates
[2024-03-26 17:07:53,599][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:56,068][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:07:56,126][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 218 @ 1737 updates, score None) (writing took 2.5286351339891553 seconds)
[2024-03-26 17:07:56,127][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2024-03-26 17:07:56,127][train][INFO] - {"epoch": 218, "train_loss": "0.244", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.023", "train_target_var": "0.695", "train_pred_var": "0.69", "train_masked_pct": "0.501", "train_wps": "8728.9", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1737", "train_lr": "0.000162844", "train_gnorm": "2.532", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2294"}
[2024-03-26 17:07:56,130][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:07:56,192][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 219
[2024-03-26 17:07:56,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:07:56,197][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:07:56,202][fairseq.trainer][INFO] - begin training epoch 219
[2024-03-26 17:07:56,202][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:03,453][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 219 @ 1745 updates
[2024-03-26 17:08:03,455][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:06,045][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:06,083][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 219 @ 1745 updates, score None) (writing took 2.6298390249721706 seconds)
[2024-03-26 17:08:06,083][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2024-03-26 17:08:06,084][train][INFO] - {"epoch": 219, "train_loss": "0.254", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.023", "train_target_var": "0.704", "train_pred_var": "0.698", "train_masked_pct": "0.501", "train_wps": "8654.3", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1745", "train_lr": "0.000163594", "train_gnorm": "2.569", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2304"}
[2024-03-26 17:08:06,086][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:06,177][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 220
[2024-03-26 17:08:06,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:06,181][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:06,185][fairseq.trainer][INFO] - begin training epoch 220
[2024-03-26 17:08:06,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:13,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:08:13,401][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:13,462][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 45
[2024-03-26 17:08:13,465][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:13,881][valid][INFO] - {"epoch": 220, "valid_loss": "0.233", "valid_ntokens": "11721", "valid_nsentences": "25", "valid_sample_size": "11721", "valid_ema_decay": "999.023", "valid_target_var": "0.697", "valid_pred_var": "0.7", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11721", "valid_bsz": "25", "valid_num_updates": "1753", "valid_best_loss": "0.233"}
[2024-03-26 17:08:13,883][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 1753 updates
[2024-03-26 17:08:13,884][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:08:16,513][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:08:20,624][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 220 @ 1753 updates, score 0.233) (writing took 6.740812128875405 seconds)
[2024-03-26 17:08:20,625][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2024-03-26 17:08:20,626][train][INFO] - {"epoch": 220, "train_loss": "0.232", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.023", "train_target_var": "0.701", "train_pred_var": "0.695", "train_masked_pct": "0.499", "train_wps": "5925", "train_ups": "0.55", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1753", "train_lr": "0.000164344", "train_gnorm": "2.417", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2318"}
[2024-03-26 17:08:20,628][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:20,703][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 221
[2024-03-26 17:08:20,705][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:20,708][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:20,713][fairseq.trainer][INFO] - begin training epoch 221
[2024-03-26 17:08:20,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:27,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 221 @ 1761 updates
[2024-03-26 17:08:27,911][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:30,386][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:30,445][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 221 @ 1761 updates, score None) (writing took 2.5360995149239898 seconds)
[2024-03-26 17:08:30,445][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2024-03-26 17:08:30,446][train][INFO] - {"epoch": 221, "train_loss": "0.244", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.023", "train_target_var": "0.702", "train_pred_var": "0.699", "train_masked_pct": "0.498", "train_wps": "8773.2", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1761", "train_lr": "0.000165094", "train_gnorm": "2.672", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "2328"}
[2024-03-26 17:08:30,448][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:30,517][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 222
[2024-03-26 17:08:30,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:30,522][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:30,527][fairseq.trainer][INFO] - begin training epoch 222
[2024-03-26 17:08:30,527][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:37,653][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 222 @ 1769 updates
[2024-03-26 17:08:37,655][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:40,144][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:40,181][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 222 @ 1769 updates, score None) (writing took 2.5279336818493903 seconds)
[2024-03-26 17:08:40,182][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2024-03-26 17:08:40,182][train][INFO] - {"epoch": 222, "train_loss": "0.268", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.023", "train_target_var": "0.704", "train_pred_var": "0.698", "train_masked_pct": "0.5", "train_wps": "8848.5", "train_ups": "0.82", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1769", "train_lr": "0.000165844", "train_gnorm": "2.616", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2338"}
[2024-03-26 17:08:40,185][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:40,276][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 223
[2024-03-26 17:08:40,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:40,280][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:40,285][fairseq.trainer][INFO] - begin training epoch 223
[2024-03-26 17:08:40,286][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:47,502][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 223 @ 1777 updates
[2024-03-26 17:08:47,503][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:49,928][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:49,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 223 @ 1777 updates, score None) (writing took 2.4722945177927613 seconds)
[2024-03-26 17:08:49,975][fairseq_cli.train][INFO] - end of epoch 223 (average epoch stats below)
[2024-03-26 17:08:49,976][train][INFO] - {"epoch": 223, "train_loss": "0.256", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.023", "train_target_var": "0.706", "train_pred_var": "0.699", "train_masked_pct": "0.5", "train_wps": "8797.6", "train_ups": "0.82", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "1777", "train_lr": "0.000166594", "train_gnorm": "2.119", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2348"}
[2024-03-26 17:08:49,978][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:50,053][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 224
[2024-03-26 17:08:50,055][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:50,058][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:50,063][fairseq.trainer][INFO] - begin training epoch 224
[2024-03-26 17:08:50,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:08:57,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 224 @ 1785 updates
[2024-03-26 17:08:57,243][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:59,752][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:08:59,810][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 224 @ 1785 updates, score None) (writing took 2.5676558460108936 seconds)
[2024-03-26 17:08:59,810][fairseq_cli.train][INFO] - end of epoch 224 (average epoch stats below)
[2024-03-26 17:08:59,811][train][INFO] - {"epoch": 224, "train_loss": "0.233", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.024", "train_target_var": "0.701", "train_pred_var": "0.697", "train_masked_pct": "0.5", "train_wps": "8760.5", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1785", "train_lr": "0.000167344", "train_gnorm": "2.636", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2358"}
[2024-03-26 17:08:59,813][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:08:59,879][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 225
[2024-03-26 17:08:59,880][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:08:59,884][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:08:59,889][fairseq.trainer][INFO] - begin training epoch 225
[2024-03-26 17:08:59,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:07,007][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:09:07,008][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:07,091][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 46
[2024-03-26 17:09:07,094][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:07,491][valid][INFO] - {"epoch": 225, "valid_loss": "0.322", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.024", "valid_target_var": "0.707", "valid_pred_var": "0.708", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "1793", "valid_best_loss": "0.233"}
[2024-03-26 17:09:07,492][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 225 @ 1793 updates
[2024-03-26 17:09:07,494][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:09,980][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:10,033][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 225 @ 1793 updates, score 0.322) (writing took 2.5409639817662537 seconds)
[2024-03-26 17:09:10,034][fairseq_cli.train][INFO] - end of epoch 225 (average epoch stats below)
[2024-03-26 17:09:10,034][train][INFO] - {"epoch": 225, "train_loss": "0.269", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.024", "train_target_var": "0.708", "train_pred_var": "0.701", "train_masked_pct": "0.5", "train_wps": "8427.3", "train_ups": "0.78", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "1793", "train_lr": "0.000168094", "train_gnorm": "2.696", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2368"}
[2024-03-26 17:09:10,036][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:10,103][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 226
[2024-03-26 17:09:10,104][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:09:10,107][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:10,112][fairseq.trainer][INFO] - begin training epoch 226
[2024-03-26 17:09:10,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:16,307][train_inner][INFO] - {"epoch": 226, "update": 225.875, "loss": "0.267", "ntokens": "10771.4", "nsentences": "22.88", "sample_size": "10771.4", "ema_decay": "999.022", "target_var": "0.695", "pred_var": "0.689", "masked_pct": "0.5", "wps": "8491.1", "ups": "0.79", "wpb": "10771.3", "bsz": "22.9", "num_updates": "1800", "lr": "0.00016875", "gnorm": "2.583", "loss_scale": "1", "train_wall": "175", "gb_free": "11.9", "wall": "2374"}
[2024-03-26 17:09:17,250][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 226 @ 1801 updates
[2024-03-26 17:09:17,252][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:19,743][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:19,782][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 226 @ 1801 updates, score None) (writing took 2.5318326796405017 seconds)
[2024-03-26 17:09:19,783][fairseq_cli.train][INFO] - end of epoch 226 (average epoch stats below)
[2024-03-26 17:09:19,783][train][INFO] - {"epoch": 226, "train_loss": "0.295", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.024", "train_target_var": "0.711", "train_pred_var": "0.703", "train_masked_pct": "0.501", "train_wps": "8838", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1801", "train_lr": "0.000168844", "train_gnorm": "2.921", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2378"}
[2024-03-26 17:09:19,786][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:19,867][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 227
[2024-03-26 17:09:19,869][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:09:19,872][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:19,877][fairseq.trainer][INFO] - begin training epoch 227
[2024-03-26 17:09:19,877][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:27,225][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 227 @ 1809 updates
[2024-03-26 17:09:27,226][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:29,688][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:29,738][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 227 @ 1809 updates, score None) (writing took 2.51310659898445 seconds)
[2024-03-26 17:09:29,739][fairseq_cli.train][INFO] - end of epoch 227 (average epoch stats below)
[2024-03-26 17:09:29,739][train][INFO] - {"epoch": 227, "train_loss": "0.255", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.024", "train_target_var": "0.708", "train_pred_var": "0.703", "train_masked_pct": "0.499", "train_wps": "8654.6", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1809", "train_lr": "0.000169594", "train_gnorm": "2.545", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2388"}
[2024-03-26 17:09:29,741][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:29,812][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 228
[2024-03-26 17:09:29,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:09:29,816][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:29,821][fairseq.trainer][INFO] - begin training epoch 228
[2024-03-26 17:09:29,822][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:37,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 228 @ 1817 updates
[2024-03-26 17:09:37,051][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:39,534][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:39,599][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 228 @ 1817 updates, score None) (writing took 2.5519624818116426 seconds)
[2024-03-26 17:09:39,600][fairseq_cli.train][INFO] - end of epoch 228 (average epoch stats below)
[2024-03-26 17:09:39,601][train][INFO] - {"epoch": 228, "train_loss": "0.254", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.024", "train_target_var": "0.712", "train_pred_var": "0.705", "train_masked_pct": "0.501", "train_wps": "8737.2", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1817", "train_lr": "0.000170344", "train_gnorm": "2.734", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2397"}
[2024-03-26 17:09:39,604][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:39,668][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 229
[2024-03-26 17:09:39,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:09:39,673][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:39,679][fairseq.trainer][INFO] - begin training epoch 229
[2024-03-26 17:09:39,679][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:46,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 229 @ 1825 updates
[2024-03-26 17:09:46,962][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:49,439][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:49,474][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 229 @ 1825 updates, score None) (writing took 2.5137745938263834 seconds)
[2024-03-26 17:09:49,475][fairseq_cli.train][INFO] - end of epoch 229 (average epoch stats below)
[2024-03-26 17:09:49,475][train][INFO] - {"epoch": 229, "train_loss": "0.293", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.024", "train_target_var": "0.715", "train_pred_var": "0.708", "train_masked_pct": "0.5", "train_wps": "8725.3", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "1825", "train_lr": "0.000171094", "train_gnorm": "3.833", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "2407"}
[2024-03-26 17:09:49,478][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:49,567][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 230
[2024-03-26 17:09:49,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:09:49,571][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:49,576][fairseq.trainer][INFO] - begin training epoch 230
[2024-03-26 17:09:49,577][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:09:56,950][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:09:56,954][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:09:57,021][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 47
[2024-03-26 17:09:57,024][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:09:57,429][valid][INFO] - {"epoch": 230, "valid_loss": "0.247", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.024", "valid_target_var": "0.704", "valid_pred_var": "0.698", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "1833", "valid_best_loss": "0.233"}
[2024-03-26 17:09:57,431][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 230 @ 1833 updates
[2024-03-26 17:09:57,432][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:59,914][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:09:59,973][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 230 @ 1833 updates, score 0.247) (writing took 2.541820004582405 seconds)
[2024-03-26 17:09:59,973][fairseq_cli.train][INFO] - end of epoch 230 (average epoch stats below)
[2024-03-26 17:09:59,974][train][INFO] - {"epoch": 230, "train_loss": "0.283", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.024", "train_target_var": "0.711", "train_pred_var": "0.708", "train_masked_pct": "0.501", "train_wps": "8207.3", "train_ups": "0.76", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1833", "train_lr": "0.000171844", "train_gnorm": "2.943", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2418"}
[2024-03-26 17:09:59,976][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:00,038][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 231
[2024-03-26 17:10:00,039][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:00,042][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:00,047][fairseq.trainer][INFO] - begin training epoch 231
[2024-03-26 17:10:00,048][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:07,251][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 231 @ 1841 updates
[2024-03-26 17:10:07,252][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:09,736][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:09,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 231 @ 1841 updates, score None) (writing took 2.522997022140771 seconds)
[2024-03-26 17:10:09,775][fairseq_cli.train][INFO] - end of epoch 231 (average epoch stats below)
[2024-03-26 17:10:09,775][train][INFO] - {"epoch": 231, "train_loss": "0.335", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.024", "train_target_var": "0.707", "train_pred_var": "0.701", "train_masked_pct": "0.5", "train_wps": "8791.1", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "1841", "train_lr": "0.000172594", "train_gnorm": "3.423", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2428"}
[2024-03-26 17:10:09,777][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:09,859][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 232
[2024-03-26 17:10:09,861][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:09,864][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:09,869][fairseq.trainer][INFO] - begin training epoch 232
[2024-03-26 17:10:09,869][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:17,208][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 232 @ 1849 updates
[2024-03-26 17:10:17,209][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:19,709][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:19,768][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 232 @ 1849 updates, score None) (writing took 2.5601249877363443 seconds)
[2024-03-26 17:10:19,768][fairseq_cli.train][INFO] - end of epoch 232 (average epoch stats below)
[2024-03-26 17:10:19,769][train][INFO] - {"epoch": 232, "train_loss": "0.338", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.024", "train_target_var": "0.716", "train_pred_var": "0.709", "train_masked_pct": "0.499", "train_wps": "8621.4", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1849", "train_lr": "0.000173344", "train_gnorm": "3.579", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2438"}
[2024-03-26 17:10:19,771][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:19,846][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 233
[2024-03-26 17:10:19,848][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:19,851][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:19,856][fairseq.trainer][INFO] - begin training epoch 233
[2024-03-26 17:10:19,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:27,091][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 233 @ 1857 updates
[2024-03-26 17:10:27,092][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:29,575][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:29,629][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 233 @ 1857 updates, score None) (writing took 2.5378105910494924 seconds)
[2024-03-26 17:10:29,629][fairseq_cli.train][INFO] - end of epoch 233 (average epoch stats below)
[2024-03-26 17:10:29,630][train][INFO] - {"epoch": 233, "train_loss": "0.307", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.024", "train_target_var": "0.71", "train_pred_var": "0.701", "train_masked_pct": "0.5", "train_wps": "8737.6", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "1857", "train_lr": "0.000174094", "train_gnorm": "3.663", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2447"}
[2024-03-26 17:10:29,633][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:29,706][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 234
[2024-03-26 17:10:29,708][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:29,712][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:29,717][fairseq.trainer][INFO] - begin training epoch 234
[2024-03-26 17:10:29,717][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:36,852][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 234 @ 1865 updates
[2024-03-26 17:10:36,854][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:39,386][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:39,423][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 234 @ 1865 updates, score None) (writing took 2.570800129789859 seconds)
[2024-03-26 17:10:39,424][fairseq_cli.train][INFO] - end of epoch 234 (average epoch stats below)
[2024-03-26 17:10:39,424][train][INFO] - {"epoch": 234, "train_loss": "0.297", "train_ntokens": "10767.9", "train_nsentences": "22.875", "train_sample_size": "10767.9", "train_ema_decay": "999.025", "train_target_var": "0.718", "train_pred_var": "0.713", "train_masked_pct": "0.5", "train_wps": "8796.2", "train_ups": "0.82", "train_wpb": "10767.9", "train_bsz": "22.9", "train_num_updates": "1865", "train_lr": "0.000174844", "train_gnorm": "2.763", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "2457"}
[2024-03-26 17:10:39,426][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:39,510][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 235
[2024-03-26 17:10:39,512][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:39,515][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:39,520][fairseq.trainer][INFO] - begin training epoch 235
[2024-03-26 17:10:39,520][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:46,961][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:10:46,962][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:47,034][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 48
[2024-03-26 17:10:47,037][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:47,446][valid][INFO] - {"epoch": 235, "valid_loss": "0.325", "valid_ntokens": "11728", "valid_nsentences": "25", "valid_sample_size": "11728", "valid_ema_decay": "999.025", "valid_target_var": "0.711", "valid_pred_var": "0.71", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11728", "valid_bsz": "25", "valid_num_updates": "1873", "valid_best_loss": "0.233"}
[2024-03-26 17:10:47,447][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 235 @ 1873 updates
[2024-03-26 17:10:47,449][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:49,927][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:49,985][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 235 @ 1873 updates, score 0.325) (writing took 2.5375581411644816 seconds)
[2024-03-26 17:10:49,985][fairseq_cli.train][INFO] - end of epoch 235 (average epoch stats below)
[2024-03-26 17:10:49,986][train][INFO] - {"epoch": 235, "train_loss": "0.252", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.025", "train_target_var": "0.712", "train_pred_var": "0.706", "train_masked_pct": "0.499", "train_wps": "8157.3", "train_ups": "0.76", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1873", "train_lr": "0.000175594", "train_gnorm": "2.213", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2468"}
[2024-03-26 17:10:49,989][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:10:50,051][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 236
[2024-03-26 17:10:50,052][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:10:50,055][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:10:50,060][fairseq.trainer][INFO] - begin training epoch 236
[2024-03-26 17:10:50,061][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:10:57,439][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 236 @ 1881 updates
[2024-03-26 17:10:57,441][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:59,925][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:10:59,983][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 236 @ 1881 updates, score None) (writing took 2.5435098162852228 seconds)
[2024-03-26 17:10:59,983][fairseq_cli.train][INFO] - end of epoch 236 (average epoch stats below)
[2024-03-26 17:10:59,984][train][INFO] - {"epoch": 236, "train_loss": "0.256", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.025", "train_target_var": "0.716", "train_pred_var": "0.711", "train_masked_pct": "0.5", "train_wps": "8618.1", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1881", "train_lr": "0.000176344", "train_gnorm": "1.948", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2478"}
[2024-03-26 17:10:59,986][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:00,047][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 237
[2024-03-26 17:11:00,048][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:00,051][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:00,056][fairseq.trainer][INFO] - begin training epoch 237
[2024-03-26 17:11:00,057][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:07,318][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 237 @ 1889 updates
[2024-03-26 17:11:07,319][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:09,819][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:09,877][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 237 @ 1889 updates, score None) (writing took 2.5586394597776234 seconds)
[2024-03-26 17:11:09,877][fairseq_cli.train][INFO] - end of epoch 237 (average epoch stats below)
[2024-03-26 17:11:09,878][train][INFO] - {"epoch": 237, "train_loss": "0.313", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.025", "train_target_var": "0.719", "train_pred_var": "0.711", "train_masked_pct": "0.5", "train_wps": "8708.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1889", "train_lr": "0.000177094", "train_gnorm": "2.095", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2488"}
[2024-03-26 17:11:09,880][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:09,943][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 238
[2024-03-26 17:11:09,944][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:09,947][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:09,952][fairseq.trainer][INFO] - begin training epoch 238
[2024-03-26 17:11:09,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:17,024][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 238 @ 1897 updates
[2024-03-26 17:11:17,025][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:19,530][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:19,561][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 238 @ 1897 updates, score None) (writing took 2.5372048588469625 seconds)
[2024-03-26 17:11:19,562][fairseq_cli.train][INFO] - end of epoch 238 (average epoch stats below)
[2024-03-26 17:11:19,562][train][INFO] - {"epoch": 238, "train_loss": "0.292", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.025", "train_target_var": "0.719", "train_pred_var": "0.712", "train_masked_pct": "0.501", "train_wps": "8896.7", "train_ups": "0.83", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "1897", "train_lr": "0.000177844", "train_gnorm": "2.016", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "2497"}
[2024-03-26 17:11:19,564][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:19,659][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 239
[2024-03-26 17:11:19,661][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:19,664][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:19,669][fairseq.trainer][INFO] - begin training epoch 239
[2024-03-26 17:11:19,669][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:26,974][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 239 @ 1905 updates
[2024-03-26 17:11:26,975][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:29,478][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:29,536][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 239 @ 1905 updates, score None) (writing took 2.562314254231751 seconds)
[2024-03-26 17:11:29,537][fairseq_cli.train][INFO] - end of epoch 239 (average epoch stats below)
[2024-03-26 17:11:29,538][train][INFO] - {"epoch": 239, "train_loss": "0.331", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.025", "train_target_var": "0.715", "train_pred_var": "0.706", "train_masked_pct": "0.5", "train_wps": "8637.2", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "1905", "train_lr": "0.000178594", "train_gnorm": "2.729", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2507"}
[2024-03-26 17:11:29,540][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:29,603][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 240
[2024-03-26 17:11:29,605][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:29,608][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:29,612][fairseq.trainer][INFO] - begin training epoch 240
[2024-03-26 17:11:29,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:36,983][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:11:36,984][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:37,047][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 49
[2024-03-26 17:11:37,050][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:37,462][valid][INFO] - {"epoch": 240, "valid_loss": "0.274", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.025", "valid_target_var": "0.727", "valid_pred_var": "0.729", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "1913", "valid_best_loss": "0.233"}
[2024-03-26 17:11:37,464][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 240 @ 1913 updates
[2024-03-26 17:11:37,465][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:39,941][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:40,001][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 240 @ 1913 updates, score 0.274) (writing took 2.537310894113034 seconds)
[2024-03-26 17:11:40,001][fairseq_cli.train][INFO] - end of epoch 240 (average epoch stats below)
[2024-03-26 17:11:40,002][train][INFO] - {"epoch": 240, "train_loss": "0.283", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.025", "train_target_var": "0.719", "train_pred_var": "0.716", "train_masked_pct": "0.501", "train_wps": "8234.3", "train_ups": "0.76", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "1913", "train_lr": "0.000179344", "train_gnorm": "2.376", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2518"}
[2024-03-26 17:11:40,004][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:40,067][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 241
[2024-03-26 17:11:40,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:40,071][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:40,076][fairseq.trainer][INFO] - begin training epoch 241
[2024-03-26 17:11:40,076][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:47,469][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 241 @ 1921 updates
[2024-03-26 17:11:47,471][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:49,974][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:50,034][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 241 @ 1921 updates, score None) (writing took 2.564663961995393 seconds)
[2024-03-26 17:11:50,034][fairseq_cli.train][INFO] - end of epoch 241 (average epoch stats below)
[2024-03-26 17:11:50,035][train][INFO] - {"epoch": 241, "train_loss": "0.252", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.025", "train_target_var": "0.721", "train_pred_var": "0.715", "train_masked_pct": "0.501", "train_wps": "8588.5", "train_ups": "0.8", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "1921", "train_lr": "0.000180094", "train_gnorm": "1.522", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "2528"}
[2024-03-26 17:11:50,037][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:11:50,101][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 242
[2024-03-26 17:11:50,102][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:11:50,106][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:11:50,111][fairseq.trainer][INFO] - begin training epoch 242
[2024-03-26 17:11:50,111][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:11:57,373][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 242 @ 1929 updates
[2024-03-26 17:11:57,374][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:59,898][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:11:59,955][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 242 @ 1929 updates, score None) (writing took 2.582712615840137 seconds)
[2024-03-26 17:11:59,956][fairseq_cli.train][INFO] - end of epoch 242 (average epoch stats below)
[2024-03-26 17:11:59,957][train][INFO] - {"epoch": 242, "train_loss": "0.269", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.025", "train_target_var": "0.722", "train_pred_var": "0.717", "train_masked_pct": "0.5", "train_wps": "8683.4", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1929", "train_lr": "0.000180844", "train_gnorm": "1.855", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2538"}
[2024-03-26 17:11:59,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:00,022][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 243
[2024-03-26 17:12:00,024][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:00,027][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:00,032][fairseq.trainer][INFO] - begin training epoch 243
[2024-03-26 17:12:00,033][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:07,362][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 243 @ 1937 updates
[2024-03-26 17:12:07,363][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:10,033][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:10,093][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 243 @ 1937 updates, score None) (writing took 2.731074429117143 seconds)
[2024-03-26 17:12:10,093][fairseq_cli.train][INFO] - end of epoch 243 (average epoch stats below)
[2024-03-26 17:12:10,095][train][INFO] - {"epoch": 243, "train_loss": "0.255", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.026", "train_target_var": "0.722", "train_pred_var": "0.718", "train_masked_pct": "0.498", "train_wps": "8498.9", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1937", "train_lr": "0.000181594", "train_gnorm": "2.066", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2548"}
[2024-03-26 17:12:10,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:10,159][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 244
[2024-03-26 17:12:10,161][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:10,164][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:10,169][fairseq.trainer][INFO] - begin training epoch 244
[2024-03-26 17:12:10,169][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:17,391][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 244 @ 1945 updates
[2024-03-26 17:12:17,392][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:19,864][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:19,925][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 244 @ 1945 updates, score None) (writing took 2.5339746098034084 seconds)
[2024-03-26 17:12:19,926][fairseq_cli.train][INFO] - end of epoch 244 (average epoch stats below)
[2024-03-26 17:12:19,926][train][INFO] - {"epoch": 244, "train_loss": "0.277", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.026", "train_target_var": "0.727", "train_pred_var": "0.719", "train_masked_pct": "0.5", "train_wps": "8763.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1945", "train_lr": "0.000182344", "train_gnorm": "2.345", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2558"}
[2024-03-26 17:12:19,928][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:19,990][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 245
[2024-03-26 17:12:19,992][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:19,995][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:20,000][fairseq.trainer][INFO] - begin training epoch 245
[2024-03-26 17:12:20,000][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:27,265][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:12:27,266][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:27,327][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 50
[2024-03-26 17:12:27,330][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:27,750][valid][INFO] - {"epoch": 245, "valid_loss": "0.411", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.026", "valid_target_var": "0.723", "valid_pred_var": "0.723", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "1953", "valid_best_loss": "0.233"}
[2024-03-26 17:12:27,751][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 245 @ 1953 updates
[2024-03-26 17:12:27,753][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:30,237][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:30,296][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 245 @ 1953 updates, score 0.411) (writing took 2.545127288904041 seconds)
[2024-03-26 17:12:30,297][fairseq_cli.train][INFO] - end of epoch 245 (average epoch stats below)
[2024-03-26 17:12:30,297][train][INFO] - {"epoch": 245, "train_loss": "0.274", "train_ntokens": "10770.6", "train_nsentences": "22.875", "train_sample_size": "10770.6", "train_ema_decay": "999.026", "train_target_var": "0.726", "train_pred_var": "0.72", "train_masked_pct": "0.499", "train_wps": "8308.4", "train_ups": "0.77", "train_wpb": "10770.6", "train_bsz": "22.9", "train_num_updates": "1953", "train_lr": "0.000183094", "train_gnorm": "2.142", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2568"}
[2024-03-26 17:12:30,299][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:30,361][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 246
[2024-03-26 17:12:30,362][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:30,365][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:30,370][fairseq.trainer][INFO] - begin training epoch 246
[2024-03-26 17:12:30,371][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:37,770][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 246 @ 1961 updates
[2024-03-26 17:12:37,771][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:40,497][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:40,557][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 246 @ 1961 updates, score None) (writing took 2.787611609324813 seconds)
[2024-03-26 17:12:40,558][fairseq_cli.train][INFO] - end of epoch 246 (average epoch stats below)
[2024-03-26 17:12:40,558][train][INFO] - {"epoch": 246, "train_loss": "0.296", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.026", "train_target_var": "0.723", "train_pred_var": "0.717", "train_masked_pct": "0.501", "train_wps": "8396.8", "train_ups": "0.78", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1961", "train_lr": "0.000183844", "train_gnorm": "1.486", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2578"}
[2024-03-26 17:12:40,560][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:40,622][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 247
[2024-03-26 17:12:40,624][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:40,627][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:40,632][fairseq.trainer][INFO] - begin training epoch 247
[2024-03-26 17:12:40,632][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:48,027][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 247 @ 1969 updates
[2024-03-26 17:12:48,029][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:50,524][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:12:50,560][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 247 @ 1969 updates, score None) (writing took 2.532993192784488 seconds)
[2024-03-26 17:12:50,561][fairseq_cli.train][INFO] - end of epoch 247 (average epoch stats below)
[2024-03-26 17:12:50,561][train][INFO] - {"epoch": 247, "train_loss": "0.234", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.026", "train_target_var": "0.725", "train_pred_var": "0.72", "train_masked_pct": "0.499", "train_wps": "8613.3", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "1969", "train_lr": "0.000184594", "train_gnorm": "1.261", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2588"}
[2024-03-26 17:12:50,564][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:12:50,653][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 248
[2024-03-26 17:12:50,654][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:12:50,658][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:12:50,662][fairseq.trainer][INFO] - begin training epoch 248
[2024-03-26 17:12:50,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:12:58,054][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 248 @ 1977 updates
[2024-03-26 17:12:58,055][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:00,553][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:00,613][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 248 @ 1977 updates, score None) (writing took 2.5591667578555644 seconds)
[2024-03-26 17:13:00,614][fairseq_cli.train][INFO] - end of epoch 248 (average epoch stats below)
[2024-03-26 17:13:00,615][train][INFO] - {"epoch": 248, "train_loss": "0.25", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.026", "train_target_var": "0.728", "train_pred_var": "0.722", "train_masked_pct": "0.499", "train_wps": "8570.7", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "1977", "train_lr": "0.000185344", "train_gnorm": "2.01", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.6", "train_wall": "2598"}
[2024-03-26 17:13:00,617][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:00,678][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 249
[2024-03-26 17:13:00,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:00,683][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:00,688][fairseq.trainer][INFO] - begin training epoch 249
[2024-03-26 17:13:00,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:07,802][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 249 @ 1985 updates
[2024-03-26 17:13:07,803][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:10,263][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:10,323][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 249 @ 1985 updates, score None) (writing took 2.520798791665584 seconds)
[2024-03-26 17:13:10,323][fairseq_cli.train][INFO] - end of epoch 249 (average epoch stats below)
[2024-03-26 17:13:10,324][train][INFO] - {"epoch": 249, "train_loss": "0.251", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.026", "train_target_var": "0.73", "train_pred_var": "0.724", "train_masked_pct": "0.499", "train_wps": "8873.3", "train_ups": "0.82", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1985", "train_lr": "0.000186094", "train_gnorm": "1.978", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "2608"}
[2024-03-26 17:13:10,326][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:10,389][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 250
[2024-03-26 17:13:10,391][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:10,394][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:10,399][fairseq.trainer][INFO] - begin training epoch 250
[2024-03-26 17:13:10,399][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:17,651][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:13:17,652][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:17,715][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 51
[2024-03-26 17:13:17,718][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:18,129][valid][INFO] - {"epoch": 250, "valid_loss": "0.36", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.026", "valid_target_var": "0.727", "valid_pred_var": "0.751", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "1993", "valid_best_loss": "0.233"}
[2024-03-26 17:13:18,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 250 @ 1993 updates
[2024-03-26 17:13:18,132][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:20,598][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:20,665][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 250 @ 1993 updates, score 0.36) (writing took 2.5346791818737984 seconds)
[2024-03-26 17:13:20,666][fairseq_cli.train][INFO] - end of epoch 250 (average epoch stats below)
[2024-03-26 17:13:20,667][train][INFO] - {"epoch": 250, "train_loss": "0.289", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.026", "train_target_var": "0.727", "train_pred_var": "0.72", "train_masked_pct": "0.5", "train_wps": "8330.1", "train_ups": "0.77", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "1993", "train_lr": "0.000186844", "train_gnorm": "2.85", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2618"}
[2024-03-26 17:13:20,669][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:20,733][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 251
[2024-03-26 17:13:20,734][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:20,737][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:20,742][fairseq.trainer][INFO] - begin training epoch 251
[2024-03-26 17:13:20,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:27,070][train_inner][INFO] - {"epoch": 251, "update": 250.875, "loss": "0.283", "ntokens": "10766.9", "nsentences": "22.87", "sample_size": "10766.9", "ema_decay": "999.025", "target_var": "0.719", "pred_var": "0.713", "masked_pct": "0.5", "wps": "8587.3", "ups": "0.8", "wpb": "10766.9", "bsz": "22.9", "num_updates": "2000", "lr": "0.0001875", "gnorm": "2.443", "loss_scale": "1", "train_wall": "175", "gb_free": "5.5", "wall": "2625"}
[2024-03-26 17:13:28,077][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 251 @ 2001 updates
[2024-03-26 17:13:28,078][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:30,582][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:30,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 251 @ 2001 updates, score None) (writing took 2.544120579957962 seconds)
[2024-03-26 17:13:30,622][fairseq_cli.train][INFO] - end of epoch 251 (average epoch stats below)
[2024-03-26 17:13:30,624][train][INFO] - {"epoch": 251, "train_loss": "0.333", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.026", "train_target_var": "0.729", "train_pred_var": "0.723", "train_masked_pct": "0.5", "train_wps": "8653.7", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2001", "train_lr": "0.000187594", "train_gnorm": "2.73", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2628"}
[2024-03-26 17:13:30,626][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:30,713][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 252
[2024-03-26 17:13:30,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:30,718][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:30,723][fairseq.trainer][INFO] - begin training epoch 252
[2024-03-26 17:13:30,724][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:38,017][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 252 @ 2009 updates
[2024-03-26 17:13:38,019][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:40,540][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:40,600][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 252 @ 2009 updates, score None) (writing took 2.58270366396755 seconds)
[2024-03-26 17:13:40,600][fairseq_cli.train][INFO] - end of epoch 252 (average epoch stats below)
[2024-03-26 17:13:40,601][train][INFO] - {"epoch": 252, "train_loss": "0.322", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.026", "train_target_var": "0.729", "train_pred_var": "0.722", "train_masked_pct": "0.5", "train_wps": "8634.6", "train_ups": "0.8", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "2009", "train_lr": "0.000188344", "train_gnorm": "3.122", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2638"}
[2024-03-26 17:13:40,603][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:40,664][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 253
[2024-03-26 17:13:40,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:40,669][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:40,674][fairseq.trainer][INFO] - begin training epoch 253
[2024-03-26 17:13:40,674][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:47,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 253 @ 2017 updates
[2024-03-26 17:13:47,898][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:50,369][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:13:50,428][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 253 @ 2017 updates, score None) (writing took 2.5317108570598066 seconds)
[2024-03-26 17:13:50,429][fairseq_cli.train][INFO] - end of epoch 253 (average epoch stats below)
[2024-03-26 17:13:50,430][train][INFO] - {"epoch": 253, "train_loss": "0.377", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.027", "train_target_var": "0.728", "train_pred_var": "0.722", "train_masked_pct": "0.5", "train_wps": "8766.1", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2017", "train_lr": "0.000189094", "train_gnorm": "3.502", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2648"}
[2024-03-26 17:13:50,432][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:13:50,493][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 254
[2024-03-26 17:13:50,495][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:13:50,498][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:13:50,503][fairseq.trainer][INFO] - begin training epoch 254
[2024-03-26 17:13:50,503][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:13:57,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 254 @ 2025 updates
[2024-03-26 17:13:57,788][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:00,264][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:00,322][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 254 @ 2025 updates, score None) (writing took 2.5356268770992756 seconds)
[2024-03-26 17:14:00,322][fairseq_cli.train][INFO] - end of epoch 254 (average epoch stats below)
[2024-03-26 17:14:00,323][train][INFO] - {"epoch": 254, "train_loss": "0.289", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.027", "train_target_var": "0.728", "train_pred_var": "0.72", "train_masked_pct": "0.5", "train_wps": "8708.6", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2025", "train_lr": "0.000189844", "train_gnorm": "2.412", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2658"}
[2024-03-26 17:14:00,325][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:00,388][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 255
[2024-03-26 17:14:00,390][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:00,393][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:00,398][fairseq.trainer][INFO] - begin training epoch 255
[2024-03-26 17:14:00,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:07,495][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:14:07,496][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:07,561][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 52
[2024-03-26 17:14:07,564][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:07,979][valid][INFO] - {"epoch": 255, "valid_loss": "0.294", "valid_ntokens": "11709", "valid_nsentences": "25", "valid_sample_size": "11709", "valid_ema_decay": "999.027", "valid_target_var": "0.734", "valid_pred_var": "0.74", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11709", "valid_bsz": "25", "valid_num_updates": "2033", "valid_best_loss": "0.233"}
[2024-03-26 17:14:07,980][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 255 @ 2033 updates
[2024-03-26 17:14:07,982][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:10,491][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:10,529][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 255 @ 2033 updates, score 0.294) (writing took 2.54874324798584 seconds)
[2024-03-26 17:14:10,530][fairseq_cli.train][INFO] - end of epoch 255 (average epoch stats below)
[2024-03-26 17:14:10,530][train][INFO] - {"epoch": 255, "train_loss": "0.263", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.027", "train_target_var": "0.73", "train_pred_var": "0.722", "train_masked_pct": "0.5", "train_wps": "8441.5", "train_ups": "0.78", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2033", "train_lr": "0.000190594", "train_gnorm": "2.857", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "2668"}
[2024-03-26 17:14:10,532][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:10,616][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 256
[2024-03-26 17:14:10,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:10,621][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:10,626][fairseq.trainer][INFO] - begin training epoch 256
[2024-03-26 17:14:10,626][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:18,006][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 256 @ 2041 updates
[2024-03-26 17:14:18,008][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:20,505][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:20,564][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 256 @ 2041 updates, score None) (writing took 2.557663632091135 seconds)
[2024-03-26 17:14:20,565][fairseq_cli.train][INFO] - end of epoch 256 (average epoch stats below)
[2024-03-26 17:14:20,566][train][INFO] - {"epoch": 256, "train_loss": "0.251", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.027", "train_target_var": "0.734", "train_pred_var": "0.729", "train_masked_pct": "0.499", "train_wps": "8586.3", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2041", "train_lr": "0.000191344", "train_gnorm": "2.098", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "2678"}
[2024-03-26 17:14:20,568][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:20,630][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 257
[2024-03-26 17:14:20,632][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:20,636][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:20,640][fairseq.trainer][INFO] - begin training epoch 257
[2024-03-26 17:14:20,641][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:27,974][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 257 @ 2049 updates
[2024-03-26 17:14:27,975][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:30,437][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:30,498][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 257 @ 2049 updates, score None) (writing took 2.5236177751794457 seconds)
[2024-03-26 17:14:30,498][fairseq_cli.train][INFO] - end of epoch 257 (average epoch stats below)
[2024-03-26 17:14:30,499][train][INFO] - {"epoch": 257, "train_loss": "0.28", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.027", "train_target_var": "0.726", "train_pred_var": "0.722", "train_masked_pct": "0.5", "train_wps": "8674.7", "train_ups": "0.81", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "2049", "train_lr": "0.000192094", "train_gnorm": "3.583", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2688"}
[2024-03-26 17:14:30,501][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:30,563][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 258
[2024-03-26 17:14:30,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:30,569][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:30,573][fairseq.trainer][INFO] - begin training epoch 258
[2024-03-26 17:14:30,574][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:37,916][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 258 @ 2057 updates
[2024-03-26 17:14:37,917][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:40,413][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:40,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 258 @ 2057 updates, score None) (writing took 2.554943042807281 seconds)
[2024-03-26 17:14:40,471][fairseq_cli.train][INFO] - end of epoch 258 (average epoch stats below)
[2024-03-26 17:14:40,472][train][INFO] - {"epoch": 258, "train_loss": "0.3", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.027", "train_target_var": "0.728", "train_pred_var": "0.721", "train_masked_pct": "0.5", "train_wps": "8638.7", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2057", "train_lr": "0.000192844", "train_gnorm": "2.442", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "2698"}
[2024-03-26 17:14:40,474][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:40,547][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 259
[2024-03-26 17:14:40,549][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:40,552][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:40,556][fairseq.trainer][INFO] - begin training epoch 259
[2024-03-26 17:14:40,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:47,889][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 259 @ 2065 updates
[2024-03-26 17:14:47,891][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:50,370][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:14:50,430][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 259 @ 2065 updates, score None) (writing took 2.541096624918282 seconds)
[2024-03-26 17:14:50,431][fairseq_cli.train][INFO] - end of epoch 259 (average epoch stats below)
[2024-03-26 17:14:50,431][train][INFO] - {"epoch": 259, "train_loss": "0.298", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.027", "train_target_var": "0.733", "train_pred_var": "0.725", "train_masked_pct": "0.5", "train_wps": "8651", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2065", "train_lr": "0.000193594", "train_gnorm": "2.344", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2708"}
[2024-03-26 17:14:50,433][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:50,496][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 260
[2024-03-26 17:14:50,498][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:14:50,501][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:50,506][fairseq.trainer][INFO] - begin training epoch 260
[2024-03-26 17:14:50,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:14:57,569][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:14:57,570][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:14:57,635][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 53
[2024-03-26 17:14:57,639][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:14:58,046][valid][INFO] - {"epoch": 260, "valid_loss": "0.315", "valid_ntokens": "11702", "valid_nsentences": "25", "valid_sample_size": "11702", "valid_ema_decay": "999.027", "valid_target_var": "0.732", "valid_pred_var": "0.733", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11702", "valid_bsz": "25", "valid_num_updates": "2073", "valid_best_loss": "0.233"}
[2024-03-26 17:14:58,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 260 @ 2073 updates
[2024-03-26 17:14:58,049][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:00,549][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:00,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 260 @ 2073 updates, score 0.315) (writing took 2.5559331849217415 seconds)
[2024-03-26 17:15:00,604][fairseq_cli.train][INFO] - end of epoch 260 (average epoch stats below)
[2024-03-26 17:15:00,605][train][INFO] - {"epoch": 260, "train_loss": "0.323", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.027", "train_target_var": "0.734", "train_pred_var": "0.727", "train_masked_pct": "0.501", "train_wps": "8469.7", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2073", "train_lr": "0.000194344", "train_gnorm": "2.484", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2718"}
[2024-03-26 17:15:00,608][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:00,671][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 261
[2024-03-26 17:15:00,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:00,676][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:00,681][fairseq.trainer][INFO] - begin training epoch 261
[2024-03-26 17:15:00,682][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:07,996][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 261 @ 2081 updates
[2024-03-26 17:15:07,997][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:10,447][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:10,508][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 261 @ 2081 updates, score None) (writing took 2.5120665109716356 seconds)
[2024-03-26 17:15:10,508][fairseq_cli.train][INFO] - end of epoch 261 (average epoch stats below)
[2024-03-26 17:15:10,509][train][INFO] - {"epoch": 261, "train_loss": "0.245", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.027", "train_target_var": "0.732", "train_pred_var": "0.727", "train_masked_pct": "0.5", "train_wps": "8699.7", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2081", "train_lr": "0.000195094", "train_gnorm": "1.998", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2728"}
[2024-03-26 17:15:10,511][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:10,574][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 262
[2024-03-26 17:15:10,576][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:10,579][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:10,584][fairseq.trainer][INFO] - begin training epoch 262
[2024-03-26 17:15:10,585][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:17,876][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 262 @ 2089 updates
[2024-03-26 17:15:17,878][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:20,374][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:20,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 262 @ 2089 updates, score None) (writing took 2.5525030619464815 seconds)
[2024-03-26 17:15:20,429][fairseq_cli.train][INFO] - end of epoch 262 (average epoch stats below)
[2024-03-26 17:15:20,430][train][INFO] - {"epoch": 262, "train_loss": "0.268", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.028", "train_target_var": "0.739", "train_pred_var": "0.732", "train_masked_pct": "0.499", "train_wps": "8684.2", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2089", "train_lr": "0.000195844", "train_gnorm": "2.269", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2738"}
[2024-03-26 17:15:20,432][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:20,500][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 263
[2024-03-26 17:15:20,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:20,504][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:20,509][fairseq.trainer][INFO] - begin training epoch 263
[2024-03-26 17:15:20,510][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:27,735][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 263 @ 2097 updates
[2024-03-26 17:15:27,736][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:30,203][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:30,262][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 263 @ 2097 updates, score None) (writing took 2.5272766100242734 seconds)
[2024-03-26 17:15:30,263][fairseq_cli.train][INFO] - end of epoch 263 (average epoch stats below)
[2024-03-26 17:15:30,263][train][INFO] - {"epoch": 263, "train_loss": "0.279", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.028", "train_target_var": "0.733", "train_pred_var": "0.728", "train_masked_pct": "0.5", "train_wps": "8762.7", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2097", "train_lr": "0.000196594", "train_gnorm": "3.059", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.2", "train_wall": "2748"}
[2024-03-26 17:15:30,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:30,326][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 264
[2024-03-26 17:15:30,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:30,331][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:30,336][fairseq.trainer][INFO] - begin training epoch 264
[2024-03-26 17:15:30,336][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:37,605][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 264 @ 2105 updates
[2024-03-26 17:15:37,606][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:40,118][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:40,176][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 264 @ 2105 updates, score None) (writing took 2.570905044209212 seconds)
[2024-03-26 17:15:40,176][fairseq_cli.train][INFO] - end of epoch 264 (average epoch stats below)
[2024-03-26 17:15:40,177][train][INFO] - {"epoch": 264, "train_loss": "0.241", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.028", "train_target_var": "0.734", "train_pred_var": "0.728", "train_masked_pct": "0.5", "train_wps": "8691.3", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2105", "train_lr": "0.000197344", "train_gnorm": "2.755", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2758"}
[2024-03-26 17:15:40,179][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:40,245][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 265
[2024-03-26 17:15:40,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:40,250][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:40,255][fairseq.trainer][INFO] - begin training epoch 265
[2024-03-26 17:15:40,256][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:47,630][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:15:47,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:47,696][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 54
[2024-03-26 17:15:47,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:48,111][valid][INFO] - {"epoch": 265, "valid_loss": "0.244", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.028", "valid_target_var": "0.737", "valid_pred_var": "0.738", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "2113", "valid_best_loss": "0.233"}
[2024-03-26 17:15:48,113][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 265 @ 2113 updates
[2024-03-26 17:15:48,114][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:50,624][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:15:50,679][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 265 @ 2113 updates, score 0.244) (writing took 2.5658002509735525 seconds)
[2024-03-26 17:15:50,679][fairseq_cli.train][INFO] - end of epoch 265 (average epoch stats below)
[2024-03-26 17:15:50,680][train][INFO] - {"epoch": 265, "train_loss": "0.218", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.028", "train_target_var": "0.738", "train_pred_var": "0.732", "train_masked_pct": "0.5", "train_wps": "8203.3", "train_ups": "0.76", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2113", "train_lr": "0.000198094", "train_gnorm": "1.719", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2769"}
[2024-03-26 17:15:50,682][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:15:50,751][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 266
[2024-03-26 17:15:50,753][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:15:50,756][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:15:50,761][fairseq.trainer][INFO] - begin training epoch 266
[2024-03-26 17:15:50,761][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:15:57,973][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 266 @ 2121 updates
[2024-03-26 17:15:57,975][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:00,486][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:00,546][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 266 @ 2121 updates, score None) (writing took 2.5733442488126457 seconds)
[2024-03-26 17:16:00,546][fairseq_cli.train][INFO] - end of epoch 266 (average epoch stats below)
[2024-03-26 17:16:00,547][train][INFO] - {"epoch": 266, "train_loss": "0.246", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.028", "train_target_var": "0.737", "train_pred_var": "0.731", "train_masked_pct": "0.498", "train_wps": "8732.8", "train_ups": "0.81", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "2121", "train_lr": "0.000198844", "train_gnorm": "2.355", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2778"}
[2024-03-26 17:16:00,549][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:00,610][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 267
[2024-03-26 17:16:00,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:00,616][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:00,620][fairseq.trainer][INFO] - begin training epoch 267
[2024-03-26 17:16:00,621][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:08,072][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 267 @ 2129 updates
[2024-03-26 17:16:08,074][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:10,553][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:10,613][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 267 @ 2129 updates, score None) (writing took 2.5406989250332117 seconds)
[2024-03-26 17:16:10,614][fairseq_cli.train][INFO] - end of epoch 267 (average epoch stats below)
[2024-03-26 17:16:10,614][train][INFO] - {"epoch": 267, "train_loss": "0.306", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.028", "train_target_var": "0.738", "train_pred_var": "0.731", "train_masked_pct": "0.499", "train_wps": "8558.5", "train_ups": "0.79", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2129", "train_lr": "0.000199594", "train_gnorm": "3.104", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2788"}
[2024-03-26 17:16:10,616][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:10,677][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 268
[2024-03-26 17:16:10,678][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:10,681][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:10,686][fairseq.trainer][INFO] - begin training epoch 268
[2024-03-26 17:16:10,687][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:17,984][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 268 @ 2137 updates
[2024-03-26 17:16:17,985][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:20,469][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:20,529][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 268 @ 2137 updates, score None) (writing took 2.545413119252771 seconds)
[2024-03-26 17:16:20,531][fairseq_cli.train][INFO] - end of epoch 268 (average epoch stats below)
[2024-03-26 17:16:20,531][train][INFO] - {"epoch": 268, "train_loss": "0.318", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.028", "train_target_var": "0.737", "train_pred_var": "0.729", "train_masked_pct": "0.5", "train_wps": "8687.7", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2137", "train_lr": "0.000200344", "train_gnorm": "4.736", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2798"}
[2024-03-26 17:16:20,533][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:20,593][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 269
[2024-03-26 17:16:20,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:20,598][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:20,603][fairseq.trainer][INFO] - begin training epoch 269
[2024-03-26 17:16:20,603][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:27,906][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 269 @ 2145 updates
[2024-03-26 17:16:27,908][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:30,415][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:30,452][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 269 @ 2145 updates, score None) (writing took 2.545909935608506 seconds)
[2024-03-26 17:16:30,453][fairseq_cli.train][INFO] - end of epoch 269 (average epoch stats below)
[2024-03-26 17:16:30,453][train][INFO] - {"epoch": 269, "train_loss": "0.284", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.028", "train_target_var": "0.736", "train_pred_var": "0.729", "train_masked_pct": "0.499", "train_wps": "8683.7", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2145", "train_lr": "0.000201094", "train_gnorm": "2.312", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "2808"}
[2024-03-26 17:16:30,456][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:30,543][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 270
[2024-03-26 17:16:30,544][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:30,548][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:30,552][fairseq.trainer][INFO] - begin training epoch 270
[2024-03-26 17:16:30,553][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:37,809][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:16:37,810][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:37,872][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 55
[2024-03-26 17:16:37,876][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:38,286][valid][INFO] - {"epoch": 270, "valid_loss": "0.237", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.028", "valid_target_var": "0.739", "valid_pred_var": "0.743", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "2153", "valid_best_loss": "0.233"}
[2024-03-26 17:16:38,288][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 270 @ 2153 updates
[2024-03-26 17:16:38,289][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:40,786][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:40,847][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 270 @ 2153 updates, score 0.237) (writing took 2.5593634387478232 seconds)
[2024-03-26 17:16:40,848][fairseq_cli.train][INFO] - end of epoch 270 (average epoch stats below)
[2024-03-26 17:16:40,848][train][INFO] - {"epoch": 270, "train_loss": "0.234", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.028", "train_target_var": "0.737", "train_pred_var": "0.733", "train_masked_pct": "0.501", "train_wps": "8288.1", "train_ups": "0.77", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2153", "train_lr": "0.000201844", "train_gnorm": "2.184", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2819"}
[2024-03-26 17:16:40,850][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:40,912][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 271
[2024-03-26 17:16:40,914][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:40,917][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:40,922][fairseq.trainer][INFO] - begin training epoch 271
[2024-03-26 17:16:40,923][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:48,097][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 271 @ 2161 updates
[2024-03-26 17:16:48,098][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:50,578][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:16:50,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 271 @ 2161 updates, score None) (writing took 2.5374604710377753 seconds)
[2024-03-26 17:16:50,635][fairseq_cli.train][INFO] - end of epoch 271 (average epoch stats below)
[2024-03-26 17:16:50,636][train][INFO] - {"epoch": 271, "train_loss": "0.3", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.028", "train_target_var": "0.741", "train_pred_var": "0.736", "train_masked_pct": "0.5", "train_wps": "8803.3", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2161", "train_lr": "0.000202594", "train_gnorm": "2.469", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2828"}
[2024-03-26 17:16:50,638][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:16:50,700][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 272
[2024-03-26 17:16:50,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:16:50,705][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:16:50,709][fairseq.trainer][INFO] - begin training epoch 272
[2024-03-26 17:16:50,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:16:58,217][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 272 @ 2169 updates
[2024-03-26 17:16:58,219][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:00,696][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:00,756][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 272 @ 2169 updates, score None) (writing took 2.538511237129569 seconds)
[2024-03-26 17:17:00,756][fairseq_cli.train][INFO] - end of epoch 272 (average epoch stats below)
[2024-03-26 17:17:00,757][train][INFO] - {"epoch": 272, "train_loss": "0.393", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.029", "train_target_var": "0.739", "train_pred_var": "0.732", "train_masked_pct": "0.5", "train_wps": "8512.4", "train_ups": "0.79", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2169", "train_lr": "0.000203344", "train_gnorm": "2.339", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2839"}
[2024-03-26 17:17:00,760][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:00,822][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 273
[2024-03-26 17:17:00,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:00,826][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:00,831][fairseq.trainer][INFO] - begin training epoch 273
[2024-03-26 17:17:00,832][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:08,134][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 273 @ 2177 updates
[2024-03-26 17:17:08,135][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:10,600][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:10,653][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 273 @ 2177 updates, score None) (writing took 2.5191041827201843 seconds)
[2024-03-26 17:17:10,654][fairseq_cli.train][INFO] - end of epoch 273 (average epoch stats below)
[2024-03-26 17:17:10,654][train][INFO] - {"epoch": 273, "train_loss": "0.306", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.029", "train_target_var": "0.742", "train_pred_var": "0.734", "train_masked_pct": "0.501", "train_wps": "8705.6", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2177", "train_lr": "0.000204094", "train_gnorm": "2.038", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2848"}
[2024-03-26 17:17:10,656][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:10,734][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 274
[2024-03-26 17:17:10,735][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:10,738][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:10,743][fairseq.trainer][INFO] - begin training epoch 274
[2024-03-26 17:17:10,744][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:17,957][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 274 @ 2185 updates
[2024-03-26 17:17:17,959][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:20,450][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:20,509][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 274 @ 2185 updates, score None) (writing took 2.5517907538451254 seconds)
[2024-03-26 17:17:20,510][fairseq_cli.train][INFO] - end of epoch 274 (average epoch stats below)
[2024-03-26 17:17:20,510][train][INFO] - {"epoch": 274, "train_loss": "0.291", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.029", "train_target_var": "0.738", "train_pred_var": "0.732", "train_masked_pct": "0.499", "train_wps": "8741.2", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2185", "train_lr": "0.000204844", "train_gnorm": "1.776", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2858"}
[2024-03-26 17:17:20,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:20,576][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 275
[2024-03-26 17:17:20,577][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:20,581][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:20,585][fairseq.trainer][INFO] - begin training epoch 275
[2024-03-26 17:17:20,586][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:27,880][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:17:27,882][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:27,944][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 56
[2024-03-26 17:17:27,947][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:28,367][valid][INFO] - {"epoch": 275, "valid_loss": "0.293", "valid_ntokens": "11709", "valid_nsentences": "25", "valid_sample_size": "11709", "valid_ema_decay": "999.029", "valid_target_var": "0.751", "valid_pred_var": "0.754", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11709", "valid_bsz": "25", "valid_num_updates": "2193", "valid_best_loss": "0.233"}
[2024-03-26 17:17:28,368][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 275 @ 2193 updates
[2024-03-26 17:17:28,370][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:30,850][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:30,912][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 275 @ 2193 updates, score 0.293) (writing took 2.5437514148652554 seconds)
[2024-03-26 17:17:30,913][fairseq_cli.train][INFO] - end of epoch 275 (average epoch stats below)
[2024-03-26 17:17:30,913][train][INFO] - {"epoch": 275, "train_loss": "0.287", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.029", "train_target_var": "0.746", "train_pred_var": "0.739", "train_masked_pct": "0.5", "train_wps": "8282.8", "train_ups": "0.77", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2193", "train_lr": "0.000205594", "train_gnorm": "1.475", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2869"}
[2024-03-26 17:17:30,915][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:30,978][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 276
[2024-03-26 17:17:30,979][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:30,982][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:30,987][fairseq.trainer][INFO] - begin training epoch 276
[2024-03-26 17:17:30,988][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:38,065][train_inner][INFO] - {"epoch": 276, "update": 275.875, "loss": "0.288", "ntokens": "10826", "nsentences": "22.995", "sample_size": "10826", "ema_decay": "999.028", "target_var": "0.735", "pred_var": "0.729", "masked_pct": "0.5", "wps": "8626.5", "ups": "0.8", "wpb": "10826", "bsz": "23", "num_updates": "2200", "lr": "0.00020625", "gnorm": "2.517", "loss_scale": "1", "train_wall": "176", "gb_free": "5.4", "wall": "2876"}
[2024-03-26 17:17:38,219][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 276 @ 2201 updates
[2024-03-26 17:17:38,221][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:40,695][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:40,732][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 276 @ 2201 updates, score None) (writing took 2.51243644207716 seconds)
[2024-03-26 17:17:40,733][fairseq_cli.train][INFO] - end of epoch 276 (average epoch stats below)
[2024-03-26 17:17:40,733][train][INFO] - {"epoch": 276, "train_loss": "0.27", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.029", "train_target_var": "0.744", "train_pred_var": "0.737", "train_masked_pct": "0.5", "train_wps": "8774.4", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2201", "train_lr": "0.000206344", "train_gnorm": "1.42", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2879"}
[2024-03-26 17:17:40,735][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:40,819][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 277
[2024-03-26 17:17:40,821][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:40,824][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:40,829][fairseq.trainer][INFO] - begin training epoch 277
[2024-03-26 17:17:40,829][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:48,007][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 277 @ 2209 updates
[2024-03-26 17:17:48,009][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:50,509][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:17:50,570][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 277 @ 2209 updates, score None) (writing took 2.5627731210552156 seconds)
[2024-03-26 17:17:50,571][fairseq_cli.train][INFO] - end of epoch 277 (average epoch stats below)
[2024-03-26 17:17:50,571][train][INFO] - {"epoch": 277, "train_loss": "0.316", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.029", "train_target_var": "0.745", "train_pred_var": "0.74", "train_masked_pct": "0.501", "train_wps": "8758.3", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2209", "train_lr": "0.000207094", "train_gnorm": "3.391", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "2888"}
[2024-03-26 17:17:50,573][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:17:50,635][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 278
[2024-03-26 17:17:50,636][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:17:50,639][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:17:50,644][fairseq.trainer][INFO] - begin training epoch 278
[2024-03-26 17:17:50,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:17:57,970][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 278 @ 2217 updates
[2024-03-26 17:17:57,971][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:00,454][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:00,491][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 278 @ 2217 updates, score None) (writing took 2.5214629103429615 seconds)
[2024-03-26 17:18:00,492][fairseq_cli.train][INFO] - end of epoch 278 (average epoch stats below)
[2024-03-26 17:18:00,492][train][INFO] - {"epoch": 278, "train_loss": "0.296", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.029", "train_target_var": "0.745", "train_pred_var": "0.737", "train_masked_pct": "0.5", "train_wps": "8684.5", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2217", "train_lr": "0.000207844", "train_gnorm": "2.416", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2898"}
[2024-03-26 17:18:00,495][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:00,581][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 279
[2024-03-26 17:18:00,583][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:00,586][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:00,591][fairseq.trainer][INFO] - begin training epoch 279
[2024-03-26 17:18:00,591][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:07,760][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 279 @ 2225 updates
[2024-03-26 17:18:07,762][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:10,238][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:10,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 279 @ 2225 updates, score None) (writing took 2.532815877813846 seconds)
[2024-03-26 17:18:10,294][fairseq_cli.train][INFO] - end of epoch 279 (average epoch stats below)
[2024-03-26 17:18:10,295][train][INFO] - {"epoch": 279, "train_loss": "0.346", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.029", "train_target_var": "0.749", "train_pred_var": "0.74", "train_masked_pct": "0.5", "train_wps": "8789.8", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2225", "train_lr": "0.000208594", "train_gnorm": "5.544", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2908"}
[2024-03-26 17:18:10,297][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:10,366][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 280
[2024-03-26 17:18:10,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:10,371][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:10,376][fairseq.trainer][INFO] - begin training epoch 280
[2024-03-26 17:18:10,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:17,682][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:18:17,683][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:17,746][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 57
[2024-03-26 17:18:17,749][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:18,170][valid][INFO] - {"epoch": 280, "valid_loss": "0.341", "valid_ntokens": "11695", "valid_nsentences": "25", "valid_sample_size": "11695", "valid_ema_decay": "999.029", "valid_target_var": "0.745", "valid_pred_var": "0.733", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11695", "valid_bsz": "25", "valid_num_updates": "2233", "valid_best_loss": "0.233"}
[2024-03-26 17:18:18,172][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 280 @ 2233 updates
[2024-03-26 17:18:18,174][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:20,657][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:20,694][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 280 @ 2233 updates, score 0.341) (writing took 2.521928866393864 seconds)
[2024-03-26 17:18:20,695][fairseq_cli.train][INFO] - end of epoch 280 (average epoch stats below)
[2024-03-26 17:18:20,695][train][INFO] - {"epoch": 280, "train_loss": "0.413", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.029", "train_target_var": "0.739", "train_pred_var": "0.732", "train_masked_pct": "0.499", "train_wps": "8283.8", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2233", "train_lr": "0.000209344", "train_gnorm": "2.375", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2919"}
[2024-03-26 17:18:20,698][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:20,783][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 281
[2024-03-26 17:18:20,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:20,788][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:20,793][fairseq.trainer][INFO] - begin training epoch 281
[2024-03-26 17:18:20,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:27,946][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 281 @ 2241 updates
[2024-03-26 17:18:27,947][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:30,449][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:30,512][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 281 @ 2241 updates, score None) (writing took 2.565671098884195 seconds)
[2024-03-26 17:18:30,512][fairseq_cli.train][INFO] - end of epoch 281 (average epoch stats below)
[2024-03-26 17:18:30,513][train][INFO] - {"epoch": 281, "train_loss": "0.403", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.03", "train_target_var": "0.744", "train_pred_var": "0.736", "train_masked_pct": "0.499", "train_wps": "8776.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2241", "train_lr": "0.000210094", "train_gnorm": "2.503", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2928"}
[2024-03-26 17:18:30,515][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:30,578][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 282
[2024-03-26 17:18:30,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:30,583][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:30,588][fairseq.trainer][INFO] - begin training epoch 282
[2024-03-26 17:18:30,588][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:37,791][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 282 @ 2249 updates
[2024-03-26 17:18:37,793][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:40,278][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:40,339][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 282 @ 2249 updates, score None) (writing took 2.547157616354525 seconds)
[2024-03-26 17:18:40,339][fairseq_cli.train][INFO] - end of epoch 282 (average epoch stats below)
[2024-03-26 17:18:40,340][train][INFO] - {"epoch": 282, "train_loss": "0.331", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.03", "train_target_var": "0.744", "train_pred_var": "0.739", "train_masked_pct": "0.499", "train_wps": "8768.2", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2249", "train_lr": "0.000210844", "train_gnorm": "2.693", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2938"}
[2024-03-26 17:18:40,342][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:40,405][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 283
[2024-03-26 17:18:40,406][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:40,409][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:40,414][fairseq.trainer][INFO] - begin training epoch 283
[2024-03-26 17:18:40,415][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:47,572][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 283 @ 2257 updates
[2024-03-26 17:18:47,573][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:50,048][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:50,110][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 283 @ 2257 updates, score None) (writing took 2.538342180661857 seconds)
[2024-03-26 17:18:50,111][fairseq_cli.train][INFO] - end of epoch 283 (average epoch stats below)
[2024-03-26 17:18:50,111][train][INFO] - {"epoch": 283, "train_loss": "0.354", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.03", "train_target_var": "0.752", "train_pred_var": "0.742", "train_masked_pct": "0.501", "train_wps": "8818.2", "train_ups": "0.82", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "2257", "train_lr": "0.000211594", "train_gnorm": "2.36", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2948"}
[2024-03-26 17:18:50,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:18:50,179][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 284
[2024-03-26 17:18:50,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:18:50,184][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:18:50,188][fairseq.trainer][INFO] - begin training epoch 284
[2024-03-26 17:18:50,189][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:18:57,403][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 284 @ 2265 updates
[2024-03-26 17:18:57,404][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:18:59,954][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:00,014][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 284 @ 2265 updates, score None) (writing took 2.6109691811725497 seconds)
[2024-03-26 17:19:00,015][fairseq_cli.train][INFO] - end of epoch 284 (average epoch stats below)
[2024-03-26 17:19:00,015][train][INFO] - {"epoch": 284, "train_loss": "0.313", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.03", "train_target_var": "0.749", "train_pred_var": "0.741", "train_masked_pct": "0.499", "train_wps": "8700", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2265", "train_lr": "0.000212344", "train_gnorm": "2.199", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2958"}
[2024-03-26 17:19:00,017][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:00,081][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 285
[2024-03-26 17:19:00,083][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:00,086][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:00,091][fairseq.trainer][INFO] - begin training epoch 285
[2024-03-26 17:19:00,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:07,403][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:19:07,405][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:07,495][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 58
[2024-03-26 17:19:07,499][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:07,893][valid][INFO] - {"epoch": 285, "valid_loss": "0.331", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.03", "valid_target_var": "0.753", "valid_pred_var": "0.734", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "2273", "valid_best_loss": "0.233"}
[2024-03-26 17:19:07,894][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 285 @ 2273 updates
[2024-03-26 17:19:07,896][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:10,399][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:10,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 285 @ 2273 updates, score 0.331) (writing took 2.5657648243941367 seconds)
[2024-03-26 17:19:10,461][fairseq_cli.train][INFO] - end of epoch 285 (average epoch stats below)
[2024-03-26 17:19:10,463][train][INFO] - {"epoch": 285, "train_loss": "0.301", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.03", "train_target_var": "0.749", "train_pred_var": "0.745", "train_masked_pct": "0.499", "train_wps": "8246.7", "train_ups": "0.77", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2273", "train_lr": "0.000213094", "train_gnorm": "2.139", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "2968"}
[2024-03-26 17:19:10,465][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:10,527][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 286
[2024-03-26 17:19:10,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:10,532][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:10,537][fairseq.trainer][INFO] - begin training epoch 286
[2024-03-26 17:19:10,537][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:17,925][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 286 @ 2281 updates
[2024-03-26 17:19:17,926][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:20,421][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:20,481][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 286 @ 2281 updates, score None) (writing took 2.5568352048285306 seconds)
[2024-03-26 17:19:20,482][fairseq_cli.train][INFO] - end of epoch 286 (average epoch stats below)
[2024-03-26 17:19:20,483][train][INFO] - {"epoch": 286, "train_loss": "0.289", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.03", "train_target_var": "0.75", "train_pred_var": "0.744", "train_masked_pct": "0.5", "train_wps": "8599.3", "train_ups": "0.8", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2281", "train_lr": "0.000213844", "train_gnorm": "2.294", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2978"}
[2024-03-26 17:19:20,485][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:20,546][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 287
[2024-03-26 17:19:20,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:20,550][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:20,556][fairseq.trainer][INFO] - begin training epoch 287
[2024-03-26 17:19:20,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:27,923][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 287 @ 2289 updates
[2024-03-26 17:19:27,925][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:30,410][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:30,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 287 @ 2289 updates, score None) (writing took 2.5475611337460577 seconds)
[2024-03-26 17:19:30,471][fairseq_cli.train][INFO] - end of epoch 287 (average epoch stats below)
[2024-03-26 17:19:30,472][train][INFO] - {"epoch": 287, "train_loss": "0.343", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.03", "train_target_var": "0.752", "train_pred_var": "0.743", "train_masked_pct": "0.499", "train_wps": "8624.4", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "2289", "train_lr": "0.000214594", "train_gnorm": "4.284", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "2988"}
[2024-03-26 17:19:30,474][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:30,536][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 288
[2024-03-26 17:19:30,537][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:30,540][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:30,545][fairseq.trainer][INFO] - begin training epoch 288
[2024-03-26 17:19:30,546][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:37,907][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 288 @ 2297 updates
[2024-03-26 17:19:37,909][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:40,378][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:40,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 288 @ 2297 updates, score None) (writing took 2.5219261310994625 seconds)
[2024-03-26 17:19:40,430][fairseq_cli.train][INFO] - end of epoch 288 (average epoch stats below)
[2024-03-26 17:19:40,431][train][INFO] - {"epoch": 288, "train_loss": "0.309", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.03", "train_target_var": "0.744", "train_pred_var": "0.736", "train_masked_pct": "0.499", "train_wps": "8651", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "2297", "train_lr": "0.000215344", "train_gnorm": "1.941", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "2998"}
[2024-03-26 17:19:40,433][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:40,509][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 289
[2024-03-26 17:19:40,510][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:40,513][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:40,518][fairseq.trainer][INFO] - begin training epoch 289
[2024-03-26 17:19:40,519][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:47,812][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 289 @ 2305 updates
[2024-03-26 17:19:47,814][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:50,338][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:19:50,392][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 289 @ 2305 updates, score None) (writing took 2.5797905903309584 seconds)
[2024-03-26 17:19:50,393][fairseq_cli.train][INFO] - end of epoch 289 (average epoch stats below)
[2024-03-26 17:19:50,393][train][INFO] - {"epoch": 289, "train_loss": "0.315", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.03", "train_target_var": "0.747", "train_pred_var": "0.737", "train_masked_pct": "0.501", "train_wps": "8648.6", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2305", "train_lr": "0.000216094", "train_gnorm": "2.541", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3008"}
[2024-03-26 17:19:50,395][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:50,466][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 290
[2024-03-26 17:19:50,468][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:19:50,471][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:50,475][fairseq.trainer][INFO] - begin training epoch 290
[2024-03-26 17:19:50,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:19:57,778][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:19:57,779][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:19:57,842][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 59
[2024-03-26 17:19:57,845][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:19:58,258][valid][INFO] - {"epoch": 290, "valid_loss": "0.307", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.031", "valid_target_var": "0.764", "valid_pred_var": "0.779", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "2313", "valid_best_loss": "0.233"}
[2024-03-26 17:19:58,260][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 290 @ 2313 updates
[2024-03-26 17:19:58,261][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:00,741][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:00,805][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 290 @ 2313 updates, score 0.307) (writing took 2.5457215257920325 seconds)
[2024-03-26 17:20:00,806][fairseq_cli.train][INFO] - end of epoch 290 (average epoch stats below)
[2024-03-26 17:20:00,807][train][INFO] - {"epoch": 290, "train_loss": "0.311", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.03", "train_target_var": "0.753", "train_pred_var": "0.745", "train_masked_pct": "0.499", "train_wps": "8273.4", "train_ups": "0.77", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2313", "train_lr": "0.000216844", "train_gnorm": "1.934", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3019"}
[2024-03-26 17:20:00,809][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:00,892][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 291
[2024-03-26 17:20:00,894][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:00,897][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:00,901][fairseq.trainer][INFO] - begin training epoch 291
[2024-03-26 17:20:00,902][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:08,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 291 @ 2321 updates
[2024-03-26 17:20:08,133][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:10,622][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:10,671][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 291 @ 2321 updates, score None) (writing took 2.5399945941753685 seconds)
[2024-03-26 17:20:10,672][fairseq_cli.train][INFO] - end of epoch 291 (average epoch stats below)
[2024-03-26 17:20:10,672][train][INFO] - {"epoch": 291, "train_loss": "0.243", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.031", "train_target_var": "0.754", "train_pred_var": "0.747", "train_masked_pct": "0.499", "train_wps": "8732.5", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2321", "train_lr": "0.000217594", "train_gnorm": "1.842", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3029"}
[2024-03-26 17:20:10,675][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:10,755][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 292
[2024-03-26 17:20:10,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:10,760][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:10,764][fairseq.trainer][INFO] - begin training epoch 292
[2024-03-26 17:20:10,765][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:18,000][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 292 @ 2329 updates
[2024-03-26 17:20:18,001][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:20,489][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:20,522][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 292 @ 2329 updates, score None) (writing took 2.5219181426800787 seconds)
[2024-03-26 17:20:20,522][fairseq_cli.train][INFO] - end of epoch 292 (average epoch stats below)
[2024-03-26 17:20:20,523][train][INFO] - {"epoch": 292, "train_loss": "0.227", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.031", "train_target_var": "0.752", "train_pred_var": "0.748", "train_masked_pct": "0.501", "train_wps": "8746.8", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2329", "train_lr": "0.000218344", "train_gnorm": "2.296", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3038"}
[2024-03-26 17:20:20,525][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:20,614][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 293
[2024-03-26 17:20:20,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:20,619][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:20,624][fairseq.trainer][INFO] - begin training epoch 293
[2024-03-26 17:20:20,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:27,899][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 293 @ 2337 updates
[2024-03-26 17:20:27,901][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:30,398][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:30,462][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 293 @ 2337 updates, score None) (writing took 2.562917387112975 seconds)
[2024-03-26 17:20:30,463][fairseq_cli.train][INFO] - end of epoch 293 (average epoch stats below)
[2024-03-26 17:20:30,464][train][INFO] - {"epoch": 293, "train_loss": "0.228", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.031", "train_target_var": "0.754", "train_pred_var": "0.749", "train_masked_pct": "0.501", "train_wps": "8667.5", "train_ups": "0.8", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "2337", "train_lr": "0.000219094", "train_gnorm": "2.137", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3048"}
[2024-03-26 17:20:30,466][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:30,530][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 294
[2024-03-26 17:20:30,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:30,535][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:30,539][fairseq.trainer][INFO] - begin training epoch 294
[2024-03-26 17:20:30,540][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:37,882][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 294 @ 2345 updates
[2024-03-26 17:20:37,884][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:40,371][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:40,433][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 294 @ 2345 updates, score None) (writing took 2.551120614632964 seconds)
[2024-03-26 17:20:40,434][fairseq_cli.train][INFO] - end of epoch 294 (average epoch stats below)
[2024-03-26 17:20:40,435][train][INFO] - {"epoch": 294, "train_loss": "0.255", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.031", "train_target_var": "0.753", "train_pred_var": "0.747", "train_masked_pct": "0.498", "train_wps": "8640.4", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2345", "train_lr": "0.000219844", "train_gnorm": "2.105", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "3058"}
[2024-03-26 17:20:40,437][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:40,500][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 295
[2024-03-26 17:20:40,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:40,505][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:40,510][fairseq.trainer][INFO] - begin training epoch 295
[2024-03-26 17:20:40,511][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:47,905][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:20:47,907][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:47,985][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 60
[2024-03-26 17:20:47,988][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:48,395][valid][INFO] - {"epoch": 295, "valid_loss": "0.282", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.031", "valid_target_var": "0.754", "valid_pred_var": "0.748", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "2353", "valid_best_loss": "0.233"}
[2024-03-26 17:20:48,396][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 295 @ 2353 updates
[2024-03-26 17:20:48,398][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:50,895][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:20:50,957][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 295 @ 2353 updates, score 0.282) (writing took 2.5604101261124015 seconds)
[2024-03-26 17:20:50,957][fairseq_cli.train][INFO] - end of epoch 295 (average epoch stats below)
[2024-03-26 17:20:50,958][train][INFO] - {"epoch": 295, "train_loss": "0.262", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.031", "train_target_var": "0.753", "train_pred_var": "0.748", "train_masked_pct": "0.499", "train_wps": "8187.9", "train_ups": "0.76", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2353", "train_lr": "0.000220594", "train_gnorm": "1.759", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3069"}
[2024-03-26 17:20:50,960][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:20:51,022][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 296
[2024-03-26 17:20:51,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:20:51,026][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:20:51,031][fairseq.trainer][INFO] - begin training epoch 296
[2024-03-26 17:20:51,032][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:20:58,322][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 296 @ 2361 updates
[2024-03-26 17:20:58,323][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:00,808][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:00,871][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 296 @ 2361 updates, score None) (writing took 2.5488134203478694 seconds)
[2024-03-26 17:21:00,872][fairseq_cli.train][INFO] - end of epoch 296 (average epoch stats below)
[2024-03-26 17:21:00,872][train][INFO] - {"epoch": 296, "train_loss": "0.328", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.031", "train_target_var": "0.751", "train_pred_var": "0.744", "train_masked_pct": "0.499", "train_wps": "8690.1", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2361", "train_lr": "0.000221344", "train_gnorm": "2.225", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3079"}
[2024-03-26 17:21:00,874][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:00,937][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 297
[2024-03-26 17:21:00,938][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:00,941][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:00,946][fairseq.trainer][INFO] - begin training epoch 297
[2024-03-26 17:21:00,947][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:08,029][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 297 @ 2369 updates
[2024-03-26 17:21:08,030][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:10,521][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:10,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 297 @ 2369 updates, score None) (writing took 2.5541649400256574 seconds)
[2024-03-26 17:21:10,584][fairseq_cli.train][INFO] - end of epoch 297 (average epoch stats below)
[2024-03-26 17:21:10,584][train][INFO] - {"epoch": 297, "train_loss": "0.346", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.031", "train_target_var": "0.749", "train_pred_var": "0.741", "train_masked_pct": "0.501", "train_wps": "8871", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2369", "train_lr": "0.000222094", "train_gnorm": "2.366", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3088"}
[2024-03-26 17:21:10,587][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:10,649][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 298
[2024-03-26 17:21:10,651][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:10,654][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:10,659][fairseq.trainer][INFO] - begin training epoch 298
[2024-03-26 17:21:10,659][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:17,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 298 @ 2377 updates
[2024-03-26 17:21:17,970][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:20,495][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:20,556][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 298 @ 2377 updates, score None) (writing took 2.5874949148856103 seconds)
[2024-03-26 17:21:20,557][fairseq_cli.train][INFO] - end of epoch 298 (average epoch stats below)
[2024-03-26 17:21:20,557][train][INFO] - {"epoch": 298, "train_loss": "0.355", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.031", "train_target_var": "0.754", "train_pred_var": "0.746", "train_masked_pct": "0.501", "train_wps": "8639.5", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2377", "train_lr": "0.000222844", "train_gnorm": "2.655", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3098"}
[2024-03-26 17:21:20,559][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:20,622][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 299
[2024-03-26 17:21:20,623][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:20,626][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:20,631][fairseq.trainer][INFO] - begin training epoch 299
[2024-03-26 17:21:20,632][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:27,907][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 299 @ 2385 updates
[2024-03-26 17:21:27,909][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:30,397][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:30,457][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 299 @ 2385 updates, score None) (writing took 2.5503706419840455 seconds)
[2024-03-26 17:21:30,458][fairseq_cli.train][INFO] - end of epoch 299 (average epoch stats below)
[2024-03-26 17:21:30,459][train][INFO] - {"epoch": 299, "train_loss": "0.311", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.031", "train_target_var": "0.754", "train_pred_var": "0.746", "train_masked_pct": "0.5", "train_wps": "8702", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2385", "train_lr": "0.000223594", "train_gnorm": "2.82", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3108"}
[2024-03-26 17:21:30,461][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:30,524][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 300
[2024-03-26 17:21:30,526][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:30,529][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:30,534][fairseq.trainer][INFO] - begin training epoch 300
[2024-03-26 17:21:30,534][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:37,904][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:21:37,905][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:37,978][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 61
[2024-03-26 17:21:37,982][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:38,397][valid][INFO] - {"epoch": 300, "valid_loss": "0.385", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.032", "valid_target_var": "0.755", "valid_pred_var": "0.749", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "2393", "valid_best_loss": "0.233"}
[2024-03-26 17:21:38,399][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 300 @ 2393 updates
[2024-03-26 17:21:38,400][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:40,877][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:40,938][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 300 @ 2393 updates, score 0.385) (writing took 2.539686289150268 seconds)
[2024-03-26 17:21:40,939][fairseq_cli.train][INFO] - end of epoch 300 (average epoch stats below)
[2024-03-26 17:21:40,939][train][INFO] - {"epoch": 300, "train_loss": "0.381", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.032", "train_target_var": "0.75", "train_pred_var": "0.74", "train_masked_pct": "0.498", "train_wps": "8220.3", "train_ups": "0.76", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2393", "train_lr": "0.000224344", "train_gnorm": "2.632", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3119"}
[2024-03-26 17:21:40,941][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:41,006][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 301
[2024-03-26 17:21:41,007][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:41,010][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:41,017][fairseq.trainer][INFO] - begin training epoch 301
[2024-03-26 17:21:41,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:47,170][train_inner][INFO] - {"epoch": 301, "update": 300.875, "loss": "0.317", "ntokens": "10713.5", "nsentences": "22.755", "sample_size": "10713.5", "ema_decay": "999.03", "target_var": "0.75", "pred_var": "0.742", "masked_pct": "0.5", "wps": "8601.6", "ups": "0.8", "wpb": "10713.5", "bsz": "22.8", "num_updates": "2400", "lr": "0.000225", "gnorm": "2.591", "loss_scale": "1", "train_wall": "174", "gb_free": "5.4", "wall": "3125"}
[2024-03-26 17:21:48,179][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 301 @ 2401 updates
[2024-03-26 17:21:48,181][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:50,658][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:21:50,696][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 301 @ 2401 updates, score None) (writing took 2.5170405441895127 seconds)
[2024-03-26 17:21:50,698][fairseq_cli.train][INFO] - end of epoch 301 (average epoch stats below)
[2024-03-26 17:21:50,698][train][INFO] - {"epoch": 301, "train_loss": "0.35", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.032", "train_target_var": "0.752", "train_pred_var": "0.742", "train_masked_pct": "0.5", "train_wps": "8829.2", "train_ups": "0.82", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2401", "train_lr": "0.000225094", "train_gnorm": "3.353", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3129"}
[2024-03-26 17:21:50,700][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:21:50,785][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 302
[2024-03-26 17:21:50,786][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:21:50,789][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:21:50,794][fairseq.trainer][INFO] - begin training epoch 302
[2024-03-26 17:21:50,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:21:58,217][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 302 @ 2409 updates
[2024-03-26 17:21:58,219][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:00,669][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:00,701][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 302 @ 2409 updates, score None) (writing took 2.4840469700284302 seconds)
[2024-03-26 17:22:00,701][fairseq_cli.train][INFO] - end of epoch 302 (average epoch stats below)
[2024-03-26 17:22:00,702][train][INFO] - {"epoch": 302, "train_loss": "0.284", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.032", "train_target_var": "0.759", "train_pred_var": "0.753", "train_masked_pct": "0.499", "train_wps": "8612.6", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2409", "train_lr": "0.000225844", "train_gnorm": "2.186", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3139"}
[2024-03-26 17:22:00,704][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:00,794][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 303
[2024-03-26 17:22:00,796][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:00,799][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:00,803][fairseq.trainer][INFO] - begin training epoch 303
[2024-03-26 17:22:00,804][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:08,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 303 @ 2417 updates
[2024-03-26 17:22:08,123][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:10,610][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:10,683][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 303 @ 2417 updates, score None) (writing took 2.561350141186267 seconds)
[2024-03-26 17:22:10,684][fairseq_cli.train][INFO] - end of epoch 303 (average epoch stats below)
[2024-03-26 17:22:10,685][train][INFO] - {"epoch": 303, "train_loss": "0.261", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.032", "train_target_var": "0.758", "train_pred_var": "0.752", "train_masked_pct": "0.5", "train_wps": "8630.9", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2417", "train_lr": "0.000226594", "train_gnorm": "2.254", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3149"}
[2024-03-26 17:22:10,689][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:10,755][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 304
[2024-03-26 17:22:10,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:10,761][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:10,766][fairseq.trainer][INFO] - begin training epoch 304
[2024-03-26 17:22:10,766][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:17,903][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 304 @ 2425 updates
[2024-03-26 17:22:17,905][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:20,374][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:20,410][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 304 @ 2425 updates, score None) (writing took 2.5066254241392016 seconds)
[2024-03-26 17:22:20,411][fairseq_cli.train][INFO] - end of epoch 304 (average epoch stats below)
[2024-03-26 17:22:20,412][train][INFO] - {"epoch": 304, "train_loss": "0.334", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.032", "train_target_var": "0.761", "train_pred_var": "0.751", "train_masked_pct": "0.498", "train_wps": "8858.3", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2425", "train_lr": "0.000227344", "train_gnorm": "2.902", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3158"}
[2024-03-26 17:22:20,414][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:20,500][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 305
[2024-03-26 17:22:20,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:20,505][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:20,510][fairseq.trainer][INFO] - begin training epoch 305
[2024-03-26 17:22:20,510][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:27,874][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:22:27,875][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:27,937][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 62
[2024-03-26 17:22:27,940][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:28,343][valid][INFO] - {"epoch": 305, "valid_loss": "0.304", "valid_ntokens": "11719", "valid_nsentences": "25", "valid_sample_size": "11719", "valid_ema_decay": "999.032", "valid_target_var": "0.755", "valid_pred_var": "0.746", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11719", "valid_bsz": "25", "valid_num_updates": "2433", "valid_best_loss": "0.233"}
[2024-03-26 17:22:28,345][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 305 @ 2433 updates
[2024-03-26 17:22:28,346][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:30,814][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:30,848][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 305 @ 2433 updates, score 0.304) (writing took 2.5039483830332756 seconds)
[2024-03-26 17:22:30,849][fairseq_cli.train][INFO] - end of epoch 305 (average epoch stats below)
[2024-03-26 17:22:30,850][train][INFO] - {"epoch": 305, "train_loss": "0.377", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.032", "train_target_var": "0.75", "train_pred_var": "0.745", "train_masked_pct": "0.501", "train_wps": "8253.7", "train_ups": "0.77", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2433", "train_lr": "0.000228094", "train_gnorm": "3.341", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3169"}
[2024-03-26 17:22:30,852][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:30,935][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 306
[2024-03-26 17:22:30,936][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:30,939][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:30,942][fairseq.trainer][INFO] - begin training epoch 306
[2024-03-26 17:22:30,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:38,207][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 306 @ 2441 updates
[2024-03-26 17:22:38,209][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:40,693][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:40,754][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 306 @ 2441 updates, score None) (writing took 2.546661556698382 seconds)
[2024-03-26 17:22:40,755][fairseq_cli.train][INFO] - end of epoch 306 (average epoch stats below)
[2024-03-26 17:22:40,755][train][INFO] - {"epoch": 306, "train_loss": "0.319", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.032", "train_target_var": "0.756", "train_pred_var": "0.749", "train_masked_pct": "0.501", "train_wps": "8698.6", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2441", "train_lr": "0.000228844", "train_gnorm": "2.229", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3179"}
[2024-03-26 17:22:40,757][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:40,819][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 307
[2024-03-26 17:22:40,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:40,823][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:40,828][fairseq.trainer][INFO] - begin training epoch 307
[2024-03-26 17:22:40,829][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:48,064][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 307 @ 2449 updates
[2024-03-26 17:22:48,065][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:50,565][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:22:50,602][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 307 @ 2449 updates, score None) (writing took 2.5384170399047434 seconds)
[2024-03-26 17:22:50,603][fairseq_cli.train][INFO] - end of epoch 307 (average epoch stats below)
[2024-03-26 17:22:50,604][train][INFO] - {"epoch": 307, "train_loss": "0.303", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.032", "train_target_var": "0.755", "train_pred_var": "0.747", "train_masked_pct": "0.498", "train_wps": "8748.3", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2449", "train_lr": "0.000229594", "train_gnorm": "2.041", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3188"}
[2024-03-26 17:22:50,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:22:50,711][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 308
[2024-03-26 17:22:50,712][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:22:50,715][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:22:50,720][fairseq.trainer][INFO] - begin training epoch 308
[2024-03-26 17:22:50,721][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:22:58,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 308 @ 2457 updates
[2024-03-26 17:22:58,123][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:00,619][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:00,677][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 308 @ 2457 updates, score None) (writing took 2.556106859818101 seconds)
[2024-03-26 17:23:00,678][fairseq_cli.train][INFO] - end of epoch 308 (average epoch stats below)
[2024-03-26 17:23:00,678][train][INFO] - {"epoch": 308, "train_loss": "0.26", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.032", "train_target_var": "0.758", "train_pred_var": "0.751", "train_masked_pct": "0.499", "train_wps": "8552.3", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2457", "train_lr": "0.000230344", "train_gnorm": "1.884", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3199"}
[2024-03-26 17:23:00,681][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:00,743][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 309
[2024-03-26 17:23:00,744][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:00,748][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:00,752][fairseq.trainer][INFO] - begin training epoch 309
[2024-03-26 17:23:00,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:08,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 309 @ 2465 updates
[2024-03-26 17:23:08,048][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:10,553][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:10,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 309 @ 2465 updates, score None) (writing took 2.570465323049575 seconds)
[2024-03-26 17:23:10,618][fairseq_cli.train][INFO] - end of epoch 309 (average epoch stats below)
[2024-03-26 17:23:10,618][train][INFO] - {"epoch": 309, "train_loss": "0.296", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.032", "train_target_var": "0.758", "train_pred_var": "0.752", "train_masked_pct": "0.5", "train_wps": "8668.3", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2465", "train_lr": "0.000231094", "train_gnorm": "3.808", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3208"}
[2024-03-26 17:23:10,620][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:10,681][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 310
[2024-03-26 17:23:10,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:10,686][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:10,691][fairseq.trainer][INFO] - begin training epoch 310
[2024-03-26 17:23:10,691][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:18,007][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:23:18,008][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:18,083][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 63
[2024-03-26 17:23:18,087][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:18,503][valid][INFO] - {"epoch": 310, "valid_loss": "0.308", "valid_ntokens": "11709", "valid_nsentences": "25", "valid_sample_size": "11709", "valid_ema_decay": "999.033", "valid_target_var": "0.765", "valid_pred_var": "0.769", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11709", "valid_bsz": "25", "valid_num_updates": "2473", "valid_best_loss": "0.233"}
[2024-03-26 17:23:18,504][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 310 @ 2473 updates
[2024-03-26 17:23:18,506][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:20,969][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:21,024][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 310 @ 2473 updates, score 0.308) (writing took 2.520022473298013 seconds)
[2024-03-26 17:23:21,026][fairseq_cli.train][INFO] - end of epoch 310 (average epoch stats below)
[2024-03-26 17:23:21,026][train][INFO] - {"epoch": 310, "train_loss": "0.326", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.033", "train_target_var": "0.757", "train_pred_var": "0.749", "train_masked_pct": "0.501", "train_wps": "8278.3", "train_ups": "0.77", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2473", "train_lr": "0.000231844", "train_gnorm": "2.756", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3219"}
[2024-03-26 17:23:21,029][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:21,091][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 311
[2024-03-26 17:23:21,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:21,096][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:21,101][fairseq.trainer][INFO] - begin training epoch 311
[2024-03-26 17:23:21,102][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:28,496][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 311 @ 2481 updates
[2024-03-26 17:23:28,497][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:30,991][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:31,051][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 311 @ 2481 updates, score None) (writing took 2.555306659080088 seconds)
[2024-03-26 17:23:31,052][fairseq_cli.train][INFO] - end of epoch 311 (average epoch stats below)
[2024-03-26 17:23:31,052][train][INFO] - {"epoch": 311, "train_loss": "0.416", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.033", "train_target_var": "0.759", "train_pred_var": "0.75", "train_masked_pct": "0.5", "train_wps": "8594.3", "train_ups": "0.8", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "2481", "train_lr": "0.000232594", "train_gnorm": "2.211", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "3229"}
[2024-03-26 17:23:31,054][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:31,117][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 312
[2024-03-26 17:23:31,118][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:31,122][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:31,127][fairseq.trainer][INFO] - begin training epoch 312
[2024-03-26 17:23:31,127][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:38,374][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 312 @ 2489 updates
[2024-03-26 17:23:38,376][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:40,893][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:40,953][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 312 @ 2489 updates, score None) (writing took 2.5784788969904184 seconds)
[2024-03-26 17:23:40,953][fairseq_cli.train][INFO] - end of epoch 312 (average epoch stats below)
[2024-03-26 17:23:40,954][train][INFO] - {"epoch": 312, "train_loss": "0.368", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.033", "train_target_var": "0.76", "train_pred_var": "0.751", "train_masked_pct": "0.499", "train_wps": "8701.6", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2489", "train_lr": "0.000233344", "train_gnorm": "2.232", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "3239"}
[2024-03-26 17:23:40,956][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:41,019][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 313
[2024-03-26 17:23:41,030][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:41,034][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:41,038][fairseq.trainer][INFO] - begin training epoch 313
[2024-03-26 17:23:41,039][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:48,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 313 @ 2497 updates
[2024-03-26 17:23:48,423][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:50,925][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:23:50,985][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 313 @ 2497 updates, score None) (writing took 2.5630058627575636 seconds)
[2024-03-26 17:23:50,986][fairseq_cli.train][INFO] - end of epoch 313 (average epoch stats below)
[2024-03-26 17:23:50,986][train][INFO] - {"epoch": 313, "train_loss": "0.279", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.033", "train_target_var": "0.759", "train_pred_var": "0.75", "train_masked_pct": "0.501", "train_wps": "8589.1", "train_ups": "0.8", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2497", "train_lr": "0.000234094", "train_gnorm": "1.628", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3249"}
[2024-03-26 17:23:50,988][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:23:51,055][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 314
[2024-03-26 17:23:51,057][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:23:51,060][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:23:51,065][fairseq.trainer][INFO] - begin training epoch 314
[2024-03-26 17:23:51,065][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:23:58,246][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 314 @ 2505 updates
[2024-03-26 17:23:58,248][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:00,728][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:00,786][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 314 @ 2505 updates, score None) (writing took 2.5397733417339623 seconds)
[2024-03-26 17:24:00,787][fairseq_cli.train][INFO] - end of epoch 314 (average epoch stats below)
[2024-03-26 17:24:00,787][train][INFO] - {"epoch": 314, "train_loss": "0.264", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.033", "train_target_var": "0.762", "train_pred_var": "0.754", "train_masked_pct": "0.501", "train_wps": "8790.8", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2505", "train_lr": "0.000234844", "train_gnorm": "1.829", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3259"}
[2024-03-26 17:24:00,789][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:00,850][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 315
[2024-03-26 17:24:00,852][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:00,855][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:00,860][fairseq.trainer][INFO] - begin training epoch 315
[2024-03-26 17:24:00,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:24:08,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:24:08,069][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:08,131][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 64
[2024-03-26 17:24:08,134][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:08,536][valid][INFO] - {"epoch": 315, "valid_loss": "0.222", "valid_ntokens": "11724", "valid_nsentences": "25", "valid_sample_size": "11724", "valid_ema_decay": "999.033", "valid_target_var": "0.756", "valid_pred_var": "0.749", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11724", "valid_bsz": "25", "valid_num_updates": "2513", "valid_best_loss": "0.222"}
[2024-03-26 17:24:08,538][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 315 @ 2513 updates
[2024-03-26 17:24:08,539][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:24:11,146][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_best.pt
[2024-03-26 17:24:15,226][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_best.pt (epoch 315 @ 2513 updates, score 0.222) (writing took 6.6879976582713425 seconds)
[2024-03-26 17:24:15,227][fairseq_cli.train][INFO] - end of epoch 315 (average epoch stats below)
[2024-03-26 17:24:15,228][train][INFO] - {"epoch": 315, "train_loss": "0.258", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.033", "train_target_var": "0.76", "train_pred_var": "0.754", "train_masked_pct": "0.501", "train_wps": "5966.5", "train_ups": "0.55", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2513", "train_lr": "0.000235594", "train_gnorm": "1.896", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3273"}
[2024-03-26 17:24:15,230][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:15,301][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 316
[2024-03-26 17:24:15,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:15,306][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:15,310][fairseq.trainer][INFO] - begin training epoch 316
[2024-03-26 17:24:15,311][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:24:22,450][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 316 @ 2521 updates
[2024-03-26 17:24:22,451][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:24,932][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:24,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 316 @ 2521 updates, score None) (writing took 2.5409756950102746 seconds)
[2024-03-26 17:24:24,991][fairseq_cli.train][INFO] - end of epoch 316 (average epoch stats below)
[2024-03-26 17:24:24,992][train][INFO] - {"epoch": 316, "train_loss": "0.304", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.033", "train_target_var": "0.762", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8824.1", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2521", "train_lr": "0.000236344", "train_gnorm": "1.868", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3283"}
[2024-03-26 17:24:24,994][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:25,059][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 317
[2024-03-26 17:24:25,061][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:25,064][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:25,069][fairseq.trainer][INFO] - begin training epoch 317
[2024-03-26 17:24:25,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:24:32,315][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 317 @ 2529 updates
[2024-03-26 17:24:32,317][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:34,827][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:34,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 317 @ 2529 updates, score None) (writing took 2.5717307147569954 seconds)
[2024-03-26 17:24:34,888][fairseq_cli.train][INFO] - end of epoch 317 (average epoch stats below)
[2024-03-26 17:24:34,888][train][INFO] - {"epoch": 317, "train_loss": "0.376", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.033", "train_target_var": "0.76", "train_pred_var": "0.752", "train_masked_pct": "0.501", "train_wps": "8706.8", "train_ups": "0.81", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "2529", "train_lr": "0.000237094", "train_gnorm": "2.495", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3293"}
[2024-03-26 17:24:34,890][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:34,954][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 318
[2024-03-26 17:24:34,956][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:34,959][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:34,964][fairseq.trainer][INFO] - begin training epoch 318
[2024-03-26 17:24:34,964][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:24:42,222][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 318 @ 2537 updates
[2024-03-26 17:24:42,224][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:44,714][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:44,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 318 @ 2537 updates, score None) (writing took 2.5513176172971725 seconds)
[2024-03-26 17:24:44,775][fairseq_cli.train][INFO] - end of epoch 318 (average epoch stats below)
[2024-03-26 17:24:44,775][train][INFO] - {"epoch": 318, "train_loss": "0.343", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.033", "train_target_var": "0.763", "train_pred_var": "0.753", "train_masked_pct": "0.5", "train_wps": "8714.4", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2537", "train_lr": "0.000237844", "train_gnorm": "2.102", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3303"}
[2024-03-26 17:24:44,777][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:44,841][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 319
[2024-03-26 17:24:44,843][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:44,846][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:44,851][fairseq.trainer][INFO] - begin training epoch 319
[2024-03-26 17:24:44,851][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:24:52,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 319 @ 2545 updates
[2024-03-26 17:24:52,144][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:54,640][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:24:54,675][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 319 @ 2545 updates, score None) (writing took 2.533799356315285 seconds)
[2024-03-26 17:24:54,676][fairseq_cli.train][INFO] - end of epoch 319 (average epoch stats below)
[2024-03-26 17:24:54,676][train][INFO] - {"epoch": 319, "train_loss": "0.289", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.034", "train_target_var": "0.759", "train_pred_var": "0.751", "train_masked_pct": "0.498", "train_wps": "8702.1", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2545", "train_lr": "0.000238594", "train_gnorm": "1.962", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3313"}
[2024-03-26 17:24:54,678][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:24:54,759][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 320
[2024-03-26 17:24:54,760][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:24:54,763][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:24:54,768][fairseq.trainer][INFO] - begin training epoch 320
[2024-03-26 17:24:54,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:02,061][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:25:02,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:02,139][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 65
[2024-03-26 17:25:02,143][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:02,558][valid][INFO] - {"epoch": 320, "valid_loss": "0.274", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.034", "valid_target_var": "0.758", "valid_pred_var": "0.756", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "2553", "valid_best_loss": "0.222"}
[2024-03-26 17:25:02,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 320 @ 2553 updates
[2024-03-26 17:25:02,561][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:05,045][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:05,087][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 320 @ 2553 updates, score 0.274) (writing took 2.5276446738280356 seconds)
[2024-03-26 17:25:05,087][fairseq_cli.train][INFO] - end of epoch 320 (average epoch stats below)
[2024-03-26 17:25:05,088][train][INFO] - {"epoch": 320, "train_loss": "0.264", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.034", "train_target_var": "0.763", "train_pred_var": "0.757", "train_masked_pct": "0.501", "train_wps": "8275.2", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2553", "train_lr": "0.000239344", "train_gnorm": "1.361", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3323"}
[2024-03-26 17:25:05,090][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:05,171][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 321
[2024-03-26 17:25:05,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:05,176][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:05,181][fairseq.trainer][INFO] - begin training epoch 321
[2024-03-26 17:25:05,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:12,189][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 321 @ 2561 updates
[2024-03-26 17:25:12,190][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:14,652][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:14,707][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 321 @ 2561 updates, score None) (writing took 2.5181173500604928 seconds)
[2024-03-26 17:25:14,708][fairseq_cli.train][INFO] - end of epoch 321 (average epoch stats below)
[2024-03-26 17:25:14,708][train][INFO] - {"epoch": 321, "train_loss": "0.349", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.034", "train_target_var": "0.759", "train_pred_var": "0.75", "train_masked_pct": "0.501", "train_wps": "8956", "train_ups": "0.83", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2561", "train_lr": "0.000240094", "train_gnorm": "1.843", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3333"}
[2024-03-26 17:25:14,710][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:14,776][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 322
[2024-03-26 17:25:14,778][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:14,781][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:14,785][fairseq.trainer][INFO] - begin training epoch 322
[2024-03-26 17:25:14,786][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:22,194][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 322 @ 2569 updates
[2024-03-26 17:25:22,195][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:24,686][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:24,743][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 322 @ 2569 updates, score None) (writing took 2.5493008513003588 seconds)
[2024-03-26 17:25:24,744][fairseq_cli.train][INFO] - end of epoch 322 (average epoch stats below)
[2024-03-26 17:25:24,745][train][INFO] - {"epoch": 322, "train_loss": "0.361", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.034", "train_target_var": "0.76", "train_pred_var": "0.752", "train_masked_pct": "0.501", "train_wps": "8584.8", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2569", "train_lr": "0.000240844", "train_gnorm": "2.261", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3343"}
[2024-03-26 17:25:24,747][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:24,813][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 323
[2024-03-26 17:25:24,815][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:24,818][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:24,823][fairseq.trainer][INFO] - begin training epoch 323
[2024-03-26 17:25:24,823][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:32,040][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 323 @ 2577 updates
[2024-03-26 17:25:32,041][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:34,499][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:34,556][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 323 @ 2577 updates, score None) (writing took 2.5161132691428065 seconds)
[2024-03-26 17:25:34,556][fairseq_cli.train][INFO] - end of epoch 323 (average epoch stats below)
[2024-03-26 17:25:34,557][train][INFO] - {"epoch": 323, "train_loss": "0.347", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.034", "train_target_var": "0.761", "train_pred_var": "0.754", "train_masked_pct": "0.501", "train_wps": "8781.3", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2577", "train_lr": "0.000241594", "train_gnorm": "2.695", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "3352"}
[2024-03-26 17:25:34,559][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:34,621][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 324
[2024-03-26 17:25:34,623][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:34,626][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:34,631][fairseq.trainer][INFO] - begin training epoch 324
[2024-03-26 17:25:34,632][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:42,056][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 324 @ 2585 updates
[2024-03-26 17:25:42,057][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:44,549][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:44,595][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 324 @ 2585 updates, score None) (writing took 2.538681196048856 seconds)
[2024-03-26 17:25:44,595][fairseq_cli.train][INFO] - end of epoch 324 (average epoch stats below)
[2024-03-26 17:25:44,596][train][INFO] - {"epoch": 324, "train_loss": "0.332", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.034", "train_target_var": "0.757", "train_pred_var": "0.749", "train_masked_pct": "0.501", "train_wps": "8582.5", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2585", "train_lr": "0.000242344", "train_gnorm": "2.016", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3362"}
[2024-03-26 17:25:44,598][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:44,671][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 325
[2024-03-26 17:25:44,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:44,676][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:44,680][fairseq.trainer][INFO] - begin training epoch 325
[2024-03-26 17:25:44,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:25:52,018][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:25:52,019][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:52,082][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 66
[2024-03-26 17:25:52,086][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:52,497][valid][INFO] - {"epoch": 325, "valid_loss": "0.314", "valid_ntokens": "11715", "valid_nsentences": "25", "valid_sample_size": "11715", "valid_ema_decay": "999.034", "valid_target_var": "0.764", "valid_pred_var": "0.761", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11715", "valid_bsz": "25", "valid_num_updates": "2593", "valid_best_loss": "0.222"}
[2024-03-26 17:25:52,499][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 325 @ 2593 updates
[2024-03-26 17:25:52,500][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:54,987][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:25:55,035][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 325 @ 2593 updates, score 0.314) (writing took 2.53602515719831 seconds)
[2024-03-26 17:25:55,035][fairseq_cli.train][INFO] - end of epoch 325 (average epoch stats below)
[2024-03-26 17:25:55,036][train][INFO] - {"epoch": 325, "train_loss": "0.408", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.034", "train_target_var": "0.765", "train_pred_var": "0.756", "train_masked_pct": "0.5", "train_wps": "8252.9", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2593", "train_lr": "0.000243094", "train_gnorm": "2.152", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3373"}
[2024-03-26 17:25:55,038][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:25:55,112][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 326
[2024-03-26 17:25:55,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:25:55,116][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:25:55,121][fairseq.trainer][INFO] - begin training epoch 326
[2024-03-26 17:25:55,122][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:01,332][train_inner][INFO] - {"epoch": 326, "update": 325.875, "loss": "0.32", "ntokens": "10768.4", "nsentences": "22.875", "sample_size": "10768.4", "ema_decay": "999.033", "target_var": "0.759", "pred_var": "0.752", "masked_pct": "0.5", "wps": "8473.7", "ups": "0.79", "wpb": "10768.4", "bsz": "22.9", "num_updates": "2600", "lr": "0.00024375", "gnorm": "2.236", "loss_scale": "1", "train_wall": "175", "gb_free": "5.8", "wall": "3379"}
[2024-03-26 17:26:02,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 326 @ 2601 updates
[2024-03-26 17:26:02,341][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:04,814][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:04,873][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 326 @ 2601 updates, score None) (writing took 2.5327997049316764 seconds)
[2024-03-26 17:26:04,874][fairseq_cli.train][INFO] - end of epoch 326 (average epoch stats below)
[2024-03-26 17:26:04,874][train][INFO] - {"epoch": 326, "train_loss": "0.275", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.034", "train_target_var": "0.763", "train_pred_var": "0.756", "train_masked_pct": "0.501", "train_wps": "8757.8", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "2601", "train_lr": "0.000243844", "train_gnorm": "1.856", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3383"}
[2024-03-26 17:26:04,876][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:04,938][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 327
[2024-03-26 17:26:04,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:04,943][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:04,947][fairseq.trainer][INFO] - begin training epoch 327
[2024-03-26 17:26:04,948][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:12,181][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 327 @ 2609 updates
[2024-03-26 17:26:12,183][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:14,764][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:14,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 327 @ 2609 updates, score None) (writing took 2.6307470900937915 seconds)
[2024-03-26 17:26:14,812][fairseq_cli.train][INFO] - end of epoch 327 (average epoch stats below)
[2024-03-26 17:26:14,812][train][INFO] - {"epoch": 327, "train_loss": "0.327", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.034", "train_target_var": "0.769", "train_pred_var": "0.762", "train_masked_pct": "0.5", "train_wps": "8669.5", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2609", "train_lr": "0.000244594", "train_gnorm": "1.845", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3393"}
[2024-03-26 17:26:14,814][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:14,891][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 328
[2024-03-26 17:26:14,892][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:14,895][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:14,900][fairseq.trainer][INFO] - begin training epoch 328
[2024-03-26 17:26:14,901][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:22,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 328 @ 2617 updates
[2024-03-26 17:26:22,303][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:24,784][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:24,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 328 @ 2617 updates, score None) (writing took 2.5407795240171254 seconds)
[2024-03-26 17:26:24,843][fairseq_cli.train][INFO] - end of epoch 328 (average epoch stats below)
[2024-03-26 17:26:24,843][train][INFO] - {"epoch": 328, "train_loss": "0.498", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.034", "train_target_var": "0.76", "train_pred_var": "0.749", "train_masked_pct": "0.501", "train_wps": "8589.1", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2617", "train_lr": "0.000245344", "train_gnorm": "2.399", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3403"}
[2024-03-26 17:26:24,846][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:24,910][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 329
[2024-03-26 17:26:24,912][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:24,915][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:24,920][fairseq.trainer][INFO] - begin training epoch 329
[2024-03-26 17:26:24,921][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:32,251][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 329 @ 2625 updates
[2024-03-26 17:26:32,252][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:34,727][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:34,758][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 329 @ 2625 updates, score None) (writing took 2.5069142570719123 seconds)
[2024-03-26 17:26:34,758][fairseq_cli.train][INFO] - end of epoch 329 (average epoch stats below)
[2024-03-26 17:26:34,759][train][INFO] - {"epoch": 329, "train_loss": "0.389", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.035", "train_target_var": "0.764", "train_pred_var": "0.753", "train_masked_pct": "0.5", "train_wps": "8689.7", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2625", "train_lr": "0.000246094", "train_gnorm": "2.063", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3413"}
[2024-03-26 17:26:34,761][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:34,854][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 330
[2024-03-26 17:26:34,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:34,858][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:34,863][fairseq.trainer][INFO] - begin training epoch 330
[2024-03-26 17:26:34,864][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:42,297][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:26:42,298][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:42,361][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 67
[2024-03-26 17:26:42,365][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:42,778][valid][INFO] - {"epoch": 330, "valid_loss": "0.357", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.035", "valid_target_var": "0.761", "valid_pred_var": "0.76", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "2633", "valid_best_loss": "0.222"}
[2024-03-26 17:26:42,779][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 330 @ 2633 updates
[2024-03-26 17:26:42,781][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:45,254][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:45,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 330 @ 2633 updates, score 0.357) (writing took 2.508643629029393 seconds)
[2024-03-26 17:26:45,289][fairseq_cli.train][INFO] - end of epoch 330 (average epoch stats below)
[2024-03-26 17:26:45,290][train][INFO] - {"epoch": 330, "train_loss": "0.372", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.035", "train_target_var": "0.762", "train_pred_var": "0.753", "train_masked_pct": "0.5", "train_wps": "8181.3", "train_ups": "0.76", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2633", "train_lr": "0.000246844", "train_gnorm": "2.498", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3423"}
[2024-03-26 17:26:45,292][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:45,382][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 331
[2024-03-26 17:26:45,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:45,386][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:45,391][fairseq.trainer][INFO] - begin training epoch 331
[2024-03-26 17:26:45,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:26:52,845][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 331 @ 2641 updates
[2024-03-26 17:26:52,846][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:55,339][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:26:55,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 331 @ 2641 updates, score None) (writing took 2.5517256380990148 seconds)
[2024-03-26 17:26:55,397][fairseq_cli.train][INFO] - end of epoch 331 (average epoch stats below)
[2024-03-26 17:26:55,398][train][INFO] - {"epoch": 331, "train_loss": "0.396", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.035", "train_target_var": "0.766", "train_pred_var": "0.758", "train_masked_pct": "0.499", "train_wps": "8524.5", "train_ups": "0.79", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2641", "train_lr": "0.000247594", "train_gnorm": "1.929", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3433"}
[2024-03-26 17:26:55,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:26:55,463][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 332
[2024-03-26 17:26:55,464][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:26:55,467][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:26:55,472][fairseq.trainer][INFO] - begin training epoch 332
[2024-03-26 17:26:55,473][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:02,717][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 332 @ 2649 updates
[2024-03-26 17:27:02,719][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:05,223][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:05,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 332 @ 2649 updates, score None) (writing took 2.5510919028893113 seconds)
[2024-03-26 17:27:05,269][fairseq_cli.train][INFO] - end of epoch 332 (average epoch stats below)
[2024-03-26 17:27:05,269][train][INFO] - {"epoch": 332, "train_loss": "0.351", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.035", "train_target_var": "0.766", "train_pred_var": "0.757", "train_masked_pct": "0.501", "train_wps": "8727.1", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2649", "train_lr": "0.000248344", "train_gnorm": "3.543", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3443"}
[2024-03-26 17:27:05,272][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:05,354][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 333
[2024-03-26 17:27:05,355][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:05,358][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:05,363][fairseq.trainer][INFO] - begin training epoch 333
[2024-03-26 17:27:05,363][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:12,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 333 @ 2657 updates
[2024-03-26 17:27:12,644][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:15,134][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:15,194][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 333 @ 2657 updates, score None) (writing took 2.5509085576049984 seconds)
[2024-03-26 17:27:15,194][fairseq_cli.train][INFO] - end of epoch 333 (average epoch stats below)
[2024-03-26 17:27:15,195][train][INFO] - {"epoch": 333, "train_loss": "0.377", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.035", "train_target_var": "0.765", "train_pred_var": "0.756", "train_masked_pct": "0.5", "train_wps": "8681", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2657", "train_lr": "0.000249094", "train_gnorm": "2.741", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3453"}
[2024-03-26 17:27:15,197][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:15,259][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 334
[2024-03-26 17:27:15,261][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:15,264][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:15,269][fairseq.trainer][INFO] - begin training epoch 334
[2024-03-26 17:27:15,270][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:22,658][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 334 @ 2665 updates
[2024-03-26 17:27:22,660][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:25,129][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:25,189][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 334 @ 2665 updates, score None) (writing took 2.5301676806993783 seconds)
[2024-03-26 17:27:25,189][fairseq_cli.train][INFO] - end of epoch 334 (average epoch stats below)
[2024-03-26 17:27:25,190][train][INFO] - {"epoch": 334, "train_loss": "0.382", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.035", "train_target_var": "0.767", "train_pred_var": "0.758", "train_masked_pct": "0.499", "train_wps": "8620.8", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2665", "train_lr": "0.000249844", "train_gnorm": "2.065", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3463"}
[2024-03-26 17:27:25,192][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:25,253][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 335
[2024-03-26 17:27:25,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:25,258][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:25,263][fairseq.trainer][INFO] - begin training epoch 335
[2024-03-26 17:27:25,264][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:32,537][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:27:32,538][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:32,615][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 68
[2024-03-26 17:27:32,618][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:33,031][valid][INFO] - {"epoch": 335, "valid_loss": "0.384", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.035", "valid_target_var": "0.769", "valid_pred_var": "0.764", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "2673", "valid_best_loss": "0.222"}
[2024-03-26 17:27:33,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 335 @ 2673 updates
[2024-03-26 17:27:33,034][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:35,504][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:35,550][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 335 @ 2673 updates, score 0.384) (writing took 2.5177417220547795 seconds)
[2024-03-26 17:27:35,551][fairseq_cli.train][INFO] - end of epoch 335 (average epoch stats below)
[2024-03-26 17:27:35,552][train][INFO] - {"epoch": 335, "train_loss": "0.401", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.035", "train_target_var": "0.768", "train_pred_var": "0.758", "train_masked_pct": "0.499", "train_wps": "8314.4", "train_ups": "0.77", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2673", "train_lr": "0.000250594", "train_gnorm": "3.52", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3473"}
[2024-03-26 17:27:35,554][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:35,628][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 336
[2024-03-26 17:27:35,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:35,632][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:35,637][fairseq.trainer][INFO] - begin training epoch 336
[2024-03-26 17:27:35,638][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:42,971][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 336 @ 2681 updates
[2024-03-26 17:27:42,973][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:45,428][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:45,480][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 336 @ 2681 updates, score None) (writing took 2.5088308127596974 seconds)
[2024-03-26 17:27:45,481][fairseq_cli.train][INFO] - end of epoch 336 (average epoch stats below)
[2024-03-26 17:27:45,481][train][INFO] - {"epoch": 336, "train_loss": "0.408", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.035", "train_target_var": "0.767", "train_pred_var": "0.758", "train_masked_pct": "0.501", "train_wps": "8677.3", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2681", "train_lr": "0.000251344", "train_gnorm": "2.985", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3483"}
[2024-03-26 17:27:45,483][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:45,551][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 337
[2024-03-26 17:27:45,553][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:45,556][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:45,561][fairseq.trainer][INFO] - begin training epoch 337
[2024-03-26 17:27:45,562][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:27:52,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 337 @ 2689 updates
[2024-03-26 17:27:52,961][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:55,468][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:27:55,528][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 337 @ 2689 updates, score None) (writing took 2.567594612017274 seconds)
[2024-03-26 17:27:55,528][fairseq_cli.train][INFO] - end of epoch 337 (average epoch stats below)
[2024-03-26 17:27:55,529][train][INFO] - {"epoch": 337, "train_loss": "0.339", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.035", "train_target_var": "0.767", "train_pred_var": "0.759", "train_masked_pct": "0.5", "train_wps": "8574.9", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2689", "train_lr": "0.000252094", "train_gnorm": "2.249", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3493"}
[2024-03-26 17:27:55,531][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:27:55,595][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 338
[2024-03-26 17:27:55,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:27:55,599][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:27:55,604][fairseq.trainer][INFO] - begin training epoch 338
[2024-03-26 17:27:55,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:02,902][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 338 @ 2697 updates
[2024-03-26 17:28:02,904][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:05,411][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:05,459][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 338 @ 2697 updates, score None) (writing took 2.5570414271205664 seconds)
[2024-03-26 17:28:05,460][fairseq_cli.train][INFO] - end of epoch 338 (average epoch stats below)
[2024-03-26 17:28:05,460][train][INFO] - {"epoch": 338, "train_loss": "0.428", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.036", "train_target_var": "0.766", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8676.1", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2697", "train_lr": "0.000252844", "train_gnorm": "2.624", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "3503"}
[2024-03-26 17:28:05,463][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:05,536][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 339
[2024-03-26 17:28:05,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:05,541][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:05,546][fairseq.trainer][INFO] - begin training epoch 339
[2024-03-26 17:28:05,546][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:12,721][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 339 @ 2705 updates
[2024-03-26 17:28:12,722][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:15,206][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:15,243][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 339 @ 2705 updates, score None) (writing took 2.5219653439708054 seconds)
[2024-03-26 17:28:15,243][fairseq_cli.train][INFO] - end of epoch 339 (average epoch stats below)
[2024-03-26 17:28:15,244][train][INFO] - {"epoch": 339, "train_loss": "0.424", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.036", "train_target_var": "0.767", "train_pred_var": "0.755", "train_masked_pct": "0.5", "train_wps": "8806.5", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2705", "train_lr": "0.000253594", "train_gnorm": "3.072", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3513"}
[2024-03-26 17:28:15,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:15,330][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 340
[2024-03-26 17:28:15,332][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:15,335][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:15,340][fairseq.trainer][INFO] - begin training epoch 340
[2024-03-26 17:28:15,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:22,607][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:28:22,608][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:22,669][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 69
[2024-03-26 17:28:22,672][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:23,090][valid][INFO] - {"epoch": 340, "valid_loss": "0.586", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.036", "valid_target_var": "0.766", "valid_pred_var": "0.75", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "2713", "valid_best_loss": "0.222"}
[2024-03-26 17:28:23,092][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 340 @ 2713 updates
[2024-03-26 17:28:23,093][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:25,567][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:25,627][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 340 @ 2713 updates, score 0.586) (writing took 2.534888301976025 seconds)
[2024-03-26 17:28:25,627][fairseq_cli.train][INFO] - end of epoch 340 (average epoch stats below)
[2024-03-26 17:28:25,628][train][INFO] - {"epoch": 340, "train_loss": "0.417", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.036", "train_target_var": "0.766", "train_pred_var": "0.757", "train_masked_pct": "0.5", "train_wps": "8297.4", "train_ups": "0.77", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2713", "train_lr": "0.000254344", "train_gnorm": "2.412", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3523"}
[2024-03-26 17:28:25,630][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:25,691][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 341
[2024-03-26 17:28:25,693][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:25,696][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:25,701][fairseq.trainer][INFO] - begin training epoch 341
[2024-03-26 17:28:25,701][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:32,868][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 341 @ 2721 updates
[2024-03-26 17:28:32,870][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:35,355][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:35,392][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 341 @ 2721 updates, score None) (writing took 2.5238524302840233 seconds)
[2024-03-26 17:28:35,393][fairseq_cli.train][INFO] - end of epoch 341 (average epoch stats below)
[2024-03-26 17:28:35,393][train][INFO] - {"epoch": 341, "train_loss": "0.64", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.036", "train_target_var": "0.767", "train_pred_var": "0.752", "train_masked_pct": "0.501", "train_wps": "8822.5", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2721", "train_lr": "0.000255094", "train_gnorm": "3.35", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "3533"}
[2024-03-26 17:28:35,396][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:35,480][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 342
[2024-03-26 17:28:35,482][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:35,485][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:35,489][fairseq.trainer][INFO] - begin training epoch 342
[2024-03-26 17:28:35,490][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:42,533][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 342 @ 2729 updates
[2024-03-26 17:28:42,534][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:45,089][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:45,150][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 342 @ 2729 updates, score None) (writing took 2.6174296410754323 seconds)
[2024-03-26 17:28:45,151][fairseq_cli.train][INFO] - end of epoch 342 (average epoch stats below)
[2024-03-26 17:28:45,151][train][INFO] - {"epoch": 342, "train_loss": "0.456", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.036", "train_target_var": "0.769", "train_pred_var": "0.759", "train_masked_pct": "0.5", "train_wps": "8829.6", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2729", "train_lr": "0.000255844", "train_gnorm": "3.829", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3543"}
[2024-03-26 17:28:45,153][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:45,218][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 343
[2024-03-26 17:28:45,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:45,222][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:45,227][fairseq.trainer][INFO] - begin training epoch 343
[2024-03-26 17:28:45,227][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:28:52,402][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 343 @ 2737 updates
[2024-03-26 17:28:52,403][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:54,894][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:28:54,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 343 @ 2737 updates, score None) (writing took 2.5521061210893095 seconds)
[2024-03-26 17:28:54,955][fairseq_cli.train][INFO] - end of epoch 343 (average epoch stats below)
[2024-03-26 17:28:54,956][train][INFO] - {"epoch": 343, "train_loss": "0.419", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.036", "train_target_var": "0.766", "train_pred_var": "0.756", "train_masked_pct": "0.5", "train_wps": "8787.5", "train_ups": "0.82", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2737", "train_lr": "0.000256594", "train_gnorm": "3.803", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3553"}
[2024-03-26 17:28:54,958][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:28:55,021][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 344
[2024-03-26 17:28:55,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:28:55,026][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:28:55,031][fairseq.trainer][INFO] - begin training epoch 344
[2024-03-26 17:28:55,032][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:02,231][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 344 @ 2745 updates
[2024-03-26 17:29:02,232][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:04,728][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:04,791][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 344 @ 2745 updates, score None) (writing took 2.5605792459100485 seconds)
[2024-03-26 17:29:04,792][fairseq_cli.train][INFO] - end of epoch 344 (average epoch stats below)
[2024-03-26 17:29:04,792][train][INFO] - {"epoch": 344, "train_loss": "0.402", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.036", "train_target_var": "0.769", "train_pred_var": "0.761", "train_masked_pct": "0.501", "train_wps": "8759.5", "train_ups": "0.81", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2745", "train_lr": "0.000257344", "train_gnorm": "2.878", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3563"}
[2024-03-26 17:29:04,794][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:04,856][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 345
[2024-03-26 17:29:04,858][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:04,861][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:04,866][fairseq.trainer][INFO] - begin training epoch 345
[2024-03-26 17:29:04,866][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:12,271][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:29:12,273][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:12,336][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 70
[2024-03-26 17:29:12,340][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:12,739][valid][INFO] - {"epoch": 345, "valid_loss": "0.374", "valid_ntokens": "11720", "valid_nsentences": "25", "valid_sample_size": "11720", "valid_ema_decay": "999.036", "valid_target_var": "0.761", "valid_pred_var": "0.755", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11720", "valid_bsz": "25", "valid_num_updates": "2753", "valid_best_loss": "0.222"}
[2024-03-26 17:29:12,741][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 345 @ 2753 updates
[2024-03-26 17:29:12,743][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:15,224][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:15,276][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 345 @ 2753 updates, score 0.374) (writing took 2.5349784903228283 seconds)
[2024-03-26 17:29:15,276][fairseq_cli.train][INFO] - end of epoch 345 (average epoch stats below)
[2024-03-26 17:29:15,277][train][INFO] - {"epoch": 345, "train_loss": "0.379", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.036", "train_target_var": "0.77", "train_pred_var": "0.76", "train_masked_pct": "0.5", "train_wps": "8218.2", "train_ups": "0.76", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2753", "train_lr": "0.000258094", "train_gnorm": "2.452", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3573"}
[2024-03-26 17:29:15,279][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:15,343][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 346
[2024-03-26 17:29:15,344][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:15,348][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:15,353][fairseq.trainer][INFO] - begin training epoch 346
[2024-03-26 17:29:15,353][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:22,749][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 346 @ 2761 updates
[2024-03-26 17:29:22,750][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:25,204][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:25,267][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 346 @ 2761 updates, score None) (writing took 2.5179511439055204 seconds)
[2024-03-26 17:29:25,268][fairseq_cli.train][INFO] - end of epoch 346 (average epoch stats below)
[2024-03-26 17:29:25,268][train][INFO] - {"epoch": 346, "train_loss": "0.429", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.036", "train_target_var": "0.764", "train_pred_var": "0.755", "train_masked_pct": "0.501", "train_wps": "8622.9", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "2761", "train_lr": "0.000258844", "train_gnorm": "1.936", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3583"}
[2024-03-26 17:29:25,270][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:25,332][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 347
[2024-03-26 17:29:25,334][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:25,337][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:25,342][fairseq.trainer][INFO] - begin training epoch 347
[2024-03-26 17:29:25,342][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:32,569][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 347 @ 2769 updates
[2024-03-26 17:29:32,571][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:35,150][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:35,212][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 347 @ 2769 updates, score None) (writing took 2.642443584743887 seconds)
[2024-03-26 17:29:35,212][fairseq_cli.train][INFO] - end of epoch 347 (average epoch stats below)
[2024-03-26 17:29:35,213][train][INFO] - {"epoch": 347, "train_loss": "0.424", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.036", "train_target_var": "0.769", "train_pred_var": "0.76", "train_masked_pct": "0.501", "train_wps": "8663.6", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2769", "train_lr": "0.000259594", "train_gnorm": "1.971", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3593"}
[2024-03-26 17:29:35,215][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:35,278][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 348
[2024-03-26 17:29:35,280][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:35,283][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:35,288][fairseq.trainer][INFO] - begin training epoch 348
[2024-03-26 17:29:35,288][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:42,694][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 348 @ 2777 updates
[2024-03-26 17:29:42,696][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:45,211][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:45,274][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 348 @ 2777 updates, score None) (writing took 2.5791396722197533 seconds)
[2024-03-26 17:29:45,274][fairseq_cli.train][INFO] - end of epoch 348 (average epoch stats below)
[2024-03-26 17:29:45,275][train][INFO] - {"epoch": 348, "train_loss": "0.354", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.037", "train_target_var": "0.769", "train_pred_var": "0.76", "train_masked_pct": "0.501", "train_wps": "8563.3", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2777", "train_lr": "0.000260344", "train_gnorm": "1.385", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3603"}
[2024-03-26 17:29:45,277][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:45,340][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 349
[2024-03-26 17:29:45,342][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:45,345][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:45,350][fairseq.trainer][INFO] - begin training epoch 349
[2024-03-26 17:29:45,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:29:52,696][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 349 @ 2785 updates
[2024-03-26 17:29:52,698][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:55,200][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:29:55,250][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 349 @ 2785 updates, score None) (writing took 2.5537131601013243 seconds)
[2024-03-26 17:29:55,250][fairseq_cli.train][INFO] - end of epoch 349 (average epoch stats below)
[2024-03-26 17:29:55,251][train][INFO] - {"epoch": 349, "train_loss": "0.414", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.037", "train_target_var": "0.771", "train_pred_var": "0.759", "train_masked_pct": "0.501", "train_wps": "8636.4", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2785", "train_lr": "0.000261094", "train_gnorm": "1.849", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3613"}
[2024-03-26 17:29:55,254][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:29:55,328][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 350
[2024-03-26 17:29:55,330][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:29:55,333][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:29:55,338][fairseq.trainer][INFO] - begin training epoch 350
[2024-03-26 17:29:55,338][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:02,527][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:30:02,528][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:02,590][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 71
[2024-03-26 17:30:02,594][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:03,015][valid][INFO] - {"epoch": 350, "valid_loss": "0.392", "valid_ntokens": "11700", "valid_nsentences": "25", "valid_sample_size": "11700", "valid_ema_decay": "999.037", "valid_target_var": "0.778", "valid_pred_var": "0.777", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11700", "valid_bsz": "25", "valid_num_updates": "2793", "valid_best_loss": "0.222"}
[2024-03-26 17:30:03,017][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 350 @ 2793 updates
[2024-03-26 17:30:03,018][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:05,503][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:05,561][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 350 @ 2793 updates, score 0.392) (writing took 2.5435225586406887 seconds)
[2024-03-26 17:30:05,561][fairseq_cli.train][INFO] - end of epoch 350 (average epoch stats below)
[2024-03-26 17:30:05,562][train][INFO] - {"epoch": 350, "train_loss": "0.387", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.037", "train_target_var": "0.77", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8356.3", "train_ups": "0.78", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "2793", "train_lr": "0.000261844", "train_gnorm": "1.588", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3623"}
[2024-03-26 17:30:05,564][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:05,624][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 351
[2024-03-26 17:30:05,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:05,629][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:05,634][fairseq.trainer][INFO] - begin training epoch 351
[2024-03-26 17:30:05,635][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:12,065][train_inner][INFO] - {"epoch": 351, "update": 350.875, "loss": "0.411", "ntokens": "10769.2", "nsentences": "22.875", "sample_size": "10769.2", "ema_decay": "999.036", "target_var": "0.767", "pred_var": "0.757", "masked_pct": "0.5", "wps": "8590.2", "ups": "0.8", "wpb": "10769.2", "bsz": "22.9", "num_updates": "2800", "lr": "0.0002625", "gnorm": "2.507", "loss_scale": "1", "train_wall": "176", "gb_free": "5.5", "wall": "3630"}
[2024-03-26 17:30:13,073][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 351 @ 2801 updates
[2024-03-26 17:30:13,074][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:15,559][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:15,622][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 351 @ 2801 updates, score None) (writing took 2.5497122686356306 seconds)
[2024-03-26 17:30:15,623][fairseq_cli.train][INFO] - end of epoch 351 (average epoch stats below)
[2024-03-26 17:30:15,624][train][INFO] - {"epoch": 351, "train_loss": "0.479", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.037", "train_target_var": "0.77", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8563.2", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2801", "train_lr": "0.000262594", "train_gnorm": "1.742", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3633"}
[2024-03-26 17:30:15,626][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:15,687][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 352
[2024-03-26 17:30:15,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:15,692][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:15,697][fairseq.trainer][INFO] - begin training epoch 352
[2024-03-26 17:30:15,697][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:22,849][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 352 @ 2809 updates
[2024-03-26 17:30:22,850][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:25,355][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:25,388][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 352 @ 2809 updates, score None) (writing took 2.539251513313502 seconds)
[2024-03-26 17:30:25,388][fairseq_cli.train][INFO] - end of epoch 352 (average epoch stats below)
[2024-03-26 17:30:25,389][train][INFO] - {"epoch": 352, "train_loss": "0.446", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.037", "train_target_var": "0.772", "train_pred_var": "0.763", "train_masked_pct": "0.501", "train_wps": "8822.4", "train_ups": "0.82", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2809", "train_lr": "0.000263344", "train_gnorm": "2.262", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3643"}
[2024-03-26 17:30:25,391][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:25,484][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 353
[2024-03-26 17:30:25,486][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:25,489][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:25,493][fairseq.trainer][INFO] - begin training epoch 353
[2024-03-26 17:30:25,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:32,703][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 353 @ 2817 updates
[2024-03-26 17:30:32,704][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:35,197][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:35,259][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 353 @ 2817 updates, score None) (writing took 2.556448040995747 seconds)
[2024-03-26 17:30:35,260][fairseq_cli.train][INFO] - end of epoch 353 (average epoch stats below)
[2024-03-26 17:30:35,261][train][INFO] - {"epoch": 353, "train_loss": "0.445", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.037", "train_target_var": "0.77", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8728.8", "train_ups": "0.81", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "2817", "train_lr": "0.000264094", "train_gnorm": "2.622", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3653"}
[2024-03-26 17:30:35,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:35,326][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 354
[2024-03-26 17:30:35,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:35,331][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:35,336][fairseq.trainer][INFO] - begin training epoch 354
[2024-03-26 17:30:35,337][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:42,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 354 @ 2825 updates
[2024-03-26 17:30:42,787][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:45,255][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:45,310][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 354 @ 2825 updates, score None) (writing took 2.524278131313622 seconds)
[2024-03-26 17:30:45,311][fairseq_cli.train][INFO] - end of epoch 354 (average epoch stats below)
[2024-03-26 17:30:45,312][train][INFO] - {"epoch": 354, "train_loss": "0.426", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.037", "train_target_var": "0.766", "train_pred_var": "0.759", "train_masked_pct": "0.499", "train_wps": "8572.5", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2825", "train_lr": "0.000264844", "train_gnorm": "2.614", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3663"}
[2024-03-26 17:30:45,314][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:45,375][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 355
[2024-03-26 17:30:45,377][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:45,380][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:45,385][fairseq.trainer][INFO] - begin training epoch 355
[2024-03-26 17:30:45,385][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:30:52,671][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:30:52,672][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:52,736][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 72
[2024-03-26 17:30:52,740][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:53,140][valid][INFO] - {"epoch": 355, "valid_loss": "0.344", "valid_ntokens": "11704", "valid_nsentences": "25", "valid_sample_size": "11704", "valid_ema_decay": "999.037", "valid_target_var": "0.768", "valid_pred_var": "0.772", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11704", "valid_bsz": "25", "valid_num_updates": "2833", "valid_best_loss": "0.222"}
[2024-03-26 17:30:53,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 355 @ 2833 updates
[2024-03-26 17:30:53,143][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:55,546][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:30:55,602][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 355 @ 2833 updates, score 0.344) (writing took 2.460456637199968 seconds)
[2024-03-26 17:30:55,603][fairseq_cli.train][INFO] - end of epoch 355 (average epoch stats below)
[2024-03-26 17:30:55,604][train][INFO] - {"epoch": 355, "train_loss": "0.513", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.037", "train_target_var": "0.77", "train_pred_var": "0.758", "train_masked_pct": "0.501", "train_wps": "8371.5", "train_ups": "0.78", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2833", "train_lr": "0.000265594", "train_gnorm": "3.047", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3673"}
[2024-03-26 17:30:55,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:30:55,668][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 356
[2024-03-26 17:30:55,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:30:55,673][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:30:55,677][fairseq.trainer][INFO] - begin training epoch 356
[2024-03-26 17:30:55,678][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:02,943][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 356 @ 2841 updates
[2024-03-26 17:31:02,944][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:05,452][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:05,515][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 356 @ 2841 updates, score None) (writing took 2.5727913002483547 seconds)
[2024-03-26 17:31:05,516][fairseq_cli.train][INFO] - end of epoch 356 (average epoch stats below)
[2024-03-26 17:31:05,517][train][INFO] - {"epoch": 356, "train_loss": "0.47", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.037", "train_target_var": "0.771", "train_pred_var": "0.759", "train_masked_pct": "0.498", "train_wps": "8691.3", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2841", "train_lr": "0.000266344", "train_gnorm": "3.11", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "3683"}
[2024-03-26 17:31:05,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:05,580][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 357
[2024-03-26 17:31:05,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:05,584][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:05,589][fairseq.trainer][INFO] - begin training epoch 357
[2024-03-26 17:31:05,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:13,039][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 357 @ 2849 updates
[2024-03-26 17:31:13,041][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:15,564][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:15,628][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 357 @ 2849 updates, score None) (writing took 2.5886146211996675 seconds)
[2024-03-26 17:31:15,629][fairseq_cli.train][INFO] - end of epoch 357 (average epoch stats below)
[2024-03-26 17:31:15,629][train][INFO] - {"epoch": 357, "train_loss": "0.429", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.038", "train_target_var": "0.768", "train_pred_var": "0.759", "train_masked_pct": "0.499", "train_wps": "8519.6", "train_ups": "0.79", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2849", "train_lr": "0.000267094", "train_gnorm": "2.275", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3693"}
[2024-03-26 17:31:15,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:15,695][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 358
[2024-03-26 17:31:15,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:15,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:15,704][fairseq.trainer][INFO] - begin training epoch 358
[2024-03-26 17:31:15,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:22,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 358 @ 2857 updates
[2024-03-26 17:31:22,961][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:25,593][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:25,656][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 358 @ 2857 updates, score None) (writing took 2.6967359469272196 seconds)
[2024-03-26 17:31:25,657][fairseq_cli.train][INFO] - end of epoch 358 (average epoch stats below)
[2024-03-26 17:31:25,658][train][INFO] - {"epoch": 358, "train_loss": "0.565", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.038", "train_target_var": "0.77", "train_pred_var": "0.756", "train_masked_pct": "0.501", "train_wps": "8591.7", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "2857", "train_lr": "0.000267844", "train_gnorm": "2.23", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3703"}
[2024-03-26 17:31:25,660][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:25,723][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 359
[2024-03-26 17:31:25,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:25,728][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:25,732][fairseq.trainer][INFO] - begin training epoch 359
[2024-03-26 17:31:25,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:32,964][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 359 @ 2865 updates
[2024-03-26 17:31:32,966][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:35,442][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:35,505][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 359 @ 2865 updates, score None) (writing took 2.5409136516973376 seconds)
[2024-03-26 17:31:35,506][fairseq_cli.train][INFO] - end of epoch 359 (average epoch stats below)
[2024-03-26 17:31:35,507][train][INFO] - {"epoch": 359, "train_loss": "0.504", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.038", "train_target_var": "0.772", "train_pred_var": "0.761", "train_masked_pct": "0.501", "train_wps": "8747.5", "train_ups": "0.81", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "2865", "train_lr": "0.000268594", "train_gnorm": "1.898", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3713"}
[2024-03-26 17:31:35,509][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:35,571][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 360
[2024-03-26 17:31:35,572][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:35,576][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:35,581][fairseq.trainer][INFO] - begin training epoch 360
[2024-03-26 17:31:35,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:42,893][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:31:42,894][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:42,955][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 73
[2024-03-26 17:31:42,959][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:43,368][valid][INFO] - {"epoch": 360, "valid_loss": "0.331", "valid_ntokens": "11702", "valid_nsentences": "25", "valid_sample_size": "11702", "valid_ema_decay": "999.038", "valid_target_var": "0.775", "valid_pred_var": "0.766", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11702", "valid_bsz": "25", "valid_num_updates": "2873", "valid_best_loss": "0.222"}
[2024-03-26 17:31:43,370][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 360 @ 2873 updates
[2024-03-26 17:31:43,371][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:45,865][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:45,910][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 360 @ 2873 updates, score 0.331) (writing took 2.539753579068929 seconds)
[2024-03-26 17:31:45,911][fairseq_cli.train][INFO] - end of epoch 360 (average epoch stats below)
[2024-03-26 17:31:45,911][train][INFO] - {"epoch": 360, "train_loss": "0.391", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.038", "train_target_var": "0.769", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8280.9", "train_ups": "0.77", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2873", "train_lr": "0.000269344", "train_gnorm": "1.988", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3724"}
[2024-03-26 17:31:45,913][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:45,984][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 361
[2024-03-26 17:31:45,986][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:45,989][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:45,994][fairseq.trainer][INFO] - begin training epoch 361
[2024-03-26 17:31:45,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:31:53,305][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 361 @ 2881 updates
[2024-03-26 17:31:53,307][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:55,785][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:31:55,847][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 361 @ 2881 updates, score None) (writing took 2.5415232833474874 seconds)
[2024-03-26 17:31:55,848][fairseq_cli.train][INFO] - end of epoch 361 (average epoch stats below)
[2024-03-26 17:31:55,848][train][INFO] - {"epoch": 361, "train_loss": "0.405", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.038", "train_target_var": "0.773", "train_pred_var": "0.764", "train_masked_pct": "0.498", "train_wps": "8670.2", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "2881", "train_lr": "0.000270094", "train_gnorm": "2.054", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3734"}
[2024-03-26 17:31:55,850][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:31:55,913][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 362
[2024-03-26 17:31:55,915][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:31:55,918][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:31:55,923][fairseq.trainer][INFO] - begin training epoch 362
[2024-03-26 17:31:55,924][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:03,429][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 362 @ 2889 updates
[2024-03-26 17:32:03,430][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:06,010][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:06,062][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 362 @ 2889 updates, score None) (writing took 2.6325530540198088 seconds)
[2024-03-26 17:32:06,062][fairseq_cli.train][INFO] - end of epoch 362 (average epoch stats below)
[2024-03-26 17:32:06,063][train][INFO] - {"epoch": 362, "train_loss": "0.52", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.038", "train_target_var": "0.772", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8433.7", "train_ups": "0.78", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "2889", "train_lr": "0.000270844", "train_gnorm": "3.021", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3744"}
[2024-03-26 17:32:06,066][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:06,143][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 363
[2024-03-26 17:32:06,145][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:06,148][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:06,153][fairseq.trainer][INFO] - begin training epoch 363
[2024-03-26 17:32:06,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:13,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 363 @ 2897 updates
[2024-03-26 17:32:13,492][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:15,988][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:16,051][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 363 @ 2897 updates, score None) (writing took 2.559970481786877 seconds)
[2024-03-26 17:32:16,051][fairseq_cli.train][INFO] - end of epoch 363 (average epoch stats below)
[2024-03-26 17:32:16,052][train][INFO] - {"epoch": 363, "train_loss": "0.427", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.038", "train_target_var": "0.774", "train_pred_var": "0.765", "train_masked_pct": "0.501", "train_wps": "8626", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "2897", "train_lr": "0.000271594", "train_gnorm": "1.791", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "3754"}
[2024-03-26 17:32:16,054][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:16,119][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 364
[2024-03-26 17:32:16,121][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:16,124][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:16,129][fairseq.trainer][INFO] - begin training epoch 364
[2024-03-26 17:32:16,129][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:23,306][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 364 @ 2905 updates
[2024-03-26 17:32:23,308][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:25,810][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:25,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 364 @ 2905 updates, score None) (writing took 2.5534770698286593 seconds)
[2024-03-26 17:32:25,860][fairseq_cli.train][INFO] - end of epoch 364 (average epoch stats below)
[2024-03-26 17:32:25,861][train][INFO] - {"epoch": 364, "train_loss": "0.506", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.038", "train_target_var": "0.772", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8782.9", "train_ups": "0.82", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "2905", "train_lr": "0.000272344", "train_gnorm": "2.179", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3764"}
[2024-03-26 17:32:25,863][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:25,939][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 365
[2024-03-26 17:32:25,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:25,944][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:25,949][fairseq.trainer][INFO] - begin training epoch 365
[2024-03-26 17:32:25,949][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:33,316][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:32:33,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:33,379][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 74
[2024-03-26 17:32:33,383][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:33,796][valid][INFO] - {"epoch": 365, "valid_loss": "0.441", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.038", "valid_target_var": "0.774", "valid_pred_var": "0.77", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "2913", "valid_best_loss": "0.222"}
[2024-03-26 17:32:33,797][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 365 @ 2913 updates
[2024-03-26 17:32:33,799][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:36,287][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:36,343][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 365 @ 2913 updates, score 0.441) (writing took 2.5459526889026165 seconds)
[2024-03-26 17:32:36,344][fairseq_cli.train][INFO] - end of epoch 365 (average epoch stats below)
[2024-03-26 17:32:36,344][train][INFO] - {"epoch": 365, "train_loss": "0.547", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.038", "train_target_var": "0.771", "train_pred_var": "0.757", "train_masked_pct": "0.499", "train_wps": "8218.6", "train_ups": "0.76", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "2913", "train_lr": "0.000273094", "train_gnorm": "3.303", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3774"}
[2024-03-26 17:32:36,346][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:36,408][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 366
[2024-03-26 17:32:36,410][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:36,413][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:36,418][fairseq.trainer][INFO] - begin training epoch 366
[2024-03-26 17:32:36,419][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:43,714][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 366 @ 2921 updates
[2024-03-26 17:32:43,716][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:46,180][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:46,244][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 366 @ 2921 updates, score None) (writing took 2.5291796610690653 seconds)
[2024-03-26 17:32:46,244][fairseq_cli.train][INFO] - end of epoch 366 (average epoch stats below)
[2024-03-26 17:32:46,245][train][INFO] - {"epoch": 366, "train_loss": "0.478", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.038", "train_target_var": "0.769", "train_pred_var": "0.757", "train_masked_pct": "0.5", "train_wps": "8703", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "2921", "train_lr": "0.000273844", "train_gnorm": "3.006", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3784"}
[2024-03-26 17:32:46,247][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:46,309][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 367
[2024-03-26 17:32:46,311][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:46,314][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:46,319][fairseq.trainer][INFO] - begin training epoch 367
[2024-03-26 17:32:46,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:32:53,579][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 367 @ 2929 updates
[2024-03-26 17:32:53,580][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:56,056][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:32:56,117][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 367 @ 2929 updates, score None) (writing took 2.5380896078422666 seconds)
[2024-03-26 17:32:56,118][fairseq_cli.train][INFO] - end of epoch 367 (average epoch stats below)
[2024-03-26 17:32:56,118][train][INFO] - {"epoch": 367, "train_loss": "0.451", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.039", "train_target_var": "0.774", "train_pred_var": "0.763", "train_masked_pct": "0.498", "train_wps": "8726.1", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2929", "train_lr": "0.000274594", "train_gnorm": "2.318", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3794"}
[2024-03-26 17:32:56,120][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:32:56,186][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 368
[2024-03-26 17:32:56,188][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:32:56,191][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:32:56,195][fairseq.trainer][INFO] - begin training epoch 368
[2024-03-26 17:32:56,196][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:03,651][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 368 @ 2937 updates
[2024-03-26 17:33:03,653][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:06,143][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:06,205][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 368 @ 2937 updates, score None) (writing took 2.5541418087668717 seconds)
[2024-03-26 17:33:06,206][fairseq_cli.train][INFO] - end of epoch 368 (average epoch stats below)
[2024-03-26 17:33:06,206][train][INFO] - {"epoch": 368, "train_loss": "0.489", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.039", "train_target_var": "0.775", "train_pred_var": "0.763", "train_masked_pct": "0.5", "train_wps": "8541.2", "train_ups": "0.79", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2937", "train_lr": "0.000275344", "train_gnorm": "1.952", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3804"}
[2024-03-26 17:33:06,208][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:06,272][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 369
[2024-03-26 17:33:06,274][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:06,277][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:06,282][fairseq.trainer][INFO] - begin training epoch 369
[2024-03-26 17:33:06,283][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:13,604][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 369 @ 2945 updates
[2024-03-26 17:33:13,606][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:16,108][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:16,170][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 369 @ 2945 updates, score None) (writing took 2.565510696731508 seconds)
[2024-03-26 17:33:16,170][fairseq_cli.train][INFO] - end of epoch 369 (average epoch stats below)
[2024-03-26 17:33:16,171][train][INFO] - {"epoch": 369, "train_loss": "0.47", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.039", "train_target_var": "0.77", "train_pred_var": "0.757", "train_masked_pct": "0.501", "train_wps": "8646.7", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "2945", "train_lr": "0.000276094", "train_gnorm": "1.609", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3814"}
[2024-03-26 17:33:16,173][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:16,233][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 370
[2024-03-26 17:33:16,235][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:16,238][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:16,243][fairseq.trainer][INFO] - begin training epoch 370
[2024-03-26 17:33:16,243][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:23,399][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:33:23,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:23,463][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 75
[2024-03-26 17:33:23,466][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:23,879][valid][INFO] - {"epoch": 370, "valid_loss": "0.431", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.039", "valid_target_var": "0.777", "valid_pred_var": "0.768", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "2953", "valid_best_loss": "0.222"}
[2024-03-26 17:33:23,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 370 @ 2953 updates
[2024-03-26 17:33:23,883][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:26,365][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:26,400][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 370 @ 2953 updates, score 0.431) (writing took 2.5194213348440826 seconds)
[2024-03-26 17:33:26,401][fairseq_cli.train][INFO] - end of epoch 370 (average epoch stats below)
[2024-03-26 17:33:26,402][train][INFO] - {"epoch": 370, "train_loss": "0.524", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.039", "train_target_var": "0.772", "train_pred_var": "0.76", "train_masked_pct": "0.5", "train_wps": "8421.4", "train_ups": "0.78", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2953", "train_lr": "0.000276844", "train_gnorm": "1.756", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3824"}
[2024-03-26 17:33:26,404][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:26,494][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 371
[2024-03-26 17:33:26,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:26,499][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:26,504][fairseq.trainer][INFO] - begin training epoch 371
[2024-03-26 17:33:26,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:33,750][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 371 @ 2961 updates
[2024-03-26 17:33:33,751][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:36,233][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:36,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 371 @ 2961 updates, score None) (writing took 2.5434369379654527 seconds)
[2024-03-26 17:33:36,294][fairseq_cli.train][INFO] - end of epoch 371 (average epoch stats below)
[2024-03-26 17:33:36,295][train][INFO] - {"epoch": 371, "train_loss": "0.479", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.039", "train_target_var": "0.77", "train_pred_var": "0.758", "train_masked_pct": "0.499", "train_wps": "8709.6", "train_ups": "0.81", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "2961", "train_lr": "0.000277594", "train_gnorm": "1.802", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3834"}
[2024-03-26 17:33:36,297][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:36,366][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 372
[2024-03-26 17:33:36,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:36,371][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:36,376][fairseq.trainer][INFO] - begin training epoch 372
[2024-03-26 17:33:36,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:43,625][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 372 @ 2969 updates
[2024-03-26 17:33:43,627][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:46,114][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:46,176][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 372 @ 2969 updates, score None) (writing took 2.550898917019367 seconds)
[2024-03-26 17:33:46,177][fairseq_cli.train][INFO] - end of epoch 372 (average epoch stats below)
[2024-03-26 17:33:46,178][train][INFO] - {"epoch": 372, "train_loss": "0.506", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.039", "train_target_var": "0.771", "train_pred_var": "0.757", "train_masked_pct": "0.499", "train_wps": "8717.6", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "2969", "train_lr": "0.000278344", "train_gnorm": "1.961", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3844"}
[2024-03-26 17:33:46,180][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:46,242][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 373
[2024-03-26 17:33:46,244][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:46,247][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:46,252][fairseq.trainer][INFO] - begin training epoch 373
[2024-03-26 17:33:46,252][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:33:53,691][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 373 @ 2977 updates
[2024-03-26 17:33:53,693][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:56,184][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:33:56,231][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 373 @ 2977 updates, score None) (writing took 2.5397071060724556 seconds)
[2024-03-26 17:33:56,232][fairseq_cli.train][INFO] - end of epoch 373 (average epoch stats below)
[2024-03-26 17:33:56,232][train][INFO] - {"epoch": 373, "train_loss": "0.483", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.039", "train_target_var": "0.777", "train_pred_var": "0.766", "train_masked_pct": "0.499", "train_wps": "8568.6", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "2977", "train_lr": "0.000279094", "train_gnorm": "2.314", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3854"}
[2024-03-26 17:33:56,235][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:33:56,316][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 374
[2024-03-26 17:33:56,318][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:33:56,321][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:33:56,326][fairseq.trainer][INFO] - begin training epoch 374
[2024-03-26 17:33:56,327][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:03,571][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 374 @ 2985 updates
[2024-03-26 17:34:03,572][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:06,062][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:06,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 374 @ 2985 updates, score None) (writing took 2.5270403930917382 seconds)
[2024-03-26 17:34:06,099][fairseq_cli.train][INFO] - end of epoch 374 (average epoch stats below)
[2024-03-26 17:34:06,099][train][INFO] - {"epoch": 374, "train_loss": "0.559", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.039", "train_target_var": "0.775", "train_pred_var": "0.76", "train_masked_pct": "0.5", "train_wps": "8732.6", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "2985", "train_lr": "0.000279844", "train_gnorm": "2.649", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3864"}
[2024-03-26 17:34:06,102][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:06,190][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 375
[2024-03-26 17:34:06,192][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:06,195][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:06,200][fairseq.trainer][INFO] - begin training epoch 375
[2024-03-26 17:34:06,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:13,560][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:34:13,561][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:13,623][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 76
[2024-03-26 17:34:13,626][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:14,042][valid][INFO] - {"epoch": 375, "valid_loss": "0.331", "valid_ntokens": "11715", "valid_nsentences": "25", "valid_sample_size": "11715", "valid_ema_decay": "999.039", "valid_target_var": "0.769", "valid_pred_var": "0.764", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11715", "valid_bsz": "25", "valid_num_updates": "2993", "valid_best_loss": "0.222"}
[2024-03-26 17:34:14,044][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 375 @ 2993 updates
[2024-03-26 17:34:14,045][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:16,522][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:16,554][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 375 @ 2993 updates, score 0.331) (writing took 2.5107180778868496 seconds)
[2024-03-26 17:34:16,555][fairseq_cli.train][INFO] - end of epoch 375 (average epoch stats below)
[2024-03-26 17:34:16,556][train][INFO] - {"epoch": 375, "train_loss": "0.48", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.039", "train_target_var": "0.771", "train_pred_var": "0.76", "train_masked_pct": "0.5", "train_wps": "8239.8", "train_ups": "0.77", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "2993", "train_lr": "0.000280594", "train_gnorm": "2.635", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3874"}
[2024-03-26 17:34:16,558][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:16,637][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 376
[2024-03-26 17:34:16,639][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:16,642][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:16,647][fairseq.trainer][INFO] - begin training epoch 376
[2024-03-26 17:34:16,647][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:23,923][train_inner][INFO] - {"epoch": 376, "update": 375.875, "loss": "0.478", "ntokens": "10825.8", "nsentences": "22.995", "sample_size": "10825.8", "ema_decay": "999.038", "target_var": "0.771", "pred_var": "0.76", "masked_pct": "0.5", "wps": "8596.7", "ups": "0.79", "wpb": "10825.8", "bsz": "23", "num_updates": "3000", "lr": "0.00028125", "gnorm": "2.332", "loss_scale": "1", "train_wall": "177", "gb_free": "5.1", "wall": "3882"}
[2024-03-26 17:34:24,076][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 376 @ 3001 updates
[2024-03-26 17:34:24,078][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:26,548][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:26,609][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 376 @ 3001 updates, score None) (writing took 2.5327433766797185 seconds)
[2024-03-26 17:34:26,610][fairseq_cli.train][INFO] - end of epoch 376 (average epoch stats below)
[2024-03-26 17:34:26,610][train][INFO] - {"epoch": 376, "train_loss": "0.45", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.04", "train_target_var": "0.776", "train_pred_var": "0.766", "train_masked_pct": "0.501", "train_wps": "8568.5", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "3001", "train_lr": "0.000281344", "train_gnorm": "2.07", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3884"}
[2024-03-26 17:34:26,612][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:26,673][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 377
[2024-03-26 17:34:26,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:26,678][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:26,682][fairseq.trainer][INFO] - begin training epoch 377
[2024-03-26 17:34:26,683][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:33,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 377 @ 3009 updates
[2024-03-26 17:34:33,882][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:36,380][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:36,433][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 377 @ 3009 updates, score None) (writing took 2.5520503567531705 seconds)
[2024-03-26 17:34:36,433][fairseq_cli.train][INFO] - end of epoch 377 (average epoch stats below)
[2024-03-26 17:34:36,434][train][INFO] - {"epoch": 377, "train_loss": "0.498", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.04", "train_target_var": "0.773", "train_pred_var": "0.76", "train_masked_pct": "0.5", "train_wps": "8771", "train_ups": "0.81", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "3009", "train_lr": "0.000282094", "train_gnorm": "1.867", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "3894"}
[2024-03-26 17:34:36,436][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:36,506][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 378
[2024-03-26 17:34:36,507][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:36,510][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:36,515][fairseq.trainer][INFO] - begin training epoch 378
[2024-03-26 17:34:36,516][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:43,674][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 378 @ 3017 updates
[2024-03-26 17:34:43,675][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:46,169][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:46,228][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 378 @ 3017 updates, score None) (writing took 2.554146329406649 seconds)
[2024-03-26 17:34:46,228][fairseq_cli.train][INFO] - end of epoch 378 (average epoch stats below)
[2024-03-26 17:34:46,229][train][INFO] - {"epoch": 378, "train_loss": "0.517", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.04", "train_target_var": "0.768", "train_pred_var": "0.755", "train_masked_pct": "0.5", "train_wps": "8795.4", "train_ups": "0.82", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "3017", "train_lr": "0.000282844", "train_gnorm": "2.174", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3904"}
[2024-03-26 17:34:46,231][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:46,293][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 379
[2024-03-26 17:34:46,295][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:46,298][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:46,303][fairseq.trainer][INFO] - begin training epoch 379
[2024-03-26 17:34:46,304][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:34:53,797][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 379 @ 3025 updates
[2024-03-26 17:34:53,798][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:56,308][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:34:56,368][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 379 @ 3025 updates, score None) (writing took 2.5709561482071877 seconds)
[2024-03-26 17:34:56,369][fairseq_cli.train][INFO] - end of epoch 379 (average epoch stats below)
[2024-03-26 17:34:56,370][train][INFO] - {"epoch": 379, "train_loss": "0.438", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.04", "train_target_var": "0.773", "train_pred_var": "0.762", "train_masked_pct": "0.5", "train_wps": "8496.7", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3025", "train_lr": "0.000283594", "train_gnorm": "1.742", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3914"}
[2024-03-26 17:34:56,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:34:56,434][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 380
[2024-03-26 17:34:56,436][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:34:56,439][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:34:56,444][fairseq.trainer][INFO] - begin training epoch 380
[2024-03-26 17:34:56,444][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:03,736][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:35:03,737][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:03,799][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 77
[2024-03-26 17:35:03,802][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:04,211][valid][INFO] - {"epoch": 380, "valid_loss": "0.408", "valid_ntokens": "11694", "valid_nsentences": "25", "valid_sample_size": "11694", "valid_ema_decay": "999.04", "valid_target_var": "0.774", "valid_pred_var": "0.769", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11694", "valid_bsz": "25", "valid_num_updates": "3033", "valid_best_loss": "0.222"}
[2024-03-26 17:35:04,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 380 @ 3033 updates
[2024-03-26 17:35:04,214][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:06,715][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:06,777][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 380 @ 3033 updates, score 0.408) (writing took 2.5643310891464353 seconds)
[2024-03-26 17:35:06,778][fairseq_cli.train][INFO] - end of epoch 380 (average epoch stats below)
[2024-03-26 17:35:06,779][train][INFO] - {"epoch": 380, "train_loss": "0.535", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.04", "train_target_var": "0.773", "train_pred_var": "0.761", "train_masked_pct": "0.498", "train_wps": "8277.3", "train_ups": "0.77", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3033", "train_lr": "0.000284344", "train_gnorm": "1.979", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3925"}
[2024-03-26 17:35:06,781][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:06,844][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 381
[2024-03-26 17:35:06,845][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:06,848][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:06,853][fairseq.trainer][INFO] - begin training epoch 381
[2024-03-26 17:35:06,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:14,043][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 381 @ 3041 updates
[2024-03-26 17:35:14,045][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:16,529][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:16,592][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 381 @ 3041 updates, score None) (writing took 2.5486535700038075 seconds)
[2024-03-26 17:35:16,592][fairseq_cli.train][INFO] - end of epoch 381 (average epoch stats below)
[2024-03-26 17:35:16,593][train][INFO] - {"epoch": 381, "train_loss": "0.467", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.04", "train_target_var": "0.771", "train_pred_var": "0.759", "train_masked_pct": "0.501", "train_wps": "8778.8", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3041", "train_lr": "0.000285094", "train_gnorm": "1.797", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3934"}
[2024-03-26 17:35:16,595][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:16,658][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 382
[2024-03-26 17:35:16,660][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:16,663][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:16,668][fairseq.trainer][INFO] - begin training epoch 382
[2024-03-26 17:35:16,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:24,100][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 382 @ 3049 updates
[2024-03-26 17:35:24,102][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:26,595][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:26,655][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 382 @ 3049 updates, score None) (writing took 2.554910996928811 seconds)
[2024-03-26 17:35:26,656][fairseq_cli.train][INFO] - end of epoch 382 (average epoch stats below)
[2024-03-26 17:35:26,657][train][INFO] - {"epoch": 382, "train_loss": "0.459", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.04", "train_target_var": "0.772", "train_pred_var": "0.76", "train_masked_pct": "0.499", "train_wps": "8561.5", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3049", "train_lr": "0.000285844", "train_gnorm": "1.872", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3944"}
[2024-03-26 17:35:26,659][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:26,723][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 383
[2024-03-26 17:35:26,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:26,728][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:26,732][fairseq.trainer][INFO] - begin training epoch 383
[2024-03-26 17:35:26,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:33,850][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 383 @ 3057 updates
[2024-03-26 17:35:33,852][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:36,322][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:36,384][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 383 @ 3057 updates, score None) (writing took 2.5338033721782267 seconds)
[2024-03-26 17:35:36,385][fairseq_cli.train][INFO] - end of epoch 383 (average epoch stats below)
[2024-03-26 17:35:36,386][train][INFO] - {"epoch": 383, "train_loss": "0.61", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.04", "train_target_var": "0.773", "train_pred_var": "0.763", "train_masked_pct": "0.501", "train_wps": "8856.2", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3057", "train_lr": "0.000286594", "train_gnorm": "2.593", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "3954"}
[2024-03-26 17:35:36,388][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:36,453][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 384
[2024-03-26 17:35:36,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:36,458][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:36,463][fairseq.trainer][INFO] - begin training epoch 384
[2024-03-26 17:35:36,464][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:43,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 384 @ 3065 updates
[2024-03-26 17:35:43,885][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:46,369][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:46,425][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 384 @ 3065 updates, score None) (writing took 2.5414775698445737 seconds)
[2024-03-26 17:35:46,426][fairseq_cli.train][INFO] - end of epoch 384 (average epoch stats below)
[2024-03-26 17:35:46,427][train][INFO] - {"epoch": 384, "train_loss": "0.542", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.04", "train_target_var": "0.776", "train_pred_var": "0.762", "train_masked_pct": "0.501", "train_wps": "8580.2", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3065", "train_lr": "0.000287344", "train_gnorm": "2.435", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "3964"}
[2024-03-26 17:35:46,429][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:46,491][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 385
[2024-03-26 17:35:46,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:46,495][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:46,501][fairseq.trainer][INFO] - begin training epoch 385
[2024-03-26 17:35:46,501][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:35:53,817][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:35:53,818][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:53,880][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 78
[2024-03-26 17:35:53,883][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:54,286][valid][INFO] - {"epoch": 385, "valid_loss": "0.556", "valid_ntokens": "11715", "valid_nsentences": "25", "valid_sample_size": "11715", "valid_ema_decay": "999.041", "valid_target_var": "0.774", "valid_pred_var": "0.781", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11715", "valid_bsz": "25", "valid_num_updates": "3073", "valid_best_loss": "0.222"}
[2024-03-26 17:35:54,287][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 385 @ 3073 updates
[2024-03-26 17:35:54,289][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:56,777][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:35:56,837][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 385 @ 3073 updates, score 0.556) (writing took 2.54984743706882 seconds)
[2024-03-26 17:35:56,838][fairseq_cli.train][INFO] - end of epoch 385 (average epoch stats below)
[2024-03-26 17:35:56,838][train][INFO] - {"epoch": 385, "train_loss": "0.531", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.041", "train_target_var": "0.772", "train_pred_var": "0.756", "train_masked_pct": "0.5", "train_wps": "8274.9", "train_ups": "0.77", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3073", "train_lr": "0.000288094", "train_gnorm": "2.512", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "3975"}
[2024-03-26 17:35:56,840][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:35:56,903][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 386
[2024-03-26 17:35:56,905][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:35:56,908][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:35:56,912][fairseq.trainer][INFO] - begin training epoch 386
[2024-03-26 17:35:56,913][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:04,225][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 386 @ 3081 updates
[2024-03-26 17:36:04,227][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:06,707][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:06,768][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 386 @ 3081 updates, score None) (writing took 2.5431625000201166 seconds)
[2024-03-26 17:36:06,769][fairseq_cli.train][INFO] - end of epoch 386 (average epoch stats below)
[2024-03-26 17:36:06,770][train][INFO] - {"epoch": 386, "train_loss": "0.647", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.041", "train_target_var": "0.77", "train_pred_var": "0.756", "train_masked_pct": "0.501", "train_wps": "8675.4", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3081", "train_lr": "0.000288844", "train_gnorm": "2.843", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "3985"}
[2024-03-26 17:36:06,772][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:06,835][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 387
[2024-03-26 17:36:06,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:06,840][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:06,845][fairseq.trainer][INFO] - begin training epoch 387
[2024-03-26 17:36:06,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:14,256][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 387 @ 3089 updates
[2024-03-26 17:36:14,258][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:16,733][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:16,794][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 387 @ 3089 updates, score None) (writing took 2.537631468847394 seconds)
[2024-03-26 17:36:16,795][fairseq_cli.train][INFO] - end of epoch 387 (average epoch stats below)
[2024-03-26 17:36:16,795][train][INFO] - {"epoch": 387, "train_loss": "0.607", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.041", "train_target_var": "0.77", "train_pred_var": "0.754", "train_masked_pct": "0.5", "train_wps": "8594.3", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3089", "train_lr": "0.000289594", "train_gnorm": "2.362", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "3995"}
[2024-03-26 17:36:16,798][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:16,860][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 388
[2024-03-26 17:36:16,862][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:16,865][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:16,870][fairseq.trainer][INFO] - begin training epoch 388
[2024-03-26 17:36:16,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:24,337][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 388 @ 3097 updates
[2024-03-26 17:36:24,339][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:26,818][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:26,878][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 388 @ 3097 updates, score None) (writing took 2.540811310056597 seconds)
[2024-03-26 17:36:26,879][fairseq_cli.train][INFO] - end of epoch 388 (average epoch stats below)
[2024-03-26 17:36:26,880][train][INFO] - {"epoch": 388, "train_loss": "0.527", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.041", "train_target_var": "0.774", "train_pred_var": "0.762", "train_masked_pct": "0.499", "train_wps": "8544", "train_ups": "0.79", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3097", "train_lr": "0.000290344", "train_gnorm": "2.84", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4005"}
[2024-03-26 17:36:26,882][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:26,944][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 389
[2024-03-26 17:36:26,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:26,949][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:26,954][fairseq.trainer][INFO] - begin training epoch 389
[2024-03-26 17:36:26,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:34,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 389 @ 3105 updates
[2024-03-26 17:36:34,392][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:36,861][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:36,907][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 389 @ 3105 updates, score None) (writing took 2.5173616260290146 seconds)
[2024-03-26 17:36:36,907][fairseq_cli.train][INFO] - end of epoch 389 (average epoch stats below)
[2024-03-26 17:36:36,908][train][INFO] - {"epoch": 389, "train_loss": "0.539", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.041", "train_target_var": "0.775", "train_pred_var": "0.76", "train_masked_pct": "0.498", "train_wps": "8590.7", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "3105", "train_lr": "0.000291094", "train_gnorm": "2.156", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4015"}
[2024-03-26 17:36:36,910][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:36,989][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 390
[2024-03-26 17:36:36,992][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:36,995][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:37,000][fairseq.trainer][INFO] - begin training epoch 390
[2024-03-26 17:36:37,000][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:44,477][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:36:44,478][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:44,574][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 79
[2024-03-26 17:36:44,577][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:45,001][valid][INFO] - {"epoch": 390, "valid_loss": "0.53", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.041", "valid_target_var": "0.775", "valid_pred_var": "0.767", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "3113", "valid_best_loss": "0.222"}
[2024-03-26 17:36:45,003][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 390 @ 3113 updates
[2024-03-26 17:36:45,004][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:47,490][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:47,530][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 390 @ 3113 updates, score 0.53) (writing took 2.5277261696755886 seconds)
[2024-03-26 17:36:47,531][fairseq_cli.train][INFO] - end of epoch 390 (average epoch stats below)
[2024-03-26 17:36:47,531][train][INFO] - {"epoch": 390, "train_loss": "0.498", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.041", "train_target_var": "0.775", "train_pred_var": "0.764", "train_masked_pct": "0.498", "train_wps": "8110.5", "train_ups": "0.75", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3113", "train_lr": "0.000291844", "train_gnorm": "1.95", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4025"}
[2024-03-26 17:36:47,533][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:47,616][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 391
[2024-03-26 17:36:47,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:47,621][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:47,626][fairseq.trainer][INFO] - begin training epoch 391
[2024-03-26 17:36:47,626][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:36:55,066][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 391 @ 3121 updates
[2024-03-26 17:36:55,067][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:57,537][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:36:57,578][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 391 @ 3121 updates, score None) (writing took 2.5120892990380526 seconds)
[2024-03-26 17:36:57,578][fairseq_cli.train][INFO] - end of epoch 391 (average epoch stats below)
[2024-03-26 17:36:57,579][train][INFO] - {"epoch": 391, "train_loss": "0.605", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.041", "train_target_var": "0.776", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8574.7", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3121", "train_lr": "0.000292594", "train_gnorm": "2.012", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4035"}
[2024-03-26 17:36:57,581][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:36:57,662][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 392
[2024-03-26 17:36:57,664][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:36:57,667][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:36:57,671][fairseq.trainer][INFO] - begin training epoch 392
[2024-03-26 17:36:57,672][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:05,002][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 392 @ 3129 updates
[2024-03-26 17:37:05,003][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:07,587][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:07,647][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 392 @ 3129 updates, score None) (writing took 2.6458400869742036 seconds)
[2024-03-26 17:37:07,648][fairseq_cli.train][INFO] - end of epoch 392 (average epoch stats below)
[2024-03-26 17:37:07,649][train][INFO] - {"epoch": 392, "train_loss": "0.604", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.041", "train_target_var": "0.774", "train_pred_var": "0.761", "train_masked_pct": "0.5", "train_wps": "8556.4", "train_ups": "0.79", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3129", "train_lr": "0.000293344", "train_gnorm": "1.751", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4045"}
[2024-03-26 17:37:07,651][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:07,715][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 393
[2024-03-26 17:37:07,717][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:07,720][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:07,725][fairseq.trainer][INFO] - begin training epoch 393
[2024-03-26 17:37:07,725][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:14,958][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 393 @ 3137 updates
[2024-03-26 17:37:14,959][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:17,423][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:17,484][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 393 @ 3137 updates, score None) (writing took 2.525926544331014 seconds)
[2024-03-26 17:37:17,484][fairseq_cli.train][INFO] - end of epoch 393 (average epoch stats below)
[2024-03-26 17:37:17,485][train][INFO] - {"epoch": 393, "train_loss": "0.565", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.041", "train_target_var": "0.775", "train_pred_var": "0.763", "train_masked_pct": "0.499", "train_wps": "8758.7", "train_ups": "0.81", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "3137", "train_lr": "0.000294094", "train_gnorm": "2.115", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4055"}
[2024-03-26 17:37:17,487][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:17,581][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 394
[2024-03-26 17:37:17,583][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:17,586][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:17,591][fairseq.trainer][INFO] - begin training epoch 394
[2024-03-26 17:37:17,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:24,862][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 394 @ 3145 updates
[2024-03-26 17:37:24,863][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:27,342][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:27,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 394 @ 3145 updates, score None) (writing took 2.534390945918858 seconds)
[2024-03-26 17:37:27,397][fairseq_cli.train][INFO] - end of epoch 394 (average epoch stats below)
[2024-03-26 17:37:27,397][train][INFO] - {"epoch": 394, "train_loss": "0.583", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.041", "train_target_var": "0.772", "train_pred_var": "0.755", "train_masked_pct": "0.499", "train_wps": "8692.2", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3145", "train_lr": "0.000294844", "train_gnorm": "2.78", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4065"}
[2024-03-26 17:37:27,399][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:27,460][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 395
[2024-03-26 17:37:27,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:27,465][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:27,473][fairseq.trainer][INFO] - begin training epoch 395
[2024-03-26 17:37:27,473][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:34,903][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:37:34,904][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:34,973][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 80
[2024-03-26 17:37:34,977][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:35,393][valid][INFO] - {"epoch": 395, "valid_loss": "0.605", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.042", "valid_target_var": "0.776", "valid_pred_var": "0.77", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "3153", "valid_best_loss": "0.222"}
[2024-03-26 17:37:35,395][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 395 @ 3153 updates
[2024-03-26 17:37:35,396][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:37,872][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:37,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 395 @ 3153 updates, score 0.605) (writing took 2.5350717059336603 seconds)
[2024-03-26 17:37:37,931][fairseq_cli.train][INFO] - end of epoch 395 (average epoch stats below)
[2024-03-26 17:37:37,931][train][INFO] - {"epoch": 395, "train_loss": "0.564", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.042", "train_target_var": "0.771", "train_pred_var": "0.758", "train_masked_pct": "0.5", "train_wps": "8178.7", "train_ups": "0.76", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3153", "train_lr": "0.000295594", "train_gnorm": "2.364", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "4076"}
[2024-03-26 17:37:37,933][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:37,995][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 396
[2024-03-26 17:37:37,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:38,000][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:38,004][fairseq.trainer][INFO] - begin training epoch 396
[2024-03-26 17:37:38,005][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:45,384][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 396 @ 3161 updates
[2024-03-26 17:37:45,385][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:47,858][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:47,917][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 396 @ 3161 updates, score None) (writing took 2.5334125882945955 seconds)
[2024-03-26 17:37:47,918][fairseq_cli.train][INFO] - end of epoch 396 (average epoch stats below)
[2024-03-26 17:37:47,918][train][INFO] - {"epoch": 396, "train_loss": "0.63", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.042", "train_target_var": "0.771", "train_pred_var": "0.754", "train_masked_pct": "0.499", "train_wps": "8626.9", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3161", "train_lr": "0.000296344", "train_gnorm": "2.104", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4086"}
[2024-03-26 17:37:47,920][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:47,984][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 397
[2024-03-26 17:37:47,985][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:47,988][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:47,993][fairseq.trainer][INFO] - begin training epoch 397
[2024-03-26 17:37:47,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:37:55,319][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 397 @ 3169 updates
[2024-03-26 17:37:55,321][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:57,897][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:37:57,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 397 @ 3169 updates, score None) (writing took 2.61044611223042 seconds)
[2024-03-26 17:37:57,931][fairseq_cli.train][INFO] - end of epoch 397 (average epoch stats below)
[2024-03-26 17:37:57,931][train][INFO] - {"epoch": 397, "train_loss": "0.564", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.042", "train_target_var": "0.776", "train_pred_var": "0.764", "train_masked_pct": "0.499", "train_wps": "8604.5", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3169", "train_lr": "0.000297094", "train_gnorm": "2.937", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4096"}
[2024-03-26 17:37:57,934][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:37:58,026][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 398
[2024-03-26 17:37:58,028][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:37:58,031][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:37:58,036][fairseq.trainer][INFO] - begin training epoch 398
[2024-03-26 17:37:58,036][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:05,485][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 398 @ 3177 updates
[2024-03-26 17:38:05,487][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:07,987][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:08,035][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 398 @ 3177 updates, score None) (writing took 2.550245848018676 seconds)
[2024-03-26 17:38:08,036][fairseq_cli.train][INFO] - end of epoch 398 (average epoch stats below)
[2024-03-26 17:38:08,036][train][INFO] - {"epoch": 398, "train_loss": "0.484", "train_ntokens": "10768", "train_nsentences": "22.875", "train_sample_size": "10768", "train_ema_decay": "999.042", "train_target_var": "0.773", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8525.6", "train_ups": "0.79", "train_wpb": "10768", "train_bsz": "22.9", "train_num_updates": "3177", "train_lr": "0.000297844", "train_gnorm": "2.329", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4106"}
[2024-03-26 17:38:08,038][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:08,116][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 399
[2024-03-26 17:38:08,118][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:08,121][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:08,126][fairseq.trainer][INFO] - begin training epoch 399
[2024-03-26 17:38:08,127][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:15,461][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 399 @ 3185 updates
[2024-03-26 17:38:15,462][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:17,948][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:18,009][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 399 @ 3185 updates, score None) (writing took 2.548234081827104 seconds)
[2024-03-26 17:38:18,010][fairseq_cli.train][INFO] - end of epoch 399 (average epoch stats below)
[2024-03-26 17:38:18,010][train][INFO] - {"epoch": 399, "train_loss": "0.496", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.042", "train_target_var": "0.778", "train_pred_var": "0.765", "train_masked_pct": "0.501", "train_wps": "8638.8", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3185", "train_lr": "0.000298594", "train_gnorm": "1.931", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4116"}
[2024-03-26 17:38:18,013][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:18,090][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 400
[2024-03-26 17:38:18,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:18,095][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:18,100][fairseq.trainer][INFO] - begin training epoch 400
[2024-03-26 17:38:18,100][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:25,374][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:38:25,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:25,451][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 81
[2024-03-26 17:38:25,454][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:25,852][valid][INFO] - {"epoch": 400, "valid_loss": "0.404", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.042", "valid_target_var": "0.771", "valid_pred_var": "0.766", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "3193", "valid_best_loss": "0.222"}
[2024-03-26 17:38:25,854][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 400 @ 3193 updates
[2024-03-26 17:38:25,856][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:28,344][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:28,406][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 400 @ 3193 updates, score 0.404) (writing took 2.552152283024043 seconds)
[2024-03-26 17:38:28,407][fairseq_cli.train][INFO] - end of epoch 400 (average epoch stats below)
[2024-03-26 17:38:28,407][train][INFO] - {"epoch": 400, "train_loss": "0.499", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.042", "train_target_var": "0.774", "train_pred_var": "0.762", "train_masked_pct": "0.501", "train_wps": "8286.9", "train_ups": "0.77", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3193", "train_lr": "0.000299344", "train_gnorm": "1.616", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4126"}
[2024-03-26 17:38:28,409][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:28,471][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 401
[2024-03-26 17:38:28,472][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:28,475][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:28,480][fairseq.trainer][INFO] - begin training epoch 401
[2024-03-26 17:38:28,480][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:34,845][train_inner][INFO] - {"epoch": 401, "update": 400.875, "loss": "0.543", "ntokens": "10712.3", "nsentences": "22.755", "sample_size": "10712.3", "ema_decay": "999.041", "target_var": "0.773", "pred_var": "0.76", "masked_pct": "0.5", "wps": "8538.3", "ups": "0.8", "wpb": "10712.3", "bsz": "22.8", "num_updates": "3200", "lr": "0.0003", "gnorm": "2.208", "loss_scale": "1", "train_wall": "176", "gb_free": "5.1", "wall": "4133"}
[2024-03-26 17:38:35,861][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 401 @ 3201 updates
[2024-03-26 17:38:35,862][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:38,354][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:38,392][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 401 @ 3201 updates, score None) (writing took 2.531315390020609 seconds)
[2024-03-26 17:38:38,392][fairseq_cli.train][INFO] - end of epoch 401 (average epoch stats below)
[2024-03-26 17:38:38,393][train][INFO] - {"epoch": 401, "train_loss": "0.56", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.042", "train_target_var": "0.77", "train_pred_var": "0.756", "train_masked_pct": "0.498", "train_wps": "8628.3", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3201", "train_lr": "0.000300094", "train_gnorm": "1.939", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4136"}
[2024-03-26 17:38:38,395][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:38,484][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 402
[2024-03-26 17:38:38,485][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:38,489][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:38,493][fairseq.trainer][INFO] - begin training epoch 402
[2024-03-26 17:38:38,495][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:45,913][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 402 @ 3209 updates
[2024-03-26 17:38:45,915][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:48,401][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:48,463][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 402 @ 3209 updates, score None) (writing took 2.549954069778323 seconds)
[2024-03-26 17:38:48,464][fairseq_cli.train][INFO] - end of epoch 402 (average epoch stats below)
[2024-03-26 17:38:48,464][train][INFO] - {"epoch": 402, "train_loss": "0.575", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.042", "train_target_var": "0.775", "train_pred_var": "0.761", "train_masked_pct": "0.501", "train_wps": "8555.2", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3209", "train_lr": "0.000300844", "train_gnorm": "1.734", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4146"}
[2024-03-26 17:38:48,467][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:48,529][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 403
[2024-03-26 17:38:48,531][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:48,534][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:48,538][fairseq.trainer][INFO] - begin training epoch 403
[2024-03-26 17:38:48,539][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:38:55,728][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 403 @ 3217 updates
[2024-03-26 17:38:55,729][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:58,237][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:38:58,298][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 403 @ 3217 updates, score None) (writing took 2.5703095416538417 seconds)
[2024-03-26 17:38:58,299][fairseq_cli.train][INFO] - end of epoch 403 (average epoch stats below)
[2024-03-26 17:38:58,300][train][INFO] - {"epoch": 403, "train_loss": "0.504", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.042", "train_target_var": "0.774", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8760.2", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3217", "train_lr": "0.000301594", "train_gnorm": "2.14", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4156"}
[2024-03-26 17:38:58,303][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:38:58,367][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 404
[2024-03-26 17:38:58,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:38:58,372][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:38:58,377][fairseq.trainer][INFO] - begin training epoch 404
[2024-03-26 17:38:58,377][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:05,474][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 404 @ 3225 updates
[2024-03-26 17:39:05,476][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:07,972][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:08,028][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 404 @ 3225 updates, score None) (writing took 2.554022085852921 seconds)
[2024-03-26 17:39:08,029][fairseq_cli.train][INFO] - end of epoch 404 (average epoch stats below)
[2024-03-26 17:39:08,030][train][INFO] - {"epoch": 404, "train_loss": "0.615", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.043", "train_target_var": "0.773", "train_pred_var": "0.761", "train_masked_pct": "0.499", "train_wps": "8855.2", "train_ups": "0.82", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3225", "train_lr": "0.000302344", "train_gnorm": "2.625", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4166"}
[2024-03-26 17:39:08,032][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:08,100][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 405
[2024-03-26 17:39:08,101][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:08,105][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:08,109][fairseq.trainer][INFO] - begin training epoch 405
[2024-03-26 17:39:08,110][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:15,604][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:39:15,605][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:15,668][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 82
[2024-03-26 17:39:15,671][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:16,082][valid][INFO] - {"epoch": 405, "valid_loss": "0.469", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.043", "valid_target_var": "0.774", "valid_pred_var": "0.766", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "3233", "valid_best_loss": "0.222"}
[2024-03-26 17:39:16,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 405 @ 3233 updates
[2024-03-26 17:39:16,085][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:18,554][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:18,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 405 @ 3233 updates, score 0.469) (writing took 2.532812516205013 seconds)
[2024-03-26 17:39:18,618][fairseq_cli.train][INFO] - end of epoch 405 (average epoch stats below)
[2024-03-26 17:39:18,619][train][INFO] - {"epoch": 405, "train_loss": "0.591", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.043", "train_target_var": "0.772", "train_pred_var": "0.759", "train_masked_pct": "0.499", "train_wps": "8136.6", "train_ups": "0.76", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3233", "train_lr": "0.000303094", "train_gnorm": "2.177", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4176"}
[2024-03-26 17:39:18,621][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:18,684][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 406
[2024-03-26 17:39:18,685][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:18,688][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:18,693][fairseq.trainer][INFO] - begin training epoch 406
[2024-03-26 17:39:18,693][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:25,961][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 406 @ 3241 updates
[2024-03-26 17:39:25,963][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:28,421][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:28,481][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 406 @ 3241 updates, score None) (writing took 2.5196422007866204 seconds)
[2024-03-26 17:39:28,481][fairseq_cli.train][INFO] - end of epoch 406 (average epoch stats below)
[2024-03-26 17:39:28,482][train][INFO] - {"epoch": 406, "train_loss": "0.573", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.043", "train_target_var": "0.773", "train_pred_var": "0.759", "train_masked_pct": "0.501", "train_wps": "8735.7", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3241", "train_lr": "0.000303844", "train_gnorm": "2.456", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4186"}
[2024-03-26 17:39:28,484][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:28,545][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 407
[2024-03-26 17:39:28,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:28,550][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:28,555][fairseq.trainer][INFO] - begin training epoch 407
[2024-03-26 17:39:28,555][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:35,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 407 @ 3249 updates
[2024-03-26 17:39:35,961][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:38,469][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:38,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 407 @ 3249 updates, score None) (writing took 2.611065126955509 seconds)
[2024-03-26 17:39:38,572][fairseq_cli.train][INFO] - end of epoch 407 (average epoch stats below)
[2024-03-26 17:39:38,573][train][INFO] - {"epoch": 407, "train_loss": "0.655", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.043", "train_target_var": "0.773", "train_pred_var": "0.756", "train_masked_pct": "0.499", "train_wps": "8539.3", "train_ups": "0.79", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "3249", "train_lr": "0.000304594", "train_gnorm": "2.514", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4196"}
[2024-03-26 17:39:38,576][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:38,638][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 408
[2024-03-26 17:39:38,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:38,643][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:38,648][fairseq.trainer][INFO] - begin training epoch 408
[2024-03-26 17:39:38,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:46,034][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 408 @ 3257 updates
[2024-03-26 17:39:46,036][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:48,532][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:48,575][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 408 @ 3257 updates, score None) (writing took 2.5409312858246267 seconds)
[2024-03-26 17:39:48,576][fairseq_cli.train][INFO] - end of epoch 408 (average epoch stats below)
[2024-03-26 17:39:48,577][train][INFO] - {"epoch": 408, "train_loss": "0.644", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.043", "train_target_var": "0.773", "train_pred_var": "0.756", "train_masked_pct": "0.499", "train_wps": "8612.7", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3257", "train_lr": "0.000305344", "train_gnorm": "2.548", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4206"}
[2024-03-26 17:39:48,580][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:48,664][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 409
[2024-03-26 17:39:48,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:48,669][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:48,674][fairseq.trainer][INFO] - begin training epoch 409
[2024-03-26 17:39:48,674][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:39:56,082][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 409 @ 3265 updates
[2024-03-26 17:39:56,084][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:58,579][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:39:58,639][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 409 @ 3265 updates, score None) (writing took 2.5567305120639503 seconds)
[2024-03-26 17:39:58,639][fairseq_cli.train][INFO] - end of epoch 409 (average epoch stats below)
[2024-03-26 17:39:58,640][train][INFO] - {"epoch": 409, "train_loss": "0.773", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.043", "train_target_var": "0.773", "train_pred_var": "0.755", "train_masked_pct": "0.5", "train_wps": "8563", "train_ups": "0.8", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "3265", "train_lr": "0.000306094", "train_gnorm": "2.991", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4216"}
[2024-03-26 17:39:58,642][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:39:58,713][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 410
[2024-03-26 17:39:58,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:39:58,718][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:39:58,723][fairseq.trainer][INFO] - begin training epoch 410
[2024-03-26 17:39:58,724][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:06,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:40:06,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:06,176][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 83
[2024-03-26 17:40:06,179][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:06,580][valid][INFO] - {"epoch": 410, "valid_loss": "0.465", "valid_ntokens": "11719", "valid_nsentences": "25", "valid_sample_size": "11719", "valid_ema_decay": "999.043", "valid_target_var": "0.773", "valid_pred_var": "0.759", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11719", "valid_bsz": "25", "valid_num_updates": "3273", "valid_best_loss": "0.222"}
[2024-03-26 17:40:06,582][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 410 @ 3273 updates
[2024-03-26 17:40:06,583][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:09,080][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:09,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 410 @ 3273 updates, score 0.465) (writing took 2.5618684687651694 seconds)
[2024-03-26 17:40:09,144][fairseq_cli.train][INFO] - end of epoch 410 (average epoch stats below)
[2024-03-26 17:40:09,145][train][INFO] - {"epoch": 410, "train_loss": "0.657", "train_ntokens": "10770.5", "train_nsentences": "22.875", "train_sample_size": "10770.5", "train_ema_decay": "999.043", "train_target_var": "0.774", "train_pred_var": "0.757", "train_masked_pct": "0.5", "train_wps": "8202.6", "train_ups": "0.76", "train_wpb": "10770.5", "train_bsz": "22.9", "train_num_updates": "3273", "train_lr": "0.000306844", "train_gnorm": "2.843", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4227"}
[2024-03-26 17:40:09,147][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:09,209][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 411
[2024-03-26 17:40:09,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:09,213][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:09,218][fairseq.trainer][INFO] - begin training epoch 411
[2024-03-26 17:40:09,219][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:16,476][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 411 @ 3281 updates
[2024-03-26 17:40:16,477][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:18,958][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:19,021][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 411 @ 3281 updates, score None) (writing took 2.54526602383703 seconds)
[2024-03-26 17:40:19,022][fairseq_cli.train][INFO] - end of epoch 411 (average epoch stats below)
[2024-03-26 17:40:19,022][train][INFO] - {"epoch": 411, "train_loss": "0.683", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.043", "train_target_var": "0.774", "train_pred_var": "0.757", "train_masked_pct": "0.501", "train_wps": "8723.6", "train_ups": "0.81", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "3281", "train_lr": "0.000307594", "train_gnorm": "2.331", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4237"}
[2024-03-26 17:40:19,024][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:19,088][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 412
[2024-03-26 17:40:19,089][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:19,092][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:19,097][fairseq.trainer][INFO] - begin training epoch 412
[2024-03-26 17:40:19,098][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:26,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 412 @ 3289 updates
[2024-03-26 17:40:26,484][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:28,997][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:29,059][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 412 @ 3289 updates, score None) (writing took 2.576098612975329 seconds)
[2024-03-26 17:40:29,060][fairseq_cli.train][INFO] - end of epoch 412 (average epoch stats below)
[2024-03-26 17:40:29,060][train][INFO] - {"epoch": 412, "train_loss": "0.695", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.043", "train_target_var": "0.774", "train_pred_var": "0.757", "train_masked_pct": "0.501", "train_wps": "8583.4", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3289", "train_lr": "0.000308344", "train_gnorm": "2.132", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4247"}
[2024-03-26 17:40:29,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:29,128][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 413
[2024-03-26 17:40:29,130][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:29,133][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:29,138][fairseq.trainer][INFO] - begin training epoch 413
[2024-03-26 17:40:29,138][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:36,500][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 413 @ 3297 updates
[2024-03-26 17:40:36,502][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:39,013][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:39,052][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 413 @ 3297 updates, score None) (writing took 2.551756509114057 seconds)
[2024-03-26 17:40:39,053][fairseq_cli.train][INFO] - end of epoch 413 (average epoch stats below)
[2024-03-26 17:40:39,053][train][INFO] - {"epoch": 413, "train_loss": "0.664", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.043", "train_target_var": "0.77", "train_pred_var": "0.752", "train_masked_pct": "0.501", "train_wps": "8622.6", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3297", "train_lr": "0.000309094", "train_gnorm": "1.971", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4257"}
[2024-03-26 17:40:39,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:39,142][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 414
[2024-03-26 17:40:39,144][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:39,147][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:39,152][fairseq.trainer][INFO] - begin training epoch 414
[2024-03-26 17:40:39,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:46,481][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 414 @ 3305 updates
[2024-03-26 17:40:46,482][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:48,955][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:49,017][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 414 @ 3305 updates, score None) (writing took 2.5362113579176366 seconds)
[2024-03-26 17:40:49,017][fairseq_cli.train][INFO] - end of epoch 414 (average epoch stats below)
[2024-03-26 17:40:49,018][train][INFO] - {"epoch": 414, "train_loss": "0.637", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.044", "train_target_var": "0.774", "train_pred_var": "0.759", "train_masked_pct": "0.5", "train_wps": "8646.1", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3305", "train_lr": "0.000309844", "train_gnorm": "1.907", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4267"}
[2024-03-26 17:40:49,020][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:49,084][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 415
[2024-03-26 17:40:49,086][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:49,089][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:49,094][fairseq.trainer][INFO] - begin training epoch 415
[2024-03-26 17:40:49,095][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:40:56,442][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:40:56,443][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:56,505][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 84
[2024-03-26 17:40:56,509][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:56,928][valid][INFO] - {"epoch": 415, "valid_loss": "0.419", "valid_ntokens": "11719", "valid_nsentences": "25", "valid_sample_size": "11719", "valid_ema_decay": "999.044", "valid_target_var": "0.769", "valid_pred_var": "0.763", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11719", "valid_bsz": "25", "valid_num_updates": "3313", "valid_best_loss": "0.222"}
[2024-03-26 17:40:56,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 415 @ 3313 updates
[2024-03-26 17:40:56,931][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:59,423][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:40:59,488][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 415 @ 3313 updates, score 0.419) (writing took 2.5583756822161376 seconds)
[2024-03-26 17:40:59,488][fairseq_cli.train][INFO] - end of epoch 415 (average epoch stats below)
[2024-03-26 17:40:59,489][train][INFO] - {"epoch": 415, "train_loss": "0.654", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.044", "train_target_var": "0.772", "train_pred_var": "0.756", "train_masked_pct": "0.501", "train_wps": "8228.7", "train_ups": "0.76", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3313", "train_lr": "0.000310594", "train_gnorm": "1.671", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4277"}
[2024-03-26 17:40:59,491][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:40:59,554][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 416
[2024-03-26 17:40:59,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:40:59,559][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:40:59,564][fairseq.trainer][INFO] - begin training epoch 416
[2024-03-26 17:40:59,565][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:06,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 416 @ 3321 updates
[2024-03-26 17:41:06,980][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:09,488][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:09,554][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 416 @ 3321 updates, score None) (writing took 2.5751509466208518 seconds)
[2024-03-26 17:41:09,555][fairseq_cli.train][INFO] - end of epoch 416 (average epoch stats below)
[2024-03-26 17:41:09,555][train][INFO] - {"epoch": 416, "train_loss": "0.574", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.044", "train_target_var": "0.769", "train_pred_var": "0.753", "train_masked_pct": "0.498", "train_wps": "8559.5", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3321", "train_lr": "0.000311344", "train_gnorm": "1.598", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4287"}
[2024-03-26 17:41:09,558][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:09,620][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 417
[2024-03-26 17:41:09,622][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:41:09,625][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:09,630][fairseq.trainer][INFO] - begin training epoch 417
[2024-03-26 17:41:09,630][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:16,959][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 417 @ 3329 updates
[2024-03-26 17:41:16,961][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:19,461][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:19,528][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 417 @ 3329 updates, score None) (writing took 2.5688710790127516 seconds)
[2024-03-26 17:41:19,529][fairseq_cli.train][INFO] - end of epoch 417 (average epoch stats below)
[2024-03-26 17:41:19,530][train][INFO] - {"epoch": 417, "train_loss": "0.651", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.044", "train_target_var": "0.771", "train_pred_var": "0.754", "train_masked_pct": "0.5", "train_wps": "8638.7", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3329", "train_lr": "0.000312094", "train_gnorm": "2.226", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4297"}
[2024-03-26 17:41:19,533][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:19,595][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 418
[2024-03-26 17:41:19,597][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:41:19,600][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:19,605][fairseq.trainer][INFO] - begin training epoch 418
[2024-03-26 17:41:19,606][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:26,975][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 418 @ 3337 updates
[2024-03-26 17:41:26,977][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:29,463][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:29,504][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 418 @ 3337 updates, score None) (writing took 2.528528500813991 seconds)
[2024-03-26 17:41:29,505][fairseq_cli.train][INFO] - end of epoch 418 (average epoch stats below)
[2024-03-26 17:41:29,505][train][INFO] - {"epoch": 418, "train_loss": "0.617", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.044", "train_target_var": "0.772", "train_pred_var": "0.758", "train_masked_pct": "0.499", "train_wps": "8637.8", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3337", "train_lr": "0.000312844", "train_gnorm": "2.172", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4307"}
[2024-03-26 17:41:29,507][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:29,592][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 419
[2024-03-26 17:41:29,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:41:29,597][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:29,602][fairseq.trainer][INFO] - begin training epoch 419
[2024-03-26 17:41:29,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:36,802][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 419 @ 3345 updates
[2024-03-26 17:41:36,804][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:39,290][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:39,353][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 419 @ 3345 updates, score None) (writing took 2.5505329580046237 seconds)
[2024-03-26 17:41:39,353][fairseq_cli.train][INFO] - end of epoch 419 (average epoch stats below)
[2024-03-26 17:41:39,354][train][INFO] - {"epoch": 419, "train_loss": "0.755", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.044", "train_target_var": "0.771", "train_pred_var": "0.755", "train_masked_pct": "0.5", "train_wps": "8749", "train_ups": "0.81", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "3345", "train_lr": "0.000313594", "train_gnorm": "2.681", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4317"}
[2024-03-26 17:41:39,356][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:39,417][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 420
[2024-03-26 17:41:39,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:41:39,421][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:39,426][fairseq.trainer][INFO] - begin training epoch 420
[2024-03-26 17:41:39,427][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:46,857][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:41:46,858][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:46,921][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 85
[2024-03-26 17:41:46,925][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:47,336][valid][INFO] - {"epoch": 420, "valid_loss": "0.665", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.044", "valid_target_var": "0.775", "valid_pred_var": "0.761", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "3353", "valid_best_loss": "0.222"}
[2024-03-26 17:41:47,338][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 420 @ 3353 updates
[2024-03-26 17:41:47,340][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:49,799][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:49,862][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 420 @ 3353 updates, score 0.665) (writing took 2.5235890857875347 seconds)
[2024-03-26 17:41:49,862][fairseq_cli.train][INFO] - end of epoch 420 (average epoch stats below)
[2024-03-26 17:41:49,863][train][INFO] - {"epoch": 420, "train_loss": "0.725", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.044", "train_target_var": "0.77", "train_pred_var": "0.754", "train_masked_pct": "0.498", "train_wps": "8198.2", "train_ups": "0.76", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3353", "train_lr": "0.000314344", "train_gnorm": "2.734", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4328"}
[2024-03-26 17:41:49,865][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:41:49,928][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 421
[2024-03-26 17:41:49,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:41:49,933][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:41:49,938][fairseq.trainer][INFO] - begin training epoch 421
[2024-03-26 17:41:49,938][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:41:57,476][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 421 @ 3361 updates
[2024-03-26 17:41:57,478][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:41:59,988][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:00,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 421 @ 3361 updates, score None) (writing took 2.5821494390256703 seconds)
[2024-03-26 17:42:00,060][fairseq_cli.train][INFO] - end of epoch 421 (average epoch stats below)
[2024-03-26 17:42:00,060][train][INFO] - {"epoch": 421, "train_loss": "0.778", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.044", "train_target_var": "0.77", "train_pred_var": "0.75", "train_masked_pct": "0.501", "train_wps": "8449.3", "train_ups": "0.78", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3361", "train_lr": "0.000315094", "train_gnorm": "3.982", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4338"}
[2024-03-26 17:42:00,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:00,127][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 422
[2024-03-26 17:42:00,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:00,133][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:00,138][fairseq.trainer][INFO] - begin training epoch 422
[2024-03-26 17:42:00,138][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:07,532][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 422 @ 3369 updates
[2024-03-26 17:42:07,533][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:10,043][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:10,101][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 422 @ 3369 updates, score None) (writing took 2.5694039459340274 seconds)
[2024-03-26 17:42:10,102][fairseq_cli.train][INFO] - end of epoch 422 (average epoch stats below)
[2024-03-26 17:42:10,103][train][INFO] - {"epoch": 422, "train_loss": "0.897", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.044", "train_target_var": "0.768", "train_pred_var": "0.748", "train_masked_pct": "0.498", "train_wps": "8579.1", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3369", "train_lr": "0.000315844", "train_gnorm": "3.192", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4348"}
[2024-03-26 17:42:10,105][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:10,176][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 423
[2024-03-26 17:42:10,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:10,181][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:10,186][fairseq.trainer][INFO] - begin training epoch 423
[2024-03-26 17:42:10,186][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:17,532][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 423 @ 3377 updates
[2024-03-26 17:42:17,534][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:20,046][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:20,110][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 423 @ 3377 updates, score None) (writing took 2.5782155781053007 seconds)
[2024-03-26 17:42:20,111][fairseq_cli.train][INFO] - end of epoch 423 (average epoch stats below)
[2024-03-26 17:42:20,112][train][INFO] - {"epoch": 423, "train_loss": "0.727", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.045", "train_target_var": "0.773", "train_pred_var": "0.756", "train_masked_pct": "0.499", "train_wps": "8608.6", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3377", "train_lr": "0.000316594", "train_gnorm": "2.487", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4358"}
[2024-03-26 17:42:20,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:20,177][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 424
[2024-03-26 17:42:20,179][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:20,182][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:20,186][fairseq.trainer][INFO] - begin training epoch 424
[2024-03-26 17:42:20,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:27,449][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 424 @ 3385 updates
[2024-03-26 17:42:27,450][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:29,938][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:30,000][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 424 @ 3385 updates, score None) (writing took 2.5513441027142107 seconds)
[2024-03-26 17:42:30,001][fairseq_cli.train][INFO] - end of epoch 424 (average epoch stats below)
[2024-03-26 17:42:30,002][train][INFO] - {"epoch": 424, "train_loss": "0.66", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.045", "train_target_var": "0.774", "train_pred_var": "0.755", "train_masked_pct": "0.5", "train_wps": "8712.1", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "3385", "train_lr": "0.000317344", "train_gnorm": "2.403", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4368"}
[2024-03-26 17:42:30,004][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:30,067][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 425
[2024-03-26 17:42:30,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:30,071][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:30,076][fairseq.trainer][INFO] - begin training epoch 425
[2024-03-26 17:42:30,077][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:37,382][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:42:37,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:37,448][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 86
[2024-03-26 17:42:37,451][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:37,862][valid][INFO] - {"epoch": 425, "valid_loss": "0.657", "valid_ntokens": "11728", "valid_nsentences": "25", "valid_sample_size": "11728", "valid_ema_decay": "999.045", "valid_target_var": "0.776", "valid_pred_var": "0.765", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11728", "valid_bsz": "25", "valid_num_updates": "3393", "valid_best_loss": "0.222"}
[2024-03-26 17:42:37,864][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 425 @ 3393 updates
[2024-03-26 17:42:37,865][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:40,343][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:40,406][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 425 @ 3393 updates, score 0.657) (writing took 2.5423723799176514 seconds)
[2024-03-26 17:42:40,407][fairseq_cli.train][INFO] - end of epoch 425 (average epoch stats below)
[2024-03-26 17:42:40,407][train][INFO] - {"epoch": 425, "train_loss": "0.814", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.045", "train_target_var": "0.771", "train_pred_var": "0.753", "train_masked_pct": "0.499", "train_wps": "8280.5", "train_ups": "0.77", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3393", "train_lr": "0.000318094", "train_gnorm": "3.85", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4378"}
[2024-03-26 17:42:40,409][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:40,471][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 426
[2024-03-26 17:42:40,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:40,476][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:40,481][fairseq.trainer][INFO] - begin training epoch 426
[2024-03-26 17:42:40,481][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:46,820][train_inner][INFO] - {"epoch": 426, "update": 425.875, "loss": "0.672", "ntokens": "10769.5", "nsentences": "22.875", "sample_size": "10769.5", "ema_decay": "999.044", "target_var": "0.772", "pred_var": "0.756", "masked_pct": "0.5", "wps": "8548.1", "ups": "0.79", "wpb": "10769.5", "bsz": "22.9", "num_updates": "3400", "lr": "0.00031875", "gnorm": "2.481", "loss_scale": "1", "train_wall": "177", "gb_free": "5.1", "wall": "4385"}
[2024-03-26 17:42:47,788][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 426 @ 3401 updates
[2024-03-26 17:42:47,790][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:50,293][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:42:50,335][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 426 @ 3401 updates, score None) (writing took 2.546535105910152 seconds)
[2024-03-26 17:42:50,335][fairseq_cli.train][INFO] - end of epoch 426 (average epoch stats below)
[2024-03-26 17:42:50,336][train][INFO] - {"epoch": 426, "train_loss": "0.723", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.045", "train_target_var": "0.771", "train_pred_var": "0.751", "train_masked_pct": "0.5", "train_wps": "8678.2", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3401", "train_lr": "0.000318844", "train_gnorm": "2.846", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4388"}
[2024-03-26 17:42:50,338][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:42:50,424][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 427
[2024-03-26 17:42:50,426][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:42:50,429][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:42:50,435][fairseq.trainer][INFO] - begin training epoch 427
[2024-03-26 17:42:50,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:42:57,871][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 427 @ 3409 updates
[2024-03-26 17:42:57,873][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:00,374][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:00,438][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 427 @ 3409 updates, score None) (writing took 2.5668078758753836 seconds)
[2024-03-26 17:43:00,439][fairseq_cli.train][INFO] - end of epoch 427 (average epoch stats below)
[2024-03-26 17:43:00,439][train][INFO] - {"epoch": 427, "train_loss": "0.766", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.045", "train_target_var": "0.765", "train_pred_var": "0.749", "train_masked_pct": "0.5", "train_wps": "8527.7", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3409", "train_lr": "0.000319594", "train_gnorm": "2.8", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4398"}
[2024-03-26 17:43:00,441][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:00,506][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 428
[2024-03-26 17:43:00,508][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:00,511][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:00,516][fairseq.trainer][INFO] - begin training epoch 428
[2024-03-26 17:43:00,516][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:07,980][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 428 @ 3417 updates
[2024-03-26 17:43:07,982][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:10,476][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:10,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 428 @ 3417 updates, score None) (writing took 2.563150639180094 seconds)
[2024-03-26 17:43:10,544][fairseq_cli.train][INFO] - end of epoch 428 (average epoch stats below)
[2024-03-26 17:43:10,545][train][INFO] - {"epoch": 428, "train_loss": "0.743", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.045", "train_target_var": "0.77", "train_pred_var": "0.752", "train_masked_pct": "0.499", "train_wps": "8525.8", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3417", "train_lr": "0.000320344", "train_gnorm": "2.75", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4408"}
[2024-03-26 17:43:10,547][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:10,609][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 429
[2024-03-26 17:43:10,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:10,614][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:10,619][fairseq.trainer][INFO] - begin training epoch 429
[2024-03-26 17:43:10,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:18,035][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 429 @ 3425 updates
[2024-03-26 17:43:18,036][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:20,519][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:20,586][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 429 @ 3425 updates, score None) (writing took 2.5513765197247267 seconds)
[2024-03-26 17:43:20,587][fairseq_cli.train][INFO] - end of epoch 429 (average epoch stats below)
[2024-03-26 17:43:20,588][train][INFO] - {"epoch": 429, "train_loss": "0.725", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.045", "train_target_var": "0.773", "train_pred_var": "0.754", "train_masked_pct": "0.5", "train_wps": "8579.7", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3425", "train_lr": "0.000321094", "train_gnorm": "2.178", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4418"}
[2024-03-26 17:43:20,590][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:20,653][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 430
[2024-03-26 17:43:20,654][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:20,657][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:20,662][fairseq.trainer][INFO] - begin training epoch 430
[2024-03-26 17:43:20,662][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:28,070][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:43:28,071][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:28,146][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 87
[2024-03-26 17:43:28,149][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:28,562][valid][INFO] - {"epoch": 430, "valid_loss": "0.512", "valid_ntokens": "11695", "valid_nsentences": "25", "valid_sample_size": "11695", "valid_ema_decay": "999.045", "valid_target_var": "0.779", "valid_pred_var": "0.76", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11695", "valid_bsz": "25", "valid_num_updates": "3433", "valid_best_loss": "0.222"}
[2024-03-26 17:43:28,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 430 @ 3433 updates
[2024-03-26 17:43:28,565][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:31,064][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:31,122][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 430 @ 3433 updates, score 0.512) (writing took 2.5587011808529496 seconds)
[2024-03-26 17:43:31,123][fairseq_cli.train][INFO] - end of epoch 430 (average epoch stats below)
[2024-03-26 17:43:31,124][train][INFO] - {"epoch": 430, "train_loss": "0.731", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.045", "train_target_var": "0.768", "train_pred_var": "0.75", "train_masked_pct": "0.499", "train_wps": "8177.5", "train_ups": "0.76", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3433", "train_lr": "0.000321844", "train_gnorm": "2.284", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4429"}
[2024-03-26 17:43:31,126][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:31,186][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 431
[2024-03-26 17:43:31,187][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:31,190][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:31,195][fairseq.trainer][INFO] - begin training epoch 431
[2024-03-26 17:43:31,196][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:38,652][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 431 @ 3441 updates
[2024-03-26 17:43:38,653][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:41,154][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:41,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 431 @ 3441 updates, score None) (writing took 2.5701436190865934 seconds)
[2024-03-26 17:43:41,222][fairseq_cli.train][INFO] - end of epoch 431 (average epoch stats below)
[2024-03-26 17:43:41,223][train][INFO] - {"epoch": 431, "train_loss": "0.721", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.045", "train_target_var": "0.772", "train_pred_var": "0.751", "train_masked_pct": "0.499", "train_wps": "8531.2", "train_ups": "0.79", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3441", "train_lr": "0.000322594", "train_gnorm": "2.514", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "4439"}
[2024-03-26 17:43:41,225][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:41,289][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 432
[2024-03-26 17:43:41,291][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:41,294][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:41,299][fairseq.trainer][INFO] - begin training epoch 432
[2024-03-26 17:43:41,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:48,446][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 432 @ 3449 updates
[2024-03-26 17:43:48,447][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:50,958][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:43:51,025][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 432 @ 3449 updates, score None) (writing took 2.579004932194948 seconds)
[2024-03-26 17:43:51,025][fairseq_cli.train][INFO] - end of epoch 432 (average epoch stats below)
[2024-03-26 17:43:51,026][train][INFO] - {"epoch": 432, "train_loss": "0.718", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.045", "train_target_var": "0.771", "train_pred_var": "0.753", "train_masked_pct": "0.501", "train_wps": "8789", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3449", "train_lr": "0.000323344", "train_gnorm": "2.262", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4449"}
[2024-03-26 17:43:51,028][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:43:51,091][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 433
[2024-03-26 17:43:51,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:43:51,095][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:43:51,100][fairseq.trainer][INFO] - begin training epoch 433
[2024-03-26 17:43:51,101][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:43:58,400][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 433 @ 3457 updates
[2024-03-26 17:43:58,402][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:00,919][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:00,964][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 433 @ 3457 updates, score None) (writing took 2.5636567156761885 seconds)
[2024-03-26 17:44:00,965][fairseq_cli.train][INFO] - end of epoch 433 (average epoch stats below)
[2024-03-26 17:44:00,966][train][INFO] - {"epoch": 433, "train_loss": "0.76", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.046", "train_target_var": "0.771", "train_pred_var": "0.75", "train_masked_pct": "0.5", "train_wps": "8668.6", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3457", "train_lr": "0.000324094", "train_gnorm": "2.178", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4459"}
[2024-03-26 17:44:00,968][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:01,053][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 434
[2024-03-26 17:44:01,055][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:01,058][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:01,063][fairseq.trainer][INFO] - begin training epoch 434
[2024-03-26 17:44:01,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:08,451][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 434 @ 3465 updates
[2024-03-26 17:44:08,453][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:10,937][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:11,002][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 434 @ 3465 updates, score None) (writing took 2.5507214977405965 seconds)
[2024-03-26 17:44:11,003][fairseq_cli.train][INFO] - end of epoch 434 (average epoch stats below)
[2024-03-26 17:44:11,003][train][INFO] - {"epoch": 434, "train_loss": "0.722", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.046", "train_target_var": "0.772", "train_pred_var": "0.753", "train_masked_pct": "0.499", "train_wps": "8583.3", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3465", "train_lr": "0.000324844", "train_gnorm": "2.821", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4469"}
[2024-03-26 17:44:11,005][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:11,066][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 435
[2024-03-26 17:44:11,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:11,071][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:11,076][fairseq.trainer][INFO] - begin training epoch 435
[2024-03-26 17:44:11,077][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:18,301][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:44:18,302][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:18,367][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 88
[2024-03-26 17:44:18,370][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:18,785][valid][INFO] - {"epoch": 435, "valid_loss": "0.662", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.046", "valid_target_var": "0.775", "valid_pred_var": "0.764", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "3473", "valid_best_loss": "0.222"}
[2024-03-26 17:44:18,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 435 @ 3473 updates
[2024-03-26 17:44:18,788][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:21,301][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:21,366][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 435 @ 3473 updates, score 0.662) (writing took 2.5794325568713248 seconds)
[2024-03-26 17:44:21,366][fairseq_cli.train][INFO] - end of epoch 435 (average epoch stats below)
[2024-03-26 17:44:21,367][train][INFO] - {"epoch": 435, "train_loss": "0.824", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.046", "train_target_var": "0.769", "train_pred_var": "0.75", "train_masked_pct": "0.5", "train_wps": "8312.9", "train_ups": "0.77", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3473", "train_lr": "0.000325594", "train_gnorm": "3.162", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4479"}
[2024-03-26 17:44:21,369][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:21,430][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 436
[2024-03-26 17:44:21,432][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:21,435][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:21,440][fairseq.trainer][INFO] - begin training epoch 436
[2024-03-26 17:44:21,440][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:28,726][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 436 @ 3481 updates
[2024-03-26 17:44:28,728][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:31,210][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:31,264][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 436 @ 3481 updates, score None) (writing took 2.5376070109196007 seconds)
[2024-03-26 17:44:31,264][fairseq_cli.train][INFO] - end of epoch 436 (average epoch stats below)
[2024-03-26 17:44:31,265][train][INFO] - {"epoch": 436, "train_loss": "0.77", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.046", "train_target_var": "0.771", "train_pred_var": "0.754", "train_masked_pct": "0.5", "train_wps": "8704.2", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3481", "train_lr": "0.000326344", "train_gnorm": "3.097", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4489"}
[2024-03-26 17:44:31,268][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:31,329][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 437
[2024-03-26 17:44:31,331][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:31,334][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:31,339][fairseq.trainer][INFO] - begin training epoch 437
[2024-03-26 17:44:31,340][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:38,603][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 437 @ 3489 updates
[2024-03-26 17:44:38,604][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:41,085][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:41,142][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 437 @ 3489 updates, score None) (writing took 2.539165571797639 seconds)
[2024-03-26 17:44:41,143][fairseq_cli.train][INFO] - end of epoch 437 (average epoch stats below)
[2024-03-26 17:44:41,143][train][INFO] - {"epoch": 437, "train_loss": "0.785", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.046", "train_target_var": "0.769", "train_pred_var": "0.748", "train_masked_pct": "0.5", "train_wps": "8722.2", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3489", "train_lr": "0.000327094", "train_gnorm": "3.37", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4499"}
[2024-03-26 17:44:41,146][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:41,217][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 438
[2024-03-26 17:44:41,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:41,222][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:41,227][fairseq.trainer][INFO] - begin training epoch 438
[2024-03-26 17:44:41,227][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:48,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 438 @ 3497 updates
[2024-03-26 17:44:48,561][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:51,056][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:44:51,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 438 @ 3497 updates, score None) (writing took 2.5394762381911278 seconds)
[2024-03-26 17:44:51,099][fairseq_cli.train][INFO] - end of epoch 438 (average epoch stats below)
[2024-03-26 17:44:51,100][train][INFO] - {"epoch": 438, "train_loss": "0.831", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.046", "train_target_var": "0.77", "train_pred_var": "0.749", "train_masked_pct": "0.5", "train_wps": "8653.5", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3497", "train_lr": "0.000327844", "train_gnorm": "2.48", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4509"}
[2024-03-26 17:44:51,102][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:44:51,189][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 439
[2024-03-26 17:44:51,190][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:44:51,193][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:44:51,198][fairseq.trainer][INFO] - begin training epoch 439
[2024-03-26 17:44:51,199][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:44:58,501][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 439 @ 3505 updates
[2024-03-26 17:44:58,502][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:00,993][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:01,041][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 439 @ 3505 updates, score None) (writing took 2.540600927080959 seconds)
[2024-03-26 17:45:01,042][fairseq_cli.train][INFO] - end of epoch 439 (average epoch stats below)
[2024-03-26 17:45:01,042][train][INFO] - {"epoch": 439, "train_loss": "0.807", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.046", "train_target_var": "0.768", "train_pred_var": "0.746", "train_masked_pct": "0.501", "train_wps": "8665", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "3505", "train_lr": "0.000328594", "train_gnorm": "2.062", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4519"}
[2024-03-26 17:45:01,044][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:01,127][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 440
[2024-03-26 17:45:01,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:01,132][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:01,137][fairseq.trainer][INFO] - begin training epoch 440
[2024-03-26 17:45:01,138][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:08,677][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:45:08,678][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:08,743][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 89
[2024-03-26 17:45:08,746][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:09,152][valid][INFO] - {"epoch": 440, "valid_loss": "0.701", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.046", "valid_target_var": "0.77", "valid_pred_var": "0.753", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "3513", "valid_best_loss": "0.222"}
[2024-03-26 17:45:09,153][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 440 @ 3513 updates
[2024-03-26 17:45:09,155][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:11,662][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:11,697][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 440 @ 3513 updates, score 0.701) (writing took 2.544075976125896 seconds)
[2024-03-26 17:45:11,698][fairseq_cli.train][INFO] - end of epoch 440 (average epoch stats below)
[2024-03-26 17:45:11,699][train][INFO] - {"epoch": 440, "train_loss": "0.819", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.046", "train_target_var": "0.767", "train_pred_var": "0.746", "train_masked_pct": "0.5", "train_wps": "8084.7", "train_ups": "0.75", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "3513", "train_lr": "0.000329344", "train_gnorm": "2.545", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4530"}
[2024-03-26 17:45:11,701][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:11,792][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 441
[2024-03-26 17:45:11,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:11,797][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:11,802][fairseq.trainer][INFO] - begin training epoch 441
[2024-03-26 17:45:11,802][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:19,036][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 441 @ 3521 updates
[2024-03-26 17:45:19,038][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:21,560][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:21,627][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 441 @ 3521 updates, score None) (writing took 2.5907364431768656 seconds)
[2024-03-26 17:45:21,628][fairseq_cli.train][INFO] - end of epoch 441 (average epoch stats below)
[2024-03-26 17:45:21,629][train][INFO] - {"epoch": 441, "train_loss": "0.885", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.046", "train_target_var": "0.766", "train_pred_var": "0.745", "train_masked_pct": "0.499", "train_wps": "8676.7", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3521", "train_lr": "0.000330094", "train_gnorm": "2.337", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4539"}
[2024-03-26 17:45:21,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:21,695][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 442
[2024-03-26 17:45:21,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:21,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:21,705][fairseq.trainer][INFO] - begin training epoch 442
[2024-03-26 17:45:21,706][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:29,168][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 442 @ 3529 updates
[2024-03-26 17:45:29,169][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:31,661][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:31,728][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 442 @ 3529 updates, score None) (writing took 2.560654981993139 seconds)
[2024-03-26 17:45:31,729][fairseq_cli.train][INFO] - end of epoch 442 (average epoch stats below)
[2024-03-26 17:45:31,729][train][INFO] - {"epoch": 442, "train_loss": "0.879", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.047", "train_target_var": "0.767", "train_pred_var": "0.747", "train_masked_pct": "0.499", "train_wps": "8529.5", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3529", "train_lr": "0.000330844", "train_gnorm": "1.918", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4550"}
[2024-03-26 17:45:31,732][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:31,794][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 443
[2024-03-26 17:45:31,796][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:31,799][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:31,804][fairseq.trainer][INFO] - begin training epoch 443
[2024-03-26 17:45:31,804][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:39,240][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 443 @ 3537 updates
[2024-03-26 17:45:39,241][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:41,736][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:41,800][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 443 @ 3537 updates, score None) (writing took 2.560269224923104 seconds)
[2024-03-26 17:45:41,801][fairseq_cli.train][INFO] - end of epoch 443 (average epoch stats below)
[2024-03-26 17:45:41,801][train][INFO] - {"epoch": 443, "train_loss": "0.844", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.047", "train_target_var": "0.765", "train_pred_var": "0.741", "train_masked_pct": "0.501", "train_wps": "8554.8", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3537", "train_lr": "0.000331594", "train_gnorm": "2.218", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4560"}
[2024-03-26 17:45:41,803][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:41,865][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 444
[2024-03-26 17:45:41,866][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:41,870][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:41,875][fairseq.trainer][INFO] - begin training epoch 444
[2024-03-26 17:45:41,875][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:49,195][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 444 @ 3545 updates
[2024-03-26 17:45:49,197][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:51,686][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:45:51,745][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 444 @ 3545 updates, score None) (writing took 2.549982548225671 seconds)
[2024-03-26 17:45:51,746][fairseq_cli.train][INFO] - end of epoch 444 (average epoch stats below)
[2024-03-26 17:45:51,746][train][INFO] - {"epoch": 444, "train_loss": "0.838", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.047", "train_target_var": "0.77", "train_pred_var": "0.748", "train_masked_pct": "0.499", "train_wps": "8664.3", "train_ups": "0.8", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "3545", "train_lr": "0.000332344", "train_gnorm": "2.984", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4570"}
[2024-03-26 17:45:51,748][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:51,815][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 445
[2024-03-26 17:45:51,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:45:51,820][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:51,824][fairseq.trainer][INFO] - begin training epoch 445
[2024-03-26 17:45:51,825][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:45:59,185][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:45:59,186][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:45:59,250][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 90
[2024-03-26 17:45:59,253][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:45:59,673][valid][INFO] - {"epoch": 445, "valid_loss": "0.717", "valid_ntokens": "11697", "valid_nsentences": "25", "valid_sample_size": "11697", "valid_ema_decay": "999.047", "valid_target_var": "0.768", "valid_pred_var": "0.758", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11697", "valid_bsz": "25", "valid_num_updates": "3553", "valid_best_loss": "0.222"}
[2024-03-26 17:45:59,675][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 445 @ 3553 updates
[2024-03-26 17:45:59,677][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:02,252][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:02,313][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 445 @ 3553 updates, score 0.717) (writing took 2.6375242550857365 seconds)
[2024-03-26 17:46:02,313][fairseq_cli.train][INFO] - end of epoch 445 (average epoch stats below)
[2024-03-26 17:46:02,314][train][INFO] - {"epoch": 445, "train_loss": "0.755", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.047", "train_target_var": "0.767", "train_pred_var": "0.747", "train_masked_pct": "0.498", "train_wps": "8152.4", "train_ups": "0.76", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "3553", "train_lr": "0.000333094", "train_gnorm": "2.605", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4580"}
[2024-03-26 17:46:02,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:02,378][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 446
[2024-03-26 17:46:02,380][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:02,383][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:02,388][fairseq.trainer][INFO] - begin training epoch 446
[2024-03-26 17:46:02,388][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:09,797][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 446 @ 3561 updates
[2024-03-26 17:46:09,799][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:12,301][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:12,369][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 446 @ 3561 updates, score None) (writing took 2.5714290970936418 seconds)
[2024-03-26 17:46:12,369][fairseq_cli.train][INFO] - end of epoch 446 (average epoch stats below)
[2024-03-26 17:46:12,370][train][INFO] - {"epoch": 446, "train_loss": "0.873", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.047", "train_target_var": "0.767", "train_pred_var": "0.747", "train_masked_pct": "0.498", "train_wps": "8568.1", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3561", "train_lr": "0.000333844", "train_gnorm": "2.655", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4590"}
[2024-03-26 17:46:12,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:12,436][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 447
[2024-03-26 17:46:12,438][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:12,441][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:12,446][fairseq.trainer][INFO] - begin training epoch 447
[2024-03-26 17:46:12,446][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:19,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 447 @ 3569 updates
[2024-03-26 17:46:19,931][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:22,437][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:22,502][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 447 @ 3569 updates, score None) (writing took 2.572340033017099 seconds)
[2024-03-26 17:46:22,503][fairseq_cli.train][INFO] - end of epoch 447 (average epoch stats below)
[2024-03-26 17:46:22,503][train][INFO] - {"epoch": 447, "train_loss": "0.917", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.047", "train_target_var": "0.769", "train_pred_var": "0.747", "train_masked_pct": "0.5", "train_wps": "8502.6", "train_ups": "0.79", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3569", "train_lr": "0.000334594", "train_gnorm": "2.436", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4600"}
[2024-03-26 17:46:22,505][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:22,567][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 448
[2024-03-26 17:46:22,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:22,571][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:22,576][fairseq.trainer][INFO] - begin training epoch 448
[2024-03-26 17:46:22,577][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:29,835][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 448 @ 3577 updates
[2024-03-26 17:46:29,836][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:32,343][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:32,409][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 448 @ 3577 updates, score None) (writing took 2.573932211846113 seconds)
[2024-03-26 17:46:32,409][fairseq_cli.train][INFO] - end of epoch 448 (average epoch stats below)
[2024-03-26 17:46:32,410][train][INFO] - {"epoch": 448, "train_loss": "0.852", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.047", "train_target_var": "0.766", "train_pred_var": "0.745", "train_masked_pct": "0.5", "train_wps": "8697.3", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3577", "train_lr": "0.000335344", "train_gnorm": "2.566", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4610"}
[2024-03-26 17:46:32,412][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:32,496][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 449
[2024-03-26 17:46:32,498][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:32,501][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:32,506][fairseq.trainer][INFO] - begin training epoch 449
[2024-03-26 17:46:32,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:39,937][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 449 @ 3585 updates
[2024-03-26 17:46:39,938][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:42,414][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:42,479][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 449 @ 3585 updates, score None) (writing took 2.5419543366879225 seconds)
[2024-03-26 17:46:42,479][fairseq_cli.train][INFO] - end of epoch 449 (average epoch stats below)
[2024-03-26 17:46:42,480][train][INFO] - {"epoch": 449, "train_loss": "0.872", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.047", "train_target_var": "0.767", "train_pred_var": "0.745", "train_masked_pct": "0.499", "train_wps": "8555.6", "train_ups": "0.79", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3585", "train_lr": "0.000336094", "train_gnorm": "3.144", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4620"}
[2024-03-26 17:46:42,482][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:42,544][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 450
[2024-03-26 17:46:42,546][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:42,549][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:42,554][fairseq.trainer][INFO] - begin training epoch 450
[2024-03-26 17:46:42,554][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:49,946][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:46:49,947][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:50,023][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 91
[2024-03-26 17:46:50,027][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:50,430][valid][INFO] - {"epoch": 450, "valid_loss": "0.576", "valid_ntokens": "11720", "valid_nsentences": "25", "valid_sample_size": "11720", "valid_ema_decay": "999.047", "valid_target_var": "0.767", "valid_pred_var": "0.763", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11720", "valid_bsz": "25", "valid_num_updates": "3593", "valid_best_loss": "0.222"}
[2024-03-26 17:46:50,432][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 450 @ 3593 updates
[2024-03-26 17:46:50,433][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:52,930][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:46:52,995][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 450 @ 3593 updates, score 0.576) (writing took 2.563311825040728 seconds)
[2024-03-26 17:46:52,996][fairseq_cli.train][INFO] - end of epoch 450 (average epoch stats below)
[2024-03-26 17:46:52,997][train][INFO] - {"epoch": 450, "train_loss": "0.836", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.047", "train_target_var": "0.768", "train_pred_var": "0.748", "train_masked_pct": "0.499", "train_wps": "8193.3", "train_ups": "0.76", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "3593", "train_lr": "0.000336844", "train_gnorm": "2.626", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4631"}
[2024-03-26 17:46:52,999][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:46:53,062][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 451
[2024-03-26 17:46:53,064][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:46:53,067][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:46:53,072][fairseq.trainer][INFO] - begin training epoch 451
[2024-03-26 17:46:53,072][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:46:59,514][train_inner][INFO] - {"epoch": 451, "update": 450.875, "loss": "0.8", "ntokens": "10769", "nsentences": "22.875", "sample_size": "10769", "ema_decay": "999.046", "target_var": "0.769", "pred_var": "0.749", "masked_pct": "0.499", "wps": "8523.4", "ups": "0.79", "wpb": "10769", "bsz": "22.9", "num_updates": "3600", "lr": "0.0003375", "gnorm": "2.561", "loss_scale": "1", "train_wall": "178", "gb_free": "5.3", "wall": "4637"}
[2024-03-26 17:47:00,480][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 451 @ 3601 updates
[2024-03-26 17:47:00,482][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:02,991][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:03,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 451 @ 3601 updates, score None) (writing took 2.577174176927656 seconds)
[2024-03-26 17:47:03,058][fairseq_cli.train][INFO] - end of epoch 451 (average epoch stats below)
[2024-03-26 17:47:03,059][train][INFO] - {"epoch": 451, "train_loss": "0.731", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.047", "train_target_var": "0.766", "train_pred_var": "0.747", "train_masked_pct": "0.498", "train_wps": "8561.9", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3601", "train_lr": "0.000337594", "train_gnorm": "1.938", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4641"}
[2024-03-26 17:47:03,061][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:03,124][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 452
[2024-03-26 17:47:03,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:03,129][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:03,133][fairseq.trainer][INFO] - begin training epoch 452
[2024-03-26 17:47:03,134][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:47:10,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 452 @ 3609 updates
[2024-03-26 17:47:10,396][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:12,899][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:12,966][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 452 @ 3609 updates, score None) (writing took 2.5716041708365083 seconds)
[2024-03-26 17:47:12,966][fairseq_cli.train][INFO] - end of epoch 452 (average epoch stats below)
[2024-03-26 17:47:12,967][train][INFO] - {"epoch": 452, "train_loss": "0.782", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.048", "train_target_var": "0.769", "train_pred_var": "0.751", "train_masked_pct": "0.501", "train_wps": "8696.5", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3609", "train_lr": "0.000338344", "train_gnorm": "2.429", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4651"}
[2024-03-26 17:47:12,969][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:13,030][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 453
[2024-03-26 17:47:13,032][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:13,035][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:13,039][fairseq.trainer][INFO] - begin training epoch 453
[2024-03-26 17:47:13,040][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:47:20,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 453 @ 3617 updates
[2024-03-26 17:47:20,361][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:22,852][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:22,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 453 @ 3617 updates, score None) (writing took 2.527548684272915 seconds)
[2024-03-26 17:47:22,888][fairseq_cli.train][INFO] - end of epoch 453 (average epoch stats below)
[2024-03-26 17:47:22,889][train][INFO] - {"epoch": 453, "train_loss": "0.8", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.048", "train_target_var": "0.767", "train_pred_var": "0.748", "train_masked_pct": "0.499", "train_wps": "8683.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3617", "train_lr": "0.000339094", "train_gnorm": "2.191", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4661"}
[2024-03-26 17:47:22,891][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:22,985][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 454
[2024-03-26 17:47:22,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:22,990][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:22,994][fairseq.trainer][INFO] - begin training epoch 454
[2024-03-26 17:47:22,995][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:47:30,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 454 @ 3625 updates
[2024-03-26 17:47:30,272][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:32,762][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:32,830][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 454 @ 3625 updates, score None) (writing took 2.5585283138789237 seconds)
[2024-03-26 17:47:32,830][fairseq_cli.train][INFO] - end of epoch 454 (average epoch stats below)
[2024-03-26 17:47:32,831][train][INFO] - {"epoch": 454, "train_loss": "0.815", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.048", "train_target_var": "0.763", "train_pred_var": "0.742", "train_masked_pct": "0.498", "train_wps": "8665.3", "train_ups": "0.8", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "3625", "train_lr": "0.000339844", "train_gnorm": "2.305", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4671"}
[2024-03-26 17:47:32,833][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:32,898][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 455
[2024-03-26 17:47:32,900][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:32,903][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:32,907][fairseq.trainer][INFO] - begin training epoch 455
[2024-03-26 17:47:32,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:47:40,152][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:47:40,153][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:40,221][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 92
[2024-03-26 17:47:40,225][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:40,639][valid][INFO] - {"epoch": 455, "valid_loss": "0.65", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.048", "valid_target_var": "0.773", "valid_pred_var": "0.757", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "3633", "valid_best_loss": "0.222"}
[2024-03-26 17:47:40,640][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 455 @ 3633 updates
[2024-03-26 17:47:40,641][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:43,144][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:43,215][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 455 @ 3633 updates, score 0.65) (writing took 2.5746193788945675 seconds)
[2024-03-26 17:47:43,215][fairseq_cli.train][INFO] - end of epoch 455 (average epoch stats below)
[2024-03-26 17:47:43,216][train][INFO] - {"epoch": 455, "train_loss": "0.778", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.048", "train_target_var": "0.767", "train_pred_var": "0.749", "train_masked_pct": "0.499", "train_wps": "8295.8", "train_ups": "0.77", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "3633", "train_lr": "0.000340594", "train_gnorm": "2.336", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4681"}
[2024-03-26 17:47:43,218][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:43,282][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 456
[2024-03-26 17:47:43,284][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:43,287][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:43,292][fairseq.trainer][INFO] - begin training epoch 456
[2024-03-26 17:47:43,292][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:47:50,638][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 456 @ 3641 updates
[2024-03-26 17:47:50,639][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:53,133][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:47:53,200][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 456 @ 3641 updates, score None) (writing took 2.562141742091626 seconds)
[2024-03-26 17:47:53,201][fairseq_cli.train][INFO] - end of epoch 456 (average epoch stats below)
[2024-03-26 17:47:53,202][train][INFO] - {"epoch": 456, "train_loss": "0.827", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.048", "train_target_var": "0.765", "train_pred_var": "0.741", "train_masked_pct": "0.501", "train_wps": "8628.2", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3641", "train_lr": "0.000341344", "train_gnorm": "2.32", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4691"}
[2024-03-26 17:47:53,204][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:47:53,266][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 457
[2024-03-26 17:47:53,268][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:47:53,271][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:47:53,277][fairseq.trainer][INFO] - begin training epoch 457
[2024-03-26 17:47:53,277][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:00,507][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 457 @ 3649 updates
[2024-03-26 17:48:00,509][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:03,021][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:03,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 457 @ 3649 updates, score None) (writing took 2.580987930763513 seconds)
[2024-03-26 17:48:03,089][fairseq_cli.train][INFO] - end of epoch 457 (average epoch stats below)
[2024-03-26 17:48:03,090][train][INFO] - {"epoch": 457, "train_loss": "0.868", "train_ntokens": "10767.9", "train_nsentences": "22.875", "train_sample_size": "10767.9", "train_ema_decay": "999.048", "train_target_var": "0.768", "train_pred_var": "0.747", "train_masked_pct": "0.499", "train_wps": "8712.3", "train_ups": "0.81", "train_wpb": "10767.9", "train_bsz": "22.9", "train_num_updates": "3649", "train_lr": "0.000342094", "train_gnorm": "2.48", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4701"}
[2024-03-26 17:48:03,092][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:03,155][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 458
[2024-03-26 17:48:03,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:03,159][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:03,164][fairseq.trainer][INFO] - begin training epoch 458
[2024-03-26 17:48:03,165][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:10,480][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 458 @ 3657 updates
[2024-03-26 17:48:10,481][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:12,966][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:13,015][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 458 @ 3657 updates, score None) (writing took 2.5355103784240782 seconds)
[2024-03-26 17:48:13,016][fairseq_cli.train][INFO] - end of epoch 458 (average epoch stats below)
[2024-03-26 17:48:13,017][train][INFO] - {"epoch": 458, "train_loss": "0.877", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.048", "train_target_var": "0.769", "train_pred_var": "0.746", "train_masked_pct": "0.5", "train_wps": "8678.7", "train_ups": "0.81", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "3657", "train_lr": "0.000342844", "train_gnorm": "3.069", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4711"}
[2024-03-26 17:48:13,019][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:13,097][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 459
[2024-03-26 17:48:13,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:13,102][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:13,107][fairseq.trainer][INFO] - begin training epoch 459
[2024-03-26 17:48:13,107][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:20,237][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 459 @ 3665 updates
[2024-03-26 17:48:20,238][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:22,691][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:22,755][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 459 @ 3665 updates, score None) (writing took 2.5178140476346016 seconds)
[2024-03-26 17:48:22,755][fairseq_cli.train][INFO] - end of epoch 459 (average epoch stats below)
[2024-03-26 17:48:22,756][train][INFO] - {"epoch": 459, "train_loss": "0.937", "train_ntokens": "10770.4", "train_nsentences": "22.875", "train_sample_size": "10770.4", "train_ema_decay": "999.048", "train_target_var": "0.767", "train_pred_var": "0.745", "train_masked_pct": "0.5", "train_wps": "8848.1", "train_ups": "0.82", "train_wpb": "10770.4", "train_bsz": "22.9", "train_num_updates": "3665", "train_lr": "0.000343594", "train_gnorm": "3.215", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4721"}
[2024-03-26 17:48:22,758][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:22,820][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 460
[2024-03-26 17:48:22,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:22,825][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:22,830][fairseq.trainer][INFO] - begin training epoch 460
[2024-03-26 17:48:22,831][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:30,190][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:48:30,191][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:30,268][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 93
[2024-03-26 17:48:30,271][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:30,691][valid][INFO] - {"epoch": 460, "valid_loss": "0.716", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.048", "valid_target_var": "0.773", "valid_pred_var": "0.753", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "3673", "valid_best_loss": "0.222"}
[2024-03-26 17:48:30,692][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 460 @ 3673 updates
[2024-03-26 17:48:30,694][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:33,205][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:33,272][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 460 @ 3673 updates, score 0.716) (writing took 2.580067922361195 seconds)
[2024-03-26 17:48:33,273][fairseq_cli.train][INFO] - end of epoch 460 (average epoch stats below)
[2024-03-26 17:48:33,274][train][INFO] - {"epoch": 460, "train_loss": "0.949", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.048", "train_target_var": "0.764", "train_pred_var": "0.741", "train_masked_pct": "0.5", "train_wps": "8191.8", "train_ups": "0.76", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3673", "train_lr": "0.000344344", "train_gnorm": "2.944", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4731"}
[2024-03-26 17:48:33,276][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:33,337][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 461
[2024-03-26 17:48:33,339][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:33,342][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:33,347][fairseq.trainer][INFO] - begin training epoch 461
[2024-03-26 17:48:33,347][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:40,740][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 461 @ 3681 updates
[2024-03-26 17:48:40,742][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:43,248][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:43,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 461 @ 3681 updates, score None) (writing took 2.5480136019177735 seconds)
[2024-03-26 17:48:43,289][fairseq_cli.train][INFO] - end of epoch 461 (average epoch stats below)
[2024-03-26 17:48:43,290][train][INFO] - {"epoch": 461, "train_loss": "0.87", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.049", "train_target_var": "0.76", "train_pred_var": "0.738", "train_masked_pct": "0.499", "train_wps": "8601.8", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3681", "train_lr": "0.000345094", "train_gnorm": "2.833", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "4741"}
[2024-03-26 17:48:43,292][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:43,385][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 462
[2024-03-26 17:48:43,387][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:43,390][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:43,395][fairseq.trainer][INFO] - begin training epoch 462
[2024-03-26 17:48:43,395][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:48:50,852][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 462 @ 3689 updates
[2024-03-26 17:48:50,854][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:53,339][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:48:53,405][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 462 @ 3689 updates, score None) (writing took 2.5524783679284155 seconds)
[2024-03-26 17:48:53,405][fairseq_cli.train][INFO] - end of epoch 462 (average epoch stats below)
[2024-03-26 17:48:53,406][train][INFO] - {"epoch": 462, "train_loss": "0.914", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.049", "train_target_var": "0.767", "train_pred_var": "0.746", "train_masked_pct": "0.5", "train_wps": "8517.2", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3689", "train_lr": "0.000345844", "train_gnorm": "2.565", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "4751"}
[2024-03-26 17:48:53,408][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:48:53,469][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 463
[2024-03-26 17:48:53,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:48:53,474][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:48:53,479][fairseq.trainer][INFO] - begin training epoch 463
[2024-03-26 17:48:53,479][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:00,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 463 @ 3697 updates
[2024-03-26 17:49:00,787][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:03,254][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:03,320][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 463 @ 3697 updates, score None) (writing took 2.5342987067997456 seconds)
[2024-03-26 17:49:03,321][fairseq_cli.train][INFO] - end of epoch 463 (average epoch stats below)
[2024-03-26 17:49:03,321][train][INFO] - {"epoch": 463, "train_loss": "0.876", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.049", "train_target_var": "0.767", "train_pred_var": "0.745", "train_masked_pct": "0.5", "train_wps": "8690", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3697", "train_lr": "0.000346594", "train_gnorm": "2.288", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4761"}
[2024-03-26 17:49:03,323][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:03,385][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 464
[2024-03-26 17:49:03,387][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:03,390][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:03,395][fairseq.trainer][INFO] - begin training epoch 464
[2024-03-26 17:49:03,396][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:10,830][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 464 @ 3705 updates
[2024-03-26 17:49:10,831][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:13,307][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:13,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 464 @ 3705 updates, score None) (writing took 2.544556104578078 seconds)
[2024-03-26 17:49:13,375][fairseq_cli.train][INFO] - end of epoch 464 (average epoch stats below)
[2024-03-26 17:49:13,376][train][INFO] - {"epoch": 464, "train_loss": "0.835", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.049", "train_target_var": "0.766", "train_pred_var": "0.746", "train_masked_pct": "0.499", "train_wps": "8569.2", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3705", "train_lr": "0.000347344", "train_gnorm": "2.247", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4771"}
[2024-03-26 17:49:13,378][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:13,440][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 465
[2024-03-26 17:49:13,441][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:13,445][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:13,449][fairseq.trainer][INFO] - begin training epoch 465
[2024-03-26 17:49:13,450][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:20,884][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:49:20,885][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:20,949][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 94
[2024-03-26 17:49:20,952][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:21,358][valid][INFO] - {"epoch": 465, "valid_loss": "0.805", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.049", "valid_target_var": "0.768", "valid_pred_var": "0.749", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "3713", "valid_best_loss": "0.222"}
[2024-03-26 17:49:21,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 465 @ 3713 updates
[2024-03-26 17:49:21,360][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:23,871][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:23,935][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 465 @ 3713 updates, score 0.805) (writing took 2.576311584096402 seconds)
[2024-03-26 17:49:23,936][fairseq_cli.train][INFO] - end of epoch 465 (average epoch stats below)
[2024-03-26 17:49:23,937][train][INFO] - {"epoch": 465, "train_loss": "0.842", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.049", "train_target_var": "0.767", "train_pred_var": "0.745", "train_masked_pct": "0.501", "train_wps": "8159.1", "train_ups": "0.76", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3713", "train_lr": "0.000348094", "train_gnorm": "2.503", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4782"}
[2024-03-26 17:49:23,939][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:24,001][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 466
[2024-03-26 17:49:24,003][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:24,006][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:24,011][fairseq.trainer][INFO] - begin training epoch 466
[2024-03-26 17:49:24,011][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:31,357][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 466 @ 3721 updates
[2024-03-26 17:49:31,358][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:33,842][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:33,879][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 466 @ 3721 updates, score None) (writing took 2.5222397902980447 seconds)
[2024-03-26 17:49:33,880][fairseq_cli.train][INFO] - end of epoch 466 (average epoch stats below)
[2024-03-26 17:49:33,880][train][INFO] - {"epoch": 466, "train_loss": "0.962", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.049", "train_target_var": "0.764", "train_pred_var": "0.739", "train_masked_pct": "0.5", "train_wps": "8665.3", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3721", "train_lr": "0.000348844", "train_gnorm": "3.014", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4792"}
[2024-03-26 17:49:33,883][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:33,975][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 467
[2024-03-26 17:49:33,977][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:33,980][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:33,985][fairseq.trainer][INFO] - begin training epoch 467
[2024-03-26 17:49:33,986][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:41,344][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 467 @ 3729 updates
[2024-03-26 17:49:41,346][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:43,837][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:43,881][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 467 @ 3729 updates, score None) (writing took 2.5365320122800767 seconds)
[2024-03-26 17:49:43,882][fairseq_cli.train][INFO] - end of epoch 467 (average epoch stats below)
[2024-03-26 17:49:43,882][train][INFO] - {"epoch": 467, "train_loss": "0.895", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.049", "train_target_var": "0.765", "train_pred_var": "0.743", "train_masked_pct": "0.499", "train_wps": "8614.9", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3729", "train_lr": "0.000349594", "train_gnorm": "2.669", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4802"}
[2024-03-26 17:49:43,884][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:43,970][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 468
[2024-03-26 17:49:43,972][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:43,975][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:43,980][fairseq.trainer][INFO] - begin training epoch 468
[2024-03-26 17:49:43,980][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:49:51,260][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 468 @ 3737 updates
[2024-03-26 17:49:51,263][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:53,748][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:49:53,814][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 468 @ 3737 updates, score None) (writing took 2.5536819137632847 seconds)
[2024-03-26 17:49:53,815][fairseq_cli.train][INFO] - end of epoch 468 (average epoch stats below)
[2024-03-26 17:49:53,815][train][INFO] - {"epoch": 468, "train_loss": "0.866", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.049", "train_target_var": "0.769", "train_pred_var": "0.746", "train_masked_pct": "0.501", "train_wps": "8674.5", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3737", "train_lr": "0.000350344", "train_gnorm": "3.132", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4812"}
[2024-03-26 17:49:53,817][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:49:53,879][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 469
[2024-03-26 17:49:53,881][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:49:53,885][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:49:53,889][fairseq.trainer][INFO] - begin training epoch 469
[2024-03-26 17:49:53,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:01,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 469 @ 3745 updates
[2024-03-26 17:50:01,050][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:03,565][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:03,604][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 469 @ 3745 updates, score None) (writing took 2.5551696391776204 seconds)
[2024-03-26 17:50:03,605][fairseq_cli.train][INFO] - end of epoch 469 (average epoch stats below)
[2024-03-26 17:50:03,605][train][INFO] - {"epoch": 469, "train_loss": "1.064", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.049", "train_target_var": "0.766", "train_pred_var": "0.744", "train_masked_pct": "0.5", "train_wps": "8800.9", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3745", "train_lr": "0.000351094", "train_gnorm": "3.247", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "4821"}
[2024-03-26 17:50:03,607][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:03,697][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 470
[2024-03-26 17:50:03,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:03,701][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:03,705][fairseq.trainer][INFO] - begin training epoch 470
[2024-03-26 17:50:03,706][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:11,006][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:50:11,008][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:11,072][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 95
[2024-03-26 17:50:11,075][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:11,491][valid][INFO] - {"epoch": 470, "valid_loss": "1.014", "valid_ntokens": "11719", "valid_nsentences": "25", "valid_sample_size": "11719", "valid_ema_decay": "999.05", "valid_target_var": "0.772", "valid_pred_var": "0.748", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11719", "valid_bsz": "25", "valid_num_updates": "3753", "valid_best_loss": "0.222"}
[2024-03-26 17:50:11,493][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 470 @ 3753 updates
[2024-03-26 17:50:11,495][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:14,107][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:14,151][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 470 @ 3753 updates, score 1.014) (writing took 2.6575750899501145 seconds)
[2024-03-26 17:50:14,151][fairseq_cli.train][INFO] - end of epoch 470 (average epoch stats below)
[2024-03-26 17:50:14,152][train][INFO] - {"epoch": 470, "train_loss": "0.964", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.049", "train_target_var": "0.766", "train_pred_var": "0.741", "train_masked_pct": "0.499", "train_wps": "8169.1", "train_ups": "0.76", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3753", "train_lr": "0.000351844", "train_gnorm": "3.499", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4832"}
[2024-03-26 17:50:14,154][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:14,238][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 471
[2024-03-26 17:50:14,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:14,243][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:14,248][fairseq.trainer][INFO] - begin training epoch 471
[2024-03-26 17:50:14,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:21,684][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 471 @ 3761 updates
[2024-03-26 17:50:21,686][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:24,168][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:24,203][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 471 @ 3761 updates, score None) (writing took 2.5191526017151773 seconds)
[2024-03-26 17:50:24,204][fairseq_cli.train][INFO] - end of epoch 471 (average epoch stats below)
[2024-03-26 17:50:24,205][train][INFO] - {"epoch": 471, "train_loss": "0.949", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.05", "train_target_var": "0.765", "train_pred_var": "0.74", "train_masked_pct": "0.5", "train_wps": "8570.4", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3761", "train_lr": "0.000352594", "train_gnorm": "2.506", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4842"}
[2024-03-26 17:50:24,207][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:24,307][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 472
[2024-03-26 17:50:24,308][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:24,311][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:24,315][fairseq.trainer][INFO] - begin training epoch 472
[2024-03-26 17:50:24,315][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:31,653][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 472 @ 3769 updates
[2024-03-26 17:50:31,655][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:34,154][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:34,218][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 472 @ 3769 updates, score None) (writing took 2.5646217497996986 seconds)
[2024-03-26 17:50:34,218][fairseq_cli.train][INFO] - end of epoch 472 (average epoch stats below)
[2024-03-26 17:50:34,219][train][INFO] - {"epoch": 472, "train_loss": "0.983", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.05", "train_target_var": "0.764", "train_pred_var": "0.739", "train_masked_pct": "0.5", "train_wps": "8604", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3769", "train_lr": "0.000353344", "train_gnorm": "2.912", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "4852"}
[2024-03-26 17:50:34,221][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:34,290][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 473
[2024-03-26 17:50:34,292][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:34,295][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:34,300][fairseq.trainer][INFO] - begin training epoch 473
[2024-03-26 17:50:34,301][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:41,670][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 473 @ 3777 updates
[2024-03-26 17:50:41,672][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:44,334][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:44,402][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 473 @ 3777 updates, score None) (writing took 2.7321142181754112 seconds)
[2024-03-26 17:50:44,403][fairseq_cli.train][INFO] - end of epoch 473 (average epoch stats below)
[2024-03-26 17:50:44,403][train][INFO] - {"epoch": 473, "train_loss": "0.897", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.05", "train_target_var": "0.764", "train_pred_var": "0.741", "train_masked_pct": "0.5", "train_wps": "8460.3", "train_ups": "0.79", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "3777", "train_lr": "0.000354094", "train_gnorm": "2.392", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "4862"}
[2024-03-26 17:50:44,406][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:44,469][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 474
[2024-03-26 17:50:44,470][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:44,473][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:44,478][fairseq.trainer][INFO] - begin training epoch 474
[2024-03-26 17:50:44,479][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:50:51,856][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 474 @ 3785 updates
[2024-03-26 17:50:51,857][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:54,331][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:50:54,398][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 474 @ 3785 updates, score None) (writing took 2.542483319994062 seconds)
[2024-03-26 17:50:54,399][fairseq_cli.train][INFO] - end of epoch 474 (average epoch stats below)
[2024-03-26 17:50:54,399][train][INFO] - {"epoch": 474, "train_loss": "0.886", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.05", "train_target_var": "0.764", "train_pred_var": "0.744", "train_masked_pct": "0.501", "train_wps": "8619.1", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3785", "train_lr": "0.000354844", "train_gnorm": "2.066", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4872"}
[2024-03-26 17:50:54,402][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:50:54,462][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 475
[2024-03-26 17:50:54,464][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:50:54,467][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:50:54,472][fairseq.trainer][INFO] - begin training epoch 475
[2024-03-26 17:50:54,472][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:01,821][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:51:01,822][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:01,897][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 96
[2024-03-26 17:51:01,900][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:02,305][valid][INFO] - {"epoch": 475, "valid_loss": "0.938", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.05", "valid_target_var": "0.771", "valid_pred_var": "0.745", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "3793", "valid_best_loss": "0.222"}
[2024-03-26 17:51:02,307][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 475 @ 3793 updates
[2024-03-26 17:51:02,308][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:04,812][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:04,878][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 475 @ 3793 updates, score 0.938) (writing took 2.5716422516852617 seconds)
[2024-03-26 17:51:04,879][fairseq_cli.train][INFO] - end of epoch 475 (average epoch stats below)
[2024-03-26 17:51:04,880][train][INFO] - {"epoch": 475, "train_loss": "0.887", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.05", "train_target_var": "0.762", "train_pred_var": "0.741", "train_masked_pct": "0.5", "train_wps": "8221.6", "train_ups": "0.76", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3793", "train_lr": "0.000355594", "train_gnorm": "2.196", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4883"}
[2024-03-26 17:51:04,882][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:04,945][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 476
[2024-03-26 17:51:04,947][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:04,950][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:04,955][fairseq.trainer][INFO] - begin training epoch 476
[2024-03-26 17:51:04,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:11,450][train_inner][INFO] - {"epoch": 476, "update": 475.875, "loss": "0.89", "ntokens": "10769.2", "nsentences": "22.875", "sample_size": "10769.2", "ema_decay": "999.049", "target_var": "0.766", "pred_var": "0.744", "masked_pct": "0.5", "wps": "8549.2", "ups": "0.79", "wpb": "10769.2", "bsz": "22.9", "num_updates": "3800", "lr": "0.00035625", "gnorm": "2.635", "loss_scale": "1", "train_wall": "177", "gb_free": "5.1", "wall": "4889"}
[2024-03-26 17:51:12,418][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 476 @ 3801 updates
[2024-03-26 17:51:12,420][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:14,915][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:14,981][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 476 @ 3801 updates, score None) (writing took 2.5629780469462276 seconds)
[2024-03-26 17:51:14,982][fairseq_cli.train][INFO] - end of epoch 476 (average epoch stats below)
[2024-03-26 17:51:14,982][train][INFO] - {"epoch": 476, "train_loss": "0.95", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.05", "train_target_var": "0.763", "train_pred_var": "0.737", "train_masked_pct": "0.499", "train_wps": "8527.9", "train_ups": "0.79", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3801", "train_lr": "0.000356344", "train_gnorm": "2.529", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4893"}
[2024-03-26 17:51:14,984][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:15,047][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 477
[2024-03-26 17:51:15,049][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:15,053][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:15,057][fairseq.trainer][INFO] - begin training epoch 477
[2024-03-26 17:51:15,058][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:22,460][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 477 @ 3809 updates
[2024-03-26 17:51:22,462][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:24,946][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:24,998][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 477 @ 3809 updates, score None) (writing took 2.5377504103817046 seconds)
[2024-03-26 17:51:24,999][fairseq_cli.train][INFO] - end of epoch 477 (average epoch stats below)
[2024-03-26 17:51:24,999][train][INFO] - {"epoch": 477, "train_loss": "0.914", "train_ntokens": "10770.6", "train_nsentences": "22.875", "train_sample_size": "10770.6", "train_ema_decay": "999.05", "train_target_var": "0.762", "train_pred_var": "0.738", "train_masked_pct": "0.501", "train_wps": "8602.4", "train_ups": "0.8", "train_wpb": "10770.6", "train_bsz": "22.9", "train_num_updates": "3809", "train_lr": "0.000357094", "train_gnorm": "2.637", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4903"}
[2024-03-26 17:51:25,001][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:25,076][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 478
[2024-03-26 17:51:25,078][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:25,081][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:25,086][fairseq.trainer][INFO] - begin training epoch 478
[2024-03-26 17:51:25,086][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:32,411][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 478 @ 3817 updates
[2024-03-26 17:51:32,412][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:34,899][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:34,964][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 478 @ 3817 updates, score None) (writing took 2.553203463088721 seconds)
[2024-03-26 17:51:34,965][fairseq_cli.train][INFO] - end of epoch 478 (average epoch stats below)
[2024-03-26 17:51:34,965][train][INFO] - {"epoch": 478, "train_loss": "0.946", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.05", "train_target_var": "0.764", "train_pred_var": "0.739", "train_masked_pct": "0.501", "train_wps": "8644.7", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3817", "train_lr": "0.000357844", "train_gnorm": "2.134", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4913"}
[2024-03-26 17:51:34,967][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:35,031][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 479
[2024-03-26 17:51:35,033][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:35,036][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:35,040][fairseq.trainer][INFO] - begin training epoch 479
[2024-03-26 17:51:35,041][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:42,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 479 @ 3825 updates
[2024-03-26 17:51:42,330][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:44,833][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:44,876][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 479 @ 3825 updates, score None) (writing took 2.54762648884207 seconds)
[2024-03-26 17:51:44,877][fairseq_cli.train][INFO] - end of epoch 479 (average epoch stats below)
[2024-03-26 17:51:44,877][train][INFO] - {"epoch": 479, "train_loss": "0.916", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.05", "train_target_var": "0.763", "train_pred_var": "0.741", "train_masked_pct": "0.501", "train_wps": "8691.8", "train_ups": "0.81", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "3825", "train_lr": "0.000358594", "train_gnorm": "2.093", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4923"}
[2024-03-26 17:51:44,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:44,966][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 480
[2024-03-26 17:51:44,968][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:44,971][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:44,976][fairseq.trainer][INFO] - begin training epoch 480
[2024-03-26 17:51:44,976][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:51:52,287][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:51:52,289][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:52,357][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 97
[2024-03-26 17:51:52,360][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:52,756][valid][INFO] - {"epoch": 480, "valid_loss": "0.929", "valid_ntokens": "11703", "valid_nsentences": "25", "valid_sample_size": "11703", "valid_ema_decay": "999.051", "valid_target_var": "0.766", "valid_pred_var": "0.743", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11703", "valid_bsz": "25", "valid_num_updates": "3833", "valid_best_loss": "0.222"}
[2024-03-26 17:51:52,758][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 480 @ 3833 updates
[2024-03-26 17:51:52,759][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:55,290][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:51:55,330][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 480 @ 3833 updates, score 0.929) (writing took 2.5718035050667822 seconds)
[2024-03-26 17:51:55,330][fairseq_cli.train][INFO] - end of epoch 480 (average epoch stats below)
[2024-03-26 17:51:55,331][train][INFO] - {"epoch": 480, "train_loss": "0.867", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.051", "train_target_var": "0.766", "train_pred_var": "0.744", "train_masked_pct": "0.5", "train_wps": "8241.7", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3833", "train_lr": "0.000359344", "train_gnorm": "2.176", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "4933"}
[2024-03-26 17:51:55,333][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:51:55,421][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 481
[2024-03-26 17:51:55,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:51:55,426][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:51:55,431][fairseq.trainer][INFO] - begin training epoch 481
[2024-03-26 17:51:55,431][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:02,932][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 481 @ 3841 updates
[2024-03-26 17:52:02,934][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:05,426][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:05,469][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 481 @ 3841 updates, score None) (writing took 2.536461557261646 seconds)
[2024-03-26 17:52:05,469][fairseq_cli.train][INFO] - end of epoch 481 (average epoch stats below)
[2024-03-26 17:52:05,470][train][INFO] - {"epoch": 481, "train_loss": "0.909", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.051", "train_target_var": "0.76", "train_pred_var": "0.738", "train_masked_pct": "0.501", "train_wps": "8497", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3841", "train_lr": "0.000360094", "train_gnorm": "2.188", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4943"}
[2024-03-26 17:52:05,472][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:05,561][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 482
[2024-03-26 17:52:05,563][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:05,566][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:05,571][fairseq.trainer][INFO] - begin training epoch 482
[2024-03-26 17:52:05,571][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:12,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 482 @ 3849 updates
[2024-03-26 17:52:12,867][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:15,363][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:15,408][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 482 @ 3849 updates, score None) (writing took 2.5425941101275384 seconds)
[2024-03-26 17:52:15,409][fairseq_cli.train][INFO] - end of epoch 482 (average epoch stats below)
[2024-03-26 17:52:15,409][train][INFO] - {"epoch": 482, "train_loss": "0.882", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.051", "train_target_var": "0.761", "train_pred_var": "0.735", "train_masked_pct": "0.499", "train_wps": "8667.6", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3849", "train_lr": "0.000360844", "train_gnorm": "2.3", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "4953"}
[2024-03-26 17:52:15,412][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:15,500][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 483
[2024-03-26 17:52:15,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:15,504][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:15,508][fairseq.trainer][INFO] - begin training epoch 483
[2024-03-26 17:52:15,508][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:22,956][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 483 @ 3857 updates
[2024-03-26 17:52:22,957][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:25,444][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:25,508][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 483 @ 3857 updates, score None) (writing took 2.5525746401399374 seconds)
[2024-03-26 17:52:25,509][fairseq_cli.train][INFO] - end of epoch 483 (average epoch stats below)
[2024-03-26 17:52:25,510][train][INFO] - {"epoch": 483, "train_loss": "0.894", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.051", "train_target_var": "0.764", "train_pred_var": "0.744", "train_masked_pct": "0.501", "train_wps": "8530.3", "train_ups": "0.79", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3857", "train_lr": "0.000361594", "train_gnorm": "2.735", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "4963"}
[2024-03-26 17:52:25,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:25,574][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 484
[2024-03-26 17:52:25,576][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:25,579][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:25,584][fairseq.trainer][INFO] - begin training epoch 484
[2024-03-26 17:52:25,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:32,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 484 @ 3865 updates
[2024-03-26 17:52:32,992][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:35,488][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:35,553][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 484 @ 3865 updates, score None) (writing took 2.5629924940876663 seconds)
[2024-03-26 17:52:35,554][fairseq_cli.train][INFO] - end of epoch 484 (average epoch stats below)
[2024-03-26 17:52:35,554][train][INFO] - {"epoch": 484, "train_loss": "0.869", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.051", "train_target_var": "0.764", "train_pred_var": "0.74", "train_masked_pct": "0.499", "train_wps": "8577.6", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3865", "train_lr": "0.000362344", "train_gnorm": "2.886", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.6", "train_wall": "4973"}
[2024-03-26 17:52:35,556][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:35,618][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 485
[2024-03-26 17:52:35,621][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:35,624][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:35,629][fairseq.trainer][INFO] - begin training epoch 485
[2024-03-26 17:52:35,629][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:43,054][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:52:43,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:43,119][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 98
[2024-03-26 17:52:43,122][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:43,543][valid][INFO] - {"epoch": 485, "valid_loss": "0.866", "valid_ntokens": "11717", "valid_nsentences": "25", "valid_sample_size": "11717", "valid_ema_decay": "999.051", "valid_target_var": "0.773", "valid_pred_var": "0.756", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11717", "valid_bsz": "25", "valid_num_updates": "3873", "valid_best_loss": "0.222"}
[2024-03-26 17:52:43,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 485 @ 3873 updates
[2024-03-26 17:52:43,547][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:46,039][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:46,108][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 485 @ 3873 updates, score 0.866) (writing took 2.563693295698613 seconds)
[2024-03-26 17:52:46,109][fairseq_cli.train][INFO] - end of epoch 485 (average epoch stats below)
[2024-03-26 17:52:46,109][train][INFO] - {"epoch": 485, "train_loss": "0.875", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.051", "train_target_var": "0.764", "train_pred_var": "0.742", "train_masked_pct": "0.5", "train_wps": "8162.9", "train_ups": "0.76", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "3873", "train_lr": "0.000363094", "train_gnorm": "2.521", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "4984"}
[2024-03-26 17:52:46,111][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:46,174][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 486
[2024-03-26 17:52:46,175][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:46,178][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:46,183][fairseq.trainer][INFO] - begin training epoch 486
[2024-03-26 17:52:46,184][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:52:53,608][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 486 @ 3881 updates
[2024-03-26 17:52:53,609][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:56,089][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:52:56,136][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 486 @ 3881 updates, score None) (writing took 2.527979423291981 seconds)
[2024-03-26 17:52:56,136][fairseq_cli.train][INFO] - end of epoch 486 (average epoch stats below)
[2024-03-26 17:52:56,137][train][INFO] - {"epoch": 486, "train_loss": "0.965", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.051", "train_target_var": "0.762", "train_pred_var": "0.738", "train_masked_pct": "0.5", "train_wps": "8592.2", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "3881", "train_lr": "0.000363844", "train_gnorm": "2.113", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "4994"}
[2024-03-26 17:52:56,140][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:52:56,222][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 487
[2024-03-26 17:52:56,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:52:56,228][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:52:56,232][fairseq.trainer][INFO] - begin training epoch 487
[2024-03-26 17:52:56,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:03,498][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 487 @ 3889 updates
[2024-03-26 17:53:03,499][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:05,974][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:06,038][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 487 @ 3889 updates, score None) (writing took 2.540407464373857 seconds)
[2024-03-26 17:53:06,039][fairseq_cli.train][INFO] - end of epoch 487 (average epoch stats below)
[2024-03-26 17:53:06,040][train][INFO] - {"epoch": 487, "train_loss": "0.894", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.051", "train_target_var": "0.763", "train_pred_var": "0.739", "train_masked_pct": "0.501", "train_wps": "8701.3", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3889", "train_lr": "0.000364594", "train_gnorm": "2.029", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5004"}
[2024-03-26 17:53:06,042][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:06,103][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 488
[2024-03-26 17:53:06,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:06,108][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:06,113][fairseq.trainer][INFO] - begin training epoch 488
[2024-03-26 17:53:06,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:13,384][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 488 @ 3897 updates
[2024-03-26 17:53:13,386][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:15,876][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:15,919][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 488 @ 3897 updates, score None) (writing took 2.5347393099218607 seconds)
[2024-03-26 17:53:15,920][fairseq_cli.train][INFO] - end of epoch 488 (average epoch stats below)
[2024-03-26 17:53:15,920][train][INFO] - {"epoch": 488, "train_loss": "0.957", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.051", "train_target_var": "0.761", "train_pred_var": "0.74", "train_masked_pct": "0.5", "train_wps": "8719.8", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "3897", "train_lr": "0.000365344", "train_gnorm": "2.67", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5014"}
[2024-03-26 17:53:15,922][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:16,001][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 489
[2024-03-26 17:53:16,003][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:16,006][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:16,011][fairseq.trainer][INFO] - begin training epoch 489
[2024-03-26 17:53:16,011][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:23,434][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 489 @ 3905 updates
[2024-03-26 17:53:23,435][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:25,919][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:25,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 489 @ 3905 updates, score None) (writing took 2.525203995872289 seconds)
[2024-03-26 17:53:25,960][fairseq_cli.train][INFO] - end of epoch 489 (average epoch stats below)
[2024-03-26 17:53:25,960][train][INFO] - {"epoch": 489, "train_loss": "0.949", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.051", "train_target_var": "0.762", "train_pred_var": "0.734", "train_masked_pct": "0.499", "train_wps": "8582.2", "train_ups": "0.8", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "3905", "train_lr": "0.000366094", "train_gnorm": "2.978", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5024"}
[2024-03-26 17:53:25,962][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:26,048][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 490
[2024-03-26 17:53:26,049][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:26,052][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:26,057][fairseq.trainer][INFO] - begin training epoch 490
[2024-03-26 17:53:26,058][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:33,458][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:53:33,459][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:33,526][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 99
[2024-03-26 17:53:33,529][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:33,951][valid][INFO] - {"epoch": 490, "valid_loss": "0.852", "valid_ntokens": "11701", "valid_nsentences": "25", "valid_sample_size": "11701", "valid_ema_decay": "999.052", "valid_target_var": "0.769", "valid_pred_var": "0.755", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11701", "valid_bsz": "25", "valid_num_updates": "3913", "valid_best_loss": "0.222"}
[2024-03-26 17:53:33,953][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 490 @ 3913 updates
[2024-03-26 17:53:33,954][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:36,486][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:36,547][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 490 @ 3913 updates, score 0.852) (writing took 2.594809878617525 seconds)
[2024-03-26 17:53:36,548][fairseq_cli.train][INFO] - end of epoch 490 (average epoch stats below)
[2024-03-26 17:53:36,549][train][INFO] - {"epoch": 490, "train_loss": "0.967", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.052", "train_target_var": "0.763", "train_pred_var": "0.74", "train_masked_pct": "0.5", "train_wps": "8137.8", "train_ups": "0.76", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "3913", "train_lr": "0.000366844", "train_gnorm": "2.204", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5034"}
[2024-03-26 17:53:36,551][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:36,613][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 491
[2024-03-26 17:53:36,615][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:36,618][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:36,622][fairseq.trainer][INFO] - begin training epoch 491
[2024-03-26 17:53:36,623][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:43,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 491 @ 3921 updates
[2024-03-26 17:53:43,932][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:46,412][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:46,469][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 491 @ 3921 updates, score None) (writing took 2.5380954747088253 seconds)
[2024-03-26 17:53:46,469][fairseq_cli.train][INFO] - end of epoch 491 (average epoch stats below)
[2024-03-26 17:53:46,470][train][INFO] - {"epoch": 491, "train_loss": "0.965", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.052", "train_target_var": "0.761", "train_pred_var": "0.738", "train_masked_pct": "0.499", "train_wps": "8683.6", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "3921", "train_lr": "0.000367594", "train_gnorm": "2.434", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5044"}
[2024-03-26 17:53:46,473][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:46,543][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 492
[2024-03-26 17:53:46,545][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:46,549][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:46,553][fairseq.trainer][INFO] - begin training epoch 492
[2024-03-26 17:53:46,554][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:53:54,067][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 492 @ 3929 updates
[2024-03-26 17:53:54,068][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:56,555][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:53:56,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 492 @ 3929 updates, score None) (writing took 2.554029192775488 seconds)
[2024-03-26 17:53:56,622][fairseq_cli.train][INFO] - end of epoch 492 (average epoch stats below)
[2024-03-26 17:53:56,622][train][INFO] - {"epoch": 492, "train_loss": "0.996", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.052", "train_target_var": "0.761", "train_pred_var": "0.735", "train_masked_pct": "0.499", "train_wps": "8486.7", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "3929", "train_lr": "0.000368344", "train_gnorm": "2.496", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5054"}
[2024-03-26 17:53:56,624][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:53:56,686][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 493
[2024-03-26 17:53:56,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:53:56,691][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:53:56,696][fairseq.trainer][INFO] - begin training epoch 493
[2024-03-26 17:53:56,696][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:04,077][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 493 @ 3937 updates
[2024-03-26 17:54:04,079][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:06,562][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:06,627][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 493 @ 3937 updates, score None) (writing took 2.54995554080233 seconds)
[2024-03-26 17:54:06,628][fairseq_cli.train][INFO] - end of epoch 493 (average epoch stats below)
[2024-03-26 17:54:06,628][train][INFO] - {"epoch": 493, "train_loss": "0.976", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.052", "train_target_var": "0.761", "train_pred_var": "0.737", "train_masked_pct": "0.5", "train_wps": "8610.6", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "3937", "train_lr": "0.000369094", "train_gnorm": "2.32", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5064"}
[2024-03-26 17:54:06,631][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:06,694][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 494
[2024-03-26 17:54:06,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:06,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:06,704][fairseq.trainer][INFO] - begin training epoch 494
[2024-03-26 17:54:06,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:13,901][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 494 @ 3945 updates
[2024-03-26 17:54:13,903][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:16,428][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:16,492][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 494 @ 3945 updates, score None) (writing took 2.590059021022171 seconds)
[2024-03-26 17:54:16,492][fairseq_cli.train][INFO] - end of epoch 494 (average epoch stats below)
[2024-03-26 17:54:16,493][train][INFO] - {"epoch": 494, "train_loss": "0.933", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.052", "train_target_var": "0.763", "train_pred_var": "0.74", "train_masked_pct": "0.5", "train_wps": "8734.2", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "3945", "train_lr": "0.000369844", "train_gnorm": "2.811", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5074"}
[2024-03-26 17:54:16,495][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:16,558][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 495
[2024-03-26 17:54:16,559][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:16,563][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:16,568][fairseq.trainer][INFO] - begin training epoch 495
[2024-03-26 17:54:16,569][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:23,885][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:54:23,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:23,960][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 100
[2024-03-26 17:54:23,964][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:24,367][valid][INFO] - {"epoch": 495, "valid_loss": "1.055", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.052", "valid_target_var": "0.769", "valid_pred_var": "0.744", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "3953", "valid_best_loss": "0.222"}
[2024-03-26 17:54:24,369][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 495 @ 3953 updates
[2024-03-26 17:54:24,371][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:26,960][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:27,025][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 495 @ 3953 updates, score 1.055) (writing took 2.6558270659297705 seconds)
[2024-03-26 17:54:27,026][fairseq_cli.train][INFO] - end of epoch 495 (average epoch stats below)
[2024-03-26 17:54:27,026][train][INFO] - {"epoch": 495, "train_loss": "1.019", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.052", "train_target_var": "0.761", "train_pred_var": "0.735", "train_masked_pct": "0.499", "train_wps": "8179.9", "train_ups": "0.76", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "3953", "train_lr": "0.000370594", "train_gnorm": "2.728", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5085"}
[2024-03-26 17:54:27,029][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:27,092][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 496
[2024-03-26 17:54:27,094][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:27,097][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:27,102][fairseq.trainer][INFO] - begin training epoch 496
[2024-03-26 17:54:27,102][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:34,548][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 496 @ 3961 updates
[2024-03-26 17:54:34,549][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:37,039][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:37,103][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 496 @ 3961 updates, score None) (writing took 2.555856483988464 seconds)
[2024-03-26 17:54:37,104][fairseq_cli.train][INFO] - end of epoch 496 (average epoch stats below)
[2024-03-26 17:54:37,105][train][INFO] - {"epoch": 496, "train_loss": "0.912", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.052", "train_target_var": "0.762", "train_pred_var": "0.739", "train_masked_pct": "0.499", "train_wps": "8548.7", "train_ups": "0.79", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "3961", "train_lr": "0.000371344", "train_gnorm": "2.561", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5095"}
[2024-03-26 17:54:37,107][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:37,168][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 497
[2024-03-26 17:54:37,170][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:37,174][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:37,179][fairseq.trainer][INFO] - begin training epoch 497
[2024-03-26 17:54:37,179][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:44,644][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 497 @ 3969 updates
[2024-03-26 17:54:44,645][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:47,137][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:47,202][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 497 @ 3969 updates, score None) (writing took 2.5581472939811647 seconds)
[2024-03-26 17:54:47,203][fairseq_cli.train][INFO] - end of epoch 497 (average epoch stats below)
[2024-03-26 17:54:47,203][train][INFO] - {"epoch": 497, "train_loss": "0.889", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.052", "train_target_var": "0.762", "train_pred_var": "0.74", "train_masked_pct": "0.501", "train_wps": "8531.6", "train_ups": "0.79", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "3969", "train_lr": "0.000372094", "train_gnorm": "2.172", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5105"}
[2024-03-26 17:54:47,205][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:47,266][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 498
[2024-03-26 17:54:47,268][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:47,271][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:47,276][fairseq.trainer][INFO] - begin training epoch 498
[2024-03-26 17:54:47,277][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:54:54,722][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 498 @ 3977 updates
[2024-03-26 17:54:54,723][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:57,198][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:54:57,262][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 498 @ 3977 updates, score None) (writing took 2.53994801081717 seconds)
[2024-03-26 17:54:57,263][fairseq_cli.train][INFO] - end of epoch 498 (average epoch stats below)
[2024-03-26 17:54:57,263][train][INFO] - {"epoch": 498, "train_loss": "0.93", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.052", "train_target_var": "0.761", "train_pred_var": "0.736", "train_masked_pct": "0.5", "train_wps": "8564.8", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "3977", "train_lr": "0.000372844", "train_gnorm": "2.304", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5115"}
[2024-03-26 17:54:57,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:54:57,327][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 499
[2024-03-26 17:54:57,329][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:54:57,332][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:54:57,337][fairseq.trainer][INFO] - begin training epoch 499
[2024-03-26 17:54:57,337][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:04,668][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 499 @ 3985 updates
[2024-03-26 17:55:04,670][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:07,123][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:07,187][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 499 @ 3985 updates, score None) (writing took 2.519130054395646 seconds)
[2024-03-26 17:55:07,188][fairseq_cli.train][INFO] - end of epoch 499 (average epoch stats below)
[2024-03-26 17:55:07,189][train][INFO] - {"epoch": 499, "train_loss": "0.99", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.053", "train_target_var": "0.76", "train_pred_var": "0.733", "train_masked_pct": "0.498", "train_wps": "8679.4", "train_ups": "0.81", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "3985", "train_lr": "0.000373594", "train_gnorm": "2.7", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5125"}
[2024-03-26 17:55:07,191][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:07,252][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 500
[2024-03-26 17:55:07,254][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:07,257][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:07,262][fairseq.trainer][INFO] - begin training epoch 500
[2024-03-26 17:55:07,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:14,656][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:55:14,657][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:14,719][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 101
[2024-03-26 17:55:14,723][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:15,142][valid][INFO] - {"epoch": 500, "valid_loss": "0.823", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.053", "valid_target_var": "0.771", "valid_pred_var": "0.755", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "3993", "valid_best_loss": "0.222"}
[2024-03-26 17:55:15,144][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 500 @ 3993 updates
[2024-03-26 17:55:15,145][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:17,629][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:17,669][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 500 @ 3993 updates, score 0.823) (writing took 2.525545318145305 seconds)
[2024-03-26 17:55:17,670][fairseq_cli.train][INFO] - end of epoch 500 (average epoch stats below)
[2024-03-26 17:55:17,671][train][INFO] - {"epoch": 500, "train_loss": "0.854", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.053", "train_target_var": "0.764", "train_pred_var": "0.742", "train_masked_pct": "0.499", "train_wps": "8220.2", "train_ups": "0.76", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "3993", "train_lr": "0.000374344", "train_gnorm": "1.917", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5135"}
[2024-03-26 17:55:17,673][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:17,757][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 501
[2024-03-26 17:55:17,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:17,761][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:17,766][fairseq.trainer][INFO] - begin training epoch 501
[2024-03-26 17:55:17,767][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:24,258][train_inner][INFO] - {"epoch": 501, "update": 500.875, "loss": "0.926", "ntokens": "10769", "nsentences": "22.875", "sample_size": "10769", "ema_decay": "999.051", "target_var": "0.762", "pred_var": "0.739", "masked_pct": "0.5", "wps": "8519.5", "ups": "0.79", "wpb": "10769", "bsz": "22.9", "num_updates": "4000", "lr": "0.000375", "gnorm": "2.432", "loss_scale": "1", "train_wall": "178", "gb_free": "5.3", "wall": "5142"}
[2024-03-26 17:55:25,133][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 501 @ 4001 updates
[2024-03-26 17:55:25,135][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:27,603][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:27,661][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 501 @ 4001 updates, score None) (writing took 2.5278035257942975 seconds)
[2024-03-26 17:55:27,662][fairseq_cli.train][INFO] - end of epoch 501 (average epoch stats below)
[2024-03-26 17:55:27,662][train][INFO] - {"epoch": 501, "train_loss": "0.872", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.053", "train_target_var": "0.765", "train_pred_var": "0.741", "train_masked_pct": "0.499", "train_wps": "8622.4", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "4001", "train_lr": "0.000375094", "train_gnorm": "2.754", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "5145"}
[2024-03-26 17:55:27,664][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:27,729][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 502
[2024-03-26 17:55:27,732][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:27,735][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:27,740][fairseq.trainer][INFO] - begin training epoch 502
[2024-03-26 17:55:27,740][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:35,155][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 502 @ 4009 updates
[2024-03-26 17:55:35,156][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:37,638][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:37,704][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 502 @ 4009 updates, score None) (writing took 2.54957344988361 seconds)
[2024-03-26 17:55:37,705][fairseq_cli.train][INFO] - end of epoch 502 (average epoch stats below)
[2024-03-26 17:55:37,705][train][INFO] - {"epoch": 502, "train_loss": "0.897", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.053", "train_target_var": "0.763", "train_pred_var": "0.742", "train_masked_pct": "0.501", "train_wps": "8579.2", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4009", "train_lr": "0.000375844", "train_gnorm": "2.279", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5156"}
[2024-03-26 17:55:37,707][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:37,769][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 503
[2024-03-26 17:55:37,771][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:37,774][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:37,778][fairseq.trainer][INFO] - begin training epoch 503
[2024-03-26 17:55:37,779][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:44,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 503 @ 4017 updates
[2024-03-26 17:55:44,941][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:47,423][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:47,488][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 503 @ 4017 updates, score None) (writing took 2.547797095030546 seconds)
[2024-03-26 17:55:47,489][fairseq_cli.train][INFO] - end of epoch 503 (average epoch stats below)
[2024-03-26 17:55:47,490][train][INFO] - {"epoch": 503, "train_loss": "1.053", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.053", "train_target_var": "0.761", "train_pred_var": "0.736", "train_masked_pct": "0.499", "train_wps": "8805.8", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "4017", "train_lr": "0.000376594", "train_gnorm": "2.576", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5165"}
[2024-03-26 17:55:47,492][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:47,556][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 504
[2024-03-26 17:55:47,558][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:47,561][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:47,566][fairseq.trainer][INFO] - begin training epoch 504
[2024-03-26 17:55:47,567][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:55:54,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 504 @ 4025 updates
[2024-03-26 17:55:54,938][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:57,382][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:55:57,446][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 504 @ 4025 updates, score None) (writing took 2.510061029344797 seconds)
[2024-03-26 17:55:57,447][fairseq_cli.train][INFO] - end of epoch 504 (average epoch stats below)
[2024-03-26 17:55:57,448][train][INFO] - {"epoch": 504, "train_loss": "1.039", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.053", "train_target_var": "0.763", "train_pred_var": "0.736", "train_masked_pct": "0.5", "train_wps": "8651.6", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "4025", "train_lr": "0.000377344", "train_gnorm": "3.112", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5175"}
[2024-03-26 17:55:57,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:55:57,512][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 505
[2024-03-26 17:55:57,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:55:57,517][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:55:57,522][fairseq.trainer][INFO] - begin training epoch 505
[2024-03-26 17:55:57,522][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:04,951][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:56:04,952][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:05,015][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 102
[2024-03-26 17:56:05,018][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:05,450][valid][INFO] - {"epoch": 505, "valid_loss": "0.985", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.053", "valid_target_var": "0.771", "valid_pred_var": "0.746", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "4033", "valid_best_loss": "0.222"}
[2024-03-26 17:56:05,452][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 505 @ 4033 updates
[2024-03-26 17:56:05,453][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:07,951][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:08,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 505 @ 4033 updates, score 0.985) (writing took 2.5648134318180382 seconds)
[2024-03-26 17:56:08,017][fairseq_cli.train][INFO] - end of epoch 505 (average epoch stats below)
[2024-03-26 17:56:08,018][train][INFO] - {"epoch": 505, "train_loss": "0.907", "train_ntokens": "10767.5", "train_nsentences": "22.875", "train_sample_size": "10767.5", "train_ema_decay": "999.053", "train_target_var": "0.762", "train_pred_var": "0.739", "train_masked_pct": "0.499", "train_wps": "8149.9", "train_ups": "0.76", "train_wpb": "10767.5", "train_bsz": "22.9", "train_num_updates": "4033", "train_lr": "0.000378094", "train_gnorm": "2.143", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5186"}
[2024-03-26 17:56:08,020][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:08,080][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 506
[2024-03-26 17:56:08,082][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:08,085][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:08,090][fairseq.trainer][INFO] - begin training epoch 506
[2024-03-26 17:56:08,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:15,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 506 @ 4041 updates
[2024-03-26 17:56:15,485][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:17,993][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:18,056][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 506 @ 4041 updates, score None) (writing took 2.572981955949217 seconds)
[2024-03-26 17:56:18,057][fairseq_cli.train][INFO] - end of epoch 506 (average epoch stats below)
[2024-03-26 17:56:18,058][train][INFO] - {"epoch": 506, "train_loss": "0.922", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.053", "train_target_var": "0.76", "train_pred_var": "0.737", "train_masked_pct": "0.5", "train_wps": "8581.1", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4041", "train_lr": "0.000378844", "train_gnorm": "2.389", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "5196"}
[2024-03-26 17:56:18,060][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:18,124][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 507
[2024-03-26 17:56:18,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:18,129][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:18,133][fairseq.trainer][INFO] - begin training epoch 507
[2024-03-26 17:56:18,134][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:25,515][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 507 @ 4049 updates
[2024-03-26 17:56:25,516][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:27,988][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:28,048][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 507 @ 4049 updates, score None) (writing took 2.53265942633152 seconds)
[2024-03-26 17:56:28,048][fairseq_cli.train][INFO] - end of epoch 507 (average epoch stats below)
[2024-03-26 17:56:28,049][train][INFO] - {"epoch": 507, "train_loss": "0.909", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.053", "train_target_var": "0.762", "train_pred_var": "0.737", "train_masked_pct": "0.501", "train_wps": "8623.1", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4049", "train_lr": "0.000379594", "train_gnorm": "2.333", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5206"}
[2024-03-26 17:56:28,051][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:28,113][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 508
[2024-03-26 17:56:28,114][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:28,118][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:28,122][fairseq.trainer][INFO] - begin training epoch 508
[2024-03-26 17:56:28,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:35,481][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 508 @ 4057 updates
[2024-03-26 17:56:35,483][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:37,973][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:38,026][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 508 @ 4057 updates, score None) (writing took 2.5445872796699405 seconds)
[2024-03-26 17:56:38,027][fairseq_cli.train][INFO] - end of epoch 508 (average epoch stats below)
[2024-03-26 17:56:38,027][train][INFO] - {"epoch": 508, "train_loss": "0.909", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.053", "train_target_var": "0.76", "train_pred_var": "0.737", "train_masked_pct": "0.501", "train_wps": "8634.3", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4057", "train_lr": "0.000380344", "train_gnorm": "2.265", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5216"}
[2024-03-26 17:56:38,029][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:38,106][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 509
[2024-03-26 17:56:38,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:38,111][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:38,116][fairseq.trainer][INFO] - begin training epoch 509
[2024-03-26 17:56:38,116][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:45,323][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 509 @ 4065 updates
[2024-03-26 17:56:45,324][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:47,776][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:47,837][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 509 @ 4065 updates, score None) (writing took 2.5139230680651963 seconds)
[2024-03-26 17:56:47,837][fairseq_cli.train][INFO] - end of epoch 509 (average epoch stats below)
[2024-03-26 17:56:47,838][train][INFO] - {"epoch": 509, "train_loss": "0.924", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.054", "train_target_var": "0.765", "train_pred_var": "0.743", "train_masked_pct": "0.501", "train_wps": "8781.6", "train_ups": "0.82", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "4065", "train_lr": "0.000381094", "train_gnorm": "2.379", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5226"}
[2024-03-26 17:56:47,840][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:47,901][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 510
[2024-03-26 17:56:47,903][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:47,906][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:47,911][fairseq.trainer][INFO] - begin training epoch 510
[2024-03-26 17:56:47,912][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:56:55,173][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:56:55,174][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:55,239][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 103
[2024-03-26 17:56:55,242][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:55,665][valid][INFO] - {"epoch": 510, "valid_loss": "0.968", "valid_ntokens": "11696", "valid_nsentences": "25", "valid_sample_size": "11696", "valid_ema_decay": "999.054", "valid_target_var": "0.766", "valid_pred_var": "0.74", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11696", "valid_bsz": "25", "valid_num_updates": "4073", "valid_best_loss": "0.222"}
[2024-03-26 17:56:55,666][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 510 @ 4073 updates
[2024-03-26 17:56:55,668][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:58,160][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:56:58,224][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 510 @ 4073 updates, score 0.968) (writing took 2.557187451981008 seconds)
[2024-03-26 17:56:58,224][fairseq_cli.train][INFO] - end of epoch 510 (average epoch stats below)
[2024-03-26 17:56:58,225][train][INFO] - {"epoch": 510, "train_loss": "0.953", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.054", "train_target_var": "0.76", "train_pred_var": "0.734", "train_masked_pct": "0.5", "train_wps": "8295.2", "train_ups": "0.77", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4073", "train_lr": "0.000381844", "train_gnorm": "2.693", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5236"}
[2024-03-26 17:56:58,227][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:56:58,290][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 511
[2024-03-26 17:56:58,292][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:56:58,295][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:56:58,299][fairseq.trainer][INFO] - begin training epoch 511
[2024-03-26 17:56:58,300][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:05,565][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 511 @ 4081 updates
[2024-03-26 17:57:05,567][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:08,059][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:08,104][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 511 @ 4081 updates, score None) (writing took 2.5386654641479254 seconds)
[2024-03-26 17:57:08,105][fairseq_cli.train][INFO] - end of epoch 511 (average epoch stats below)
[2024-03-26 17:57:08,105][train][INFO] - {"epoch": 511, "train_loss": "0.939", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.054", "train_target_var": "0.761", "train_pred_var": "0.737", "train_masked_pct": "0.501", "train_wps": "8720.3", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4081", "train_lr": "0.000382594", "train_gnorm": "2.564", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5246"}
[2024-03-26 17:57:08,108][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:08,192][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 512
[2024-03-26 17:57:08,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:08,197][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:08,202][fairseq.trainer][INFO] - begin training epoch 512
[2024-03-26 17:57:08,203][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:15,387][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 512 @ 4089 updates
[2024-03-26 17:57:15,389][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:17,879][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:17,913][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 512 @ 4089 updates, score None) (writing took 2.5260802539996803 seconds)
[2024-03-26 17:57:17,914][fairseq_cli.train][INFO] - end of epoch 512 (average epoch stats below)
[2024-03-26 17:57:17,915][train][INFO] - {"epoch": 512, "train_loss": "0.944", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.054", "train_target_var": "0.76", "train_pred_var": "0.739", "train_masked_pct": "0.499", "train_wps": "8783.7", "train_ups": "0.82", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4089", "train_lr": "0.000383344", "train_gnorm": "2.153", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5256"}
[2024-03-26 17:57:17,917][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:18,008][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 513
[2024-03-26 17:57:18,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:18,013][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:18,018][fairseq.trainer][INFO] - begin training epoch 513
[2024-03-26 17:57:18,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:25,345][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 513 @ 4097 updates
[2024-03-26 17:57:25,346][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:27,846][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:27,909][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 513 @ 4097 updates, score None) (writing took 2.564679453149438 seconds)
[2024-03-26 17:57:27,910][fairseq_cli.train][INFO] - end of epoch 513 (average epoch stats below)
[2024-03-26 17:57:27,911][train][INFO] - {"epoch": 513, "train_loss": "0.934", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.054", "train_target_var": "0.76", "train_pred_var": "0.735", "train_masked_pct": "0.5", "train_wps": "8619.6", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4097", "train_lr": "0.000384094", "train_gnorm": "1.979", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "5266"}
[2024-03-26 17:57:27,913][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:27,973][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 514
[2024-03-26 17:57:27,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:27,978][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:27,983][fairseq.trainer][INFO] - begin training epoch 514
[2024-03-26 17:57:27,984][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:35,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 514 @ 4105 updates
[2024-03-26 17:57:35,061][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:37,545][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:37,609][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 514 @ 4105 updates, score None) (writing took 2.5494072432629764 seconds)
[2024-03-26 17:57:37,610][fairseq_cli.train][INFO] - end of epoch 514 (average epoch stats below)
[2024-03-26 17:57:37,610][train][INFO] - {"epoch": 514, "train_loss": "0.955", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.054", "train_target_var": "0.759", "train_pred_var": "0.737", "train_masked_pct": "0.498", "train_wps": "8882.6", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "4105", "train_lr": "0.000384844", "train_gnorm": "1.921", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5275"}
[2024-03-26 17:57:37,613][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:37,679][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 515
[2024-03-26 17:57:37,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:37,683][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:37,688][fairseq.trainer][INFO] - begin training epoch 515
[2024-03-26 17:57:37,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:44,903][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:57:44,904][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:44,968][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 104
[2024-03-26 17:57:44,971][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:45,390][valid][INFO] - {"epoch": 515, "valid_loss": "0.909", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.054", "valid_target_var": "0.763", "valid_pred_var": "0.744", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "4113", "valid_best_loss": "0.222"}
[2024-03-26 17:57:45,392][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 515 @ 4113 updates
[2024-03-26 17:57:45,393][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:47,975][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:48,038][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 515 @ 4113 updates, score 0.909) (writing took 2.6463000238873065 seconds)
[2024-03-26 17:57:48,039][fairseq_cli.train][INFO] - end of epoch 515 (average epoch stats below)
[2024-03-26 17:57:48,039][train][INFO] - {"epoch": 515, "train_loss": "0.943", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.054", "train_target_var": "0.758", "train_pred_var": "0.735", "train_masked_pct": "0.5", "train_wps": "8262.2", "train_ups": "0.77", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "4113", "train_lr": "0.000385594", "train_gnorm": "2.361", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5286"}
[2024-03-26 17:57:48,042][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:48,106][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 516
[2024-03-26 17:57:48,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:48,111][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:48,115][fairseq.trainer][INFO] - begin training epoch 516
[2024-03-26 17:57:48,116][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:57:55,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 516 @ 4121 updates
[2024-03-26 17:57:55,376][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:57,874][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:57:57,940][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 516 @ 4121 updates, score None) (writing took 2.5649040592834353 seconds)
[2024-03-26 17:57:57,941][fairseq_cli.train][INFO] - end of epoch 516 (average epoch stats below)
[2024-03-26 17:57:57,941][train][INFO] - {"epoch": 516, "train_loss": "0.961", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.054", "train_target_var": "0.762", "train_pred_var": "0.737", "train_masked_pct": "0.5", "train_wps": "8702", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4121", "train_lr": "0.000386344", "train_gnorm": "2.847", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5296"}
[2024-03-26 17:57:57,944][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:57:58,007][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 517
[2024-03-26 17:57:58,009][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:57:58,012][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:57:58,017][fairseq.trainer][INFO] - begin training epoch 517
[2024-03-26 17:57:58,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:05,313][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 517 @ 4129 updates
[2024-03-26 17:58:05,315][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:07,816][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:07,881][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 517 @ 4129 updates, score None) (writing took 2.567483468912542 seconds)
[2024-03-26 17:58:07,881][fairseq_cli.train][INFO] - end of epoch 517 (average epoch stats below)
[2024-03-26 17:58:07,882][train][INFO] - {"epoch": 517, "train_loss": "1.055", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.054", "train_target_var": "0.761", "train_pred_var": "0.734", "train_masked_pct": "0.5", "train_wps": "8667.9", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4129", "train_lr": "0.000387094", "train_gnorm": "3.316", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5306"}
[2024-03-26 17:58:07,884][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:07,945][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 518
[2024-03-26 17:58:07,947][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:07,950][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:07,955][fairseq.trainer][INFO] - begin training epoch 518
[2024-03-26 17:58:07,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:15,304][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 518 @ 4137 updates
[2024-03-26 17:58:15,305][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:17,791][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:17,843][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 518 @ 4137 updates, score None) (writing took 2.538603640627116 seconds)
[2024-03-26 17:58:17,843][fairseq_cli.train][INFO] - end of epoch 518 (average epoch stats below)
[2024-03-26 17:58:17,844][train][INFO] - {"epoch": 518, "train_loss": "1.038", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.055", "train_target_var": "0.762", "train_pred_var": "0.736", "train_masked_pct": "0.5", "train_wps": "8648.2", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "4137", "train_lr": "0.000387844", "train_gnorm": "2.626", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "5316"}
[2024-03-26 17:58:17,846][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:17,920][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 519
[2024-03-26 17:58:17,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:17,926][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:17,930][fairseq.trainer][INFO] - begin training epoch 519
[2024-03-26 17:58:17,931][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:25,251][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 519 @ 4145 updates
[2024-03-26 17:58:25,253][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:27,741][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:27,805][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 519 @ 4145 updates, score None) (writing took 2.5537977339699864 seconds)
[2024-03-26 17:58:27,806][fairseq_cli.train][INFO] - end of epoch 519 (average epoch stats below)
[2024-03-26 17:58:27,806][train][INFO] - {"epoch": 519, "train_loss": "1.056", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.055", "train_target_var": "0.759", "train_pred_var": "0.733", "train_masked_pct": "0.501", "train_wps": "8648", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4145", "train_lr": "0.000388594", "train_gnorm": "2.297", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5326"}
[2024-03-26 17:58:27,808][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:27,870][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 520
[2024-03-26 17:58:27,871][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:27,874][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:27,879][fairseq.trainer][INFO] - begin training epoch 520
[2024-03-26 17:58:27,880][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:35,208][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:58:35,209][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:35,273][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 105
[2024-03-26 17:58:35,276][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:35,687][valid][INFO] - {"epoch": 520, "valid_loss": "1.039", "valid_ntokens": "11718", "valid_nsentences": "25", "valid_sample_size": "11718", "valid_ema_decay": "999.055", "valid_target_var": "0.77", "valid_pred_var": "0.733", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11718", "valid_bsz": "25", "valid_num_updates": "4153", "valid_best_loss": "0.222"}
[2024-03-26 17:58:35,690][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 520 @ 4153 updates
[2024-03-26 17:58:35,691][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:38,210][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:38,277][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 520 @ 4153 updates, score 1.039) (writing took 2.5871138931252062 seconds)
[2024-03-26 17:58:38,277][fairseq_cli.train][INFO] - end of epoch 520 (average epoch stats below)
[2024-03-26 17:58:38,278][train][INFO] - {"epoch": 520, "train_loss": "0.989", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.055", "train_target_var": "0.761", "train_pred_var": "0.736", "train_masked_pct": "0.501", "train_wps": "8227.2", "train_ups": "0.76", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "4153", "train_lr": "0.000389344", "train_gnorm": "2.043", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5336"}
[2024-03-26 17:58:38,281][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:38,344][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 521
[2024-03-26 17:58:38,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:38,349][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:38,353][fairseq.trainer][INFO] - begin training epoch 521
[2024-03-26 17:58:38,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:45,599][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 521 @ 4161 updates
[2024-03-26 17:58:45,600][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:48,094][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:48,160][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 521 @ 4161 updates, score None) (writing took 2.5615368839353323 seconds)
[2024-03-26 17:58:48,161][fairseq_cli.train][INFO] - end of epoch 521 (average epoch stats below)
[2024-03-26 17:58:48,162][train][INFO] - {"epoch": 521, "train_loss": "1.065", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.055", "train_target_var": "0.76", "train_pred_var": "0.736", "train_masked_pct": "0.501", "train_wps": "8718.4", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4161", "train_lr": "0.000390094", "train_gnorm": "2.101", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5346"}
[2024-03-26 17:58:48,164][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:48,227][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 522
[2024-03-26 17:58:48,229][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:48,232][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:48,237][fairseq.trainer][INFO] - begin training epoch 522
[2024-03-26 17:58:48,237][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:58:55,545][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 522 @ 4169 updates
[2024-03-26 17:58:55,547][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:58,053][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:58:58,118][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 522 @ 4169 updates, score None) (writing took 2.57268198300153 seconds)
[2024-03-26 17:58:58,118][fairseq_cli.train][INFO] - end of epoch 522 (average epoch stats below)
[2024-03-26 17:58:58,119][train][INFO] - {"epoch": 522, "train_loss": "1.081", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.055", "train_target_var": "0.76", "train_pred_var": "0.733", "train_masked_pct": "0.5", "train_wps": "8652.7", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4169", "train_lr": "0.000390844", "train_gnorm": "2.488", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5356"}
[2024-03-26 17:58:58,121][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:58:58,184][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 523
[2024-03-26 17:58:58,185][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:58:58,188][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:58:58,194][fairseq.trainer][INFO] - begin training epoch 523
[2024-03-26 17:58:58,194][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:05,456][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 523 @ 4177 updates
[2024-03-26 17:59:05,458][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:07,936][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:08,001][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 523 @ 4177 updates, score None) (writing took 2.544529818929732 seconds)
[2024-03-26 17:59:08,001][fairseq_cli.train][INFO] - end of epoch 523 (average epoch stats below)
[2024-03-26 17:59:08,002][train][INFO] - {"epoch": 523, "train_loss": "1.13", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.055", "train_target_var": "0.759", "train_pred_var": "0.728", "train_masked_pct": "0.499", "train_wps": "8717.9", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4177", "train_lr": "0.000391594", "train_gnorm": "2.521", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5366"}
[2024-03-26 17:59:08,004][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:08,066][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 524
[2024-03-26 17:59:08,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:08,071][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:08,076][fairseq.trainer][INFO] - begin training epoch 524
[2024-03-26 17:59:08,076][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:15,257][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 524 @ 4185 updates
[2024-03-26 17:59:15,258][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:17,732][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:17,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 524 @ 4185 updates, score None) (writing took 2.526564210653305 seconds)
[2024-03-26 17:59:17,784][fairseq_cli.train][INFO] - end of epoch 524 (average epoch stats below)
[2024-03-26 17:59:17,785][train][INFO] - {"epoch": 524, "train_loss": "1.056", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.055", "train_target_var": "0.759", "train_pred_var": "0.733", "train_masked_pct": "0.498", "train_wps": "8807.3", "train_ups": "0.82", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4185", "train_lr": "0.000392344", "train_gnorm": "2.767", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5376"}
[2024-03-26 17:59:17,787][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:17,861][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 525
[2024-03-26 17:59:17,863][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:17,866][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:17,871][fairseq.trainer][INFO] - begin training epoch 525
[2024-03-26 17:59:17,871][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:25,295][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 17:59:25,296][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:25,362][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 106
[2024-03-26 17:59:25,365][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:25,776][valid][INFO] - {"epoch": 525, "valid_loss": "1.04", "valid_ntokens": "11716", "valid_nsentences": "25", "valid_sample_size": "11716", "valid_ema_decay": "999.055", "valid_target_var": "0.763", "valid_pred_var": "0.731", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11716", "valid_bsz": "25", "valid_num_updates": "4193", "valid_best_loss": "0.222"}
[2024-03-26 17:59:25,778][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 525 @ 4193 updates
[2024-03-26 17:59:25,779][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:28,310][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:28,368][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 525 @ 4193 updates, score 1.04) (writing took 2.58981220331043 seconds)
[2024-03-26 17:59:28,368][fairseq_cli.train][INFO] - end of epoch 525 (average epoch stats below)
[2024-03-26 17:59:28,369][train][INFO] - {"epoch": 525, "train_loss": "0.998", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.055", "train_target_var": "0.76", "train_pred_var": "0.732", "train_masked_pct": "0.501", "train_wps": "8140.7", "train_ups": "0.76", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4193", "train_lr": "0.000393094", "train_gnorm": "2.339", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5386"}
[2024-03-26 17:59:28,371][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:28,433][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 526
[2024-03-26 17:59:28,435][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:28,438][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:28,443][fairseq.trainer][INFO] - begin training epoch 526
[2024-03-26 17:59:28,443][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:34,758][train_inner][INFO] - {"epoch": 526, "update": 525.875, "loss": "0.986", "ntokens": "10769", "nsentences": "22.875", "sample_size": "10769", "ema_decay": "999.054", "target_var": "0.761", "pred_var": "0.736", "masked_pct": "0.5", "wps": "8598.1", "ups": "0.8", "wpb": "10769", "bsz": "22.9", "num_updates": "4200", "lr": "0.00039375", "gnorm": "2.436", "loss_scale": "1", "train_wall": "176", "gb_free": "5.1", "wall": "5393"}
[2024-03-26 17:59:35,779][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 526 @ 4201 updates
[2024-03-26 17:59:35,781][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:38,255][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:38,321][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 526 @ 4201 updates, score None) (writing took 2.5414558919146657 seconds)
[2024-03-26 17:59:38,322][fairseq_cli.train][INFO] - end of epoch 526 (average epoch stats below)
[2024-03-26 17:59:38,322][train][INFO] - {"epoch": 526, "train_loss": "1.025", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.055", "train_target_var": "0.757", "train_pred_var": "0.731", "train_masked_pct": "0.501", "train_wps": "8655.9", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "4201", "train_lr": "0.000393844", "train_gnorm": "2.363", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5396"}
[2024-03-26 17:59:38,324][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:38,387][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 527
[2024-03-26 17:59:38,389][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:38,392][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:38,397][fairseq.trainer][INFO] - begin training epoch 527
[2024-03-26 17:59:38,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:45,558][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 527 @ 4209 updates
[2024-03-26 17:59:45,559][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:48,034][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:48,100][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 527 @ 4209 updates, score None) (writing took 2.5423224200494587 seconds)
[2024-03-26 17:59:48,101][fairseq_cli.train][INFO] - end of epoch 527 (average epoch stats below)
[2024-03-26 17:59:48,102][train][INFO] - {"epoch": 527, "train_loss": "1.067", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.055", "train_target_var": "0.762", "train_pred_var": "0.738", "train_masked_pct": "0.499", "train_wps": "8810.2", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4209", "train_lr": "0.000394594", "train_gnorm": "2.594", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5406"}
[2024-03-26 17:59:48,104][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:48,167][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 528
[2024-03-26 17:59:48,169][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:48,172][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:48,176][fairseq.trainer][INFO] - begin training epoch 528
[2024-03-26 17:59:48,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 17:59:55,534][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 528 @ 4217 updates
[2024-03-26 17:59:55,535][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:58,015][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 17:59:58,078][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 528 @ 4217 updates, score None) (writing took 2.54438681807369 seconds)
[2024-03-26 17:59:58,079][fairseq_cli.train][INFO] - end of epoch 528 (average epoch stats below)
[2024-03-26 17:59:58,080][train][INFO] - {"epoch": 528, "train_loss": "0.989", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.056", "train_target_var": "0.758", "train_pred_var": "0.731", "train_masked_pct": "0.5", "train_wps": "8634.7", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4217", "train_lr": "0.000395344", "train_gnorm": "2.749", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5416"}
[2024-03-26 17:59:58,082][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 17:59:58,144][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 529
[2024-03-26 17:59:58,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 17:59:58,149][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 17:59:58,154][fairseq.trainer][INFO] - begin training epoch 529
[2024-03-26 17:59:58,154][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:05,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 529 @ 4225 updates
[2024-03-26 18:00:05,460][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:07,931][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:07,997][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 529 @ 4225 updates, score None) (writing took 2.539216622710228 seconds)
[2024-03-26 18:00:07,997][fairseq_cli.train][INFO] - end of epoch 529 (average epoch stats below)
[2024-03-26 18:00:07,998][train][INFO] - {"epoch": 529, "train_loss": "1.057", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.056", "train_target_var": "0.756", "train_pred_var": "0.729", "train_masked_pct": "0.501", "train_wps": "8686.9", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4225", "train_lr": "0.000396094", "train_gnorm": "2.443", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5426"}
[2024-03-26 18:00:08,000][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:08,064][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 530
[2024-03-26 18:00:08,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:08,069][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:08,074][fairseq.trainer][INFO] - begin training epoch 530
[2024-03-26 18:00:08,074][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:15,525][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:00:15,526][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:15,590][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 107
[2024-03-26 18:00:15,593][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:16,002][valid][INFO] - {"epoch": 530, "valid_loss": "0.914", "valid_ntokens": "11728", "valid_nsentences": "25", "valid_sample_size": "11728", "valid_ema_decay": "999.056", "valid_target_var": "0.762", "valid_pred_var": "0.75", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11728", "valid_bsz": "25", "valid_num_updates": "4233", "valid_best_loss": "0.222"}
[2024-03-26 18:00:16,004][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 530 @ 4233 updates
[2024-03-26 18:00:16,005][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:18,516][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:18,581][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 530 @ 4233 updates, score 0.914) (writing took 2.5774198514409363 seconds)
[2024-03-26 18:00:18,582][fairseq_cli.train][INFO] - end of epoch 530 (average epoch stats below)
[2024-03-26 18:00:18,582][train][INFO] - {"epoch": 530, "train_loss": "1.038", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.056", "train_target_var": "0.76", "train_pred_var": "0.732", "train_masked_pct": "0.499", "train_wps": "8140.1", "train_ups": "0.76", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4233", "train_lr": "0.000396844", "train_gnorm": "2.909", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "5436"}
[2024-03-26 18:00:18,584][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:18,645][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 531
[2024-03-26 18:00:18,647][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:18,650][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:18,655][fairseq.trainer][INFO] - begin training epoch 531
[2024-03-26 18:00:18,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:25,882][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 531 @ 4241 updates
[2024-03-26 18:00:25,883][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:28,366][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:28,432][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 531 @ 4241 updates, score None) (writing took 2.5507337539456785 seconds)
[2024-03-26 18:00:28,433][fairseq_cli.train][INFO] - end of epoch 531 (average epoch stats below)
[2024-03-26 18:00:28,434][train][INFO] - {"epoch": 531, "train_loss": "1.039", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.056", "train_target_var": "0.758", "train_pred_var": "0.732", "train_masked_pct": "0.5", "train_wps": "8745.7", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "4241", "train_lr": "0.000397594", "train_gnorm": "2.674", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5446"}
[2024-03-26 18:00:28,436][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:28,499][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 532
[2024-03-26 18:00:28,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:28,504][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:28,509][fairseq.trainer][INFO] - begin training epoch 532
[2024-03-26 18:00:28,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:35,952][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 532 @ 4249 updates
[2024-03-26 18:00:35,956][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:38,451][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:38,511][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 532 @ 4249 updates, score None) (writing took 2.5592736043035984 seconds)
[2024-03-26 18:00:38,512][fairseq_cli.train][INFO] - end of epoch 532 (average epoch stats below)
[2024-03-26 18:00:38,512][train][INFO] - {"epoch": 532, "train_loss": "0.991", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.056", "train_target_var": "0.758", "train_pred_var": "0.733", "train_masked_pct": "0.501", "train_wps": "8548.5", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4249", "train_lr": "0.000398344", "train_gnorm": "2.423", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5456"}
[2024-03-26 18:00:38,515][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:38,584][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 533
[2024-03-26 18:00:38,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:38,588][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:38,593][fairseq.trainer][INFO] - begin training epoch 533
[2024-03-26 18:00:38,594][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:45,813][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 533 @ 4257 updates
[2024-03-26 18:00:45,814][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:48,311][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:48,380][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 533 @ 4257 updates, score None) (writing took 2.5670263287611306 seconds)
[2024-03-26 18:00:48,381][fairseq_cli.train][INFO] - end of epoch 533 (average epoch stats below)
[2024-03-26 18:00:48,381][train][INFO] - {"epoch": 533, "train_loss": "1.003", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.056", "train_target_var": "0.758", "train_pred_var": "0.729", "train_masked_pct": "0.499", "train_wps": "8730.5", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "4257", "train_lr": "0.000399094", "train_gnorm": "2.649", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5466"}
[2024-03-26 18:00:48,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:48,460][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 534
[2024-03-26 18:00:48,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:48,465][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:48,470][fairseq.trainer][INFO] - begin training epoch 534
[2024-03-26 18:00:48,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:00:55,862][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 534 @ 4265 updates
[2024-03-26 18:00:55,864][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:58,333][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:00:58,373][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 534 @ 4265 updates, score None) (writing took 2.5110108330845833 seconds)
[2024-03-26 18:00:58,374][fairseq_cli.train][INFO] - end of epoch 534 (average epoch stats below)
[2024-03-26 18:00:58,375][train][INFO] - {"epoch": 534, "train_loss": "0.922", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.056", "train_target_var": "0.761", "train_pred_var": "0.736", "train_masked_pct": "0.5", "train_wps": "8621.7", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4265", "train_lr": "0.000399844", "train_gnorm": "2.2", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5476"}
[2024-03-26 18:00:58,377][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:00:58,469][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 535
[2024-03-26 18:00:58,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:00:58,473][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:00:58,477][fairseq.trainer][INFO] - begin training epoch 535
[2024-03-26 18:00:58,477][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:05,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:01:05,697][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:05,780][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 108
[2024-03-26 18:01:05,784][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:06,194][valid][INFO] - {"epoch": 535, "valid_loss": "1.208", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.056", "valid_target_var": "0.764", "valid_pred_var": "0.737", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "4273", "valid_best_loss": "0.222"}
[2024-03-26 18:01:06,196][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 535 @ 4273 updates
[2024-03-26 18:01:06,198][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:08,771][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:08,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 535 @ 4273 updates, score 1.208) (writing took 2.626191438641399 seconds)
[2024-03-26 18:01:08,823][fairseq_cli.train][INFO] - end of epoch 535 (average epoch stats below)
[2024-03-26 18:01:08,823][train][INFO] - {"epoch": 535, "train_loss": "1.004", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.056", "train_target_var": "0.761", "train_pred_var": "0.738", "train_masked_pct": "0.5", "train_wps": "8245.6", "train_ups": "0.77", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "4273", "train_lr": "0.000400594", "train_gnorm": "2.142", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5487"}
[2024-03-26 18:01:08,826][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:08,895][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 536
[2024-03-26 18:01:08,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:08,900][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:08,905][fairseq.trainer][INFO] - begin training epoch 536
[2024-03-26 18:01:08,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:16,259][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 536 @ 4281 updates
[2024-03-26 18:01:16,260][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:18,769][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:18,838][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 536 @ 4281 updates, score None) (writing took 2.579007253050804 seconds)
[2024-03-26 18:01:18,838][fairseq_cli.train][INFO] - end of epoch 536 (average epoch stats below)
[2024-03-26 18:01:18,839][train][INFO] - {"epoch": 536, "train_loss": "1.034", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.056", "train_target_var": "0.753", "train_pred_var": "0.727", "train_masked_pct": "0.5", "train_wps": "8602.5", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4281", "train_lr": "0.000401344", "train_gnorm": "2.168", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5497"}
[2024-03-26 18:01:18,842][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:18,905][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 537
[2024-03-26 18:01:18,907][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:18,910][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:18,915][fairseq.trainer][INFO] - begin training epoch 537
[2024-03-26 18:01:18,915][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:26,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 537 @ 4289 updates
[2024-03-26 18:01:26,065][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:28,566][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:28,633][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 537 @ 4289 updates, score None) (writing took 2.569429452996701 seconds)
[2024-03-26 18:01:28,634][fairseq_cli.train][INFO] - end of epoch 537 (average epoch stats below)
[2024-03-26 18:01:28,634][train][INFO] - {"epoch": 537, "train_loss": "1.046", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.057", "train_target_var": "0.756", "train_pred_var": "0.728", "train_masked_pct": "0.5", "train_wps": "8795.8", "train_ups": "0.82", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4289", "train_lr": "0.000402094", "train_gnorm": "2.004", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5506"}
[2024-03-26 18:01:28,636][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:28,699][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 538
[2024-03-26 18:01:28,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:28,704][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:28,709][fairseq.trainer][INFO] - begin training epoch 538
[2024-03-26 18:01:28,709][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:36,193][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 538 @ 4297 updates
[2024-03-26 18:01:36,195][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:38,690][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:38,756][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 538 @ 4297 updates, score None) (writing took 2.562211620155722 seconds)
[2024-03-26 18:01:38,756][fairseq_cli.train][INFO] - end of epoch 538 (average epoch stats below)
[2024-03-26 18:01:38,757][train][INFO] - {"epoch": 538, "train_loss": "0.96", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.057", "train_target_var": "0.759", "train_pred_var": "0.735", "train_masked_pct": "0.5", "train_wps": "8512.4", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "4297", "train_lr": "0.000402844", "train_gnorm": "1.905", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5517"}
[2024-03-26 18:01:38,759][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:38,822][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 539
[2024-03-26 18:01:38,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:38,827][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:38,831][fairseq.trainer][INFO] - begin training epoch 539
[2024-03-26 18:01:38,832][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:46,223][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 539 @ 4305 updates
[2024-03-26 18:01:46,224][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:48,697][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:48,761][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 539 @ 4305 updates, score None) (writing took 2.538507327903062 seconds)
[2024-03-26 18:01:48,762][fairseq_cli.train][INFO] - end of epoch 539 (average epoch stats below)
[2024-03-26 18:01:48,763][train][INFO] - {"epoch": 539, "train_loss": "0.996", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.057", "train_target_var": "0.755", "train_pred_var": "0.729", "train_masked_pct": "0.501", "train_wps": "8610.8", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4305", "train_lr": "0.000403594", "train_gnorm": "2.154", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5527"}
[2024-03-26 18:01:48,765][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:48,826][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 540
[2024-03-26 18:01:48,828][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:48,831][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:48,836][fairseq.trainer][INFO] - begin training epoch 540
[2024-03-26 18:01:48,837][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:01:56,369][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:01:56,370][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:56,432][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 109
[2024-03-26 18:01:56,436][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:56,850][valid][INFO] - {"epoch": 540, "valid_loss": "1.043", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.057", "valid_target_var": "0.76", "valid_pred_var": "0.737", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "4313", "valid_best_loss": "0.222"}
[2024-03-26 18:01:56,852][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 540 @ 4313 updates
[2024-03-26 18:01:56,853][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:59,364][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:01:59,424][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 540 @ 4313 updates, score 1.043) (writing took 2.5720145059749484 seconds)
[2024-03-26 18:01:59,424][fairseq_cli.train][INFO] - end of epoch 540 (average epoch stats below)
[2024-03-26 18:01:59,425][train][INFO] - {"epoch": 540, "train_loss": "1.007", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.057", "train_target_var": "0.757", "train_pred_var": "0.732", "train_masked_pct": "0.498", "train_wps": "8081.1", "train_ups": "0.75", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4313", "train_lr": "0.000404344", "train_gnorm": "2.045", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5537"}
[2024-03-26 18:01:59,427][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:01:59,489][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 541
[2024-03-26 18:01:59,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:01:59,494][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:01:59,498][fairseq.trainer][INFO] - begin training epoch 541
[2024-03-26 18:01:59,499][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:06,861][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 541 @ 4321 updates
[2024-03-26 18:02:06,862][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:09,354][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:09,419][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 541 @ 4321 updates, score None) (writing took 2.558581833727658 seconds)
[2024-03-26 18:02:09,420][fairseq_cli.train][INFO] - end of epoch 541 (average epoch stats below)
[2024-03-26 18:02:09,421][train][INFO] - {"epoch": 541, "train_loss": "0.969", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.057", "train_target_var": "0.757", "train_pred_var": "0.734", "train_masked_pct": "0.499", "train_wps": "8619.5", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4321", "train_lr": "0.000405094", "train_gnorm": "2.228", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5547"}
[2024-03-26 18:02:09,423][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:09,487][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 542
[2024-03-26 18:02:09,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:02:09,493][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:09,497][fairseq.trainer][INFO] - begin training epoch 542
[2024-03-26 18:02:09,498][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:16,865][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 542 @ 4329 updates
[2024-03-26 18:02:16,866][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:19,354][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:19,389][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 542 @ 4329 updates, score None) (writing took 2.5243903268128633 seconds)
[2024-03-26 18:02:19,390][fairseq_cli.train][INFO] - end of epoch 542 (average epoch stats below)
[2024-03-26 18:02:19,390][train][INFO] - {"epoch": 542, "train_loss": "1.029", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.057", "train_target_var": "0.756", "train_pred_var": "0.729", "train_masked_pct": "0.499", "train_wps": "8642.4", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4329", "train_lr": "0.000405844", "train_gnorm": "2.327", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5557"}
[2024-03-26 18:02:19,392][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:19,482][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 543
[2024-03-26 18:02:19,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:02:19,486][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:19,491][fairseq.trainer][INFO] - begin training epoch 543
[2024-03-26 18:02:19,492][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:26,953][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 543 @ 4337 updates
[2024-03-26 18:02:26,955][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:29,421][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:29,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 543 @ 4337 updates, score None) (writing took 2.506489123683423 seconds)
[2024-03-26 18:02:29,461][fairseq_cli.train][INFO] - end of epoch 543 (average epoch stats below)
[2024-03-26 18:02:29,461][train][INFO] - {"epoch": 543, "train_loss": "1.053", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.057", "train_target_var": "0.759", "train_pred_var": "0.732", "train_masked_pct": "0.5", "train_wps": "8554.6", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4337", "train_lr": "0.000406594", "train_gnorm": "1.984", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5567"}
[2024-03-26 18:02:29,463][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:29,553][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 544
[2024-03-26 18:02:29,554][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:02:29,557][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:29,562][fairseq.trainer][INFO] - begin training epoch 544
[2024-03-26 18:02:29,563][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:36,921][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 544 @ 4345 updates
[2024-03-26 18:02:36,923][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:39,393][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:39,456][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 544 @ 4345 updates, score None) (writing took 2.5344557329081 seconds)
[2024-03-26 18:02:39,456][fairseq_cli.train][INFO] - end of epoch 544 (average epoch stats below)
[2024-03-26 18:02:39,457][train][INFO] - {"epoch": 544, "train_loss": "1.011", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.057", "train_target_var": "0.757", "train_pred_var": "0.731", "train_masked_pct": "0.499", "train_wps": "8619.7", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4345", "train_lr": "0.000407344", "train_gnorm": "2.193", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5577"}
[2024-03-26 18:02:39,459][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:39,520][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 545
[2024-03-26 18:02:39,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:02:39,525][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:39,530][fairseq.trainer][INFO] - begin training epoch 545
[2024-03-26 18:02:39,530][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:46,932][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:02:46,934][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:46,999][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 110
[2024-03-26 18:02:47,002][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:47,423][valid][INFO] - {"epoch": 545, "valid_loss": "1.124", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.057", "valid_target_var": "0.757", "valid_pred_var": "0.735", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "4353", "valid_best_loss": "0.222"}
[2024-03-26 18:02:47,425][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 545 @ 4353 updates
[2024-03-26 18:02:47,426][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:49,966][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:02:50,031][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 545 @ 4353 updates, score 1.124) (writing took 2.6062712627463043 seconds)
[2024-03-26 18:02:50,032][fairseq_cli.train][INFO] - end of epoch 545 (average epoch stats below)
[2024-03-26 18:02:50,032][train][INFO] - {"epoch": 545, "train_loss": "1.046", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.057", "train_target_var": "0.759", "train_pred_var": "0.733", "train_masked_pct": "0.5", "train_wps": "8147.4", "train_ups": "0.76", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4353", "train_lr": "0.000408094", "train_gnorm": "2.23", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5588"}
[2024-03-26 18:02:50,036][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:02:50,098][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 546
[2024-03-26 18:02:50,100][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:02:50,103][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:02:50,108][fairseq.trainer][INFO] - begin training epoch 546
[2024-03-26 18:02:50,108][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:02:57,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 546 @ 4361 updates
[2024-03-26 18:02:57,507][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:00,024][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:00,089][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 546 @ 4361 updates, score None) (writing took 2.583892517723143 seconds)
[2024-03-26 18:03:00,090][fairseq_cli.train][INFO] - end of epoch 546 (average epoch stats below)
[2024-03-26 18:03:00,091][train][INFO] - {"epoch": 546, "train_loss": "1.053", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.058", "train_target_var": "0.755", "train_pred_var": "0.728", "train_masked_pct": "0.501", "train_wps": "8566.2", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4361", "train_lr": "0.000408844", "train_gnorm": "1.972", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5598"}
[2024-03-26 18:03:00,093][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:00,157][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 547
[2024-03-26 18:03:00,159][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:00,162][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:00,167][fairseq.trainer][INFO] - begin training epoch 547
[2024-03-26 18:03:00,168][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:07,561][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 547 @ 4369 updates
[2024-03-26 18:03:07,563][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:10,070][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:10,136][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 547 @ 4369 updates, score None) (writing took 2.5750414286740124 seconds)
[2024-03-26 18:03:10,136][fairseq_cli.train][INFO] - end of epoch 547 (average epoch stats below)
[2024-03-26 18:03:10,137][train][INFO] - {"epoch": 547, "train_loss": "1.014", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.058", "train_target_var": "0.757", "train_pred_var": "0.731", "train_masked_pct": "0.499", "train_wps": "8575.9", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4369", "train_lr": "0.000409594", "train_gnorm": "1.767", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5608"}
[2024-03-26 18:03:10,139][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:10,202][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 548
[2024-03-26 18:03:10,203][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:10,207][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:10,212][fairseq.trainer][INFO] - begin training epoch 548
[2024-03-26 18:03:10,212][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:17,667][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 548 @ 4377 updates
[2024-03-26 18:03:17,668][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:20,167][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:20,230][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 548 @ 4377 updates, score None) (writing took 2.563077056314796 seconds)
[2024-03-26 18:03:20,231][fairseq_cli.train][INFO] - end of epoch 548 (average epoch stats below)
[2024-03-26 18:03:20,231][train][INFO] - {"epoch": 548, "train_loss": "1.025", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.058", "train_target_var": "0.758", "train_pred_var": "0.73", "train_masked_pct": "0.499", "train_wps": "8535.2", "train_ups": "0.79", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4377", "train_lr": "0.000410344", "train_gnorm": "1.951", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "5618"}
[2024-03-26 18:03:20,233][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:20,296][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 549
[2024-03-26 18:03:20,297][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:20,300][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:20,305][fairseq.trainer][INFO] - begin training epoch 549
[2024-03-26 18:03:20,306][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:27,703][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 549 @ 4385 updates
[2024-03-26 18:03:27,705][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:30,198][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:30,240][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 549 @ 4385 updates, score None) (writing took 2.536258011125028 seconds)
[2024-03-26 18:03:30,240][fairseq_cli.train][INFO] - end of epoch 549 (average epoch stats below)
[2024-03-26 18:03:30,241][train][INFO] - {"epoch": 549, "train_loss": "1.03", "train_ntokens": "10770.5", "train_nsentences": "22.875", "train_sample_size": "10770.5", "train_ema_decay": "999.058", "train_target_var": "0.755", "train_pred_var": "0.731", "train_masked_pct": "0.501", "train_wps": "8608.3", "train_ups": "0.8", "train_wpb": "10770.5", "train_bsz": "22.9", "train_num_updates": "4385", "train_lr": "0.000411094", "train_gnorm": "2.023", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5628"}
[2024-03-26 18:03:30,243][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:30,350][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 550
[2024-03-26 18:03:30,352][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:30,355][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:30,360][fairseq.trainer][INFO] - begin training epoch 550
[2024-03-26 18:03:30,360][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:37,745][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:03:37,746][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:37,822][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 111
[2024-03-26 18:03:37,826][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:38,236][valid][INFO] - {"epoch": 550, "valid_loss": "1.169", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.058", "valid_target_var": "0.763", "valid_pred_var": "0.741", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "4393", "valid_best_loss": "0.222"}
[2024-03-26 18:03:38,238][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 550 @ 4393 updates
[2024-03-26 18:03:38,239][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:40,831][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:40,890][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 550 @ 4393 updates, score 1.169) (writing took 2.6518277768045664 seconds)
[2024-03-26 18:03:40,890][fairseq_cli.train][INFO] - end of epoch 550 (average epoch stats below)
[2024-03-26 18:03:40,891][train][INFO] - {"epoch": 550, "train_loss": "1.007", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.058", "train_target_var": "0.757", "train_pred_var": "0.731", "train_masked_pct": "0.498", "train_wps": "8090.7", "train_ups": "0.75", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4393", "train_lr": "0.000411844", "train_gnorm": "2.156", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5639"}
[2024-03-26 18:03:40,893][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:40,955][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 551
[2024-03-26 18:03:40,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:40,960][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:40,965][fairseq.trainer][INFO] - begin training epoch 551
[2024-03-26 18:03:40,966][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:47,460][train_inner][INFO] - {"epoch": 551, "update": 550.875, "loss": "1.018", "ntokens": "10769.2", "nsentences": "22.875", "sample_size": "10769.2", "ema_decay": "999.057", "target_var": "0.758", "pred_var": "0.731", "masked_pct": "0.5", "wps": "8523.2", "ups": "0.79", "wpb": "10769.2", "bsz": "22.9", "num_updates": "4400", "lr": "0.0004125", "gnorm": "2.256", "loss_scale": "1", "train_wall": "177", "gb_free": "5.1", "wall": "5645"}
[2024-03-26 18:03:48,435][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 551 @ 4401 updates
[2024-03-26 18:03:48,436][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:50,925][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:03:50,988][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 551 @ 4401 updates, score None) (writing took 2.5537223778665066 seconds)
[2024-03-26 18:03:50,989][fairseq_cli.train][INFO] - end of epoch 551 (average epoch stats below)
[2024-03-26 18:03:50,990][train][INFO] - {"epoch": 551, "train_loss": "1.078", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.058", "train_target_var": "0.757", "train_pred_var": "0.729", "train_masked_pct": "0.5", "train_wps": "8531.3", "train_ups": "0.79", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "4401", "train_lr": "0.000412594", "train_gnorm": "2.51", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5649"}
[2024-03-26 18:03:50,992][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:03:51,056][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 552
[2024-03-26 18:03:51,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:03:51,061][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:03:51,066][fairseq.trainer][INFO] - begin training epoch 552
[2024-03-26 18:03:51,066][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:03:58,276][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 552 @ 4409 updates
[2024-03-26 18:03:58,277][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:00,768][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:00,803][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 552 @ 4409 updates, score None) (writing took 2.5271033090539277 seconds)
[2024-03-26 18:04:00,803][fairseq_cli.train][INFO] - end of epoch 552 (average epoch stats below)
[2024-03-26 18:04:00,804][train][INFO] - {"epoch": 552, "train_loss": "1.027", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.058", "train_target_var": "0.758", "train_pred_var": "0.733", "train_masked_pct": "0.5", "train_wps": "8778.8", "train_ups": "0.82", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4409", "train_lr": "0.000413344", "train_gnorm": "2.176", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5659"}
[2024-03-26 18:04:00,806][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:00,898][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 553
[2024-03-26 18:04:00,900][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:00,903][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:00,907][fairseq.trainer][INFO] - begin training epoch 553
[2024-03-26 18:04:00,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:08,243][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 553 @ 4417 updates
[2024-03-26 18:04:08,244][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:10,730][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:10,793][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 553 @ 4417 updates, score None) (writing took 2.5494272368960083 seconds)
[2024-03-26 18:04:10,794][fairseq_cli.train][INFO] - end of epoch 553 (average epoch stats below)
[2024-03-26 18:04:10,794][train][INFO] - {"epoch": 553, "train_loss": "0.99", "train_ntokens": "10770.8", "train_nsentences": "22.875", "train_sample_size": "10770.8", "train_ema_decay": "999.058", "train_target_var": "0.755", "train_pred_var": "0.729", "train_masked_pct": "0.5", "train_wps": "8625.5", "train_ups": "0.8", "train_wpb": "10770.8", "train_bsz": "22.9", "train_num_updates": "4417", "train_lr": "0.000414094", "train_gnorm": "2.38", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5669"}
[2024-03-26 18:04:10,796][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:10,858][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 554
[2024-03-26 18:04:10,860][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:10,863][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:10,868][fairseq.trainer][INFO] - begin training epoch 554
[2024-03-26 18:04:10,868][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:18,223][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 554 @ 4425 updates
[2024-03-26 18:04:18,224][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:20,714][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:20,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 554 @ 4425 updates, score None) (writing took 2.556630990933627 seconds)
[2024-03-26 18:04:20,780][fairseq_cli.train][INFO] - end of epoch 554 (average epoch stats below)
[2024-03-26 18:04:20,780][train][INFO] - {"epoch": 554, "train_loss": "1.091", "train_ntokens": "10770.5", "train_nsentences": "22.875", "train_sample_size": "10770.5", "train_ema_decay": "999.058", "train_target_var": "0.756", "train_pred_var": "0.728", "train_masked_pct": "0.499", "train_wps": "8628.8", "train_ups": "0.8", "train_wpb": "10770.5", "train_bsz": "22.9", "train_num_updates": "4425", "train_lr": "0.000414844", "train_gnorm": "2.437", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5679"}
[2024-03-26 18:04:20,782][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:20,844][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 555
[2024-03-26 18:04:20,846][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:20,849][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:20,854][fairseq.trainer][INFO] - begin training epoch 555
[2024-03-26 18:04:20,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:28,290][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:04:28,291][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:28,354][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 112
[2024-03-26 18:04:28,358][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:28,777][valid][INFO] - {"epoch": 555, "valid_loss": "1.065", "valid_ntokens": "11703", "valid_nsentences": "25", "valid_sample_size": "11703", "valid_ema_decay": "999.059", "valid_target_var": "0.758", "valid_pred_var": "0.731", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11703", "valid_bsz": "25", "valid_num_updates": "4433", "valid_best_loss": "0.222"}
[2024-03-26 18:04:28,778][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 555 @ 4433 updates
[2024-03-26 18:04:28,780][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:31,285][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:31,348][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 555 @ 4433 updates, score 1.065) (writing took 2.5697773960419 seconds)
[2024-03-26 18:04:31,349][fairseq_cli.train][INFO] - end of epoch 555 (average epoch stats below)
[2024-03-26 18:04:31,349][train][INFO] - {"epoch": 555, "train_loss": "1.013", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.058", "train_target_var": "0.755", "train_pred_var": "0.729", "train_masked_pct": "0.499", "train_wps": "8151.6", "train_ups": "0.76", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4433", "train_lr": "0.000415594", "train_gnorm": "2.066", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5689"}
[2024-03-26 18:04:31,351][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:31,413][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 556
[2024-03-26 18:04:31,415][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:31,418][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:31,423][fairseq.trainer][INFO] - begin training epoch 556
[2024-03-26 18:04:31,424][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:38,912][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 556 @ 4441 updates
[2024-03-26 18:04:38,913][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:41,414][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:41,479][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 556 @ 4441 updates, score None) (writing took 2.567133683245629 seconds)
[2024-03-26 18:04:41,479][fairseq_cli.train][INFO] - end of epoch 556 (average epoch stats below)
[2024-03-26 18:04:41,480][train][INFO] - {"epoch": 556, "train_loss": "1.043", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.059", "train_target_var": "0.756", "train_pred_var": "0.729", "train_masked_pct": "0.5", "train_wps": "8505.1", "train_ups": "0.79", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4441", "train_lr": "0.000416344", "train_gnorm": "2.595", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5699"}
[2024-03-26 18:04:41,482][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:41,547][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 557
[2024-03-26 18:04:41,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:41,552][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:41,556][fairseq.trainer][INFO] - begin training epoch 557
[2024-03-26 18:04:41,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:48,949][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 557 @ 4449 updates
[2024-03-26 18:04:48,951][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:51,475][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:04:51,538][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 557 @ 4449 updates, score None) (writing took 2.5889734509401023 seconds)
[2024-03-26 18:04:51,539][fairseq_cli.train][INFO] - end of epoch 557 (average epoch stats below)
[2024-03-26 18:04:51,540][train][INFO] - {"epoch": 557, "train_loss": "1.153", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.059", "train_target_var": "0.754", "train_pred_var": "0.724", "train_masked_pct": "0.5", "train_wps": "8565", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4449", "train_lr": "0.000417094", "train_gnorm": "2.719", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5709"}
[2024-03-26 18:04:51,542][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:04:51,606][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 558
[2024-03-26 18:04:51,607][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:04:51,610][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:04:51,615][fairseq.trainer][INFO] - begin training epoch 558
[2024-03-26 18:04:51,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:04:59,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 558 @ 4457 updates
[2024-03-26 18:04:59,165][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:01,656][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:01,719][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 558 @ 4457 updates, score None) (writing took 2.555703056976199 seconds)
[2024-03-26 18:05:01,719][fairseq_cli.train][INFO] - end of epoch 558 (average epoch stats below)
[2024-03-26 18:05:01,720][train][INFO] - {"epoch": 558, "train_loss": "1.053", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.059", "train_target_var": "0.755", "train_pred_var": "0.728", "train_masked_pct": "0.499", "train_wps": "8463", "train_ups": "0.79", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4457", "train_lr": "0.000417844", "train_gnorm": "2.265", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5720"}
[2024-03-26 18:05:01,722][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:01,786][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 559
[2024-03-26 18:05:01,787][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:01,790][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:01,795][fairseq.trainer][INFO] - begin training epoch 559
[2024-03-26 18:05:01,796][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:09,166][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 559 @ 4465 updates
[2024-03-26 18:05:09,167][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:11,630][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:11,696][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 559 @ 4465 updates, score None) (writing took 2.530616152100265 seconds)
[2024-03-26 18:05:11,697][fairseq_cli.train][INFO] - end of epoch 559 (average epoch stats below)
[2024-03-26 18:05:11,698][train][INFO] - {"epoch": 559, "train_loss": "1.015", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.059", "train_target_var": "0.758", "train_pred_var": "0.731", "train_masked_pct": "0.498", "train_wps": "8634.7", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "4465", "train_lr": "0.000418594", "train_gnorm": "2.003", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5730"}
[2024-03-26 18:05:11,700][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:11,764][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 560
[2024-03-26 18:05:11,766][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:11,769][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:11,774][fairseq.trainer][INFO] - begin training epoch 560
[2024-03-26 18:05:11,775][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:19,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:05:19,069][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:19,133][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 113
[2024-03-26 18:05:19,136][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:19,547][valid][INFO] - {"epoch": 560, "valid_loss": "1.047", "valid_ntokens": "11702", "valid_nsentences": "25", "valid_sample_size": "11702", "valid_ema_decay": "999.059", "valid_target_var": "0.762", "valid_pred_var": "0.733", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11702", "valid_bsz": "25", "valid_num_updates": "4473", "valid_best_loss": "0.222"}
[2024-03-26 18:05:19,549][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 560 @ 4473 updates
[2024-03-26 18:05:19,550][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:22,061][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:22,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 560 @ 4473 updates, score 1.047) (writing took 2.547561027109623 seconds)
[2024-03-26 18:05:22,097][fairseq_cli.train][INFO] - end of epoch 560 (average epoch stats below)
[2024-03-26 18:05:22,098][train][INFO] - {"epoch": 560, "train_loss": "1.02", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.059", "train_target_var": "0.755", "train_pred_var": "0.731", "train_masked_pct": "0.5", "train_wps": "8284.8", "train_ups": "0.77", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4473", "train_lr": "0.000419344", "train_gnorm": "2.402", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5740"}
[2024-03-26 18:05:22,100][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:22,203][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 561
[2024-03-26 18:05:22,205][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:22,208][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:22,213][fairseq.trainer][INFO] - begin training epoch 561
[2024-03-26 18:05:22,213][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:29,543][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 561 @ 4481 updates
[2024-03-26 18:05:29,545][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:32,018][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:32,081][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 561 @ 4481 updates, score None) (writing took 2.5379613069817424 seconds)
[2024-03-26 18:05:32,082][fairseq_cli.train][INFO] - end of epoch 561 (average epoch stats below)
[2024-03-26 18:05:32,082][train][INFO] - {"epoch": 561, "train_loss": "1.047", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.059", "train_target_var": "0.754", "train_pred_var": "0.728", "train_masked_pct": "0.498", "train_wps": "8628.5", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4481", "train_lr": "0.000420094", "train_gnorm": "2.429", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5750"}
[2024-03-26 18:05:32,085][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:32,148][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 562
[2024-03-26 18:05:32,149][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:32,152][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:32,157][fairseq.trainer][INFO] - begin training epoch 562
[2024-03-26 18:05:32,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:39,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 562 @ 4489 updates
[2024-03-26 18:05:39,446][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:41,961][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:42,027][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 562 @ 4489 updates, score None) (writing took 2.58230960322544 seconds)
[2024-03-26 18:05:42,028][fairseq_cli.train][INFO] - end of epoch 562 (average epoch stats below)
[2024-03-26 18:05:42,028][train][INFO] - {"epoch": 562, "train_loss": "1.129", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.059", "train_target_var": "0.756", "train_pred_var": "0.728", "train_masked_pct": "0.501", "train_wps": "8663.4", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4489", "train_lr": "0.000420844", "train_gnorm": "2.861", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "5760"}
[2024-03-26 18:05:42,030][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:42,096][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 563
[2024-03-26 18:05:42,097][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:42,101][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:42,106][fairseq.trainer][INFO] - begin training epoch 563
[2024-03-26 18:05:42,106][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:49,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 563 @ 4497 updates
[2024-03-26 18:05:49,280][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:51,786][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:05:51,850][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 563 @ 4497 updates, score None) (writing took 2.571338275913149 seconds)
[2024-03-26 18:05:51,850][fairseq_cli.train][INFO] - end of epoch 563 (average epoch stats below)
[2024-03-26 18:05:51,851][train][INFO] - {"epoch": 563, "train_loss": "1.096", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.059", "train_target_var": "0.755", "train_pred_var": "0.725", "train_masked_pct": "0.501", "train_wps": "8771.9", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4497", "train_lr": "0.000421594", "train_gnorm": "2.235", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "5770"}
[2024-03-26 18:05:51,853][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:05:51,915][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 564
[2024-03-26 18:05:51,917][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:05:51,920][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:05:51,925][fairseq.trainer][INFO] - begin training epoch 564
[2024-03-26 18:05:51,926][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:05:59,143][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 564 @ 4505 updates
[2024-03-26 18:05:59,145][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:01,636][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:01,698][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 564 @ 4505 updates, score None) (writing took 2.554198184981942 seconds)
[2024-03-26 18:06:01,698][fairseq_cli.train][INFO] - end of epoch 564 (average epoch stats below)
[2024-03-26 18:06:01,699][train][INFO] - {"epoch": 564, "train_loss": "1.144", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.059", "train_target_var": "0.757", "train_pred_var": "0.73", "train_masked_pct": "0.499", "train_wps": "8748.7", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4505", "train_lr": "0.000422344", "train_gnorm": "2.653", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5780"}
[2024-03-26 18:06:01,701][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:01,762][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 565
[2024-03-26 18:06:01,764][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:01,767][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:01,772][fairseq.trainer][INFO] - begin training epoch 565
[2024-03-26 18:06:01,772][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:09,026][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:06:09,027][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:09,091][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 114
[2024-03-26 18:06:09,094][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:09,507][valid][INFO] - {"epoch": 565, "valid_loss": "1.32", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.06", "valid_target_var": "0.762", "valid_pred_var": "0.734", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "4513", "valid_best_loss": "0.222"}
[2024-03-26 18:06:09,508][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 565 @ 4513 updates
[2024-03-26 18:06:09,510][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:12,096][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:12,131][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 565 @ 4513 updates, score 1.32) (writing took 2.6223891768604517 seconds)
[2024-03-26 18:06:12,131][fairseq_cli.train][INFO] - end of epoch 565 (average epoch stats below)
[2024-03-26 18:06:12,132][train][INFO] - {"epoch": 565, "train_loss": "1.182", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.727", "train_masked_pct": "0.501", "train_wps": "8258.9", "train_ups": "0.77", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "4513", "train_lr": "0.000423094", "train_gnorm": "2.606", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5790"}
[2024-03-26 18:06:12,135][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:12,222][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 566
[2024-03-26 18:06:12,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:12,227][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:12,232][fairseq.trainer][INFO] - begin training epoch 566
[2024-03-26 18:06:12,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:19,480][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 566 @ 4521 updates
[2024-03-26 18:06:19,481][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:21,980][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:22,045][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 566 @ 4521 updates, score None) (writing took 2.5646821693517268 seconds)
[2024-03-26 18:06:22,045][fairseq_cli.train][INFO] - end of epoch 566 (average epoch stats below)
[2024-03-26 18:06:22,047][train][INFO] - {"epoch": 566, "train_loss": "1.07", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.06", "train_target_var": "0.756", "train_pred_var": "0.728", "train_masked_pct": "0.499", "train_wps": "8689.9", "train_ups": "0.81", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4521", "train_lr": "0.000423844", "train_gnorm": "2.41", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5800"}
[2024-03-26 18:06:22,049][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:22,113][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 567
[2024-03-26 18:06:22,115][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:22,118][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:22,123][fairseq.trainer][INFO] - begin training epoch 567
[2024-03-26 18:06:22,124][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:29,532][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 567 @ 4529 updates
[2024-03-26 18:06:29,533][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:32,024][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:32,087][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 567 @ 4529 updates, score None) (writing took 2.5553154200315475 seconds)
[2024-03-26 18:06:32,088][fairseq_cli.train][INFO] - end of epoch 567 (average epoch stats below)
[2024-03-26 18:06:32,088][train][INFO] - {"epoch": 567, "train_loss": "1.123", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.06", "train_target_var": "0.755", "train_pred_var": "0.727", "train_masked_pct": "0.5", "train_wps": "8580.2", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4529", "train_lr": "0.000424594", "train_gnorm": "2.383", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5810"}
[2024-03-26 18:06:32,091][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:32,152][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 568
[2024-03-26 18:06:32,154][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:32,157][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:32,162][fairseq.trainer][INFO] - begin training epoch 568
[2024-03-26 18:06:32,163][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:39,318][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 568 @ 4537 updates
[2024-03-26 18:06:39,320][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:41,812][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:41,875][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 568 @ 4537 updates, score None) (writing took 2.5570955709554255 seconds)
[2024-03-26 18:06:41,876][fairseq_cli.train][INFO] - end of epoch 568 (average epoch stats below)
[2024-03-26 18:06:41,877][train][INFO] - {"epoch": 568, "train_loss": "1.14", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.06", "train_target_var": "0.755", "train_pred_var": "0.725", "train_masked_pct": "0.499", "train_wps": "8802.8", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4537", "train_lr": "0.000425344", "train_gnorm": "2.252", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5820"}
[2024-03-26 18:06:41,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:41,940][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 569
[2024-03-26 18:06:41,942][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:41,945][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:41,950][fairseq.trainer][INFO] - begin training epoch 569
[2024-03-26 18:06:41,950][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:49,236][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 569 @ 4545 updates
[2024-03-26 18:06:49,238][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:51,731][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:06:51,797][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 569 @ 4545 updates, score None) (writing took 2.5608766563236713 seconds)
[2024-03-26 18:06:51,798][fairseq_cli.train][INFO] - end of epoch 569 (average epoch stats below)
[2024-03-26 18:06:51,798][train][INFO] - {"epoch": 569, "train_loss": "1.087", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.06", "train_target_var": "0.756", "train_pred_var": "0.726", "train_masked_pct": "0.499", "train_wps": "8684.1", "train_ups": "0.81", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4545", "train_lr": "0.000426094", "train_gnorm": "3.155", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5830"}
[2024-03-26 18:06:51,800][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:51,863][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 570
[2024-03-26 18:06:51,864][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:06:51,867][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:51,872][fairseq.trainer][INFO] - begin training epoch 570
[2024-03-26 18:06:51,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:06:59,207][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:06:59,208][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:06:59,273][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 115
[2024-03-26 18:06:59,276][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:06:59,694][valid][INFO] - {"epoch": 570, "valid_loss": "0.996", "valid_ntokens": "11722", "valid_nsentences": "25", "valid_sample_size": "11722", "valid_ema_decay": "999.06", "valid_target_var": "0.758", "valid_pred_var": "0.728", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11722", "valid_bsz": "25", "valid_num_updates": "4553", "valid_best_loss": "0.222"}
[2024-03-26 18:06:59,696][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 570 @ 4553 updates
[2024-03-26 18:06:59,697][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:02,211][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:02,251][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 570 @ 4553 updates, score 0.996) (writing took 2.5550905680283904 seconds)
[2024-03-26 18:07:02,252][fairseq_cli.train][INFO] - end of epoch 570 (average epoch stats below)
[2024-03-26 18:07:02,252][train][INFO] - {"epoch": 570, "train_loss": "1.066", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.731", "train_masked_pct": "0.5", "train_wps": "8242", "train_ups": "0.77", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4553", "train_lr": "0.000426844", "train_gnorm": "2.724", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5840"}
[2024-03-26 18:07:02,255][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:02,342][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 571
[2024-03-26 18:07:02,344][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:02,347][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:02,352][fairseq.trainer][INFO] - begin training epoch 571
[2024-03-26 18:07:02,352][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:09,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 571 @ 4561 updates
[2024-03-26 18:07:09,484][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:11,983][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:12,024][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 571 @ 4561 updates, score None) (writing took 2.541288558859378 seconds)
[2024-03-26 18:07:12,024][fairseq_cli.train][INFO] - end of epoch 571 (average epoch stats below)
[2024-03-26 18:07:12,025][train][INFO] - {"epoch": 571, "train_loss": "1.077", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.729", "train_masked_pct": "0.501", "train_wps": "8817", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4561", "train_lr": "0.000427594", "train_gnorm": "2.841", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5850"}
[2024-03-26 18:07:12,027][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:12,117][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 572
[2024-03-26 18:07:12,119][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:12,121][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:12,125][fairseq.trainer][INFO] - begin training epoch 572
[2024-03-26 18:07:12,126][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:19,538][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 572 @ 4569 updates
[2024-03-26 18:07:19,540][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:22,050][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:22,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 572 @ 4569 updates, score None) (writing took 2.558276331052184 seconds)
[2024-03-26 18:07:22,097][fairseq_cli.train][INFO] - end of epoch 572 (average epoch stats below)
[2024-03-26 18:07:22,098][train][INFO] - {"epoch": 572, "train_loss": "1.12", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.728", "train_masked_pct": "0.499", "train_wps": "8553.8", "train_ups": "0.79", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4569", "train_lr": "0.000428344", "train_gnorm": "3.006", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "5860"}
[2024-03-26 18:07:22,100][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:22,183][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 573
[2024-03-26 18:07:22,184][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:22,188][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:22,193][fairseq.trainer][INFO] - begin training epoch 573
[2024-03-26 18:07:22,193][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:29,651][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 573 @ 4577 updates
[2024-03-26 18:07:29,652][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:32,138][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:32,190][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 573 @ 4577 updates, score None) (writing took 2.539491763804108 seconds)
[2024-03-26 18:07:32,191][fairseq_cli.train][INFO] - end of epoch 573 (average epoch stats below)
[2024-03-26 18:07:32,192][train][INFO] - {"epoch": 573, "train_loss": "1.061", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.729", "train_masked_pct": "0.5", "train_wps": "8536.2", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "4577", "train_lr": "0.000429094", "train_gnorm": "2.479", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5870"}
[2024-03-26 18:07:32,194][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:32,271][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 574
[2024-03-26 18:07:32,272][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:32,275][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:32,280][fairseq.trainer][INFO] - begin training epoch 574
[2024-03-26 18:07:32,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:39,593][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 574 @ 4585 updates
[2024-03-26 18:07:39,594][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:42,073][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:42,131][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 574 @ 4585 updates, score None) (writing took 2.53765642689541 seconds)
[2024-03-26 18:07:42,132][fairseq_cli.train][INFO] - end of epoch 574 (average epoch stats below)
[2024-03-26 18:07:42,132][train][INFO] - {"epoch": 574, "train_loss": "1.081", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.06", "train_target_var": "0.757", "train_pred_var": "0.73", "train_masked_pct": "0.499", "train_wps": "8666.9", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4585", "train_lr": "0.000429844", "train_gnorm": "2.209", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5880"}
[2024-03-26 18:07:42,134][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:42,205][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 575
[2024-03-26 18:07:42,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:42,210][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:42,214][fairseq.trainer][INFO] - begin training epoch 575
[2024-03-26 18:07:42,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:49,605][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:07:49,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:49,671][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 116
[2024-03-26 18:07:49,674][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:50,093][valid][INFO] - {"epoch": 575, "valid_loss": "1.079", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.061", "valid_target_var": "0.759", "valid_pred_var": "0.722", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "4593", "valid_best_loss": "0.222"}
[2024-03-26 18:07:50,095][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 575 @ 4593 updates
[2024-03-26 18:07:50,096][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:52,606][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:07:52,656][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 575 @ 4593 updates, score 1.079) (writing took 2.560958266723901 seconds)
[2024-03-26 18:07:52,656][fairseq_cli.train][INFO] - end of epoch 575 (average epoch stats below)
[2024-03-26 18:07:52,657][train][INFO] - {"epoch": 575, "train_loss": "1.123", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.061", "train_target_var": "0.753", "train_pred_var": "0.722", "train_masked_pct": "0.499", "train_wps": "8187", "train_ups": "0.76", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4593", "train_lr": "0.000430594", "train_gnorm": "2.367", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5890"}
[2024-03-26 18:07:52,659][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:07:52,729][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 576
[2024-03-26 18:07:52,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:07:52,733][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:07:52,738][fairseq.trainer][INFO] - begin training epoch 576
[2024-03-26 18:07:52,739][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:07:59,172][train_inner][INFO] - {"epoch": 576, "update": 575.875, "loss": "1.082", "ntokens": "10769.3", "nsentences": "22.875", "sample_size": "10769.3", "ema_decay": "999.059", "target_var": "0.756", "pred_var": "0.728", "masked_pct": "0.5", "wps": "8556.9", "ups": "0.79", "wpb": "10769.3", "bsz": "22.9", "num_updates": "4600", "lr": "0.00043125", "gnorm": "2.467", "loss_scale": "1", "train_wall": "177", "gb_free": "5.1", "wall": "5897"}
[2024-03-26 18:08:00,191][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 576 @ 4601 updates
[2024-03-26 18:08:00,192][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:02,695][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:02,760][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 576 @ 4601 updates, score None) (writing took 2.569342138245702 seconds)
[2024-03-26 18:08:02,761][fairseq_cli.train][INFO] - end of epoch 576 (average epoch stats below)
[2024-03-26 18:08:02,761][train][INFO] - {"epoch": 576, "train_loss": "1.083", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.061", "train_target_var": "0.755", "train_pred_var": "0.727", "train_masked_pct": "0.499", "train_wps": "8527.3", "train_ups": "0.79", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "4601", "train_lr": "0.000431344", "train_gnorm": "1.959", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5901"}
[2024-03-26 18:08:02,764][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:02,829][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 577
[2024-03-26 18:08:02,831][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:02,834][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:02,839][fairseq.trainer][INFO] - begin training epoch 577
[2024-03-26 18:08:02,839][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:08:10,152][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 577 @ 4609 updates
[2024-03-26 18:08:10,153][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:12,676][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:12,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 577 @ 4609 updates, score None) (writing took 2.55976600619033 seconds)
[2024-03-26 18:08:12,712][fairseq_cli.train][INFO] - end of epoch 577 (average epoch stats below)
[2024-03-26 18:08:12,713][train][INFO] - {"epoch": 577, "train_loss": "1.032", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.061", "train_target_var": "0.753", "train_pred_var": "0.728", "train_masked_pct": "0.501", "train_wps": "8657.9", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4609", "train_lr": "0.000432094", "train_gnorm": "1.988", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5911"}
[2024-03-26 18:08:12,715][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:12,803][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 578
[2024-03-26 18:08:12,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:12,808][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:12,813][fairseq.trainer][INFO] - begin training epoch 578
[2024-03-26 18:08:12,813][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:08:20,178][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 578 @ 4617 updates
[2024-03-26 18:08:20,179][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:22,673][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:22,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 578 @ 4617 updates, score None) (writing took 2.559589078184217 seconds)
[2024-03-26 18:08:22,738][fairseq_cli.train][INFO] - end of epoch 578 (average epoch stats below)
[2024-03-26 18:08:22,738][train][INFO] - {"epoch": 578, "train_loss": "1.108", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.061", "train_target_var": "0.755", "train_pred_var": "0.725", "train_masked_pct": "0.501", "train_wps": "8593.4", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4617", "train_lr": "0.000432844", "train_gnorm": "2.078", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5921"}
[2024-03-26 18:08:22,740][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:22,801][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 579
[2024-03-26 18:08:22,802][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:22,805][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:22,810][fairseq.trainer][INFO] - begin training epoch 579
[2024-03-26 18:08:22,811][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:08:30,168][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 579 @ 4625 updates
[2024-03-26 18:08:30,169][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:32,671][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:32,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 579 @ 4625 updates, score None) (writing took 2.569615739863366 seconds)
[2024-03-26 18:08:32,738][fairseq_cli.train][INFO] - end of epoch 579 (average epoch stats below)
[2024-03-26 18:08:32,739][train][INFO] - {"epoch": 579, "train_loss": "1.005", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.061", "train_target_var": "0.755", "train_pred_var": "0.73", "train_masked_pct": "0.499", "train_wps": "8615.3", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4625", "train_lr": "0.000433594", "train_gnorm": "2.104", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "5931"}
[2024-03-26 18:08:32,741][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:32,804][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 580
[2024-03-26 18:08:32,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:32,808][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:32,813][fairseq.trainer][INFO] - begin training epoch 580
[2024-03-26 18:08:32,814][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:08:40,268][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:08:40,270][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:40,336][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 117
[2024-03-26 18:08:40,340][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:40,751][valid][INFO] - {"epoch": 580, "valid_loss": "1.141", "valid_ntokens": "11715", "valid_nsentences": "25", "valid_sample_size": "11715", "valid_ema_decay": "999.061", "valid_target_var": "0.752", "valid_pred_var": "0.722", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11715", "valid_bsz": "25", "valid_num_updates": "4633", "valid_best_loss": "0.222"}
[2024-03-26 18:08:40,753][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 580 @ 4633 updates
[2024-03-26 18:08:40,754][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:43,257][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:43,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 580 @ 4633 updates, score 1.141) (writing took 2.5406235959380865 seconds)
[2024-03-26 18:08:43,294][fairseq_cli.train][INFO] - end of epoch 580 (average epoch stats below)
[2024-03-26 18:08:43,294][train][INFO] - {"epoch": 580, "train_loss": "1.037", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.061", "train_target_var": "0.754", "train_pred_var": "0.729", "train_masked_pct": "0.498", "train_wps": "8162.3", "train_ups": "0.76", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4633", "train_lr": "0.000434344", "train_gnorm": "1.88", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5941"}
[2024-03-26 18:08:43,296][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:43,389][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 581
[2024-03-26 18:08:43,391][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:43,394][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:43,399][fairseq.trainer][INFO] - begin training epoch 581
[2024-03-26 18:08:43,400][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:08:50,903][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 581 @ 4641 updates
[2024-03-26 18:08:50,905][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:53,402][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:08:53,458][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 581 @ 4641 updates, score None) (writing took 2.55500847985968 seconds)
[2024-03-26 18:08:53,459][fairseq_cli.train][INFO] - end of epoch 581 (average epoch stats below)
[2024-03-26 18:08:53,460][train][INFO] - {"epoch": 581, "train_loss": "1.072", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.061", "train_target_var": "0.752", "train_pred_var": "0.724", "train_masked_pct": "0.498", "train_wps": "8475.7", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4641", "train_lr": "0.000435094", "train_gnorm": "1.858", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5951"}
[2024-03-26 18:08:53,462][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:08:53,532][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 582
[2024-03-26 18:08:53,534][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:08:53,537][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:08:53,542][fairseq.trainer][INFO] - begin training epoch 582
[2024-03-26 18:08:53,542][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:01,022][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 582 @ 4649 updates
[2024-03-26 18:09:01,023][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:03,504][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:03,569][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 582 @ 4649 updates, score None) (writing took 2.547106593847275 seconds)
[2024-03-26 18:09:03,570][fairseq_cli.train][INFO] - end of epoch 582 (average epoch stats below)
[2024-03-26 18:09:03,571][train][INFO] - {"epoch": 582, "train_loss": "1.051", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.061", "train_target_var": "0.752", "train_pred_var": "0.724", "train_masked_pct": "0.498", "train_wps": "8521.4", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4649", "train_lr": "0.000435844", "train_gnorm": "1.748", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "5961"}
[2024-03-26 18:09:03,573][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:03,636][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 583
[2024-03-26 18:09:03,638][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:03,641][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:03,646][fairseq.trainer][INFO] - begin training epoch 583
[2024-03-26 18:09:03,646][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:11,044][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 583 @ 4657 updates
[2024-03-26 18:09:11,046][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:13,521][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:13,587][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 583 @ 4657 updates, score None) (writing took 2.54217725712806 seconds)
[2024-03-26 18:09:13,587][fairseq_cli.train][INFO] - end of epoch 583 (average epoch stats below)
[2024-03-26 18:09:13,588][train][INFO] - {"epoch": 583, "train_loss": "1.074", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.061", "train_target_var": "0.753", "train_pred_var": "0.726", "train_masked_pct": "0.498", "train_wps": "8600.8", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4657", "train_lr": "0.000436594", "train_gnorm": "1.858", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5971"}
[2024-03-26 18:09:13,590][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:13,651][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 584
[2024-03-26 18:09:13,653][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:13,656][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:13,660][fairseq.trainer][INFO] - begin training epoch 584
[2024-03-26 18:09:13,661][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:20,848][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 584 @ 4665 updates
[2024-03-26 18:09:20,850][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:23,315][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:23,379][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 584 @ 4665 updates, score None) (writing took 2.530272226780653 seconds)
[2024-03-26 18:09:23,379][fairseq_cli.train][INFO] - end of epoch 584 (average epoch stats below)
[2024-03-26 18:09:23,380][train][INFO] - {"epoch": 584, "train_loss": "1.07", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.062", "train_target_var": "0.755", "train_pred_var": "0.728", "train_masked_pct": "0.5", "train_wps": "8798.9", "train_ups": "0.82", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4665", "train_lr": "0.000437344", "train_gnorm": "1.884", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "5981"}
[2024-03-26 18:09:23,382][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:23,443][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 585
[2024-03-26 18:09:23,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:23,448][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:23,452][fairseq.trainer][INFO] - begin training epoch 585
[2024-03-26 18:09:23,453][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:30,902][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:09:30,904][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:30,967][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 118
[2024-03-26 18:09:30,971][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:31,379][valid][INFO] - {"epoch": 585, "valid_loss": "1.118", "valid_ntokens": "11706", "valid_nsentences": "25", "valid_sample_size": "11706", "valid_ema_decay": "999.062", "valid_target_var": "0.755", "valid_pred_var": "0.726", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11706", "valid_bsz": "25", "valid_num_updates": "4673", "valid_best_loss": "0.222"}
[2024-03-26 18:09:31,381][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 585 @ 4673 updates
[2024-03-26 18:09:31,382][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:33,886][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:33,942][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 585 @ 4673 updates, score 1.118) (writing took 2.560526243876666 seconds)
[2024-03-26 18:09:33,942][fairseq_cli.train][INFO] - end of epoch 585 (average epoch stats below)
[2024-03-26 18:09:33,943][train][INFO] - {"epoch": 585, "train_loss": "1.087", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.062", "train_target_var": "0.754", "train_pred_var": "0.725", "train_masked_pct": "0.499", "train_wps": "8156.8", "train_ups": "0.76", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4673", "train_lr": "0.000438094", "train_gnorm": "1.869", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "5992"}
[2024-03-26 18:09:33,945][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:34,007][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 586
[2024-03-26 18:09:34,008][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:34,011][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:34,015][fairseq.trainer][INFO] - begin training epoch 586
[2024-03-26 18:09:34,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:41,543][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 586 @ 4681 updates
[2024-03-26 18:09:41,544][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:44,048][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:44,093][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 586 @ 4681 updates, score None) (writing took 2.550391672179103 seconds)
[2024-03-26 18:09:44,094][fairseq_cli.train][INFO] - end of epoch 586 (average epoch stats below)
[2024-03-26 18:09:44,094][train][INFO] - {"epoch": 586, "train_loss": "1.092", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.062", "train_target_var": "0.754", "train_pred_var": "0.727", "train_masked_pct": "0.498", "train_wps": "8486.9", "train_ups": "0.79", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4681", "train_lr": "0.000438844", "train_gnorm": "1.93", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6002"}
[2024-03-26 18:09:44,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:44,184][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 587
[2024-03-26 18:09:44,186][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:44,189][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:44,194][fairseq.trainer][INFO] - begin training epoch 587
[2024-03-26 18:09:44,194][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:09:51,737][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 587 @ 4689 updates
[2024-03-26 18:09:51,738][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:54,227][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:09:54,292][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 587 @ 4689 updates, score None) (writing took 2.5547842397354543 seconds)
[2024-03-26 18:09:54,292][fairseq_cli.train][INFO] - end of epoch 587 (average epoch stats below)
[2024-03-26 18:09:54,293][train][INFO] - {"epoch": 587, "train_loss": "1.053", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.062", "train_target_var": "0.752", "train_pred_var": "0.726", "train_masked_pct": "0.5", "train_wps": "8448.3", "train_ups": "0.78", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4689", "train_lr": "0.000439594", "train_gnorm": "1.635", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6012"}
[2024-03-26 18:09:54,295][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:09:54,357][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 588
[2024-03-26 18:09:54,359][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:09:54,362][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:09:54,367][fairseq.trainer][INFO] - begin training epoch 588
[2024-03-26 18:09:54,367][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:01,667][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 588 @ 4697 updates
[2024-03-26 18:10:01,669][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:04,299][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:04,363][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 588 @ 4697 updates, score None) (writing took 2.6961183859966695 seconds)
[2024-03-26 18:10:04,364][fairseq_cli.train][INFO] - end of epoch 588 (average epoch stats below)
[2024-03-26 18:10:04,365][train][INFO] - {"epoch": 588, "train_loss": "1.092", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.062", "train_target_var": "0.753", "train_pred_var": "0.724", "train_masked_pct": "0.499", "train_wps": "8555", "train_ups": "0.79", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4697", "train_lr": "0.000440344", "train_gnorm": "2.379", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "6022"}
[2024-03-26 18:10:04,367][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:04,437][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 589
[2024-03-26 18:10:04,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:04,442][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:04,446][fairseq.trainer][INFO] - begin training epoch 589
[2024-03-26 18:10:04,447][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:11,804][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 589 @ 4705 updates
[2024-03-26 18:10:11,806][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:14,294][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:14,346][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 589 @ 4705 updates, score None) (writing took 2.5419616056606174 seconds)
[2024-03-26 18:10:14,347][fairseq_cli.train][INFO] - end of epoch 589 (average epoch stats below)
[2024-03-26 18:10:14,347][train][INFO] - {"epoch": 589, "train_loss": "1.082", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.062", "train_target_var": "0.751", "train_pred_var": "0.725", "train_masked_pct": "0.498", "train_wps": "8630.7", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4705", "train_lr": "0.000441094", "train_gnorm": "1.901", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6032"}
[2024-03-26 18:10:14,350][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:14,427][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 590
[2024-03-26 18:10:14,429][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:14,432][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:14,437][fairseq.trainer][INFO] - begin training epoch 590
[2024-03-26 18:10:14,438][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:21,786][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:10:21,787][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:21,871][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 119
[2024-03-26 18:10:21,874][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:22,282][valid][INFO] - {"epoch": 590, "valid_loss": "1.23", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.062", "valid_target_var": "0.752", "valid_pred_var": "0.709", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "4713", "valid_best_loss": "0.222"}
[2024-03-26 18:10:22,284][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 590 @ 4713 updates
[2024-03-26 18:10:22,285][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:24,871][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:24,937][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 590 @ 4713 updates, score 1.23) (writing took 2.652995938900858 seconds)
[2024-03-26 18:10:24,937][fairseq_cli.train][INFO] - end of epoch 590 (average epoch stats below)
[2024-03-26 18:10:24,938][train][INFO] - {"epoch": 590, "train_loss": "1.124", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.062", "train_target_var": "0.753", "train_pred_var": "0.725", "train_masked_pct": "0.5", "train_wps": "8135.2", "train_ups": "0.76", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4713", "train_lr": "0.000441844", "train_gnorm": "2.394", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6043"}
[2024-03-26 18:10:24,940][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:25,002][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 591
[2024-03-26 18:10:25,004][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:25,007][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:25,011][fairseq.trainer][INFO] - begin training epoch 591
[2024-03-26 18:10:25,012][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:32,350][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 591 @ 4721 updates
[2024-03-26 18:10:32,351][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:34,827][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:34,888][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 591 @ 4721 updates, score None) (writing took 2.5383747201412916 seconds)
[2024-03-26 18:10:34,889][fairseq_cli.train][INFO] - end of epoch 591 (average epoch stats below)
[2024-03-26 18:10:34,890][train][INFO] - {"epoch": 591, "train_loss": "1.112", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.062", "train_target_var": "0.751", "train_pred_var": "0.723", "train_masked_pct": "0.5", "train_wps": "8658.3", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4721", "train_lr": "0.000442594", "train_gnorm": "2.296", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "6053"}
[2024-03-26 18:10:34,892][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:34,956][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 592
[2024-03-26 18:10:34,958][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:34,961][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:34,966][fairseq.trainer][INFO] - begin training epoch 592
[2024-03-26 18:10:34,967][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:42,351][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 592 @ 4729 updates
[2024-03-26 18:10:42,353][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:44,845][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:44,905][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 592 @ 4729 updates, score None) (writing took 2.5533109037205577 seconds)
[2024-03-26 18:10:44,905][fairseq_cli.train][INFO] - end of epoch 592 (average epoch stats below)
[2024-03-26 18:10:44,906][train][INFO] - {"epoch": 592, "train_loss": "1.087", "train_ntokens": "10768.1", "train_nsentences": "22.875", "train_sample_size": "10768.1", "train_ema_decay": "999.062", "train_target_var": "0.752", "train_pred_var": "0.722", "train_masked_pct": "0.499", "train_wps": "8601.1", "train_ups": "0.8", "train_wpb": "10768.1", "train_bsz": "22.9", "train_num_updates": "4729", "train_lr": "0.000443344", "train_gnorm": "2.052", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6063"}
[2024-03-26 18:10:44,908][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:44,969][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 593
[2024-03-26 18:10:44,971][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:44,974][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:44,979][fairseq.trainer][INFO] - begin training epoch 593
[2024-03-26 18:10:44,980][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:10:52,431][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 593 @ 4737 updates
[2024-03-26 18:10:52,433][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:54,961][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:10:55,027][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 593 @ 4737 updates, score None) (writing took 2.5954258698038757 seconds)
[2024-03-26 18:10:55,027][fairseq_cli.train][INFO] - end of epoch 593 (average epoch stats below)
[2024-03-26 18:10:55,028][train][INFO] - {"epoch": 593, "train_loss": "1.073", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.062", "train_target_var": "0.754", "train_pred_var": "0.725", "train_masked_pct": "0.5", "train_wps": "8512", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4737", "train_lr": "0.000444094", "train_gnorm": "1.974", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6073"}
[2024-03-26 18:10:55,031][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:10:55,093][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 594
[2024-03-26 18:10:55,095][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:10:55,098][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:10:55,103][fairseq.trainer][INFO] - begin training epoch 594
[2024-03-26 18:10:55,103][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:02,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 594 @ 4745 updates
[2024-03-26 18:11:02,396][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:04,890][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:04,956][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 594 @ 4745 updates, score None) (writing took 2.561592070851475 seconds)
[2024-03-26 18:11:04,956][fairseq_cli.train][INFO] - end of epoch 594 (average epoch stats below)
[2024-03-26 18:11:04,957][train][INFO] - {"epoch": 594, "train_loss": "1.137", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.063", "train_target_var": "0.75", "train_pred_var": "0.721", "train_masked_pct": "0.501", "train_wps": "8678.4", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4745", "train_lr": "0.000444844", "train_gnorm": "2.239", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6083"}
[2024-03-26 18:11:04,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:05,021][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 595
[2024-03-26 18:11:05,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:05,026][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:05,031][fairseq.trainer][INFO] - begin training epoch 595
[2024-03-26 18:11:05,032][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:12,299][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:11:12,300][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:12,365][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 120
[2024-03-26 18:11:12,368][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:12,789][valid][INFO] - {"epoch": 595, "valid_loss": "1.336", "valid_ntokens": "11712", "valid_nsentences": "25", "valid_sample_size": "11712", "valid_ema_decay": "999.063", "valid_target_var": "0.751", "valid_pred_var": "0.715", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11712", "valid_bsz": "25", "valid_num_updates": "4753", "valid_best_loss": "0.222"}
[2024-03-26 18:11:12,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 595 @ 4753 updates
[2024-03-26 18:11:12,792][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:15,396][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:15,438][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 595 @ 4753 updates, score 1.336) (writing took 2.6477545318193734 seconds)
[2024-03-26 18:11:15,439][fairseq_cli.train][INFO] - end of epoch 595 (average epoch stats below)
[2024-03-26 18:11:15,439][train][INFO] - {"epoch": 595, "train_loss": "1.157", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.063", "train_target_var": "0.751", "train_pred_var": "0.722", "train_masked_pct": "0.499", "train_wps": "8219", "train_ups": "0.76", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "4753", "train_lr": "0.000445594", "train_gnorm": "2.35", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "6093"}
[2024-03-26 18:11:15,442][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:15,531][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 596
[2024-03-26 18:11:15,533][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:15,536][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:15,541][fairseq.trainer][INFO] - begin training epoch 596
[2024-03-26 18:11:15,541][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:22,934][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 596 @ 4761 updates
[2024-03-26 18:11:22,936][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:25,438][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:25,505][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 596 @ 4761 updates, score None) (writing took 2.5705432202667 seconds)
[2024-03-26 18:11:25,505][fairseq_cli.train][INFO] - end of epoch 596 (average epoch stats below)
[2024-03-26 18:11:25,506][train][INFO] - {"epoch": 596, "train_loss": "1.187", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.063", "train_target_var": "0.752", "train_pred_var": "0.721", "train_masked_pct": "0.499", "train_wps": "8559.3", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4761", "train_lr": "0.000446344", "train_gnorm": "2.314", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "6103"}
[2024-03-26 18:11:25,508][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:25,572][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 597
[2024-03-26 18:11:25,574][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:25,577][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:25,582][fairseq.trainer][INFO] - begin training epoch 597
[2024-03-26 18:11:25,582][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:32,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 597 @ 4769 updates
[2024-03-26 18:11:32,969][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:35,453][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:35,518][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 597 @ 4769 updates, score None) (writing took 2.5500274738296866 seconds)
[2024-03-26 18:11:35,519][fairseq_cli.train][INFO] - end of epoch 597 (average epoch stats below)
[2024-03-26 18:11:35,519][train][INFO] - {"epoch": 597, "train_loss": "1.141", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.063", "train_target_var": "0.752", "train_pred_var": "0.722", "train_masked_pct": "0.5", "train_wps": "8604.1", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "4769", "train_lr": "0.000447094", "train_gnorm": "1.96", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6113"}
[2024-03-26 18:11:35,521][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:35,585][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 598
[2024-03-26 18:11:35,587][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:35,590][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:35,595][fairseq.trainer][INFO] - begin training epoch 598
[2024-03-26 18:11:35,596][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:42,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 598 @ 4777 updates
[2024-03-26 18:11:42,980][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:45,479][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:45,542][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 598 @ 4777 updates, score None) (writing took 2.5628704712726176 seconds)
[2024-03-26 18:11:45,542][fairseq_cli.train][INFO] - end of epoch 598 (average epoch stats below)
[2024-03-26 18:11:45,543][train][INFO] - {"epoch": 598, "train_loss": "1.122", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.063", "train_target_var": "0.749", "train_pred_var": "0.72", "train_masked_pct": "0.499", "train_wps": "8595.7", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4777", "train_lr": "0.000447844", "train_gnorm": "2.733", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6123"}
[2024-03-26 18:11:45,545][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:45,607][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 599
[2024-03-26 18:11:45,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:45,612][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:45,617][fairseq.trainer][INFO] - begin training epoch 599
[2024-03-26 18:11:45,617][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:11:53,028][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 599 @ 4785 updates
[2024-03-26 18:11:53,029][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:55,511][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:11:55,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 599 @ 4785 updates, score None) (writing took 2.524066474288702 seconds)
[2024-03-26 18:11:55,553][fairseq_cli.train][INFO] - end of epoch 599 (average epoch stats below)
[2024-03-26 18:11:55,554][train][INFO] - {"epoch": 599, "train_loss": "1.13", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.063", "train_target_var": "0.75", "train_pred_var": "0.719", "train_masked_pct": "0.498", "train_wps": "8605.7", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4785", "train_lr": "0.000448594", "train_gnorm": "2.108", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6133"}
[2024-03-26 18:11:55,556][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:11:55,642][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 600
[2024-03-26 18:11:55,644][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:11:55,647][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:11:55,651][fairseq.trainer][INFO] - begin training epoch 600
[2024-03-26 18:11:55,652][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:03,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:12:03,045][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:03,107][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 121
[2024-03-26 18:12:03,110][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:03,514][valid][INFO] - {"epoch": 600, "valid_loss": "1.158", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.063", "valid_target_var": "0.751", "valid_pred_var": "0.715", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "4793", "valid_best_loss": "0.222"}
[2024-03-26 18:12:03,515][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 600 @ 4793 updates
[2024-03-26 18:12:03,517][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:06,034][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:06,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 600 @ 4793 updates, score 1.158) (writing took 2.5836194907315075 seconds)
[2024-03-26 18:12:06,100][fairseq_cli.train][INFO] - end of epoch 600 (average epoch stats below)
[2024-03-26 18:12:06,100][train][INFO] - {"epoch": 600, "train_loss": "1.185", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.063", "train_target_var": "0.749", "train_pred_var": "0.72", "train_masked_pct": "0.501", "train_wps": "8169.5", "train_ups": "0.76", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4793", "train_lr": "0.000449344", "train_gnorm": "1.896", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6144"}
[2024-03-26 18:12:06,102][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:06,164][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 601
[2024-03-26 18:12:06,166][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:06,169][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:06,174][fairseq.trainer][INFO] - begin training epoch 601
[2024-03-26 18:12:06,174][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:12,603][train_inner][INFO] - {"epoch": 601, "update": 600.875, "loss": "1.097", "ntokens": "10769", "nsentences": "22.875", "sample_size": "10769", "ema_decay": "999.062", "target_var": "0.752", "pred_var": "0.724", "masked_pct": "0.499", "wps": "8498.6", "ups": "0.79", "wpb": "10769", "bsz": "22.9", "num_updates": "4800", "lr": "0.00045", "gnorm": "2.061", "loss_scale": "1", "train_wall": "178", "gb_free": "5.6", "wall": "6150"}
[2024-03-26 18:12:13,622][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 601 @ 4801 updates
[2024-03-26 18:12:13,623][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:16,153][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:16,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 601 @ 4801 updates, score None) (writing took 2.597307736054063 seconds)
[2024-03-26 18:12:16,220][fairseq_cli.train][INFO] - end of epoch 601 (average epoch stats below)
[2024-03-26 18:12:16,220][train][INFO] - {"epoch": 601, "train_loss": "1.114", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.063", "train_target_var": "0.748", "train_pred_var": "0.719", "train_masked_pct": "0.499", "train_wps": "8512.9", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "4801", "train_lr": "0.000450094", "train_gnorm": "2.189", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6154"}
[2024-03-26 18:12:16,223][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:16,286][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 602
[2024-03-26 18:12:16,288][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:16,292][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:16,297][fairseq.trainer][INFO] - begin training epoch 602
[2024-03-26 18:12:16,297][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:23,694][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 602 @ 4809 updates
[2024-03-26 18:12:23,695][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:26,177][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:26,237][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 602 @ 4809 updates, score None) (writing took 2.5433913189917803 seconds)
[2024-03-26 18:12:26,238][fairseq_cli.train][INFO] - end of epoch 602 (average epoch stats below)
[2024-03-26 18:12:26,238][train][INFO] - {"epoch": 602, "train_loss": "1.097", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.063", "train_target_var": "0.748", "train_pred_var": "0.719", "train_masked_pct": "0.499", "train_wps": "8600.8", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4809", "train_lr": "0.000450844", "train_gnorm": "1.844", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6164"}
[2024-03-26 18:12:26,241][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:26,309][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 603
[2024-03-26 18:12:26,311][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:26,314][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:26,318][fairseq.trainer][INFO] - begin training epoch 603
[2024-03-26 18:12:26,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:33,614][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 603 @ 4817 updates
[2024-03-26 18:12:33,615][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:36,093][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:36,160][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 603 @ 4817 updates, score None) (writing took 2.546408886089921 seconds)
[2024-03-26 18:12:36,161][fairseq_cli.train][INFO] - end of epoch 603 (average epoch stats below)
[2024-03-26 18:12:36,162][train][INFO] - {"epoch": 603, "train_loss": "1.133", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.064", "train_target_var": "0.75", "train_pred_var": "0.72", "train_masked_pct": "0.501", "train_wps": "8682.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4817", "train_lr": "0.000451594", "train_gnorm": "2.181", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6174"}
[2024-03-26 18:12:36,164][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:36,225][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 604
[2024-03-26 18:12:36,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:36,230][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:36,235][fairseq.trainer][INFO] - begin training epoch 604
[2024-03-26 18:12:36,236][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:43,536][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 604 @ 4825 updates
[2024-03-26 18:12:43,537][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:46,040][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:46,104][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 604 @ 4825 updates, score None) (writing took 2.567909302189946 seconds)
[2024-03-26 18:12:46,104][fairseq_cli.train][INFO] - end of epoch 604 (average epoch stats below)
[2024-03-26 18:12:46,105][train][INFO] - {"epoch": 604, "train_loss": "1.165", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.064", "train_target_var": "0.75", "train_pred_var": "0.718", "train_masked_pct": "0.501", "train_wps": "8665.1", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4825", "train_lr": "0.000452344", "train_gnorm": "1.971", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6184"}
[2024-03-26 18:12:46,107][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:46,167][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 605
[2024-03-26 18:12:46,169][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:46,172][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:46,177][fairseq.trainer][INFO] - begin training epoch 605
[2024-03-26 18:12:46,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:12:53,753][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:12:53,754][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:53,819][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 122
[2024-03-26 18:12:53,823][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:54,237][valid][INFO] - {"epoch": 605, "valid_loss": "1.251", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.064", "valid_target_var": "0.754", "valid_pred_var": "0.717", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "4833", "valid_best_loss": "0.222"}
[2024-03-26 18:12:54,238][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 605 @ 4833 updates
[2024-03-26 18:12:54,240][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:56,759][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:12:56,827][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 605 @ 4833 updates, score 1.251) (writing took 2.588948250748217 seconds)
[2024-03-26 18:12:56,828][fairseq_cli.train][INFO] - end of epoch 605 (average epoch stats below)
[2024-03-26 18:12:56,829][train][INFO] - {"epoch": 605, "train_loss": "1.065", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.064", "train_target_var": "0.751", "train_pred_var": "0.724", "train_masked_pct": "0.5", "train_wps": "8034.4", "train_ups": "0.75", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4833", "train_lr": "0.000453094", "train_gnorm": "2.201", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6195"}
[2024-03-26 18:12:56,831][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:12:56,894][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 606
[2024-03-26 18:12:56,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:12:56,900][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:12:56,904][fairseq.trainer][INFO] - begin training epoch 606
[2024-03-26 18:12:56,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:04,326][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 606 @ 4841 updates
[2024-03-26 18:13:04,328][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:06,825][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:06,890][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 606 @ 4841 updates, score None) (writing took 2.563730358146131 seconds)
[2024-03-26 18:13:06,890][fairseq_cli.train][INFO] - end of epoch 606 (average epoch stats below)
[2024-03-26 18:13:06,891][train][INFO] - {"epoch": 606, "train_loss": "1.16", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.064", "train_target_var": "0.749", "train_pred_var": "0.719", "train_masked_pct": "0.499", "train_wps": "8563.1", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4841", "train_lr": "0.000453844", "train_gnorm": "2.093", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.9", "train_wall": "6205"}
[2024-03-26 18:13:06,893][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:06,955][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 607
[2024-03-26 18:13:06,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:06,960][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:06,964][fairseq.trainer][INFO] - begin training epoch 607
[2024-03-26 18:13:06,965][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:14,281][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 607 @ 4849 updates
[2024-03-26 18:13:14,282][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:16,779][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:16,839][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 607 @ 4849 updates, score None) (writing took 2.5588555657304823 seconds)
[2024-03-26 18:13:16,840][fairseq_cli.train][INFO] - end of epoch 607 (average epoch stats below)
[2024-03-26 18:13:16,841][train][INFO] - {"epoch": 607, "train_loss": "1.091", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.064", "train_target_var": "0.751", "train_pred_var": "0.724", "train_masked_pct": "0.5", "train_wps": "8659.5", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4849", "train_lr": "0.000454594", "train_gnorm": "2.062", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "6215"}
[2024-03-26 18:13:16,843][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:16,906][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 608
[2024-03-26 18:13:16,907][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:16,911][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:16,915][fairseq.trainer][INFO] - begin training epoch 608
[2024-03-26 18:13:16,916][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:24,338][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 608 @ 4857 updates
[2024-03-26 18:13:24,339][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:26,832][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:26,866][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 608 @ 4857 updates, score None) (writing took 2.5281082950532436 seconds)
[2024-03-26 18:13:26,866][fairseq_cli.train][INFO] - end of epoch 608 (average epoch stats below)
[2024-03-26 18:13:26,867][train][INFO] - {"epoch": 608, "train_loss": "1.184", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.064", "train_target_var": "0.75", "train_pred_var": "0.719", "train_masked_pct": "0.499", "train_wps": "8594", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4857", "train_lr": "0.000455344", "train_gnorm": "2.18", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6225"}
[2024-03-26 18:13:26,869][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:26,962][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 609
[2024-03-26 18:13:26,964][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:26,967][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:26,972][fairseq.trainer][INFO] - begin training epoch 609
[2024-03-26 18:13:26,972][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:34,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 609 @ 4865 updates
[2024-03-26 18:13:34,297][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:36,789][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:36,829][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 609 @ 4865 updates, score None) (writing took 2.534196796361357 seconds)
[2024-03-26 18:13:36,830][fairseq_cli.train][INFO] - end of epoch 609 (average epoch stats below)
[2024-03-26 18:13:36,831][train][INFO] - {"epoch": 609, "train_loss": "1.126", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.064", "train_target_var": "0.749", "train_pred_var": "0.719", "train_masked_pct": "0.5", "train_wps": "8647.5", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4865", "train_lr": "0.000456094", "train_gnorm": "1.859", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6235"}
[2024-03-26 18:13:36,833][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:36,917][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 610
[2024-03-26 18:13:36,918][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:36,921][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:36,926][fairseq.trainer][INFO] - begin training epoch 610
[2024-03-26 18:13:36,927][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:44,280][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:13:44,281][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:44,356][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 123
[2024-03-26 18:13:44,360][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:44,757][valid][INFO] - {"epoch": 610, "valid_loss": "1.141", "valid_ntokens": "11711", "valid_nsentences": "25", "valid_sample_size": "11711", "valid_ema_decay": "999.064", "valid_target_var": "0.755", "valid_pred_var": "0.725", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11711", "valid_bsz": "25", "valid_num_updates": "4873", "valid_best_loss": "0.222"}
[2024-03-26 18:13:44,759][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 610 @ 4873 updates
[2024-03-26 18:13:44,762][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:47,260][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:47,299][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 610 @ 4873 updates, score 1.141) (writing took 2.539480668026954 seconds)
[2024-03-26 18:13:47,299][fairseq_cli.train][INFO] - end of epoch 610 (average epoch stats below)
[2024-03-26 18:13:47,300][train][INFO] - {"epoch": 610, "train_loss": "1.103", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.064", "train_target_var": "0.748", "train_pred_var": "0.719", "train_masked_pct": "0.5", "train_wps": "8230.7", "train_ups": "0.76", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "4873", "train_lr": "0.000456844", "train_gnorm": "1.827", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "6245"}
[2024-03-26 18:13:47,302][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:47,389][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 611
[2024-03-26 18:13:47,391][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:47,394][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:47,399][fairseq.trainer][INFO] - begin training epoch 611
[2024-03-26 18:13:47,399][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:13:54,717][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 611 @ 4881 updates
[2024-03-26 18:13:54,718][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:57,202][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:13:57,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 611 @ 4881 updates, score None) (writing took 2.5511050587520003 seconds)
[2024-03-26 18:13:57,269][fairseq_cli.train][INFO] - end of epoch 611 (average epoch stats below)
[2024-03-26 18:13:57,269][train][INFO] - {"epoch": 611, "train_loss": "1.16", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.064", "train_target_var": "0.746", "train_pred_var": "0.716", "train_masked_pct": "0.499", "train_wps": "8642.4", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4881", "train_lr": "0.000457594", "train_gnorm": "2.365", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6255"}
[2024-03-26 18:13:57,272][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:13:57,333][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 612
[2024-03-26 18:13:57,335][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:13:57,338][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:13:57,343][fairseq.trainer][INFO] - begin training epoch 612
[2024-03-26 18:13:57,343][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:04,616][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 612 @ 4889 updates
[2024-03-26 18:14:04,617][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:07,091][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:07,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 612 @ 4889 updates, score None) (writing took 2.536297535058111 seconds)
[2024-03-26 18:14:07,153][fairseq_cli.train][INFO] - end of epoch 612 (average epoch stats below)
[2024-03-26 18:14:07,153][train][INFO] - {"epoch": 612, "train_loss": "1.221", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.064", "train_target_var": "0.748", "train_pred_var": "0.717", "train_masked_pct": "0.5", "train_wps": "8717.3", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "4889", "train_lr": "0.000458344", "train_gnorm": "2.541", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6265"}
[2024-03-26 18:14:07,155][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:07,216][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 613
[2024-03-26 18:14:07,218][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:07,221][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:07,226][fairseq.trainer][INFO] - begin training epoch 613
[2024-03-26 18:14:07,226][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:14,543][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 613 @ 4897 updates
[2024-03-26 18:14:14,545][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:17,029][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:17,094][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 613 @ 4897 updates, score None) (writing took 2.5503480257466435 seconds)
[2024-03-26 18:14:17,094][fairseq_cli.train][INFO] - end of epoch 613 (average epoch stats below)
[2024-03-26 18:14:17,095][train][INFO] - {"epoch": 613, "train_loss": "1.209", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.065", "train_target_var": "0.749", "train_pred_var": "0.718", "train_masked_pct": "0.499", "train_wps": "8666.7", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4897", "train_lr": "0.000459094", "train_gnorm": "2.235", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6275"}
[2024-03-26 18:14:17,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:17,159][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 614
[2024-03-26 18:14:17,161][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:17,164][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:17,168][fairseq.trainer][INFO] - begin training epoch 614
[2024-03-26 18:14:17,169][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:24,585][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 614 @ 4905 updates
[2024-03-26 18:14:24,586][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:27,100][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:27,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 614 @ 4905 updates, score None) (writing took 2.567153250798583 seconds)
[2024-03-26 18:14:27,152][fairseq_cli.train][INFO] - end of epoch 614 (average epoch stats below)
[2024-03-26 18:14:27,153][train][INFO] - {"epoch": 614, "train_loss": "1.181", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.065", "train_target_var": "0.75", "train_pred_var": "0.72", "train_masked_pct": "0.5", "train_wps": "8566.3", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4905", "train_lr": "0.000459844", "train_gnorm": "2.179", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6285"}
[2024-03-26 18:14:27,155][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:27,226][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 615
[2024-03-26 18:14:27,228][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:27,231][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:27,236][fairseq.trainer][INFO] - begin training epoch 615
[2024-03-26 18:14:27,236][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:34,602][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:14:34,603][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:34,667][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 124
[2024-03-26 18:14:34,670][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:35,092][valid][INFO] - {"epoch": 615, "valid_loss": "1.178", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.065", "valid_target_var": "0.754", "valid_pred_var": "0.721", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "4913", "valid_best_loss": "0.222"}
[2024-03-26 18:14:35,094][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 615 @ 4913 updates
[2024-03-26 18:14:35,095][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:37,619][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:37,685][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 615 @ 4913 updates, score 1.178) (writing took 2.5914873923175037 seconds)
[2024-03-26 18:14:37,686][fairseq_cli.train][INFO] - end of epoch 615 (average epoch stats below)
[2024-03-26 18:14:37,687][train][INFO] - {"epoch": 615, "train_loss": "1.125", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.065", "train_target_var": "0.751", "train_pred_var": "0.722", "train_masked_pct": "0.501", "train_wps": "8179.4", "train_ups": "0.76", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "4913", "train_lr": "0.000460594", "train_gnorm": "1.853", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6296"}
[2024-03-26 18:14:37,690][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:37,753][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 616
[2024-03-26 18:14:37,755][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:37,758][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:37,763][fairseq.trainer][INFO] - begin training epoch 616
[2024-03-26 18:14:37,763][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:45,103][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 616 @ 4921 updates
[2024-03-26 18:14:45,105][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:47,598][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:47,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 616 @ 4921 updates, score None) (writing took 2.5600753650069237 seconds)
[2024-03-26 18:14:47,664][fairseq_cli.train][INFO] - end of epoch 616 (average epoch stats below)
[2024-03-26 18:14:47,665][train][INFO] - {"epoch": 616, "train_loss": "1.21", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.065", "train_target_var": "0.745", "train_pred_var": "0.714", "train_masked_pct": "0.501", "train_wps": "8635.3", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "4921", "train_lr": "0.000461344", "train_gnorm": "1.988", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "6305"}
[2024-03-26 18:14:47,667][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:47,730][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 617
[2024-03-26 18:14:47,732][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:47,735][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:47,739][fairseq.trainer][INFO] - begin training epoch 617
[2024-03-26 18:14:47,740][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:14:55,065][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 617 @ 4929 updates
[2024-03-26 18:14:55,067][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:57,566][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:14:57,630][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 617 @ 4929 updates, score None) (writing took 2.5648940787650645 seconds)
[2024-03-26 18:14:57,631][fairseq_cli.train][INFO] - end of epoch 617 (average epoch stats below)
[2024-03-26 18:14:57,632][train][INFO] - {"epoch": 617, "train_loss": "1.14", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.065", "train_target_var": "0.749", "train_pred_var": "0.721", "train_masked_pct": "0.5", "train_wps": "8644.5", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "4929", "train_lr": "0.000462094", "train_gnorm": "1.848", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6315"}
[2024-03-26 18:14:57,634][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:14:57,695][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 618
[2024-03-26 18:14:57,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:14:57,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:14:57,705][fairseq.trainer][INFO] - begin training epoch 618
[2024-03-26 18:14:57,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:04,916][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 618 @ 4937 updates
[2024-03-26 18:15:04,917][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:07,387][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:07,446][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 618 @ 4937 updates, score None) (writing took 2.5296595050022006 seconds)
[2024-03-26 18:15:07,446][fairseq_cli.train][INFO] - end of epoch 618 (average epoch stats below)
[2024-03-26 18:15:07,447][train][INFO] - {"epoch": 618, "train_loss": "1.179", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.065", "train_target_var": "0.748", "train_pred_var": "0.715", "train_masked_pct": "0.5", "train_wps": "8778.4", "train_ups": "0.82", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4937", "train_lr": "0.000462844", "train_gnorm": "2.429", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6325"}
[2024-03-26 18:15:07,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:07,517][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 619
[2024-03-26 18:15:07,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:07,522][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:07,527][fairseq.trainer][INFO] - begin training epoch 619
[2024-03-26 18:15:07,527][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:14,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 619 @ 4945 updates
[2024-03-26 18:15:14,885][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:17,381][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:17,447][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 619 @ 4945 updates, score None) (writing took 2.562653223052621 seconds)
[2024-03-26 18:15:17,447][fairseq_cli.train][INFO] - end of epoch 619 (average epoch stats below)
[2024-03-26 18:15:17,448][train][INFO] - {"epoch": 619, "train_loss": "1.228", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.065", "train_target_var": "0.747", "train_pred_var": "0.716", "train_masked_pct": "0.501", "train_wps": "8616.4", "train_ups": "0.8", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "4945", "train_lr": "0.000463594", "train_gnorm": "2.096", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6335"}
[2024-03-26 18:15:17,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:17,511][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 620
[2024-03-26 18:15:17,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:17,517][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:17,521][fairseq.trainer][INFO] - begin training epoch 620
[2024-03-26 18:15:17,522][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:24,938][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:15:24,939][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:25,013][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 125
[2024-03-26 18:15:25,016][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:25,428][valid][INFO] - {"epoch": 620, "valid_loss": "1.302", "valid_ntokens": "11704", "valid_nsentences": "25", "valid_sample_size": "11704", "valid_ema_decay": "999.065", "valid_target_var": "0.742", "valid_pred_var": "0.706", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11704", "valid_bsz": "25", "valid_num_updates": "4953", "valid_best_loss": "0.222"}
[2024-03-26 18:15:25,430][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 620 @ 4953 updates
[2024-03-26 18:15:25,431][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:27,926][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:27,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 620 @ 4953 updates, score 1.302) (writing took 2.5612554168328643 seconds)
[2024-03-26 18:15:27,991][fairseq_cli.train][INFO] - end of epoch 620 (average epoch stats below)
[2024-03-26 18:15:27,992][train][INFO] - {"epoch": 620, "train_loss": "1.226", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.065", "train_target_var": "0.745", "train_pred_var": "0.712", "train_masked_pct": "0.5", "train_wps": "8171.9", "train_ups": "0.76", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "4953", "train_lr": "0.000464344", "train_gnorm": "2.381", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6346"}
[2024-03-26 18:15:27,994][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:28,057][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 621
[2024-03-26 18:15:28,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:28,061][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:28,066][fairseq.trainer][INFO] - begin training epoch 621
[2024-03-26 18:15:28,067][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:35,478][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 621 @ 4961 updates
[2024-03-26 18:15:35,479][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:37,954][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:38,020][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 621 @ 4961 updates, score None) (writing took 2.5423231991007924 seconds)
[2024-03-26 18:15:38,021][fairseq_cli.train][INFO] - end of epoch 621 (average epoch stats below)
[2024-03-26 18:15:38,021][train][INFO] - {"epoch": 621, "train_loss": "1.126", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.065", "train_target_var": "0.746", "train_pred_var": "0.716", "train_masked_pct": "0.5", "train_wps": "8591.1", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "4961", "train_lr": "0.000465094", "train_gnorm": "1.85", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6356"}
[2024-03-26 18:15:38,023][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:38,085][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 622
[2024-03-26 18:15:38,087][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:38,090][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:38,095][fairseq.trainer][INFO] - begin training epoch 622
[2024-03-26 18:15:38,096][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:45,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 622 @ 4969 updates
[2024-03-26 18:15:45,485][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:47,993][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:48,059][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 622 @ 4969 updates, score None) (writing took 2.575692413840443 seconds)
[2024-03-26 18:15:48,060][fairseq_cli.train][INFO] - end of epoch 622 (average epoch stats below)
[2024-03-26 18:15:48,060][train][INFO] - {"epoch": 622, "train_loss": "1.201", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.066", "train_target_var": "0.746", "train_pred_var": "0.715", "train_masked_pct": "0.5", "train_wps": "8582.7", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "4969", "train_lr": "0.000465844", "train_gnorm": "2.039", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6366"}
[2024-03-26 18:15:48,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:48,125][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 623
[2024-03-26 18:15:48,127][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:48,130][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:48,135][fairseq.trainer][INFO] - begin training epoch 623
[2024-03-26 18:15:48,135][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:15:55,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 623 @ 4977 updates
[2024-03-26 18:15:55,517][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:58,027][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:15:58,079][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 623 @ 4977 updates, score None) (writing took 2.5633192621171474 seconds)
[2024-03-26 18:15:58,080][fairseq_cli.train][INFO] - end of epoch 623 (average epoch stats below)
[2024-03-26 18:15:58,080][train][INFO] - {"epoch": 623, "train_loss": "1.145", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.066", "train_target_var": "0.748", "train_pred_var": "0.718", "train_masked_pct": "0.498", "train_wps": "8599.1", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "4977", "train_lr": "0.000466594", "train_gnorm": "1.808", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6376"}
[2024-03-26 18:15:58,082][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:15:58,157][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 624
[2024-03-26 18:15:58,159][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:15:58,162][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:15:58,167][fairseq.trainer][INFO] - begin training epoch 624
[2024-03-26 18:15:58,167][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:05,466][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 624 @ 4985 updates
[2024-03-26 18:16:05,467][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:07,966][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:08,035][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 624 @ 4985 updates, score None) (writing took 2.5695583526976407 seconds)
[2024-03-26 18:16:08,037][fairseq_cli.train][INFO] - end of epoch 624 (average epoch stats below)
[2024-03-26 18:16:08,037][train][INFO] - {"epoch": 624, "train_loss": "1.243", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.066", "train_target_var": "0.749", "train_pred_var": "0.72", "train_masked_pct": "0.501", "train_wps": "8653.2", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "4985", "train_lr": "0.000467344", "train_gnorm": "1.92", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6386"}
[2024-03-26 18:16:08,039][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:08,101][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 625
[2024-03-26 18:16:08,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:08,106][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:08,111][fairseq.trainer][INFO] - begin training epoch 625
[2024-03-26 18:16:08,111][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:15,544][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:16:15,545][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:15,610][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 126
[2024-03-26 18:16:15,613][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:16,037][valid][INFO] - {"epoch": 625, "valid_loss": "1.373", "valid_ntokens": "11718", "valid_nsentences": "25", "valid_sample_size": "11718", "valid_ema_decay": "999.066", "valid_target_var": "0.75", "valid_pred_var": "0.719", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11718", "valid_bsz": "25", "valid_num_updates": "4993", "valid_best_loss": "0.222"}
[2024-03-26 18:16:16,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 625 @ 4993 updates
[2024-03-26 18:16:16,040][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:18,627][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:18,694][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 625 @ 4993 updates, score 1.373) (writing took 2.655138588976115 seconds)
[2024-03-26 18:16:18,694][fairseq_cli.train][INFO] - end of epoch 625 (average epoch stats below)
[2024-03-26 18:16:18,695][train][INFO] - {"epoch": 625, "train_loss": "1.236", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.066", "train_target_var": "0.745", "train_pred_var": "0.712", "train_masked_pct": "0.499", "train_wps": "8083.9", "train_ups": "0.75", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "4993", "train_lr": "0.000468094", "train_gnorm": "2.054", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6397"}
[2024-03-26 18:16:18,697][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:18,761][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 626
[2024-03-26 18:16:18,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:18,766][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:18,771][fairseq.trainer][INFO] - begin training epoch 626
[2024-03-26 18:16:18,771][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:25,059][train_inner][INFO] - {"epoch": 626, "update": 625.875, "loss": "1.165", "ntokens": "10769.4", "nsentences": "22.875", "sample_size": "10769.4", "ema_decay": "999.065", "target_var": "0.748", "pred_var": "0.718", "masked_pct": "0.5", "wps": "8531.8", "ups": "0.79", "wpb": "10769.4", "bsz": "22.9", "num_updates": "5000", "lr": "0.00046875", "gnorm": "2.079", "loss_scale": "1", "train_wall": "177", "gb_free": "5.5", "wall": "6403"}
[2024-03-26 18:16:25,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 626 @ 5001 updates
[2024-03-26 18:16:25,932][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:28,416][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:28,481][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 626 @ 5001 updates, score None) (writing took 2.550418501254171 seconds)
[2024-03-26 18:16:28,482][fairseq_cli.train][INFO] - end of epoch 626 (average epoch stats below)
[2024-03-26 18:16:28,483][train][INFO] - {"epoch": 626, "train_loss": "1.177", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.066", "train_target_var": "0.745", "train_pred_var": "0.716", "train_masked_pct": "0.498", "train_wps": "8802.3", "train_ups": "0.82", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5001", "train_lr": "0.000468844", "train_gnorm": "2.121", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "6406"}
[2024-03-26 18:16:28,486][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:28,551][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 627
[2024-03-26 18:16:28,553][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:28,556][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:28,561][fairseq.trainer][INFO] - begin training epoch 627
[2024-03-26 18:16:28,562][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:35,857][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 627 @ 5009 updates
[2024-03-26 18:16:35,859][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:38,365][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:38,432][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 627 @ 5009 updates, score None) (writing took 2.5744393919594586 seconds)
[2024-03-26 18:16:38,432][fairseq_cli.train][INFO] - end of epoch 627 (average epoch stats below)
[2024-03-26 18:16:38,433][train][INFO] - {"epoch": 627, "train_loss": "1.194", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.066", "train_target_var": "0.743", "train_pred_var": "0.711", "train_masked_pct": "0.499", "train_wps": "8659.4", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "5009", "train_lr": "0.000469594", "train_gnorm": "1.948", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6416"}
[2024-03-26 18:16:38,435][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:38,496][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 628
[2024-03-26 18:16:38,498][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:38,501][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:38,506][fairseq.trainer][INFO] - begin training epoch 628
[2024-03-26 18:16:38,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:45,807][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 628 @ 5017 updates
[2024-03-26 18:16:45,808][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:48,292][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:48,350][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 628 @ 5017 updates, score None) (writing took 2.5437290649861097 seconds)
[2024-03-26 18:16:48,351][fairseq_cli.train][INFO] - end of epoch 628 (average epoch stats below)
[2024-03-26 18:16:48,351][train][INFO] - {"epoch": 628, "train_loss": "1.159", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.066", "train_target_var": "0.746", "train_pred_var": "0.717", "train_masked_pct": "0.498", "train_wps": "8686.5", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5017", "train_lr": "0.000470344", "train_gnorm": "2.087", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6426"}
[2024-03-26 18:16:48,353][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:48,423][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 629
[2024-03-26 18:16:48,424][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:48,427][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:48,433][fairseq.trainer][INFO] - begin training epoch 629
[2024-03-26 18:16:48,433][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:16:55,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 629 @ 5025 updates
[2024-03-26 18:16:55,788][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:58,281][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:16:58,318][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 629 @ 5025 updates, score None) (writing took 2.532005585730076 seconds)
[2024-03-26 18:16:58,319][fairseq_cli.train][INFO] - end of epoch 629 (average epoch stats below)
[2024-03-26 18:16:58,319][train][INFO] - {"epoch": 629, "train_loss": "1.181", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.066", "train_target_var": "0.748", "train_pred_var": "0.717", "train_masked_pct": "0.501", "train_wps": "8644.1", "train_ups": "0.8", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "5025", "train_lr": "0.000471094", "train_gnorm": "2.105", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6436"}
[2024-03-26 18:16:58,321][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:16:58,419][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 630
[2024-03-26 18:16:58,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:16:58,423][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:16:58,428][fairseq.trainer][INFO] - begin training epoch 630
[2024-03-26 18:16:58,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:05,812][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:17:05,813][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:05,876][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 127
[2024-03-26 18:17:05,879][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:06,292][valid][INFO] - {"epoch": 630, "valid_loss": "1.332", "valid_ntokens": "11720", "valid_nsentences": "25", "valid_sample_size": "11720", "valid_ema_decay": "999.066", "valid_target_var": "0.74", "valid_pred_var": "0.705", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11720", "valid_bsz": "25", "valid_num_updates": "5033", "valid_best_loss": "0.222"}
[2024-03-26 18:17:06,294][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 630 @ 5033 updates
[2024-03-26 18:17:06,295][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:08,798][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:08,855][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 630 @ 5033 updates, score 1.332) (writing took 2.5616187332198024 seconds)
[2024-03-26 18:17:08,856][fairseq_cli.train][INFO] - end of epoch 630 (average epoch stats below)
[2024-03-26 18:17:08,856][train][INFO] - {"epoch": 630, "train_loss": "1.18", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.066", "train_target_var": "0.744", "train_pred_var": "0.716", "train_masked_pct": "0.5", "train_wps": "8176.4", "train_ups": "0.76", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "5033", "train_lr": "0.000471844", "train_gnorm": "2.059", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6447"}
[2024-03-26 18:17:08,858][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:08,920][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 631
[2024-03-26 18:17:08,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:08,925][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:08,930][fairseq.trainer][INFO] - begin training epoch 631
[2024-03-26 18:17:08,930][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:16,408][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 631 @ 5041 updates
[2024-03-26 18:17:16,410][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:18,893][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:18,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 631 @ 5041 updates, score None) (writing took 2.551056332886219 seconds)
[2024-03-26 18:17:18,960][fairseq_cli.train][INFO] - end of epoch 631 (average epoch stats below)
[2024-03-26 18:17:18,960][train][INFO] - {"epoch": 631, "train_loss": "1.156", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.066", "train_target_var": "0.744", "train_pred_var": "0.712", "train_masked_pct": "0.499", "train_wps": "8527.2", "train_ups": "0.79", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5041", "train_lr": "0.000472594", "train_gnorm": "1.81", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6457"}
[2024-03-26 18:17:18,962][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:19,025][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 632
[2024-03-26 18:17:19,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:19,030][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:19,035][fairseq.trainer][INFO] - begin training epoch 632
[2024-03-26 18:17:19,035][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:26,322][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 632 @ 5049 updates
[2024-03-26 18:17:26,323][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:28,813][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:28,880][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 632 @ 5049 updates, score None) (writing took 2.5582810300402343 seconds)
[2024-03-26 18:17:28,881][fairseq_cli.train][INFO] - end of epoch 632 (average epoch stats below)
[2024-03-26 18:17:28,882][train][INFO] - {"epoch": 632, "train_loss": "1.227", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.067", "train_target_var": "0.748", "train_pred_var": "0.717", "train_masked_pct": "0.501", "train_wps": "8684.7", "train_ups": "0.81", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5049", "train_lr": "0.000473344", "train_gnorm": "1.982", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6467"}
[2024-03-26 18:17:28,884][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:28,945][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 633
[2024-03-26 18:17:28,947][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:28,950][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:28,955][fairseq.trainer][INFO] - begin training epoch 633
[2024-03-26 18:17:28,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:36,414][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 633 @ 5057 updates
[2024-03-26 18:17:36,416][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:38,884][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:38,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 633 @ 5057 updates, score None) (writing took 2.5334732602350414 seconds)
[2024-03-26 18:17:38,948][fairseq_cli.train][INFO] - end of epoch 633 (average epoch stats below)
[2024-03-26 18:17:38,949][train][INFO] - {"epoch": 633, "train_loss": "1.245", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.067", "train_target_var": "0.744", "train_pred_var": "0.712", "train_masked_pct": "0.501", "train_wps": "8558.5", "train_ups": "0.79", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "5057", "train_lr": "0.000474094", "train_gnorm": "2.483", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6477"}
[2024-03-26 18:17:38,951][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:39,013][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 634
[2024-03-26 18:17:39,015][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:39,018][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:39,022][fairseq.trainer][INFO] - begin training epoch 634
[2024-03-26 18:17:39,023][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:46,395][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 634 @ 5065 updates
[2024-03-26 18:17:46,396][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:48,870][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:48,947][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 634 @ 5065 updates, score None) (writing took 2.552165594883263 seconds)
[2024-03-26 18:17:48,948][fairseq_cli.train][INFO] - end of epoch 634 (average epoch stats below)
[2024-03-26 18:17:48,949][train][INFO] - {"epoch": 634, "train_loss": "1.295", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.067", "train_target_var": "0.743", "train_pred_var": "0.71", "train_masked_pct": "0.501", "train_wps": "8615.3", "train_ups": "0.8", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "5065", "train_lr": "0.000474844", "train_gnorm": "2.307", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6487"}
[2024-03-26 18:17:48,954][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:49,023][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 635
[2024-03-26 18:17:49,024][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:49,028][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:49,032][fairseq.trainer][INFO] - begin training epoch 635
[2024-03-26 18:17:49,033][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:17:56,266][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:17:56,267][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:56,330][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 128
[2024-03-26 18:17:56,333][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:56,771][valid][INFO] - {"epoch": 635, "valid_loss": "1.092", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.067", "valid_target_var": "0.746", "valid_pred_var": "0.708", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "5073", "valid_best_loss": "0.222"}
[2024-03-26 18:17:56,773][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 635 @ 5073 updates
[2024-03-26 18:17:56,774][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:59,262][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:17:59,328][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 635 @ 5073 updates, score 1.092) (writing took 2.555103566031903 seconds)
[2024-03-26 18:17:59,329][fairseq_cli.train][INFO] - end of epoch 635 (average epoch stats below)
[2024-03-26 18:17:59,329][train][INFO] - {"epoch": 635, "train_loss": "1.165", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.067", "train_target_var": "0.747", "train_pred_var": "0.717", "train_masked_pct": "0.501", "train_wps": "8300.9", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5073", "train_lr": "0.000475594", "train_gnorm": "1.895", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "6497"}
[2024-03-26 18:17:59,331][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:17:59,395][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 636
[2024-03-26 18:17:59,396][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:17:59,399][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:17:59,404][fairseq.trainer][INFO] - begin training epoch 636
[2024-03-26 18:17:59,404][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:06,701][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 636 @ 5081 updates
[2024-03-26 18:18:06,703][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:09,191][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:09,258][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 636 @ 5081 updates, score None) (writing took 2.5567080196924508 seconds)
[2024-03-26 18:18:09,259][fairseq_cli.train][INFO] - end of epoch 636 (average epoch stats below)
[2024-03-26 18:18:09,260][train][INFO] - {"epoch": 636, "train_loss": "1.264", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.067", "train_target_var": "0.744", "train_pred_var": "0.711", "train_masked_pct": "0.5", "train_wps": "8676.7", "train_ups": "0.81", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "5081", "train_lr": "0.000476344", "train_gnorm": "3.842", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6507"}
[2024-03-26 18:18:09,262][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:09,324][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 637
[2024-03-26 18:18:09,326][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:09,329][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:09,334][fairseq.trainer][INFO] - begin training epoch 637
[2024-03-26 18:18:09,334][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:16,735][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 637 @ 5089 updates
[2024-03-26 18:18:16,737][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:19,234][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:19,300][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 637 @ 5089 updates, score None) (writing took 2.5648906328715384 seconds)
[2024-03-26 18:18:19,301][fairseq_cli.train][INFO] - end of epoch 637 (average epoch stats below)
[2024-03-26 18:18:19,302][train][INFO] - {"epoch": 637, "train_loss": "1.269", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.067", "train_target_var": "0.745", "train_pred_var": "0.713", "train_masked_pct": "0.501", "train_wps": "8580.1", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5089", "train_lr": "0.000477094", "train_gnorm": "3.954", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6517"}
[2024-03-26 18:18:19,303][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:19,365][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 638
[2024-03-26 18:18:19,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:19,370][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:19,375][fairseq.trainer][INFO] - begin training epoch 638
[2024-03-26 18:18:19,375][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:26,738][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 638 @ 5097 updates
[2024-03-26 18:18:26,739][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:29,235][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:29,302][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 638 @ 5097 updates, score None) (writing took 2.5648422511294484 seconds)
[2024-03-26 18:18:29,303][fairseq_cli.train][INFO] - end of epoch 638 (average epoch stats below)
[2024-03-26 18:18:29,304][train][INFO] - {"epoch": 638, "train_loss": "1.262", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.067", "train_target_var": "0.743", "train_pred_var": "0.707", "train_masked_pct": "0.5", "train_wps": "8614.5", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5097", "train_lr": "0.000477844", "train_gnorm": "2.807", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6527"}
[2024-03-26 18:18:29,306][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:29,368][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 639
[2024-03-26 18:18:29,370][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:29,373][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:29,378][fairseq.trainer][INFO] - begin training epoch 639
[2024-03-26 18:18:29,378][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:36,721][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 639 @ 5105 updates
[2024-03-26 18:18:36,722][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:39,201][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:39,269][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 639 @ 5105 updates, score None) (writing took 2.5483653671108186 seconds)
[2024-03-26 18:18:39,270][fairseq_cli.train][INFO] - end of epoch 639 (average epoch stats below)
[2024-03-26 18:18:39,270][train][INFO] - {"epoch": 639, "train_loss": "1.239", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.067", "train_target_var": "0.746", "train_pred_var": "0.714", "train_masked_pct": "0.5", "train_wps": "8644.6", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "5105", "train_lr": "0.000478594", "train_gnorm": "2.092", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6537"}
[2024-03-26 18:18:39,273][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:39,335][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 640
[2024-03-26 18:18:39,337][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:39,340][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:39,344][fairseq.trainer][INFO] - begin training epoch 640
[2024-03-26 18:18:39,345][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:46,708][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:18:46,709][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:46,775][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 129
[2024-03-26 18:18:46,778][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:47,188][valid][INFO] - {"epoch": 640, "valid_loss": "1.538", "valid_ntokens": "11714", "valid_nsentences": "25", "valid_sample_size": "11714", "valid_ema_decay": "999.067", "valid_target_var": "0.745", "valid_pred_var": "0.701", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11714", "valid_bsz": "25", "valid_num_updates": "5113", "valid_best_loss": "0.222"}
[2024-03-26 18:18:47,189][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 640 @ 5113 updates
[2024-03-26 18:18:47,191][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:49,698][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:49,767][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 640 @ 5113 updates, score 1.538) (writing took 2.577735814731568 seconds)
[2024-03-26 18:18:49,768][fairseq_cli.train][INFO] - end of epoch 640 (average epoch stats below)
[2024-03-26 18:18:49,768][train][INFO] - {"epoch": 640, "train_loss": "1.326", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.067", "train_target_var": "0.743", "train_pred_var": "0.71", "train_masked_pct": "0.499", "train_wps": "8207.4", "train_ups": "0.76", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "5113", "train_lr": "0.000479344", "train_gnorm": "2.422", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6548"}
[2024-03-26 18:18:49,771][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:49,837][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 641
[2024-03-26 18:18:49,839][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:49,842][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:49,846][fairseq.trainer][INFO] - begin training epoch 641
[2024-03-26 18:18:49,847][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:18:57,174][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 641 @ 5121 updates
[2024-03-26 18:18:57,175][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:59,651][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:18:59,717][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 641 @ 5121 updates, score None) (writing took 2.5434664809145033 seconds)
[2024-03-26 18:18:59,718][fairseq_cli.train][INFO] - end of epoch 641 (average epoch stats below)
[2024-03-26 18:18:59,719][train][INFO] - {"epoch": 641, "train_loss": "1.25", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.068", "train_target_var": "0.747", "train_pred_var": "0.714", "train_masked_pct": "0.499", "train_wps": "8658.9", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "5121", "train_lr": "0.000480094", "train_gnorm": "2.263", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6558"}
[2024-03-26 18:18:59,721][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:18:59,785][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 642
[2024-03-26 18:18:59,787][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:18:59,790][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:18:59,795][fairseq.trainer][INFO] - begin training epoch 642
[2024-03-26 18:18:59,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:07,218][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 642 @ 5129 updates
[2024-03-26 18:19:07,219][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:09,696][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:09,739][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 642 @ 5129 updates, score None) (writing took 2.521120415069163 seconds)
[2024-03-26 18:19:09,739][fairseq_cli.train][INFO] - end of epoch 642 (average epoch stats below)
[2024-03-26 18:19:09,740][train][INFO] - {"epoch": 642, "train_loss": "1.323", "train_ntokens": "10768.4", "train_nsentences": "22.875", "train_sample_size": "10768.4", "train_ema_decay": "999.068", "train_target_var": "0.744", "train_pred_var": "0.709", "train_masked_pct": "0.499", "train_wps": "8597.1", "train_ups": "0.8", "train_wpb": "10768.4", "train_bsz": "22.9", "train_num_updates": "5129", "train_lr": "0.000480844", "train_gnorm": "2.263", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6568"}
[2024-03-26 18:19:09,742][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:09,831][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 643
[2024-03-26 18:19:09,833][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:09,837][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:09,841][fairseq.trainer][INFO] - begin training epoch 643
[2024-03-26 18:19:09,842][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:17,318][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 643 @ 5137 updates
[2024-03-26 18:19:17,319][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:19,822][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:19,869][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 643 @ 5137 updates, score None) (writing took 2.550952237099409 seconds)
[2024-03-26 18:19:19,870][fairseq_cli.train][INFO] - end of epoch 643 (average epoch stats below)
[2024-03-26 18:19:19,870][train][INFO] - {"epoch": 643, "train_loss": "1.233", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.068", "train_target_var": "0.746", "train_pred_var": "0.716", "train_masked_pct": "0.499", "train_wps": "8505.9", "train_ups": "0.79", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "5137", "train_lr": "0.000481594", "train_gnorm": "2.014", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6578"}
[2024-03-26 18:19:19,873][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:19,957][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 644
[2024-03-26 18:19:19,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:19,962][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:19,966][fairseq.trainer][INFO] - begin training epoch 644
[2024-03-26 18:19:19,967][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:27,008][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 644 @ 5145 updates
[2024-03-26 18:19:27,009][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:29,503][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:29,569][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 644 @ 5145 updates, score None) (writing took 2.561450881883502 seconds)
[2024-03-26 18:19:29,570][fairseq_cli.train][INFO] - end of epoch 644 (average epoch stats below)
[2024-03-26 18:19:29,570][train][INFO] - {"epoch": 644, "train_loss": "1.182", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.068", "train_target_var": "0.744", "train_pred_var": "0.713", "train_masked_pct": "0.5", "train_wps": "8883", "train_ups": "0.82", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5145", "train_lr": "0.000482344", "train_gnorm": "1.901", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6587"}
[2024-03-26 18:19:29,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:29,634][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 645
[2024-03-26 18:19:29,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:29,638][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:29,643][fairseq.trainer][INFO] - begin training epoch 645
[2024-03-26 18:19:29,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:36,888][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:19:36,889][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:36,955][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 130
[2024-03-26 18:19:36,959][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:37,372][valid][INFO] - {"epoch": 645, "valid_loss": "1.266", "valid_ntokens": "11710", "valid_nsentences": "25", "valid_sample_size": "11710", "valid_ema_decay": "999.068", "valid_target_var": "0.74", "valid_pred_var": "0.708", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11710", "valid_bsz": "25", "valid_num_updates": "5153", "valid_best_loss": "0.222"}
[2024-03-26 18:19:37,374][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 645 @ 5153 updates
[2024-03-26 18:19:37,375][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:39,907][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:39,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 645 @ 5153 updates, score 1.266) (writing took 2.5999702075496316 seconds)
[2024-03-26 18:19:39,974][fairseq_cli.train][INFO] - end of epoch 645 (average epoch stats below)
[2024-03-26 18:19:39,976][train][INFO] - {"epoch": 645, "train_loss": "1.251", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.068", "train_target_var": "0.743", "train_pred_var": "0.708", "train_masked_pct": "0.5", "train_wps": "8280.3", "train_ups": "0.77", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5153", "train_lr": "0.000483094", "train_gnorm": "1.999", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "6598"}
[2024-03-26 18:19:39,978][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:40,040][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 646
[2024-03-26 18:19:40,041][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:40,044][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:40,049][fairseq.trainer][INFO] - begin training epoch 646
[2024-03-26 18:19:40,050][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:47,324][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 646 @ 5161 updates
[2024-03-26 18:19:47,326][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:49,833][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:49,895][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 646 @ 5161 updates, score None) (writing took 2.570422749966383 seconds)
[2024-03-26 18:19:49,896][fairseq_cli.train][INFO] - end of epoch 646 (average epoch stats below)
[2024-03-26 18:19:49,896][train][INFO] - {"epoch": 646, "train_loss": "1.198", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.068", "train_target_var": "0.745", "train_pred_var": "0.712", "train_masked_pct": "0.501", "train_wps": "8685", "train_ups": "0.81", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "5161", "train_lr": "0.000483844", "train_gnorm": "1.922", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6608"}
[2024-03-26 18:19:49,899][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:49,962][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 647
[2024-03-26 18:19:49,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:49,967][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:49,972][fairseq.trainer][INFO] - begin training epoch 647
[2024-03-26 18:19:49,973][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:19:57,266][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 647 @ 5169 updates
[2024-03-26 18:19:57,268][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:59,759][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:19:59,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 647 @ 5169 updates, score None) (writing took 2.5558190080337226 seconds)
[2024-03-26 18:19:59,823][fairseq_cli.train][INFO] - end of epoch 647 (average epoch stats below)
[2024-03-26 18:19:59,823][train][INFO] - {"epoch": 647, "train_loss": "1.187", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.068", "train_target_var": "0.742", "train_pred_var": "0.713", "train_masked_pct": "0.501", "train_wps": "8679.4", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5169", "train_lr": "0.000484594", "train_gnorm": "1.866", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "6618"}
[2024-03-26 18:19:59,826][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:19:59,898][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 648
[2024-03-26 18:19:59,900][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:19:59,903][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:19:59,908][fairseq.trainer][INFO] - begin training epoch 648
[2024-03-26 18:19:59,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:07,115][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 648 @ 5177 updates
[2024-03-26 18:20:07,116][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:09,590][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:09,637][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 648 @ 5177 updates, score None) (writing took 2.5222103097476065 seconds)
[2024-03-26 18:20:09,638][fairseq_cli.train][INFO] - end of epoch 648 (average epoch stats below)
[2024-03-26 18:20:09,638][train][INFO] - {"epoch": 648, "train_loss": "1.211", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.068", "train_target_var": "0.744", "train_pred_var": "0.712", "train_masked_pct": "0.5", "train_wps": "8778.2", "train_ups": "0.82", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "5177", "train_lr": "0.000485344", "train_gnorm": "2.072", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.9", "train_wall": "6627"}
[2024-03-26 18:20:09,640][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:09,727][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 649
[2024-03-26 18:20:09,729][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:09,732][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:09,737][fairseq.trainer][INFO] - begin training epoch 649
[2024-03-26 18:20:09,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:17,020][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 649 @ 5185 updates
[2024-03-26 18:20:17,022][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:19,512][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:19,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 649 @ 5185 updates, score None) (writing took 2.562265556305647 seconds)
[2024-03-26 18:20:19,583][fairseq_cli.train][INFO] - end of epoch 649 (average epoch stats below)
[2024-03-26 18:20:19,584][train][INFO] - {"epoch": 649, "train_loss": "1.251", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.068", "train_target_var": "0.744", "train_pred_var": "0.712", "train_masked_pct": "0.5", "train_wps": "8663.2", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "5185", "train_lr": "0.000486094", "train_gnorm": "2.731", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6637"}
[2024-03-26 18:20:19,586][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:19,649][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 650
[2024-03-26 18:20:19,651][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:19,654][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:19,658][fairseq.trainer][INFO] - begin training epoch 650
[2024-03-26 18:20:19,659][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:26,909][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:20:26,910][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:26,973][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 131
[2024-03-26 18:20:26,976][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:27,390][valid][INFO] - {"epoch": 650, "valid_loss": "1.32", "valid_ntokens": "11719", "valid_nsentences": "25", "valid_sample_size": "11719", "valid_ema_decay": "999.069", "valid_target_var": "0.743", "valid_pred_var": "0.7", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11719", "valid_bsz": "25", "valid_num_updates": "5193", "valid_best_loss": "0.222"}
[2024-03-26 18:20:27,391][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 650 @ 5193 updates
[2024-03-26 18:20:27,393][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:29,906][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:29,947][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 650 @ 5193 updates, score 1.32) (writing took 2.5558853349648416 seconds)
[2024-03-26 18:20:29,948][fairseq_cli.train][INFO] - end of epoch 650 (average epoch stats below)
[2024-03-26 18:20:29,948][train][INFO] - {"epoch": 650, "train_loss": "1.234", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.068", "train_target_var": "0.743", "train_pred_var": "0.711", "train_masked_pct": "0.501", "train_wps": "8313.4", "train_ups": "0.77", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "5193", "train_lr": "0.000486844", "train_gnorm": "2.341", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "12", "train_wall": "6648"}
[2024-03-26 18:20:29,950][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:30,039][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 651
[2024-03-26 18:20:30,040][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:30,043][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:30,048][fairseq.trainer][INFO] - begin training epoch 651
[2024-03-26 18:20:30,049][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:37,134][train_inner][INFO] - {"epoch": 651, "update": 650.875, "loss": "1.228", "ntokens": "10826", "nsentences": "22.995", "sample_size": "10826", "ema_decay": "999.067", "target_var": "0.745", "pred_var": "0.713", "masked_pct": "0.5", "wps": "8589.5", "ups": "0.79", "wpb": "10826", "bsz": "23", "num_updates": "5200", "lr": "0.0004875", "gnorm": "2.292", "loss_scale": "1", "train_wall": "176", "gb_free": "5.7", "wall": "6655"}
[2024-03-26 18:20:37,286][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 651 @ 5201 updates
[2024-03-26 18:20:37,288][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:39,781][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:39,850][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 651 @ 5201 updates, score None) (writing took 2.5638553728349507 seconds)
[2024-03-26 18:20:39,851][fairseq_cli.train][INFO] - end of epoch 651 (average epoch stats below)
[2024-03-26 18:20:39,852][train][INFO] - {"epoch": 651, "train_loss": "1.22", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.069", "train_target_var": "0.743", "train_pred_var": "0.711", "train_masked_pct": "0.499", "train_wps": "8700.3", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5201", "train_lr": "0.000487594", "train_gnorm": "2.298", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6658"}
[2024-03-26 18:20:39,854][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:39,917][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 652
[2024-03-26 18:20:39,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:39,922][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:39,927][fairseq.trainer][INFO] - begin training epoch 652
[2024-03-26 18:20:39,928][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:47,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 652 @ 5209 updates
[2024-03-26 18:20:47,273][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:49,785][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:49,856][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 652 @ 5209 updates, score None) (writing took 2.5843674172647297 seconds)
[2024-03-26 18:20:49,856][fairseq_cli.train][INFO] - end of epoch 652 (average epoch stats below)
[2024-03-26 18:20:49,857][train][INFO] - {"epoch": 652, "train_loss": "1.232", "train_ntokens": "10768.8", "train_nsentences": "22.875", "train_sample_size": "10768.8", "train_ema_decay": "999.069", "train_target_var": "0.74", "train_pred_var": "0.711", "train_masked_pct": "0.499", "train_wps": "8611.7", "train_ups": "0.8", "train_wpb": "10768.8", "train_bsz": "22.9", "train_num_updates": "5209", "train_lr": "0.000488344", "train_gnorm": "2.101", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6668"}
[2024-03-26 18:20:49,859][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:49,922][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 653
[2024-03-26 18:20:49,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:49,926][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:49,931][fairseq.trainer][INFO] - begin training epoch 653
[2024-03-26 18:20:49,932][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:20:57,389][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 653 @ 5217 updates
[2024-03-26 18:20:57,391][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:59,854][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:20:59,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 653 @ 5217 updates, score None) (writing took 2.5111296493560076 seconds)
[2024-03-26 18:20:59,900][fairseq_cli.train][INFO] - end of epoch 653 (average epoch stats below)
[2024-03-26 18:20:59,901][train][INFO] - {"epoch": 653, "train_loss": "1.179", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.069", "train_target_var": "0.744", "train_pred_var": "0.71", "train_masked_pct": "0.499", "train_wps": "8578.2", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5217", "train_lr": "0.000489094", "train_gnorm": "2.034", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.7", "train_wall": "6678"}
[2024-03-26 18:20:59,903][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:20:59,989][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 654
[2024-03-26 18:20:59,990][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:20:59,994][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:20:59,999][fairseq.trainer][INFO] - begin training epoch 654
[2024-03-26 18:20:59,999][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:07,467][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 654 @ 5225 updates
[2024-03-26 18:21:07,468][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:09,951][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:10,020][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 654 @ 5225 updates, score None) (writing took 2.5536235300824046 seconds)
[2024-03-26 18:21:10,021][fairseq_cli.train][INFO] - end of epoch 654 (average epoch stats below)
[2024-03-26 18:21:10,022][train][INFO] - {"epoch": 654, "train_loss": "1.263", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.069", "train_target_var": "0.74", "train_pred_var": "0.707", "train_masked_pct": "0.501", "train_wps": "8512.4", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "5225", "train_lr": "0.000489844", "train_gnorm": "2.133", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6688"}
[2024-03-26 18:21:10,024][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:10,085][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 655
[2024-03-26 18:21:10,087][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:21:10,090][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:10,095][fairseq.trainer][INFO] - begin training epoch 655
[2024-03-26 18:21:10,095][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:17,518][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:21:17,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:17,584][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 132
[2024-03-26 18:21:17,588][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:18,010][valid][INFO] - {"epoch": 655, "valid_loss": "1.288", "valid_ntokens": "11707", "valid_nsentences": "25", "valid_sample_size": "11707", "valid_ema_decay": "999.069", "valid_target_var": "0.74", "valid_pred_var": "0.7", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11707", "valid_bsz": "25", "valid_num_updates": "5233", "valid_best_loss": "0.222"}
[2024-03-26 18:21:18,012][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 655 @ 5233 updates
[2024-03-26 18:21:18,013][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:20,506][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:20,573][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 655 @ 5233 updates, score 1.288) (writing took 2.561609434429556 seconds)
[2024-03-26 18:21:20,574][fairseq_cli.train][INFO] - end of epoch 655 (average epoch stats below)
[2024-03-26 18:21:20,575][train][INFO] - {"epoch": 655, "train_loss": "1.214", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.069", "train_target_var": "0.743", "train_pred_var": "0.711", "train_masked_pct": "0.498", "train_wps": "8164.9", "train_ups": "0.76", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "5233", "train_lr": "0.000490594", "train_gnorm": "1.801", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6698"}
[2024-03-26 18:21:20,577][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:20,641][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 656
[2024-03-26 18:21:20,642][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:21:20,645][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:20,650][fairseq.trainer][INFO] - begin training epoch 656
[2024-03-26 18:21:20,650][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:27,941][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 656 @ 5241 updates
[2024-03-26 18:21:27,942][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:30,441][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:30,508][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 656 @ 5241 updates, score None) (writing took 2.5679862000979483 seconds)
[2024-03-26 18:21:30,509][fairseq_cli.train][INFO] - end of epoch 656 (average epoch stats below)
[2024-03-26 18:21:30,510][train][INFO] - {"epoch": 656, "train_loss": "1.181", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.069", "train_target_var": "0.742", "train_pred_var": "0.711", "train_masked_pct": "0.5", "train_wps": "8672.8", "train_ups": "0.81", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5241", "train_lr": "0.000491344", "train_gnorm": "1.753", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6708"}
[2024-03-26 18:21:30,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:30,575][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 657
[2024-03-26 18:21:30,577][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:21:30,580][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:30,585][fairseq.trainer][INFO] - begin training epoch 657
[2024-03-26 18:21:30,585][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:37,878][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 657 @ 5249 updates
[2024-03-26 18:21:37,880][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:40,387][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:40,456][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 657 @ 5249 updates, score None) (writing took 2.5771860778331757 seconds)
[2024-03-26 18:21:40,456][fairseq_cli.train][INFO] - end of epoch 657 (average epoch stats below)
[2024-03-26 18:21:40,457][train][INFO] - {"epoch": 657, "train_loss": "1.267", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.069", "train_target_var": "0.744", "train_pred_var": "0.71", "train_masked_pct": "0.498", "train_wps": "8661.7", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5249", "train_lr": "0.000492094", "train_gnorm": "2.015", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.5", "train_wall": "6718"}
[2024-03-26 18:21:40,459][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:40,523][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 658
[2024-03-26 18:21:40,524][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:21:40,527][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:40,532][fairseq.trainer][INFO] - begin training epoch 658
[2024-03-26 18:21:40,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:47,697][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 658 @ 5257 updates
[2024-03-26 18:21:47,698][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:50,179][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:21:50,246][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 658 @ 5257 updates, score None) (writing took 2.5493761780671775 seconds)
[2024-03-26 18:21:50,247][fairseq_cli.train][INFO] - end of epoch 658 (average epoch stats below)
[2024-03-26 18:21:50,247][train][INFO] - {"epoch": 658, "train_loss": "1.264", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.069", "train_target_var": "0.743", "train_pred_var": "0.712", "train_masked_pct": "0.501", "train_wps": "8800.3", "train_ups": "0.82", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5257", "train_lr": "0.000492844", "train_gnorm": "1.982", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6728"}
[2024-03-26 18:21:50,249][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:21:50,312][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 659
[2024-03-26 18:21:50,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:21:50,317][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:21:50,322][fairseq.trainer][INFO] - begin training epoch 659
[2024-03-26 18:21:50,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:21:57,748][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 659 @ 5265 updates
[2024-03-26 18:21:57,750][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:00,228][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:00,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 659 @ 5265 updates, score None) (writing took 2.5485089388675988 seconds)
[2024-03-26 18:22:00,297][fairseq_cli.train][INFO] - end of epoch 659 (average epoch stats below)
[2024-03-26 18:22:00,298][train][INFO] - {"epoch": 659, "train_loss": "1.216", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.069", "train_target_var": "0.741", "train_pred_var": "0.707", "train_masked_pct": "0.5", "train_wps": "8572.5", "train_ups": "0.8", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "5265", "train_lr": "0.000493594", "train_gnorm": "1.982", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6738"}
[2024-03-26 18:22:00,300][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:00,362][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 660
[2024-03-26 18:22:00,363][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:00,366][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:00,371][fairseq.trainer][INFO] - begin training epoch 660
[2024-03-26 18:22:00,372][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:07,620][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:22:07,621][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:07,685][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 133
[2024-03-26 18:22:07,688][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:08,096][valid][INFO] - {"epoch": 660, "valid_loss": "1.274", "valid_ntokens": "11723", "valid_nsentences": "25", "valid_sample_size": "11723", "valid_ema_decay": "999.07", "valid_target_var": "0.745", "valid_pred_var": "0.696", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11723", "valid_bsz": "25", "valid_num_updates": "5273", "valid_best_loss": "0.222"}
[2024-03-26 18:22:08,098][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 660 @ 5273 updates
[2024-03-26 18:22:08,099][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:10,573][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:10,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 660 @ 5273 updates, score 1.274) (writing took 2.5231254640966654 seconds)
[2024-03-26 18:22:10,621][fairseq_cli.train][INFO] - end of epoch 660 (average epoch stats below)
[2024-03-26 18:22:10,622][train][INFO] - {"epoch": 660, "train_loss": "1.344", "train_ntokens": "10768", "train_nsentences": "22.875", "train_sample_size": "10768", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.708", "train_masked_pct": "0.501", "train_wps": "8344.8", "train_ups": "0.77", "train_wpb": "10768", "train_bsz": "22.9", "train_num_updates": "5273", "train_lr": "0.000494344", "train_gnorm": "2.614", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6748"}
[2024-03-26 18:22:10,624][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:10,698][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 661
[2024-03-26 18:22:10,700][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:10,703][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:10,708][fairseq.trainer][INFO] - begin training epoch 661
[2024-03-26 18:22:10,708][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:18,065][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 661 @ 5281 updates
[2024-03-26 18:22:18,066][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:20,553][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:20,624][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 661 @ 5281 updates, score None) (writing took 2.5592740941792727 seconds)
[2024-03-26 18:22:20,625][fairseq_cli.train][INFO] - end of epoch 661 (average epoch stats below)
[2024-03-26 18:22:20,626][train][INFO] - {"epoch": 661, "train_loss": "1.244", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.708", "train_masked_pct": "0.5", "train_wps": "8612.2", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "5281", "train_lr": "0.000495094", "train_gnorm": "2.007", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6758"}
[2024-03-26 18:22:20,628][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:20,692][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 662
[2024-03-26 18:22:20,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:20,697][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:20,702][fairseq.trainer][INFO] - begin training epoch 662
[2024-03-26 18:22:20,702][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:28,117][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 662 @ 5289 updates
[2024-03-26 18:22:28,119][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:30,608][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:30,677][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 662 @ 5289 updates, score None) (writing took 2.5593109489418566 seconds)
[2024-03-26 18:22:30,677][fairseq_cli.train][INFO] - end of epoch 662 (average epoch stats below)
[2024-03-26 18:22:30,678][train][INFO] - {"epoch": 662, "train_loss": "1.286", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.709", "train_masked_pct": "0.5", "train_wps": "8571.5", "train_ups": "0.8", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "5289", "train_lr": "0.000495844", "train_gnorm": "1.891", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "6769"}
[2024-03-26 18:22:30,680][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:30,742][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 663
[2024-03-26 18:22:30,744][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:30,747][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:30,752][fairseq.trainer][INFO] - begin training epoch 663
[2024-03-26 18:22:30,752][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:38,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 663 @ 5297 updates
[2024-03-26 18:22:38,120][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:40,611][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:40,657][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 663 @ 5297 updates, score None) (writing took 2.5385521091520786 seconds)
[2024-03-26 18:22:40,658][fairseq_cli.train][INFO] - end of epoch 663 (average epoch stats below)
[2024-03-26 18:22:40,659][train][INFO] - {"epoch": 663, "train_loss": "1.316", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.07", "train_target_var": "0.74", "train_pred_var": "0.704", "train_masked_pct": "0.501", "train_wps": "8632.7", "train_ups": "0.8", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "5297", "train_lr": "0.000496594", "train_gnorm": "2.097", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6778"}
[2024-03-26 18:22:40,662][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:40,748][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 664
[2024-03-26 18:22:40,750][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:40,753][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:40,758][fairseq.trainer][INFO] - begin training epoch 664
[2024-03-26 18:22:40,758][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:48,098][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 664 @ 5305 updates
[2024-03-26 18:22:48,099][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:50,597][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:22:50,667][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 664 @ 5305 updates, score None) (writing took 2.5693707717582583 seconds)
[2024-03-26 18:22:50,668][fairseq_cli.train][INFO] - end of epoch 664 (average epoch stats below)
[2024-03-26 18:22:50,668][train][INFO] - {"epoch": 664, "train_loss": "1.227", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.709", "train_masked_pct": "0.501", "train_wps": "8608", "train_ups": "0.8", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "5305", "train_lr": "0.000497344", "train_gnorm": "1.798", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6788"}
[2024-03-26 18:22:50,671][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:50,733][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 665
[2024-03-26 18:22:50,734][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:22:50,737][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:50,742][fairseq.trainer][INFO] - begin training epoch 665
[2024-03-26 18:22:50,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:22:58,052][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:22:58,054][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:22:58,115][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 134
[2024-03-26 18:22:58,119][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:22:58,538][valid][INFO] - {"epoch": 665, "valid_loss": "1.322", "valid_ntokens": "11703", "valid_nsentences": "25", "valid_sample_size": "11703", "valid_ema_decay": "999.07", "valid_target_var": "0.741", "valid_pred_var": "0.7", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11703", "valid_bsz": "25", "valid_num_updates": "5313", "valid_best_loss": "0.222"}
[2024-03-26 18:22:58,540][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 665 @ 5313 updates
[2024-03-26 18:22:58,541][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:01,022][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:01,093][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 665 @ 5313 updates, score 1.322) (writing took 2.5538736903108656 seconds)
[2024-03-26 18:23:01,094][fairseq_cli.train][INFO] - end of epoch 665 (average epoch stats below)
[2024-03-26 18:23:01,095][train][INFO] - {"epoch": 665, "train_loss": "1.212", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.07", "train_target_var": "0.74", "train_pred_var": "0.709", "train_masked_pct": "0.5", "train_wps": "8263.8", "train_ups": "0.77", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5313", "train_lr": "0.000498094", "train_gnorm": "1.628", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6799"}
[2024-03-26 18:23:01,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:01,158][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 666
[2024-03-26 18:23:01,160][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:01,163][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:01,168][fairseq.trainer][INFO] - begin training epoch 666
[2024-03-26 18:23:01,168][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:08,685][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 666 @ 5321 updates
[2024-03-26 18:23:08,686][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:11,154][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:11,199][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 666 @ 5321 updates, score None) (writing took 2.514726452063769 seconds)
[2024-03-26 18:23:11,201][fairseq_cli.train][INFO] - end of epoch 666 (average epoch stats below)
[2024-03-26 18:23:11,201][train][INFO] - {"epoch": 666, "train_loss": "1.202", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.712", "train_masked_pct": "0.498", "train_wps": "8525.7", "train_ups": "0.79", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5321", "train_lr": "0.000498844", "train_gnorm": "1.452", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6809"}
[2024-03-26 18:23:11,203][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:11,293][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 667
[2024-03-26 18:23:11,295][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:11,298][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:11,303][fairseq.trainer][INFO] - begin training epoch 667
[2024-03-26 18:23:11,303][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:18,754][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 667 @ 5329 updates
[2024-03-26 18:23:18,755][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:21,233][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:21,305][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 667 @ 5329 updates, score None) (writing took 2.550597351975739 seconds)
[2024-03-26 18:23:21,305][fairseq_cli.train][INFO] - end of epoch 667 (average epoch stats below)
[2024-03-26 18:23:21,306][train][INFO] - {"epoch": 667, "train_loss": "1.186", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.07", "train_target_var": "0.739", "train_pred_var": "0.707", "train_masked_pct": "0.498", "train_wps": "8526.3", "train_ups": "0.79", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "5329", "train_lr": "0.000499594", "train_gnorm": "1.54", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6819"}
[2024-03-26 18:23:21,308][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:21,371][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 668
[2024-03-26 18:23:21,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:21,377][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:21,382][fairseq.trainer][INFO] - begin training epoch 668
[2024-03-26 18:23:21,382][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:28,746][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 668 @ 5337 updates
[2024-03-26 18:23:28,747][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:31,235][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:31,306][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 668 @ 5337 updates, score None) (writing took 2.5600907392799854 seconds)
[2024-03-26 18:23:31,306][fairseq_cli.train][INFO] - end of epoch 668 (average epoch stats below)
[2024-03-26 18:23:31,307][train][INFO] - {"epoch": 668, "train_loss": "1.293", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.07", "train_target_var": "0.742", "train_pred_var": "0.709", "train_masked_pct": "0.501", "train_wps": "8614.7", "train_ups": "0.8", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5337", "train_lr": "0.000500344", "train_gnorm": "2.326", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6829"}
[2024-03-26 18:23:31,310][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:31,371][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 669
[2024-03-26 18:23:31,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:31,376][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:31,380][fairseq.trainer][INFO] - begin training epoch 669
[2024-03-26 18:23:31,381][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:38,650][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 669 @ 5345 updates
[2024-03-26 18:23:38,652][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:41,122][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:41,173][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 669 @ 5345 updates, score None) (writing took 2.5228683268651366 seconds)
[2024-03-26 18:23:41,174][fairseq_cli.train][INFO] - end of epoch 669 (average epoch stats below)
[2024-03-26 18:23:41,174][train][INFO] - {"epoch": 669, "train_loss": "1.266", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.07", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.498", "train_wps": "8732.5", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5345", "train_lr": "0.000501094", "train_gnorm": "2.36", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "6839"}
[2024-03-26 18:23:41,176][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:41,257][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 670
[2024-03-26 18:23:41,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:41,262][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:41,266][fairseq.trainer][INFO] - begin training epoch 670
[2024-03-26 18:23:41,267][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:48,674][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:23:48,676][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:48,740][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 135
[2024-03-26 18:23:48,743][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:49,160][valid][INFO] - {"epoch": 670, "valid_loss": "1.248", "valid_ntokens": "11722", "valid_nsentences": "25", "valid_sample_size": "11722", "valid_ema_decay": "999.071", "valid_target_var": "0.742", "valid_pred_var": "0.706", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11722", "valid_bsz": "25", "valid_num_updates": "5353", "valid_best_loss": "0.222"}
[2024-03-26 18:23:49,161][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 670 @ 5353 updates
[2024-03-26 18:23:49,163][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:51,755][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:23:51,824][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 670 @ 5353 updates, score 1.248) (writing took 2.6626187497749925 seconds)
[2024-03-26 18:23:51,824][fairseq_cli.train][INFO] - end of epoch 670 (average epoch stats below)
[2024-03-26 18:23:51,825][train][INFO] - {"epoch": 670, "train_loss": "1.253", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.071", "train_target_var": "0.743", "train_pred_var": "0.71", "train_masked_pct": "0.499", "train_wps": "8088.9", "train_ups": "0.75", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "5353", "train_lr": "0.000501844", "train_gnorm": "2.116", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6850"}
[2024-03-26 18:23:51,827][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:23:51,890][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 671
[2024-03-26 18:23:51,892][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:23:51,895][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:23:51,900][fairseq.trainer][INFO] - begin training epoch 671
[2024-03-26 18:23:51,900][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:23:59,171][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 671 @ 5361 updates
[2024-03-26 18:23:59,173][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:01,663][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:01,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 671 @ 5361 updates, score None) (writing took 2.539772337768227 seconds)
[2024-03-26 18:24:01,712][fairseq_cli.train][INFO] - end of epoch 671 (average epoch stats below)
[2024-03-26 18:24:01,712][train][INFO] - {"epoch": 671, "train_loss": "1.259", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.071", "train_target_var": "0.743", "train_pred_var": "0.712", "train_masked_pct": "0.499", "train_wps": "8714.6", "train_ups": "0.81", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5361", "train_lr": "0.000502594", "train_gnorm": "1.94", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "6860"}
[2024-03-26 18:24:01,715][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:01,802][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 672
[2024-03-26 18:24:01,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:01,807][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:01,813][fairseq.trainer][INFO] - begin training epoch 672
[2024-03-26 18:24:01,813][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:09,279][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 672 @ 5369 updates
[2024-03-26 18:24:09,280][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:11,803][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:11,849][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 672 @ 5369 updates, score None) (writing took 2.570235901977867 seconds)
[2024-03-26 18:24:11,850][fairseq_cli.train][INFO] - end of epoch 672 (average epoch stats below)
[2024-03-26 18:24:11,850][train][INFO] - {"epoch": 672, "train_loss": "1.251", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.071", "train_target_var": "0.743", "train_pred_var": "0.71", "train_masked_pct": "0.501", "train_wps": "8499.5", "train_ups": "0.79", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "5369", "train_lr": "0.000503344", "train_gnorm": "2.084", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6870"}
[2024-03-26 18:24:11,853][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:11,940][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 673
[2024-03-26 18:24:11,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:11,946][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:11,951][fairseq.trainer][INFO] - begin training epoch 673
[2024-03-26 18:24:11,951][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:19,308][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 673 @ 5377 updates
[2024-03-26 18:24:19,310][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:21,812][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:21,882][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 673 @ 5377 updates, score None) (writing took 2.5738186296075583 seconds)
[2024-03-26 18:24:21,883][fairseq_cli.train][INFO] - end of epoch 673 (average epoch stats below)
[2024-03-26 18:24:21,883][train][INFO] - {"epoch": 673, "train_loss": "1.288", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.071", "train_target_var": "0.742", "train_pred_var": "0.708", "train_masked_pct": "0.499", "train_wps": "8587.7", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5377", "train_lr": "0.000504094", "train_gnorm": "1.998", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6880"}
[2024-03-26 18:24:21,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:21,947][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 674
[2024-03-26 18:24:21,949][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:21,952][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:21,956][fairseq.trainer][INFO] - begin training epoch 674
[2024-03-26 18:24:21,957][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:29,371][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 674 @ 5385 updates
[2024-03-26 18:24:29,372][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:31,880][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:31,944][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 674 @ 5385 updates, score None) (writing took 2.5728478711098433 seconds)
[2024-03-26 18:24:31,944][fairseq_cli.train][INFO] - end of epoch 674 (average epoch stats below)
[2024-03-26 18:24:31,945][train][INFO] - {"epoch": 674, "train_loss": "1.3", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.071", "train_target_var": "0.739", "train_pred_var": "0.704", "train_masked_pct": "0.499", "train_wps": "8562.1", "train_ups": "0.8", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "5385", "train_lr": "0.000504844", "train_gnorm": "1.84", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6890"}
[2024-03-26 18:24:31,947][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:32,008][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 675
[2024-03-26 18:24:32,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:32,013][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:32,018][fairseq.trainer][INFO] - begin training epoch 675
[2024-03-26 18:24:32,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:39,454][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:24:39,455][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:39,544][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 136
[2024-03-26 18:24:39,547][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:39,953][valid][INFO] - {"epoch": 675, "valid_loss": "1.33", "valid_ntokens": "11708", "valid_nsentences": "25", "valid_sample_size": "11708", "valid_ema_decay": "999.071", "valid_target_var": "0.742", "valid_pred_var": "0.705", "valid_masked_pct": "0.487", "valid_wps": "0", "valid_wpb": "11708", "valid_bsz": "25", "valid_num_updates": "5393", "valid_best_loss": "0.222"}
[2024-03-26 18:24:39,955][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 675 @ 5393 updates
[2024-03-26 18:24:39,956][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:42,557][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:42,609][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 675 @ 5393 updates, score 1.33) (writing took 2.654134760145098 seconds)
[2024-03-26 18:24:42,609][fairseq_cli.train][INFO] - end of epoch 675 (average epoch stats below)
[2024-03-26 18:24:42,610][train][INFO] - {"epoch": 675, "train_loss": "1.282", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.071", "train_target_var": "0.741", "train_pred_var": "0.707", "train_masked_pct": "0.501", "train_wps": "8078.5", "train_ups": "0.75", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "5393", "train_lr": "0.000505594", "train_gnorm": "1.743", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6900"}
[2024-03-26 18:24:42,612][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:42,692][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 676
[2024-03-26 18:24:42,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:42,697][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:42,702][fairseq.trainer][INFO] - begin training epoch 676
[2024-03-26 18:24:42,702][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:49,077][train_inner][INFO] - {"epoch": 676, "update": 675.875, "loss": "1.252", "ntokens": "10714.8", "nsentences": "22.76", "sample_size": "10714.8", "ema_decay": "999.07", "target_var": "0.742", "pred_var": "0.709", "masked_pct": "0.5", "wps": "8505.8", "ups": "0.79", "wpb": "10714.8", "bsz": "22.8", "num_updates": "5400", "lr": "0.00050625", "gnorm": "1.976", "loss_scale": "1", "train_wall": "176", "gb_free": "5.1", "wall": "6907"}
[2024-03-26 18:24:50,034][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 676 @ 5401 updates
[2024-03-26 18:24:50,036][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:52,524][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:24:52,595][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 676 @ 5401 updates, score None) (writing took 2.5605187490582466 seconds)
[2024-03-26 18:24:52,596][fairseq_cli.train][INFO] - end of epoch 676 (average epoch stats below)
[2024-03-26 18:24:52,596][train][INFO] - {"epoch": 676, "train_loss": "1.29", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.071", "train_target_var": "0.741", "train_pred_var": "0.708", "train_masked_pct": "0.501", "train_wps": "8627.2", "train_ups": "0.8", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "5401", "train_lr": "0.000506344", "train_gnorm": "1.999", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6910"}
[2024-03-26 18:24:52,599][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:24:52,663][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 677
[2024-03-26 18:24:52,665][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:24:52,668][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:24:52,673][fairseq.trainer][INFO] - begin training epoch 677
[2024-03-26 18:24:52,673][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:24:59,867][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 677 @ 5409 updates
[2024-03-26 18:24:59,869][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:02,368][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:02,439][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 677 @ 5409 updates, score None) (writing took 2.5718443072400987 seconds)
[2024-03-26 18:25:02,440][fairseq_cli.train][INFO] - end of epoch 677 (average epoch stats below)
[2024-03-26 18:25:02,440][train][INFO] - {"epoch": 677, "train_loss": "1.38", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.071", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.501", "train_wps": "8753.3", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "5409", "train_lr": "0.000507094", "train_gnorm": "2.585", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6920"}
[2024-03-26 18:25:02,442][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:02,503][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 678
[2024-03-26 18:25:02,505][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:02,508][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:02,513][fairseq.trainer][INFO] - begin training epoch 678
[2024-03-26 18:25:02,513][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:25:09,662][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 678 @ 5417 updates
[2024-03-26 18:25:09,664][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:12,136][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:12,210][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 678 @ 5417 updates, score None) (writing took 2.5476155770011246 seconds)
[2024-03-26 18:25:12,211][fairseq_cli.train][INFO] - end of epoch 678 (average epoch stats below)
[2024-03-26 18:25:12,211][train][INFO] - {"epoch": 678, "train_loss": "1.315", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.071", "train_target_var": "0.741", "train_pred_var": "0.706", "train_masked_pct": "0.5", "train_wps": "8818.4", "train_ups": "0.82", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5417", "train_lr": "0.000507844", "train_gnorm": "2.333", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6930"}
[2024-03-26 18:25:12,213][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:12,276][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 679
[2024-03-26 18:25:12,278][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:12,281][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:12,286][fairseq.trainer][INFO] - begin training epoch 679
[2024-03-26 18:25:12,287][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:25:19,791][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 679 @ 5425 updates
[2024-03-26 18:25:19,792][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:22,260][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:22,331][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 679 @ 5425 updates, score None) (writing took 2.540222038049251 seconds)
[2024-03-26 18:25:22,332][fairseq_cli.train][INFO] - end of epoch 679 (average epoch stats below)
[2024-03-26 18:25:22,332][train][INFO] - {"epoch": 679, "train_loss": "1.34", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.499", "train_wps": "8513.2", "train_ups": "0.79", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5425", "train_lr": "0.000508594", "train_gnorm": "2.256", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6940"}
[2024-03-26 18:25:22,334][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:22,397][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 680
[2024-03-26 18:25:22,398][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:22,401][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:22,406][fairseq.trainer][INFO] - begin training epoch 680
[2024-03-26 18:25:22,407][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:25:29,633][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:25:29,634][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:29,711][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 137
[2024-03-26 18:25:29,714][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:30,130][valid][INFO] - {"epoch": 680, "valid_loss": "1.359", "valid_ntokens": "11704", "valid_nsentences": "25", "valid_sample_size": "11704", "valid_ema_decay": "999.072", "valid_target_var": "0.739", "valid_pred_var": "0.699", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11704", "valid_bsz": "25", "valid_num_updates": "5433", "valid_best_loss": "0.222"}
[2024-03-26 18:25:30,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 680 @ 5433 updates
[2024-03-26 18:25:30,133][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:32,630][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:32,691][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 680 @ 5433 updates, score 1.359) (writing took 2.558381007052958 seconds)
[2024-03-26 18:25:32,691][fairseq_cli.train][INFO] - end of epoch 680 (average epoch stats below)
[2024-03-26 18:25:32,692][train][INFO] - {"epoch": 680, "train_loss": "1.328", "train_ntokens": "10769.2", "train_nsentences": "22.875", "train_sample_size": "10769.2", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.501", "train_wps": "8317.1", "train_ups": "0.77", "train_wpb": "10769.2", "train_bsz": "22.9", "train_num_updates": "5433", "train_lr": "0.000509344", "train_gnorm": "1.903", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6951"}
[2024-03-26 18:25:32,694][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:32,756][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 681
[2024-03-26 18:25:32,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:32,761][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:32,766][fairseq.trainer][INFO] - begin training epoch 681
[2024-03-26 18:25:32,766][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:25:40,014][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 681 @ 5441 updates
[2024-03-26 18:25:40,015][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:42,528][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:42,576][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 681 @ 5441 updates, score None) (writing took 2.5619032331742346 seconds)
[2024-03-26 18:25:42,577][fairseq_cli.train][INFO] - end of epoch 681 (average epoch stats below)
[2024-03-26 18:25:42,578][train][INFO] - {"epoch": 681, "train_loss": "1.286", "train_ntokens": "10768.9", "train_nsentences": "22.875", "train_sample_size": "10768.9", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.706", "train_masked_pct": "0.5", "train_wps": "8715.4", "train_ups": "0.81", "train_wpb": "10768.9", "train_bsz": "22.9", "train_num_updates": "5441", "train_lr": "0.000510094", "train_gnorm": "1.875", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6960"}
[2024-03-26 18:25:42,580][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:42,671][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 682
[2024-03-26 18:25:42,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:42,677][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:42,682][fairseq.trainer][INFO] - begin training epoch 682
[2024-03-26 18:25:42,682][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:25:49,994][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 682 @ 5449 updates
[2024-03-26 18:25:49,995][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:52,476][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:25:52,549][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 682 @ 5449 updates, score None) (writing took 2.555894553195685 seconds)
[2024-03-26 18:25:52,550][fairseq_cli.train][INFO] - end of epoch 682 (average epoch stats below)
[2024-03-26 18:25:52,551][train][INFO] - {"epoch": 682, "train_loss": "1.279", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.072", "train_target_var": "0.739", "train_pred_var": "0.705", "train_masked_pct": "0.5", "train_wps": "8639.5", "train_ups": "0.8", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5449", "train_lr": "0.000510844", "train_gnorm": "1.89", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6970"}
[2024-03-26 18:25:52,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:25:52,614][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 683
[2024-03-26 18:25:52,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:25:52,619][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:25:52,623][fairseq.trainer][INFO] - begin training epoch 683
[2024-03-26 18:25:52,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:00,094][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 683 @ 5457 updates
[2024-03-26 18:26:00,095][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:02,563][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:02,636][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 683 @ 5457 updates, score None) (writing took 2.5419841669499874 seconds)
[2024-03-26 18:26:02,636][fairseq_cli.train][INFO] - end of epoch 683 (average epoch stats below)
[2024-03-26 18:26:02,637][train][INFO] - {"epoch": 683, "train_loss": "1.231", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.708", "train_masked_pct": "0.499", "train_wps": "8541.6", "train_ups": "0.79", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "5457", "train_lr": "0.000511594", "train_gnorm": "1.87", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "6980"}
[2024-03-26 18:26:02,639][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:02,703][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 684
[2024-03-26 18:26:02,704][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:02,707][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:02,712][fairseq.trainer][INFO] - begin training epoch 684
[2024-03-26 18:26:02,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:09,747][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 684 @ 5465 updates
[2024-03-26 18:26:09,748][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:12,261][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:12,330][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 684 @ 5465 updates, score None) (writing took 2.5835048127919436 seconds)
[2024-03-26 18:26:12,331][fairseq_cli.train][INFO] - end of epoch 684 (average epoch stats below)
[2024-03-26 18:26:12,332][train][INFO] - {"epoch": 684, "train_loss": "1.274", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.707", "train_masked_pct": "0.501", "train_wps": "8887.3", "train_ups": "0.83", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5465", "train_lr": "0.000512344", "train_gnorm": "1.667", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "6990"}
[2024-03-26 18:26:12,334][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:12,396][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 685
[2024-03-26 18:26:12,398][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:12,401][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:12,406][fairseq.trainer][INFO] - begin training epoch 685
[2024-03-26 18:26:12,406][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:19,779][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:26:19,780][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:19,844][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 138
[2024-03-26 18:26:19,847][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:20,273][valid][INFO] - {"epoch": 685, "valid_loss": "1.29", "valid_ntokens": "11720", "valid_nsentences": "25", "valid_sample_size": "11720", "valid_ema_decay": "999.072", "valid_target_var": "0.735", "valid_pred_var": "0.697", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11720", "valid_bsz": "25", "valid_num_updates": "5473", "valid_best_loss": "0.222"}
[2024-03-26 18:26:20,274][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 685 @ 5473 updates
[2024-03-26 18:26:20,276][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:22,805][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:22,844][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 685 @ 5473 updates, score 1.29) (writing took 2.5690668718889356 seconds)
[2024-03-26 18:26:22,844][fairseq_cli.train][INFO] - end of epoch 685 (average epoch stats below)
[2024-03-26 18:26:22,845][train][INFO] - {"epoch": 685, "train_loss": "1.342", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.703", "train_masked_pct": "0.5", "train_wps": "8195.1", "train_ups": "0.76", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "5473", "train_lr": "0.000513094", "train_gnorm": "2.059", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7001"}
[2024-03-26 18:26:22,847][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:22,937][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 686
[2024-03-26 18:26:22,938][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:22,941][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:22,946][fairseq.trainer][INFO] - begin training epoch 686
[2024-03-26 18:26:22,947][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:30,189][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 686 @ 5481 updates
[2024-03-26 18:26:30,191][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:32,689][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:32,747][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 686 @ 5481 updates, score None) (writing took 2.5574070760048926 seconds)
[2024-03-26 18:26:32,748][fairseq_cli.train][INFO] - end of epoch 686 (average epoch stats below)
[2024-03-26 18:26:32,748][train][INFO] - {"epoch": 686, "train_loss": "1.285", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.072", "train_target_var": "0.739", "train_pred_var": "0.708", "train_masked_pct": "0.501", "train_wps": "8700.5", "train_ups": "0.81", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "5481", "train_lr": "0.000513844", "train_gnorm": "1.833", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7011"}
[2024-03-26 18:26:32,750][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:32,828][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 687
[2024-03-26 18:26:32,830][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:32,833][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:32,838][fairseq.trainer][INFO] - begin training epoch 687
[2024-03-26 18:26:32,838][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:40,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 687 @ 5489 updates
[2024-03-26 18:26:40,277][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:42,758][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:42,815][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 687 @ 5489 updates, score None) (writing took 2.540431289933622 seconds)
[2024-03-26 18:26:42,816][fairseq_cli.train][INFO] - end of epoch 687 (average epoch stats below)
[2024-03-26 18:26:42,816][train][INFO] - {"epoch": 687, "train_loss": "1.188", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.072", "train_target_var": "0.74", "train_pred_var": "0.706", "train_masked_pct": "0.499", "train_wps": "8556.9", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "5489", "train_lr": "0.000514594", "train_gnorm": "1.614", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7021"}
[2024-03-26 18:26:42,819][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:42,897][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 688
[2024-03-26 18:26:42,899][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:42,902][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:42,907][fairseq.trainer][INFO] - begin training epoch 688
[2024-03-26 18:26:42,907][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:26:50,253][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 688 @ 5497 updates
[2024-03-26 18:26:50,254][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:52,751][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:26:52,795][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 688 @ 5497 updates, score None) (writing took 2.541834100149572 seconds)
[2024-03-26 18:26:52,795][fairseq_cli.train][INFO] - end of epoch 688 (average epoch stats below)
[2024-03-26 18:26:52,796][train][INFO] - {"epoch": 688, "train_loss": "1.276", "train_ntokens": "10768.5", "train_nsentences": "22.875", "train_sample_size": "10768.5", "train_ema_decay": "999.073", "train_target_var": "0.742", "train_pred_var": "0.71", "train_masked_pct": "0.499", "train_wps": "8632.9", "train_ups": "0.8", "train_wpb": "10768.5", "train_bsz": "22.9", "train_num_updates": "5497", "train_lr": "0.000515344", "train_gnorm": "1.759", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.3", "train_wall": "7031"}
[2024-03-26 18:26:52,798][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:26:52,889][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 689
[2024-03-26 18:26:52,891][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:26:52,894][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:26:52,899][fairseq.trainer][INFO] - begin training epoch 689
[2024-03-26 18:26:52,899][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:00,169][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 689 @ 5505 updates
[2024-03-26 18:27:00,171][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:02,659][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:02,718][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 689 @ 5505 updates, score None) (writing took 2.5486356411129236 seconds)
[2024-03-26 18:27:02,719][fairseq_cli.train][INFO] - end of epoch 689 (average epoch stats below)
[2024-03-26 18:27:02,720][train][INFO] - {"epoch": 689, "train_loss": "1.26", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.073", "train_target_var": "0.741", "train_pred_var": "0.707", "train_masked_pct": "0.5", "train_wps": "8682.6", "train_ups": "0.81", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "5505", "train_lr": "0.000516094", "train_gnorm": "1.621", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7041"}
[2024-03-26 18:27:02,722][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:02,800][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 690
[2024-03-26 18:27:02,801][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:02,804][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:02,809][fairseq.trainer][INFO] - begin training epoch 690
[2024-03-26 18:27:02,810][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:10,226][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:27:10,227][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:10,290][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 139
[2024-03-26 18:27:10,293][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:10,697][valid][INFO] - {"epoch": 690, "valid_loss": "1.335", "valid_ntokens": "11713", "valid_nsentences": "25", "valid_sample_size": "11713", "valid_ema_decay": "999.073", "valid_target_var": "0.738", "valid_pred_var": "0.695", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11713", "valid_bsz": "25", "valid_num_updates": "5513", "valid_best_loss": "0.222"}
[2024-03-26 18:27:10,698][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 690 @ 5513 updates
[2024-03-26 18:27:10,700][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:13,242][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:13,313][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 690 @ 5513 updates, score 1.335) (writing took 2.6145152538083494 seconds)
[2024-03-26 18:27:13,314][fairseq_cli.train][INFO] - end of epoch 690 (average epoch stats below)
[2024-03-26 18:27:13,314][train][INFO] - {"epoch": 690, "train_loss": "1.215", "train_ntokens": "10770", "train_nsentences": "22.875", "train_sample_size": "10770", "train_ema_decay": "999.073", "train_target_var": "0.739", "train_pred_var": "0.707", "train_masked_pct": "0.501", "train_wps": "8133", "train_ups": "0.76", "train_wpb": "10770", "train_bsz": "22.9", "train_num_updates": "5513", "train_lr": "0.000516844", "train_gnorm": "1.477", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "7051"}
[2024-03-26 18:27:13,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:13,379][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 691
[2024-03-26 18:27:13,380][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:13,384][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:13,388][fairseq.trainer][INFO] - begin training epoch 691
[2024-03-26 18:27:13,389][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:20,762][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 691 @ 5521 updates
[2024-03-26 18:27:20,763][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:23,275][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:23,349][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 691 @ 5521 updates, score None) (writing took 2.5868875388987362 seconds)
[2024-03-26 18:27:23,349][fairseq_cli.train][INFO] - end of epoch 691 (average epoch stats below)
[2024-03-26 18:27:23,350][train][INFO] - {"epoch": 691, "train_loss": "1.217", "train_ntokens": "10769.1", "train_nsentences": "22.875", "train_sample_size": "10769.1", "train_ema_decay": "999.073", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.498", "train_wps": "8585.5", "train_ups": "0.8", "train_wpb": "10769.1", "train_bsz": "22.9", "train_num_updates": "5521", "train_lr": "0.000517594", "train_gnorm": "1.511", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6", "train_wall": "7061"}
[2024-03-26 18:27:23,352][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:23,415][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 692
[2024-03-26 18:27:23,416][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:23,420][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:23,424][fairseq.trainer][INFO] - begin training epoch 692
[2024-03-26 18:27:23,425][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:30,887][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 692 @ 5529 updates
[2024-03-26 18:27:30,888][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:33,408][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:33,482][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 692 @ 5529 updates, score None) (writing took 2.5955700129270554 seconds)
[2024-03-26 18:27:33,483][fairseq_cli.train][INFO] - end of epoch 692 (average epoch stats below)
[2024-03-26 18:27:33,483][train][INFO] - {"epoch": 692, "train_loss": "1.276", "train_ntokens": "10767.8", "train_nsentences": "22.875", "train_sample_size": "10767.8", "train_ema_decay": "999.073", "train_target_var": "0.739", "train_pred_var": "0.707", "train_masked_pct": "0.499", "train_wps": "8501.2", "train_ups": "0.79", "train_wpb": "10767.8", "train_bsz": "22.9", "train_num_updates": "5529", "train_lr": "0.000518344", "train_gnorm": "1.895", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7071"}
[2024-03-26 18:27:33,485][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:33,548][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 693
[2024-03-26 18:27:33,550][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:33,553][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:33,558][fairseq.trainer][INFO] - begin training epoch 693
[2024-03-26 18:27:33,558][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:40,996][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 693 @ 5537 updates
[2024-03-26 18:27:40,997][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:43,496][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:43,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 693 @ 5537 updates, score None) (writing took 2.5728118382394314 seconds)
[2024-03-26 18:27:43,569][fairseq_cli.train][INFO] - end of epoch 693 (average epoch stats below)
[2024-03-26 18:27:43,570][train][INFO] - {"epoch": 693, "train_loss": "1.307", "train_ntokens": "10768.2", "train_nsentences": "22.875", "train_sample_size": "10768.2", "train_ema_decay": "999.073", "train_target_var": "0.74", "train_pred_var": "0.707", "train_masked_pct": "0.499", "train_wps": "8541.4", "train_ups": "0.79", "train_wpb": "10768.2", "train_bsz": "22.9", "train_num_updates": "5537", "train_lr": "0.000519094", "train_gnorm": "1.937", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7081"}
[2024-03-26 18:27:43,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:43,634][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 694
[2024-03-26 18:27:43,636][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:43,639][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:43,644][fairseq.trainer][INFO] - begin training epoch 694
[2024-03-26 18:27:43,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:27:51,147][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 694 @ 5545 updates
[2024-03-26 18:27:51,148][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:53,634][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:27:53,707][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 694 @ 5545 updates, score None) (writing took 2.5601139552891254 seconds)
[2024-03-26 18:27:53,707][fairseq_cli.train][INFO] - end of epoch 694 (average epoch stats below)
[2024-03-26 18:27:53,708][train][INFO] - {"epoch": 694, "train_loss": "1.263", "train_ntokens": "10769.4", "train_nsentences": "22.875", "train_sample_size": "10769.4", "train_ema_decay": "999.073", "train_target_var": "0.74", "train_pred_var": "0.708", "train_masked_pct": "0.499", "train_wps": "8498.8", "train_ups": "0.79", "train_wpb": "10769.4", "train_bsz": "22.9", "train_num_updates": "5545", "train_lr": "0.000519844", "train_gnorm": "2.65", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "7092"}
[2024-03-26 18:27:53,710][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:27:53,773][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 695
[2024-03-26 18:27:53,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:27:53,777][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:27:53,782][fairseq.trainer][INFO] - begin training epoch 695
[2024-03-26 18:27:53,783][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:01,108][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:28:01,110][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:01,172][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 140
[2024-03-26 18:28:01,175][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:01,597][valid][INFO] - {"epoch": 695, "valid_loss": "1.293", "valid_ntokens": "11705", "valid_nsentences": "25", "valid_sample_size": "11705", "valid_ema_decay": "999.073", "valid_target_var": "0.74", "valid_pred_var": "0.697", "valid_masked_pct": "0.496", "valid_wps": "0", "valid_wpb": "11705", "valid_bsz": "25", "valid_num_updates": "5553", "valid_best_loss": "0.222"}
[2024-03-26 18:28:01,599][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 695 @ 5553 updates
[2024-03-26 18:28:01,600][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:04,190][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:04,245][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 695 @ 5553 updates, score 1.293) (writing took 2.6460933010093868 seconds)
[2024-03-26 18:28:04,246][fairseq_cli.train][INFO] - end of epoch 695 (average epoch stats below)
[2024-03-26 18:28:04,247][train][INFO] - {"epoch": 695, "train_loss": "1.314", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.073", "train_target_var": "0.738", "train_pred_var": "0.702", "train_masked_pct": "0.499", "train_wps": "8175.7", "train_ups": "0.76", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5553", "train_lr": "0.000520594", "train_gnorm": "1.913", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "7102"}
[2024-03-26 18:28:04,249][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:04,332][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 696
[2024-03-26 18:28:04,333][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:04,336][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:04,341][fairseq.trainer][INFO] - begin training epoch 696
[2024-03-26 18:28:04,342][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:11,618][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 696 @ 5561 updates
[2024-03-26 18:28:11,620][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:14,108][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:14,153][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 696 @ 5561 updates, score None) (writing took 2.5342145450413227 seconds)
[2024-03-26 18:28:14,153][fairseq_cli.train][INFO] - end of epoch 696 (average epoch stats below)
[2024-03-26 18:28:14,154][train][INFO] - {"epoch": 696, "train_loss": "1.333", "train_ntokens": "10768.6", "train_nsentences": "22.875", "train_sample_size": "10768.6", "train_ema_decay": "999.073", "train_target_var": "0.741", "train_pred_var": "0.707", "train_masked_pct": "0.501", "train_wps": "8696.2", "train_ups": "0.81", "train_wpb": "10768.6", "train_bsz": "22.9", "train_num_updates": "5561", "train_lr": "0.000521344", "train_gnorm": "2.109", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.8", "train_wall": "7112"}
[2024-03-26 18:28:14,156][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:14,249][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 697
[2024-03-26 18:28:14,250][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:14,254][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:14,259][fairseq.trainer][INFO] - begin training epoch 697
[2024-03-26 18:28:14,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:21,734][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 697 @ 5569 updates
[2024-03-26 18:28:21,736][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:24,222][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:24,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 697 @ 5569 updates, score None) (writing took 2.5598267819732428 seconds)
[2024-03-26 18:28:24,294][fairseq_cli.train][INFO] - end of epoch 697 (average epoch stats below)
[2024-03-26 18:28:24,295][train][INFO] - {"epoch": 697, "train_loss": "1.291", "train_ntokens": "10769.5", "train_nsentences": "22.875", "train_sample_size": "10769.5", "train_ema_decay": "999.073", "train_target_var": "0.74", "train_pred_var": "0.707", "train_masked_pct": "0.5", "train_wps": "8496.2", "train_ups": "0.79", "train_wpb": "10769.5", "train_bsz": "22.9", "train_num_updates": "5569", "train_lr": "0.000522094", "train_gnorm": "1.85", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.1", "train_wall": "7122"}
[2024-03-26 18:28:24,298][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:24,359][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 698
[2024-03-26 18:28:24,361][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:24,364][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:24,369][fairseq.trainer][INFO] - begin training epoch 698
[2024-03-26 18:28:24,369][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:31,720][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 698 @ 5577 updates
[2024-03-26 18:28:31,722][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:34,202][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:34,272][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 698 @ 5577 updates, score None) (writing took 2.551594375167042 seconds)
[2024-03-26 18:28:34,272][fairseq_cli.train][INFO] - end of epoch 698 (average epoch stats below)
[2024-03-26 18:28:34,273][train][INFO] - {"epoch": 698, "train_loss": "1.334", "train_ntokens": "10769.8", "train_nsentences": "22.875", "train_sample_size": "10769.8", "train_ema_decay": "999.074", "train_target_var": "0.738", "train_pred_var": "0.704", "train_masked_pct": "0.499", "train_wps": "8635.7", "train_ups": "0.8", "train_wpb": "10769.8", "train_bsz": "22.9", "train_num_updates": "5577", "train_lr": "0.000522844", "train_gnorm": "1.783", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.4", "train_wall": "7132"}
[2024-03-26 18:28:34,275][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:34,335][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 699
[2024-03-26 18:28:34,336][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:34,340][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:34,344][fairseq.trainer][INFO] - begin training epoch 699
[2024-03-26 18:28:34,345][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:41,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 699 @ 5585 updates
[2024-03-26 18:28:41,659][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:44,133][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:44,204][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 699 @ 5585 updates, score None) (writing took 2.5472454144619405 seconds)
[2024-03-26 18:28:44,205][fairseq_cli.train][INFO] - end of epoch 699 (average epoch stats below)
[2024-03-26 18:28:44,206][train][INFO] - {"epoch": 699, "train_loss": "1.332", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.074", "train_target_var": "0.739", "train_pred_var": "0.702", "train_masked_pct": "0.501", "train_wps": "8674.7", "train_ups": "0.81", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "5585", "train_lr": "0.000523594", "train_gnorm": "1.886", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "7142"}
[2024-03-26 18:28:44,208][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:44,269][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 700
[2024-03-26 18:28:44,271][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:44,274][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:44,279][fairseq.trainer][INFO] - begin training epoch 700
[2024-03-26 18:28:44,279][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:28:51,538][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-26 18:28:51,539][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:51,603][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 141
[2024-03-26 18:28:51,606][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:52,016][valid][INFO] - {"epoch": 700, "valid_loss": "1.524", "valid_ntokens": "11718", "valid_nsentences": "25", "valid_sample_size": "11718", "valid_ema_decay": "999.074", "valid_target_var": "0.735", "valid_pred_var": "0.691", "valid_masked_pct": "0.504", "valid_wps": "0", "valid_wpb": "11718", "valid_bsz": "25", "valid_num_updates": "5593", "valid_best_loss": "0.222"}
[2024-03-26 18:28:52,018][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 700 @ 5593 updates
[2024-03-26 18:28:52,019][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:54,556][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:28:54,628][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 700 @ 5593 updates, score 1.524) (writing took 2.61060210224241 seconds)
[2024-03-26 18:28:54,629][fairseq_cli.train][INFO] - end of epoch 700 (average epoch stats below)
[2024-03-26 18:28:54,630][train][INFO] - {"epoch": 700, "train_loss": "1.31", "train_ntokens": "10770.1", "train_nsentences": "22.875", "train_sample_size": "10770.1", "train_ema_decay": "999.074", "train_target_var": "0.74", "train_pred_var": "0.705", "train_masked_pct": "0.501", "train_wps": "8266.2", "train_ups": "0.77", "train_wpb": "10770.1", "train_bsz": "22.9", "train_num_updates": "5593", "train_lr": "0.000524344", "train_gnorm": "1.943", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "7152"}
[2024-03-26 18:28:54,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:28:54,695][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 701
[2024-03-26 18:28:54,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:28:54,700][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:28:54,704][fairseq.trainer][INFO] - begin training epoch 701
[2024-03-26 18:28:54,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:29:01,804][train_inner][INFO] - {"epoch": 701, "update": 700.875, "loss": "1.292", "ntokens": "10823.5", "nsentences": "22.99", "sample_size": "10823.5", "ema_decay": "999.073", "target_var": "0.74", "pred_var": "0.706", "masked_pct": "0.5", "wps": "8565.4", "ups": "0.79", "wpb": "10823.5", "bsz": "23", "num_updates": "5600", "lr": "0.000525", "gnorm": "1.918", "loss_scale": "1", "train_wall": "178", "gb_free": "5.8", "wall": "7160"}
[2024-03-26 18:29:01,957][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 701 @ 5601 updates
[2024-03-26 18:29:01,958][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:04,456][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:04,529][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 701 @ 5601 updates, score None) (writing took 2.5715316911228 seconds)
[2024-03-26 18:29:04,529][fairseq_cli.train][INFO] - end of epoch 701 (average epoch stats below)
[2024-03-26 18:29:04,530][train][INFO] - {"epoch": 701, "train_loss": "1.331", "train_ntokens": "10769.9", "train_nsentences": "22.875", "train_sample_size": "10769.9", "train_ema_decay": "999.074", "train_target_var": "0.738", "train_pred_var": "0.704", "train_masked_pct": "0.501", "train_wps": "8703.3", "train_ups": "0.81", "train_wpb": "10769.9", "train_bsz": "22.9", "train_num_updates": "5601", "train_lr": "0.000525094", "train_gnorm": "1.799", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "7162"}
[2024-03-26 18:29:04,533][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:29:04,596][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 702
[2024-03-26 18:29:04,598][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:29:04,601][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:29:04,606][fairseq.trainer][INFO] - begin training epoch 702
[2024-03-26 18:29:04,607][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:29:12,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 702 @ 5609 updates
[2024-03-26 18:29:12,040][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:14,526][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:14,598][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 702 @ 5609 updates, score None) (writing took 2.559938811697066 seconds)
[2024-03-26 18:29:14,599][fairseq_cli.train][INFO] - end of epoch 702 (average epoch stats below)
[2024-03-26 18:29:14,599][train][INFO] - {"epoch": 702, "train_loss": "1.291", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.074", "train_target_var": "0.741", "train_pred_var": "0.707", "train_masked_pct": "0.499", "train_wps": "8556.8", "train_ups": "0.79", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5609", "train_lr": "0.000525844", "train_gnorm": "1.769", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "5.2", "train_wall": "7172"}
[2024-03-26 18:29:14,601][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:29:14,665][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 703
[2024-03-26 18:29:14,667][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:29:14,670][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:29:14,675][fairseq.trainer][INFO] - begin training epoch 703
[2024-03-26 18:29:14,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:29:22,014][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 703 @ 5617 updates
[2024-03-26 18:29:22,015][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:24,659][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:24,731][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 703 @ 5617 updates, score None) (writing took 2.7177630439400673 seconds)
[2024-03-26 18:29:24,732][fairseq_cli.train][INFO] - end of epoch 703 (average epoch stats below)
[2024-03-26 18:29:24,732][train][INFO] - {"epoch": 703, "train_loss": "1.359", "train_ntokens": "10769.6", "train_nsentences": "22.875", "train_sample_size": "10769.6", "train_ema_decay": "999.074", "train_target_var": "0.737", "train_pred_var": "0.7", "train_masked_pct": "0.501", "train_wps": "8503.1", "train_ups": "0.79", "train_wpb": "10769.6", "train_bsz": "22.9", "train_num_updates": "5617", "train_lr": "0.000526594", "train_gnorm": "1.859", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "11.9", "train_wall": "7183"}
[2024-03-26 18:29:24,734][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:29:24,796][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 704
[2024-03-26 18:29:24,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:29:24,801][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:29:24,806][fairseq.trainer][INFO] - begin training epoch 704
[2024-03-26 18:29:24,806][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-26 18:29:32,079][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 704 @ 5625 updates
[2024-03-26 18:29:32,081][fairseq.trainer][INFO] - Saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:34,578][fairseq.trainer][INFO] - Finished saving checkpoint to /h/addisonw/fairseq/checkpoints/checkpoint_last.pt
[2024-03-26 18:29:34,623][fairseq.checkpoint_utils][INFO] - Saved checkpoint /h/addisonw/fairseq/checkpoints/checkpoint_last.pt (epoch 704 @ 5625 updates, score None) (writing took 2.543840607162565 seconds)
[2024-03-26 18:29:34,624][fairseq_cli.train][INFO] - end of epoch 704 (average epoch stats below)
[2024-03-26 18:29:34,624][train][INFO] - {"epoch": 704, "train_loss": "1.321", "train_ntokens": "10769", "train_nsentences": "22.875", "train_sample_size": "10769", "train_ema_decay": "999.074", "train_target_var": "0.74", "train_pred_var": "0.704", "train_masked_pct": "0.499", "train_wps": "8709.9", "train_ups": "0.81", "train_wpb": "10769", "train_bsz": "22.9", "train_num_updates": "5625", "train_lr": "0.000527344", "train_gnorm": "2.62", "train_loss_scale": "1", "train_train_wall": "7", "train_gb_free": "6.1", "train_wall": "7192"}
[2024-03-26 18:29:34,626][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-26 18:29:34,710][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 705
[2024-03-26 18:29:34,712][fairseq.data.iterators][INFO] - grouped total_num_itrs = 8
[2024-03-26 18:29:34,715][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard
[2024-03-26 18:29:34,719][fairseq.trainer][INFO] - begin training epoch 705
[2024-03-26 18:29:34,720][fairseq_cli.train][INFO] - Start iterating over samples
slurmstepd: error: *** JOB 12202314 ON gpu067 CANCELLED AT 2024-03-26T18:29:40 DUE TO TIME LIMIT ***
